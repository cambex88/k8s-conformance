I0511 00:25:40.000245      16 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-594220555
I0511 00:25:40.000409      16 e2e.go:224] Starting e2e run "4dcc6f86-7383-11e9-9c46-760f9b3dbd5d" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1557534339 - Will randomize all specs
Will run 201 of 1946 specs

May 11 00:25:40.133: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:25:40.136: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 11 00:25:40.145: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 11 00:25:40.173: INFO: The status of Pod stork-scheduler-75b8f4d565-fwzgd is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 11 00:25:40.173: INFO: 27 / 28 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 11 00:25:40.173: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
May 11 00:25:40.173: INFO: POD                               NODE                                      PHASE    GRACE  CONDITIONS
May 11 00:25:40.173: INFO: stork-scheduler-75b8f4d565-fwzgd  craig-k8s-certification-1-stellar-hand-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:25:29 +0000 UTC ContainersNotReady containers with unready status: [stork-scheduler]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:25:29 +0000 UTC ContainersNotReady containers with unready status: [stork-scheduler]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:13:51 +0000 UTC  }]
May 11 00:25:40.173: INFO: 
May 11 00:25:42.188: INFO: 28 / 28 pods in namespace 'kube-system' are running and ready (2 seconds elapsed)
May 11 00:25:42.188: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
May 11 00:25:42.188: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 11 00:25:42.195: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
May 11 00:25:42.195: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 11 00:25:42.195: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'portworx' (0 seconds elapsed)
May 11 00:25:42.195: INFO: e2e test version: v1.13.0
May 11 00:25:42.196: INFO: kube-apiserver version: v1.13.2
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:25:42.196: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename statefulset
May 11 00:25:58.839: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-grnk4
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-grnk4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-grnk4
May 11 00:25:58.855: INFO: Found 0 stateful pods, waiting for 1
May 11 00:26:08.868: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 11 00:26:08.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-grnk4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 00:26:09.130: INFO: stderr: ""
May 11 00:26:09.130: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 00:26:09.130: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 00:26:09.132: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 11 00:26:19.135: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 11 00:26:19.135: INFO: Waiting for statefulset status.replicas updated to 0
May 11 00:26:19.146: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999628s
May 11 00:26:20.148: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996450976s
May 11 00:26:21.152: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993715156s
May 11 00:26:22.154: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990664355s
May 11 00:26:23.158: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987959579s
May 11 00:26:24.161: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.98442759s
May 11 00:26:25.165: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.98075867s
May 11 00:26:26.168: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.977004683s
May 11 00:26:27.172: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.974037302s
May 11 00:26:28.176: INFO: Verifying statefulset ss doesn't scale past 1 for another 970.266598ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-grnk4
May 11 00:26:29.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-grnk4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 00:26:29.477: INFO: stderr: ""
May 11 00:26:29.477: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 00:26:29.477: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 00:26:29.479: INFO: Found 1 stateful pods, waiting for 3
May 11 00:26:39.484: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 11 00:26:39.484: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 11 00:26:39.484: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 11 00:26:39.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-grnk4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 00:26:39.785: INFO: stderr: ""
May 11 00:26:39.785: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 00:26:39.785: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 00:26:39.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-grnk4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 00:26:40.116: INFO: stderr: ""
May 11 00:26:40.116: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 00:26:40.116: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 00:26:40.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-grnk4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 00:26:40.423: INFO: stderr: ""
May 11 00:26:40.423: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 00:26:40.423: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 00:26:40.423: INFO: Waiting for statefulset status.replicas updated to 0
May 11 00:26:40.425: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 11 00:26:50.431: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 11 00:26:50.431: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 11 00:26:50.431: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 11 00:26:50.438: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999553s
May 11 00:26:51.442: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996372868s
May 11 00:26:52.446: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99311185s
May 11 00:26:53.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989045085s
May 11 00:26:54.452: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98596127s
May 11 00:26:55.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983059513s
May 11 00:26:56.457: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9802935s
May 11 00:26:57.463: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.977382201s
May 11 00:26:58.466: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971557161s
May 11 00:26:59.470: INFO: Verifying statefulset ss doesn't scale past 3 for another 968.336132ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-grnk4
May 11 00:27:00.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-grnk4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 00:27:00.822: INFO: stderr: ""
May 11 00:27:00.822: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 00:27:00.822: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 00:27:00.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-grnk4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 00:27:01.135: INFO: stderr: ""
May 11 00:27:01.135: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 00:27:01.135: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 00:27:01.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-grnk4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 00:27:01.482: INFO: stderr: ""
May 11 00:27:01.482: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 00:27:01.482: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 00:27:01.482: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 11 00:27:21.526: INFO: Deleting all statefulset in ns e2e-tests-statefulset-grnk4
May 11 00:27:21.528: INFO: Scaling statefulset ss to 0
May 11 00:27:21.534: INFO: Waiting for statefulset status.replicas updated to 0
May 11 00:27:21.536: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:27:21.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-grnk4" for this suite.
May 11 00:27:27.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:27:27.692: INFO: namespace: e2e-tests-statefulset-grnk4, resource: bindings, ignored listing per whitelist
May 11 00:27:27.711: INFO: namespace e2e-tests-statefulset-grnk4 deletion completed in 6.111869213s

• [SLOW TEST:105.515 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:27:27.711: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:27:36.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-s92lr" for this suite.
May 11 00:27:42.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:27:42.557: INFO: namespace: e2e-tests-kubelet-test-s92lr, resource: bindings, ignored listing per whitelist
May 11 00:27:42.608: INFO: namespace e2e-tests-kubelet-test-s92lr deletion completed in 6.083168937s

• [SLOW TEST:14.898 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:27:42.608: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-97bd5f50-7383-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 00:27:43.524: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-97bdbf50-7383-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-hcn8v" to be "success or failure"
May 11 00:27:43.526: INFO: Pod "pod-projected-configmaps-97bdbf50-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.808103ms
May 11 00:27:45.529: INFO: Pod "pod-projected-configmaps-97bdbf50-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004629907s
May 11 00:27:47.535: INFO: Pod "pod-projected-configmaps-97bdbf50-7383-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010916725s
STEP: Saw pod success
May 11 00:27:47.535: INFO: Pod "pod-projected-configmaps-97bdbf50-7383-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:27:47.537: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-projected-configmaps-97bdbf50-7383-11e9-9c46-760f9b3dbd5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 11 00:27:47.549: INFO: Waiting for pod pod-projected-configmaps-97bdbf50-7383-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:27:47.552: INFO: Pod pod-projected-configmaps-97bdbf50-7383-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:27:47.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hcn8v" for this suite.
May 11 00:27:54.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:27:54.441: INFO: namespace: e2e-tests-projected-hcn8v, resource: bindings, ignored listing per whitelist
May 11 00:27:54.454: INFO: namespace e2e-tests-projected-hcn8v deletion completed in 6.897326772s

• [SLOW TEST:11.846 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:27:54.455: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:27:54.574: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
May 11 00:27:54.580: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cz4fk/daemonsets","resourceVersion":"3972"},"items":null}

May 11 00:27:54.583: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cz4fk/pods","resourceVersion":"3972"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:27:54.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cz4fk" for this suite.
May 11 00:28:00.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:28:00.683: INFO: namespace: e2e-tests-daemonsets-cz4fk, resource: bindings, ignored listing per whitelist
May 11 00:28:00.728: INFO: namespace e2e-tests-daemonsets-cz4fk deletion completed in 6.111382581s

S [SKIPPING] [6.273 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  May 11 00:27:54.574: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:28:00.728: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:28:00.780: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a206459a-7383-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-z7xf5" to be "success or failure"
May 11 00:28:00.783: INFO: Pod "downwardapi-volume-a206459a-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.115007ms
May 11 00:28:02.786: INFO: Pod "downwardapi-volume-a206459a-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005662852s
May 11 00:28:04.933: INFO: Pod "downwardapi-volume-a206459a-7383-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.152823255s
STEP: Saw pod success
May 11 00:28:04.933: INFO: Pod "downwardapi-volume-a206459a-7383-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:28:05.017: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-a206459a-7383-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:28:05.254: INFO: Waiting for pod downwardapi-volume-a206459a-7383-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:28:05.607: INFO: Pod downwardapi-volume-a206459a-7383-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:28:05.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z7xf5" for this suite.
May 11 00:28:12.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:28:12.083: INFO: namespace: e2e-tests-projected-z7xf5, resource: bindings, ignored listing per whitelist
May 11 00:28:12.115: INFO: namespace e2e-tests-projected-z7xf5 deletion completed in 6.505642261s

• [SLOW TEST:11.387 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:28:12.115: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:28:12.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 version'
May 11 00:28:12.247: INFO: stderr: ""
May 11 00:28:12.247: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.2\", GitCommit:\"cff46ab41ff0bb44d8584413b598ad8360ec1def\", GitTreeState:\"clean\", BuildDate:\"2019-01-10T23:28:14Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:28:12.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8pm62" for this suite.
May 11 00:28:18.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:28:18.273: INFO: namespace: e2e-tests-kubectl-8pm62, resource: bindings, ignored listing per whitelist
May 11 00:28:18.315: INFO: namespace e2e-tests-kubectl-8pm62 deletion completed in 6.065025904s

• [SLOW TEST:6.200 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:28:18.316: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 11 00:28:18.358: INFO: Waiting up to 5m0s for pod "pod-ac80ef6c-7383-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-s4crx" to be "success or failure"
May 11 00:28:18.361: INFO: Pod "pod-ac80ef6c-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.032479ms
May 11 00:28:20.363: INFO: Pod "pod-ac80ef6c-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005491561s
May 11 00:28:22.366: INFO: Pod "pod-ac80ef6c-7383-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008198929s
STEP: Saw pod success
May 11 00:28:22.366: INFO: Pod "pod-ac80ef6c-7383-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:28:22.368: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-ac80ef6c-7383-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 00:28:22.379: INFO: Waiting for pod pod-ac80ef6c-7383-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:28:22.382: INFO: Pod pod-ac80ef6c-7383-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:28:22.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s4crx" for this suite.
May 11 00:28:28.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:28:28.405: INFO: namespace: e2e-tests-emptydir-s4crx, resource: bindings, ignored listing per whitelist
May 11 00:28:28.454: INFO: namespace e2e-tests-emptydir-s4crx deletion completed in 6.070193649s

• [SLOW TEST:10.139 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:28:28.454: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:28:28.498: INFO: Creating deployment "test-recreate-deployment"
May 11 00:28:28.501: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 11 00:28:28.505: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
May 11 00:28:30.511: INFO: Waiting deployment "test-recreate-deployment" to complete
May 11 00:28:30.513: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693131307, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693131307, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693131307, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693131307, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 11 00:28:32.516: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 11 00:28:32.521: INFO: Updating deployment test-recreate-deployment
May 11 00:28:32.521: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 11 00:28:32.570: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-fdgmg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fdgmg/deployments/test-recreate-deployment,UID:b2178fe1-7383-11e9-9f3c-000c29c278ce,ResourceVersion:4208,Generation:2,CreationTimestamp:2019-05-11 00:28:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-11 00:28:31 +0000 UTC 2019-05-11 00:28:31 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-11 00:28:31 +0000 UTC 2019-05-11 00:28:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 11 00:28:32.573: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-fdgmg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fdgmg/replicasets/test-recreate-deployment-697fbf54bf,UID:b47fb599-7383-11e9-9f3c-000c29c278ce,ResourceVersion:4207,Generation:1,CreationTimestamp:2019-05-11 00:28:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b2178fe1-7383-11e9-9f3c-000c29c278ce 0xc001906177 0xc001906178}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 11 00:28:32.573: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 11 00:28:32.573: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-fdgmg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fdgmg/replicasets/test-recreate-deployment-5dfdcc846d,UID:b2185917-7383-11e9-9f3c-000c29c278ce,ResourceVersion:4196,Generation:2,CreationTimestamp:2019-05-11 00:28:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b2178fe1-7383-11e9-9f3c-000c29c278ce 0xc0019060c7 0xc0019060c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 11 00:28:32.575: INFO: Pod "test-recreate-deployment-697fbf54bf-gffsz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-gffsz,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-fdgmg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fdgmg/pods/test-recreate-deployment-697fbf54bf-gffsz,UID:b4804419-7383-11e9-9f3c-000c29c278ce,ResourceVersion:4209,Generation:0,CreationTimestamp:2019-05-11 00:28:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf b47fb599-7383-11e9-9f3c-000c29c278ce 0xc0019069c7 0xc0019069c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gmz7p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gmz7p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gmz7p true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001906a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001906a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:28:31 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 00:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:28:32.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fdgmg" for this suite.
May 11 00:28:38.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:28:38.640: INFO: namespace: e2e-tests-deployment-fdgmg, resource: bindings, ignored listing per whitelist
May 11 00:28:38.642: INFO: namespace e2e-tests-deployment-fdgmg deletion completed in 6.065001457s

• [SLOW TEST:10.188 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:28:38.642: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b89fa125-7383-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 00:28:38.693: INFO: Waiting up to 5m0s for pod "pod-secrets-b89fe6ea-7383-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-6mk7v" to be "success or failure"
May 11 00:28:38.695: INFO: Pod "pod-secrets-b89fe6ea-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.24922ms
May 11 00:28:40.698: INFO: Pod "pod-secrets-b89fe6ea-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004872383s
May 11 00:28:42.701: INFO: Pod "pod-secrets-b89fe6ea-7383-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007783463s
STEP: Saw pod success
May 11 00:28:42.701: INFO: Pod "pod-secrets-b89fe6ea-7383-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:28:42.703: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-secrets-b89fe6ea-7383-11e9-9c46-760f9b3dbd5d container secret-volume-test: <nil>
STEP: delete the pod
May 11 00:28:42.718: INFO: Waiting for pod pod-secrets-b89fe6ea-7383-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:28:42.720: INFO: Pod pod-secrets-b89fe6ea-7383-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:28:42.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6mk7v" for this suite.
May 11 00:28:48.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:28:48.757: INFO: namespace: e2e-tests-secrets-6mk7v, resource: bindings, ignored listing per whitelist
May 11 00:28:48.792: INFO: namespace e2e-tests-secrets-6mk7v deletion completed in 6.069401797s

• [SLOW TEST:10.150 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:28:48.792: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-beac9197-7383-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 00:28:48.846: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-beaceea6-7383-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-h54r6" to be "success or failure"
May 11 00:28:48.848: INFO: Pod "pod-projected-configmaps-beaceea6-7383-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.213376ms
May 11 00:28:50.851: INFO: Pod "pod-projected-configmaps-beaceea6-7383-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005062751s
STEP: Saw pod success
May 11 00:28:50.851: INFO: Pod "pod-projected-configmaps-beaceea6-7383-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:28:50.852: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-projected-configmaps-beaceea6-7383-11e9-9c46-760f9b3dbd5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 11 00:28:50.865: INFO: Waiting for pod pod-projected-configmaps-beaceea6-7383-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:28:50.868: INFO: Pod pod-projected-configmaps-beaceea6-7383-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:28:50.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h54r6" for this suite.
May 11 00:28:56.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:28:56.902: INFO: namespace: e2e-tests-projected-h54r6, resource: bindings, ignored listing per whitelist
May 11 00:28:56.946: INFO: namespace e2e-tests-projected-h54r6 deletion completed in 6.074470175s

• [SLOW TEST:8.154 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:28:56.946: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-c38b4a0f-7383-11e9-9c46-760f9b3dbd5d
STEP: Creating configMap with name cm-test-opt-upd-c38b4a4e-7383-11e9-9c46-760f9b3dbd5d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c38b4a0f-7383-11e9-9c46-760f9b3dbd5d
STEP: Updating configmap cm-test-opt-upd-c38b4a4e-7383-11e9-9c46-760f9b3dbd5d
STEP: Creating configMap with name cm-test-opt-create-c38b4a66-7383-11e9-9c46-760f9b3dbd5d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:30:10.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wf6fj" for this suite.
May 11 00:30:32.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:30:32.574: INFO: namespace: e2e-tests-projected-wf6fj, resource: bindings, ignored listing per whitelist
May 11 00:30:32.586: INFO: namespace e2e-tests-projected-wf6fj deletion completed in 22.065147583s

• [SLOW TEST:95.640 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:30:32.586: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0511 00:30:38.861278      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 11 00:30:38.861: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:30:38.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bgs8x" for this suite.
May 11 00:30:44.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:30:44.903: INFO: namespace: e2e-tests-gc-bgs8x, resource: bindings, ignored listing per whitelist
May 11 00:30:44.945: INFO: namespace e2e-tests-gc-bgs8x deletion completed in 6.074795972s

• [SLOW TEST:12.358 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:30:44.945: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
May 11 00:30:44.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 cluster-info'
May 11 00:30:45.247: INFO: stderr: ""
May 11 00:30:45.247: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\x1b[0;32mcoredns\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:30:45.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-shrnk" for this suite.
May 11 00:30:51.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:30:51.271: INFO: namespace: e2e-tests-kubectl-shrnk, resource: bindings, ignored listing per whitelist
May 11 00:30:51.312: INFO: namespace e2e-tests-kubectl-shrnk deletion completed in 6.062016078s

• [SLOW TEST:6.367 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:30:51.312: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 11 00:30:51.355: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 11 00:30:51.359: INFO: Waiting for terminating namespaces to be deleted...
May 11 00:30:51.361: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-0 before test
May 11 00:30:51.365: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-0 from kube-system started at <nil> (0 container statuses recorded)
May 11 00:30:51.365: INFO: kube-proxy-k5lk8 from kube-system started at 2019-05-11 00:12:47 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.365: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 00:30:51.365: INFO: kubernetes-dashboard-8457c55f89-wl2rw from kube-system started at 2019-05-11 00:13:40 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.365: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 11 00:30:51.365: INFO: stork-scheduler-75b8f4d565-6ntdx from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.365: INFO: 	Container stork-scheduler ready: true, restart count 0
May 11 00:30:51.365: INFO: portworx-znwr7 from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.365: INFO: 	Container portworx ready: true, restart count 0
May 11 00:30:51.365: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-2csqh from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 00:30:51.365: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 11 00:30:51.365: INFO: 	Container systemd-logs ready: true, restart count 0
May 11 00:30:51.365: INFO: calico-node-hh8j6 from kube-system started at 2019-05-11 00:12:38 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.365: INFO: 	Container calico-node ready: true, restart count 0
May 11 00:30:51.365: INFO: stork-d8fc784c7-84cjw from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.365: INFO: 	Container stork ready: true, restart count 0
May 11 00:30:51.365: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-1 before test
May 11 00:30:51.370: INFO: coredns-6fd7dbf94c-xsrcc from kube-system started at 2019-05-11 00:13:40 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.370: INFO: 	Container coredns ready: true, restart count 0
May 11 00:30:51.370: INFO: stork-d8fc784c7-rtqlm from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.370: INFO: 	Container stork ready: true, restart count 1
May 11 00:30:51.370: INFO: kube-proxy-6bcpz from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.370: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 00:30:51.370: INFO: stork-scheduler-75b8f4d565-fwzgd from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.370: INFO: 	Container stork-scheduler ready: true, restart count 1
May 11 00:30:51.370: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-11 00:23:59 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.370: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 11 00:30:51.370: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-1 from kube-system started at <nil> (0 container statuses recorded)
May 11 00:30:51.370: INFO: calico-node-rk5xw from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.370: INFO: 	Container calico-node ready: true, restart count 0
May 11 00:30:51.370: INFO: portworx-d7vtl from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.370: INFO: 	Container portworx ready: true, restart count 0
May 11 00:30:51.370: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-s7lkz from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 00:30:51.370: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 11 00:30:51.370: INFO: 	Container systemd-logs ready: true, restart count 0
May 11 00:30:51.370: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-2 before test
May 11 00:30:51.376: INFO: sonobuoy-e2e-job-898060709b084e53 from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 00:30:51.376: INFO: 	Container e2e ready: true, restart count 0
May 11 00:30:51.376: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 11 00:30:51.376: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-9g4dc from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 00:30:51.376: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 11 00:30:51.376: INFO: 	Container systemd-logs ready: true, restart count 0
May 11 00:30:51.376: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-2 from kube-system started at <nil> (0 container statuses recorded)
May 11 00:30:51.376: INFO: dns-autoscaler-5b4847c446-k4mz5 from kube-system started at 2019-05-11 00:13:38 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.376: INFO: 	Container autoscaler ready: true, restart count 0
May 11 00:30:51.376: INFO: stork-d8fc784c7-lhpp4 from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.376: INFO: 	Container stork ready: true, restart count 1
May 11 00:30:51.376: INFO: stork-scheduler-75b8f4d565-ppzzv from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.376: INFO: 	Container stork-scheduler ready: true, restart count 0
May 11 00:30:51.376: INFO: portworx-76nlv from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.376: INFO: 	Container portworx ready: true, restart count 0
May 11 00:30:51.376: INFO: kube-proxy-b5r9f from kube-system started at 2019-05-11 00:12:35 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.376: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 00:30:51.376: INFO: calico-node-27v4g from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 00:30:51.376: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0a1ad959-7384-11e9-9c46-760f9b3dbd5d 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-0a1ad959-7384-11e9-9c46-760f9b3dbd5d off the node craig-k8s-certification-1-stellar-hand-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0a1ad959-7384-11e9-9c46-760f9b3dbd5d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:30:57.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mgvtq" for this suite.
May 11 00:31:07.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:31:07.565: INFO: namespace: e2e-tests-sched-pred-mgvtq, resource: bindings, ignored listing per whitelist
May 11 00:31:07.570: INFO: namespace e2e-tests-sched-pred-mgvtq deletion completed in 10.112749624s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.258 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:31:07.570: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 11 00:31:07.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-nw4d6'
May 11 00:31:07.900: INFO: stderr: ""
May 11 00:31:07.901: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 11 00:31:08.904: INFO: Selector matched 1 pods for map[app:redis]
May 11 00:31:08.904: INFO: Found 0 / 1
May 11 00:31:09.903: INFO: Selector matched 1 pods for map[app:redis]
May 11 00:31:09.903: INFO: Found 0 / 1
May 11 00:31:10.903: INFO: Selector matched 1 pods for map[app:redis]
May 11 00:31:10.903: INFO: Found 0 / 1
May 11 00:31:11.903: INFO: Selector matched 1 pods for map[app:redis]
May 11 00:31:11.903: INFO: Found 1 / 1
May 11 00:31:11.903: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 11 00:31:11.905: INFO: Selector matched 1 pods for map[app:redis]
May 11 00:31:11.905: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 11 00:31:11.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 patch pod redis-master-nd6qn --namespace=e2e-tests-kubectl-nw4d6 -p {"metadata":{"annotations":{"x":"y"}}}'
May 11 00:31:11.990: INFO: stderr: ""
May 11 00:31:11.990: INFO: stdout: "pod/redis-master-nd6qn patched\n"
STEP: checking annotations
May 11 00:31:11.992: INFO: Selector matched 1 pods for map[app:redis]
May 11 00:31:11.992: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:31:11.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nw4d6" for this suite.
May 11 00:31:34.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:31:34.030: INFO: namespace: e2e-tests-kubectl-nw4d6, resource: bindings, ignored listing per whitelist
May 11 00:31:34.063: INFO: namespace e2e-tests-kubectl-nw4d6 deletion completed in 22.068706853s

• [SLOW TEST:26.493 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:31:34.063: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2130246a-7384-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 00:31:34.125: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-21307961-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-8zlgs" to be "success or failure"
May 11 00:31:34.129: INFO: Pod "pod-projected-configmaps-21307961-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.739784ms
May 11 00:31:36.132: INFO: Pod "pod-projected-configmaps-21307961-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006664029s
STEP: Saw pod success
May 11 00:31:36.132: INFO: Pod "pod-projected-configmaps-21307961-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:31:36.134: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-projected-configmaps-21307961-7384-11e9-9c46-760f9b3dbd5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 11 00:31:36.147: INFO: Waiting for pod pod-projected-configmaps-21307961-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:31:36.149: INFO: Pod pod-projected-configmaps-21307961-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:31:36.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8zlgs" for this suite.
May 11 00:31:42.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:31:42.184: INFO: namespace: e2e-tests-projected-8zlgs, resource: bindings, ignored listing per whitelist
May 11 00:31:42.222: INFO: namespace e2e-tests-projected-8zlgs deletion completed in 6.070314133s

• [SLOW TEST:8.158 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:31:42.222: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 11 00:31:42.271: INFO: Waiting up to 5m0s for pod "downward-api-260b52d1-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-p7nfz" to be "success or failure"
May 11 00:31:42.274: INFO: Pod "downward-api-260b52d1-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.46424ms
May 11 00:31:44.277: INFO: Pod "downward-api-260b52d1-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006036613s
May 11 00:31:46.280: INFO: Pod "downward-api-260b52d1-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008817862s
STEP: Saw pod success
May 11 00:31:46.280: INFO: Pod "downward-api-260b52d1-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:31:46.281: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downward-api-260b52d1-7384-11e9-9c46-760f9b3dbd5d container dapi-container: <nil>
STEP: delete the pod
May 11 00:31:46.295: INFO: Waiting for pod downward-api-260b52d1-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:31:46.297: INFO: Pod downward-api-260b52d1-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:31:46.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p7nfz" for this suite.
May 11 00:31:52.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:31:52.348: INFO: namespace: e2e-tests-downward-api-p7nfz, resource: bindings, ignored listing per whitelist
May 11 00:31:52.372: INFO: namespace e2e-tests-downward-api-p7nfz deletion completed in 6.070827301s

• [SLOW TEST:10.150 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:31:52.372: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 11 00:31:54.939: INFO: Successfully updated pod "labelsupdate2c182834-7384-11e9-9c46-760f9b3dbd5d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:31:58.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bfhk9" for this suite.
May 11 00:32:20.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:32:21.030: INFO: namespace: e2e-tests-downward-api-bfhk9, resource: bindings, ignored listing per whitelist
May 11 00:32:21.038: INFO: namespace e2e-tests-downward-api-bfhk9 deletion completed in 22.069186499s

• [SLOW TEST:28.666 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:32:21.038: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3d2ef86e-7384-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 00:32:21.093: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3d2f6991-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-pnqwn" to be "success or failure"
May 11 00:32:21.096: INFO: Pod "pod-projected-secrets-3d2f6991-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.738031ms
May 11 00:32:23.201: INFO: Pod "pod-projected-secrets-3d2f6991-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107804386s
May 11 00:32:25.540: INFO: Pod "pod-projected-secrets-3d2f6991-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.446419568s
STEP: Saw pod success
May 11 00:32:25.540: INFO: Pod "pod-projected-secrets-3d2f6991-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:32:25.542: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-projected-secrets-3d2f6991-7384-11e9-9c46-760f9b3dbd5d container projected-secret-volume-test: <nil>
STEP: delete the pod
May 11 00:32:25.945: INFO: Waiting for pod pod-projected-secrets-3d2f6991-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:32:26.196: INFO: Pod pod-projected-secrets-3d2f6991-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:32:26.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pnqwn" for this suite.
May 11 00:32:32.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:32:32.300: INFO: namespace: e2e-tests-projected-pnqwn, resource: bindings, ignored listing per whitelist
May 11 00:32:32.322: INFO: namespace e2e-tests-projected-pnqwn deletion completed in 6.122023376s

• [SLOW TEST:11.283 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:32:32.322: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-lspf9
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-lspf9
STEP: Deleting pre-stop pod
May 11 00:32:49.696: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:32:49.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-lspf9" for this suite.
May 11 00:33:29.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:33:29.992: INFO: namespace: e2e-tests-prestop-lspf9, resource: bindings, ignored listing per whitelist
May 11 00:33:30.005: INFO: namespace e2e-tests-prestop-lspf9 deletion completed in 40.233884471s

• [SLOW TEST:57.683 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:33:30.005: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-2t5p5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2t5p5 to expose endpoints map[]
May 11 00:33:30.226: INFO: Get endpoints failed (9.627088ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 11 00:33:31.229: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2t5p5 exposes endpoints map[] (1.013230487s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-2t5p5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2t5p5 to expose endpoints map[pod1:[100]]
May 11 00:33:35.387: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.15350925s elapsed, will retry)
May 11 00:33:38.400: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2t5p5 exposes endpoints map[pod1:[100]] (7.165897468s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-2t5p5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2t5p5 to expose endpoints map[pod1:[100] pod2:[101]]
May 11 00:33:42.591: INFO: Unexpected endpoints: found map[6688f187-7384-11e9-9f3c-000c29c278ce:[100]], expected map[pod1:[100] pod2:[101]] (4.187952544s elapsed, will retry)
May 11 00:33:43.598: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2t5p5 exposes endpoints map[pod1:[100] pod2:[101]] (5.194249485s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-2t5p5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2t5p5 to expose endpoints map[pod2:[101]]
May 11 00:33:44.801: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2t5p5 exposes endpoints map[pod2:[101]] (1.200336548s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-2t5p5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2t5p5 to expose endpoints map[]
May 11 00:33:44.816: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2t5p5 exposes endpoints map[] (11.101945ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:33:45.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2t5p5" for this suite.
May 11 00:33:51.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:33:51.213: INFO: namespace: e2e-tests-services-2t5p5, resource: bindings, ignored listing per whitelist
May 11 00:33:51.228: INFO: namespace e2e-tests-services-2t5p5 deletion completed in 6.077823929s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:21.223 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:33:51.229: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-72fc4d43-7384-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 00:33:51.395: INFO: Waiting up to 5m0s for pod "pod-secrets-73022c58-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-w6ss9" to be "success or failure"
May 11 00:33:51.437: INFO: Pod "pod-secrets-73022c58-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 42.436419ms
May 11 00:33:53.440: INFO: Pod "pod-secrets-73022c58-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044821197s
May 11 00:33:55.443: INFO: Pod "pod-secrets-73022c58-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047800383s
STEP: Saw pod success
May 11 00:33:55.443: INFO: Pod "pod-secrets-73022c58-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:33:55.445: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-secrets-73022c58-7384-11e9-9c46-760f9b3dbd5d container secret-volume-test: <nil>
STEP: delete the pod
May 11 00:33:55.487: INFO: Waiting for pod pod-secrets-73022c58-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:33:55.492: INFO: Pod pod-secrets-73022c58-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:33:55.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w6ss9" for this suite.
May 11 00:34:01.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:34:01.583: INFO: namespace: e2e-tests-secrets-w6ss9, resource: bindings, ignored listing per whitelist
May 11 00:34:01.632: INFO: namespace e2e-tests-secrets-w6ss9 deletion completed in 6.137261445s

• [SLOW TEST:10.403 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:34:01.632: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
May 11 00:34:01.886: INFO: Waiting up to 5m0s for pod "var-expansion-7937e135-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-var-expansion-ctndt" to be "success or failure"
May 11 00:34:01.965: INFO: Pod "var-expansion-7937e135-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 78.848754ms
May 11 00:34:03.968: INFO: Pod "var-expansion-7937e135-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082347563s
May 11 00:34:06.026: INFO: Pod "var-expansion-7937e135-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.140240612s
STEP: Saw pod success
May 11 00:34:06.026: INFO: Pod "var-expansion-7937e135-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:34:06.028: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod var-expansion-7937e135-7384-11e9-9c46-760f9b3dbd5d container dapi-container: <nil>
STEP: delete the pod
May 11 00:34:06.170: INFO: Waiting for pod var-expansion-7937e135-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:34:06.235: INFO: Pod var-expansion-7937e135-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:34:06.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ctndt" for this suite.
May 11 00:34:12.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:34:12.508: INFO: namespace: e2e-tests-var-expansion-ctndt, resource: bindings, ignored listing per whitelist
May 11 00:34:12.607: INFO: namespace e2e-tests-var-expansion-ctndt deletion completed in 6.198851466s

• [SLOW TEST:10.975 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:34:12.607: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-7fbbde5e-7384-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 00:34:12.795: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7fbd3f93-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-fsnhz" to be "success or failure"
May 11 00:34:12.821: INFO: Pod "pod-projected-configmaps-7fbd3f93-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.720369ms
May 11 00:34:14.824: INFO: Pod "pod-projected-configmaps-7fbd3f93-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029542103s
May 11 00:34:16.852: INFO: Pod "pod-projected-configmaps-7fbd3f93-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057281734s
STEP: Saw pod success
May 11 00:34:16.852: INFO: Pod "pod-projected-configmaps-7fbd3f93-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:34:16.865: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-projected-configmaps-7fbd3f93-7384-11e9-9c46-760f9b3dbd5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 11 00:34:17.068: INFO: Waiting for pod pod-projected-configmaps-7fbd3f93-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:34:17.111: INFO: Pod pod-projected-configmaps-7fbd3f93-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:34:17.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fsnhz" for this suite.
May 11 00:34:23.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:34:23.214: INFO: namespace: e2e-tests-projected-fsnhz, resource: bindings, ignored listing per whitelist
May 11 00:34:23.237: INFO: namespace e2e-tests-projected-fsnhz deletion completed in 6.123258633s

• [SLOW TEST:10.630 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:34:23.237: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 11 00:34:30.198: INFO: Successfully updated pod "annotationupdate862e02cb-7384-11e9-9c46-760f9b3dbd5d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:34:32.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hf2hk" for this suite.
May 11 00:34:54.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:34:54.305: INFO: namespace: e2e-tests-projected-hf2hk, resource: bindings, ignored listing per whitelist
May 11 00:34:54.403: INFO: namespace e2e-tests-projected-hf2hk deletion completed in 22.150537125s

• [SLOW TEST:31.166 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:34:54.403: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 11 00:34:54.655: INFO: Waiting up to 5m0s for pod "downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-v6dwr" to be "success or failure"
May 11 00:34:54.678: INFO: Pod "downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.999472ms
May 11 00:34:56.693: INFO: Pod "downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038003888s
May 11 00:34:58.695: INFO: Pod "downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040149552s
May 11 00:35:00.698: INFO: Pod "downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042987865s
STEP: Saw pod success
May 11 00:35:00.698: INFO: Pod "downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:35:00.701: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d container dapi-container: <nil>
STEP: delete the pod
May 11 00:35:00.858: INFO: Waiting for pod downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:35:00.865: INFO: Pod downward-api-98b4fa97-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:35:00.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v6dwr" for this suite.
May 11 00:35:06.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:35:06.924: INFO: namespace: e2e-tests-downward-api-v6dwr, resource: bindings, ignored listing per whitelist
May 11 00:35:06.967: INFO: namespace e2e-tests-downward-api-v6dwr deletion completed in 6.099496115s

• [SLOW TEST:12.564 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:35:06.967: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a02e9206-7384-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 00:35:07.217: INFO: Waiting up to 5m0s for pod "pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-5nxpb" to be "success or failure"
May 11 00:35:07.224: INFO: Pod "pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.315043ms
May 11 00:35:09.401: INFO: Pod "pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.184158984s
May 11 00:35:11.403: INFO: Pod "pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.186618047s
May 11 00:35:13.406: INFO: Pod "pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.189221921s
STEP: Saw pod success
May 11 00:35:13.406: INFO: Pod "pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:35:13.408: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d container configmap-volume-test: <nil>
STEP: delete the pod
May 11 00:35:13.442: INFO: Waiting for pod pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:35:13.517: INFO: Pod pod-configmaps-a033bab0-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:35:13.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5nxpb" for this suite.
May 11 00:35:19.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:35:19.632: INFO: namespace: e2e-tests-configmap-5nxpb, resource: bindings, ignored listing per whitelist
May 11 00:35:19.682: INFO: namespace e2e-tests-configmap-5nxpb deletion completed in 6.161612086s

• [SLOW TEST:12.715 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:35:19.682: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:35:19.940: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-2vtzk" to be "success or failure"
May 11 00:35:20.010: INFO: Pod "downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 69.743088ms
May 11 00:35:22.013: INFO: Pod "downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072212121s
May 11 00:35:24.066: INFO: Pod "downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125267221s
May 11 00:35:26.068: INFO: Pod "downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.127981526s
STEP: Saw pod success
May 11 00:35:26.069: INFO: Pod "downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:35:26.070: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:35:26.104: INFO: Waiting for pod downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:35:26.142: INFO: Pod downwardapi-volume-a7c6bee3-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:35:26.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2vtzk" for this suite.
May 11 00:35:32.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:35:32.300: INFO: namespace: e2e-tests-downward-api-2vtzk, resource: bindings, ignored listing per whitelist
May 11 00:35:32.310: INFO: namespace e2e-tests-downward-api-2vtzk deletion completed in 6.164286278s

• [SLOW TEST:12.628 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:35:32.310: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 11 00:35:32.628: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-t2grn,SelfLink:/api/v1/namespaces/e2e-tests-watch-t2grn/configmaps/e2e-watch-test-watch-closed,UID:aed268b8-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6380,Generation:0,CreationTimestamp:2019-05-11 00:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 11 00:35:32.628: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-t2grn,SelfLink:/api/v1/namespaces/e2e-tests-watch-t2grn/configmaps/e2e-watch-test-watch-closed,UID:aed268b8-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6381,Generation:0,CreationTimestamp:2019-05-11 00:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 11 00:35:32.650: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-t2grn,SelfLink:/api/v1/namespaces/e2e-tests-watch-t2grn/configmaps/e2e-watch-test-watch-closed,UID:aed268b8-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6382,Generation:0,CreationTimestamp:2019-05-11 00:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 11 00:35:32.651: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-t2grn,SelfLink:/api/v1/namespaces/e2e-tests-watch-t2grn/configmaps/e2e-watch-test-watch-closed,UID:aed268b8-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6383,Generation:0,CreationTimestamp:2019-05-11 00:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:35:32.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-t2grn" for this suite.
May 11 00:35:38.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:35:38.706: INFO: namespace: e2e-tests-watch-t2grn, resource: bindings, ignored listing per whitelist
May 11 00:35:38.745: INFO: namespace e2e-tests-watch-t2grn deletion completed in 6.086816897s

• [SLOW TEST:6.435 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:35:38.746: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qhgl6
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-qhgl6
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-qhgl6
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-qhgl6
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-qhgl6
May 11 00:35:43.085: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qhgl6, name: ss-0, uid: b2dc79c5-7384-11e9-9f3c-000c29c278ce, status phase: Pending. Waiting for statefulset controller to delete.
May 11 00:35:47.324: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qhgl6, name: ss-0, uid: b2dc79c5-7384-11e9-9f3c-000c29c278ce, status phase: Failed. Waiting for statefulset controller to delete.
May 11 00:35:47.344: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qhgl6, name: ss-0, uid: b2dc79c5-7384-11e9-9f3c-000c29c278ce, status phase: Failed. Waiting for statefulset controller to delete.
May 11 00:35:47.347: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-qhgl6
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-qhgl6
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-qhgl6 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 11 00:35:57.384: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qhgl6
May 11 00:35:57.387: INFO: Scaling statefulset ss to 0
May 11 00:36:07.400: INFO: Waiting for statefulset status.replicas updated to 0
May 11 00:36:07.402: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:36:07.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qhgl6" for this suite.
May 11 00:36:13.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:36:13.480: INFO: namespace: e2e-tests-statefulset-qhgl6, resource: bindings, ignored listing per whitelist
May 11 00:36:13.533: INFO: namespace e2e-tests-statefulset-qhgl6 deletion completed in 6.108816298s

• [SLOW TEST:34.787 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:36:13.533: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:36:13.619: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 11 00:36:13.664: INFO: Pod name sample-pod: Found 0 pods out of 1
May 11 00:36:18.667: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 11 00:36:18.667: INFO: Creating deployment "test-rolling-update-deployment"
May 11 00:36:18.670: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 11 00:36:18.676: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 11 00:36:20.684: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 11 00:36:20.688: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693131777, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693131777, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693131777, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693131777, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 11 00:36:22.691: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 11 00:36:22.697: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-466b9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-466b9/deployments/test-rolling-update-deployment,UID:ca559b00-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6669,Generation:1,CreationTimestamp:2019-05-11 00:36:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-11 00:36:17 +0000 UTC 2019-05-11 00:36:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-11 00:36:19 +0000 UTC 2019-05-11 00:36:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 11 00:36:22.699: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-466b9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-466b9/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:ca57c66b-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6660,Generation:1,CreationTimestamp:2019-05-11 00:36:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ca559b00-7384-11e9-9f3c-000c29c278ce 0xc0016788c7 0xc0016788c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 11 00:36:22.699: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 11 00:36:22.699: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-466b9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-466b9/replicasets/test-rolling-update-controller,UID:c7535b9d-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6668,Generation:2,CreationTimestamp:2019-05-11 00:36:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ca559b00-7384-11e9-9f3c-000c29c278ce 0xc001678557 0xc001678558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 11 00:36:22.702: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-4qlxf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-4qlxf,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-466b9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-466b9/pods/test-rolling-update-deployment-68b55d7bc6-4qlxf,UID:ca5829df-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6659,Generation:0,CreationTimestamp:2019-05-11 00:36:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 ca57c66b-7384-11e9-9f3c-000c29c278ce 0xc001f8f807 0xc001f8f808}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xzjpl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xzjpl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-xzjpl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8f8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8f8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:36:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:36:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:36:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 00:36:17 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:10.233.124.145,StartTime:2019-05-11 00:36:18 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-11 00:36:20 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://990c3d8a2b0c431c5682e6d34d4ed980363d04adc13739a54b1ce29461e8bb5d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:36:22.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-466b9" for this suite.
May 11 00:36:28.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:36:28.726: INFO: namespace: e2e-tests-deployment-466b9, resource: bindings, ignored listing per whitelist
May 11 00:36:28.776: INFO: namespace e2e-tests-deployment-466b9 deletion completed in 6.069980352s

• [SLOW TEST:15.243 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:36:28.776: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:36:28.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d0d9afa6-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-sjlpj" to be "success or failure"
May 11 00:36:28.853: INFO: Pod "downwardapi-volume-d0d9afa6-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.82952ms
May 11 00:36:30.856: INFO: Pod "downwardapi-volume-d0d9afa6-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020885542s
STEP: Saw pod success
May 11 00:36:30.856: INFO: Pod "downwardapi-volume-d0d9afa6-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:36:30.858: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-d0d9afa6-7384-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:36:30.893: INFO: Waiting for pod downwardapi-volume-d0d9afa6-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:36:30.896: INFO: Pod downwardapi-volume-d0d9afa6-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:36:30.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sjlpj" for this suite.
May 11 00:36:36.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:36:36.978: INFO: namespace: e2e-tests-downward-api-sjlpj, resource: bindings, ignored listing per whitelist
May 11 00:36:37.028: INFO: namespace e2e-tests-downward-api-sjlpj deletion completed in 6.129068818s

• [SLOW TEST:8.252 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:36:37.028: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 11 00:36:37.092: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-nq2bp,SelfLink:/api/v1/namespaces/e2e-tests-watch-nq2bp/configmaps/e2e-watch-test-resource-version,UID:d54f04e1-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6785,Generation:0,CreationTimestamp:2019-05-11 00:36:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 11 00:36:37.092: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-nq2bp,SelfLink:/api/v1/namespaces/e2e-tests-watch-nq2bp/configmaps/e2e-watch-test-resource-version,UID:d54f04e1-7384-11e9-9f3c-000c29c278ce,ResourceVersion:6786,Generation:0,CreationTimestamp:2019-05-11 00:36:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:36:37.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nq2bp" for this suite.
May 11 00:36:43.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:36:43.114: INFO: namespace: e2e-tests-watch-nq2bp, resource: bindings, ignored listing per whitelist
May 11 00:36:43.167: INFO: namespace e2e-tests-watch-nq2bp deletion completed in 6.07249294s

• [SLOW TEST:6.139 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:36:43.167: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d96d4cd5-7384-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 00:36:43.230: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d96da816-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-cxtfc" to be "success or failure"
May 11 00:36:43.232: INFO: Pod "pod-projected-configmaps-d96da816-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.949818ms
May 11 00:36:45.235: INFO: Pod "pod-projected-configmaps-d96da816-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005617854s
May 11 00:36:47.238: INFO: Pod "pod-projected-configmaps-d96da816-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008175467s
STEP: Saw pod success
May 11 00:36:47.238: INFO: Pod "pod-projected-configmaps-d96da816-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:36:47.240: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-projected-configmaps-d96da816-7384-11e9-9c46-760f9b3dbd5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 11 00:36:47.253: INFO: Waiting for pod pod-projected-configmaps-d96da816-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:36:47.255: INFO: Pod pod-projected-configmaps-d96da816-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:36:47.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cxtfc" for this suite.
May 11 00:36:53.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:36:53.278: INFO: namespace: e2e-tests-projected-cxtfc, resource: bindings, ignored listing per whitelist
May 11 00:36:53.329: INFO: namespace e2e-tests-projected-cxtfc deletion completed in 6.071607456s

• [SLOW TEST:10.162 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:36:53.329: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 11 00:37:03.504: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 11 00:37:03.506: INFO: Pod pod-with-poststart-http-hook still exists
May 11 00:37:05.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 11 00:37:05.510: INFO: Pod pod-with-poststart-http-hook still exists
May 11 00:37:07.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 11 00:37:07.510: INFO: Pod pod-with-poststart-http-hook still exists
May 11 00:37:09.506: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 11 00:37:09.510: INFO: Pod pod-with-poststart-http-hook still exists
May 11 00:37:11.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 11 00:37:11.509: INFO: Pod pod-with-poststart-http-hook still exists
May 11 00:37:13.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 11 00:37:13.509: INFO: Pod pod-with-poststart-http-hook still exists
May 11 00:37:15.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 11 00:37:15.698: INFO: Pod pod-with-poststart-http-hook still exists
May 11 00:37:17.507: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 11 00:37:17.509: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:37:17.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ngrjd" for this suite.
May 11 00:37:39.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:37:39.545: INFO: namespace: e2e-tests-container-lifecycle-hook-ngrjd, resource: bindings, ignored listing per whitelist
May 11 00:37:39.577: INFO: namespace e2e-tests-container-lifecycle-hook-ngrjd deletion completed in 22.065147868s

• [SLOW TEST:46.249 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:37:39.578: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:37:39.623: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb0aec84-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-97j4x" to be "success or failure"
May 11 00:37:39.626: INFO: Pod "downwardapi-volume-fb0aec84-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.411157ms
May 11 00:37:41.628: INFO: Pod "downwardapi-volume-fb0aec84-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005709175s
STEP: Saw pod success
May 11 00:37:41.628: INFO: Pod "downwardapi-volume-fb0aec84-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:37:41.630: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod downwardapi-volume-fb0aec84-7384-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:37:41.644: INFO: Waiting for pod downwardapi-volume-fb0aec84-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:37:41.646: INFO: Pod downwardapi-volume-fb0aec84-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:37:41.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-97j4x" for this suite.
May 11 00:37:47.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:37:47.675: INFO: namespace: e2e-tests-downward-api-97j4x, resource: bindings, ignored listing per whitelist
May 11 00:37:47.715: INFO: namespace e2e-tests-downward-api-97j4x deletion completed in 6.066187768s

• [SLOW TEST:8.137 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:37:47.715: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:37:47.766: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffe58adf-7384-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-pmsmw" to be "success or failure"
May 11 00:37:47.769: INFO: Pod "downwardapi-volume-ffe58adf-7384-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.397107ms
May 11 00:37:49.772: INFO: Pod "downwardapi-volume-ffe58adf-7384-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00596937s
STEP: Saw pod success
May 11 00:37:49.772: INFO: Pod "downwardapi-volume-ffe58adf-7384-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:37:49.774: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-ffe58adf-7384-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:37:49.790: INFO: Waiting for pod downwardapi-volume-ffe58adf-7384-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:37:49.792: INFO: Pod downwardapi-volume-ffe58adf-7384-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:37:49.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pmsmw" for this suite.
May 11 00:37:55.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:37:55.839: INFO: namespace: e2e-tests-projected-pmsmw, resource: bindings, ignored listing per whitelist
May 11 00:37:55.893: INFO: namespace e2e-tests-projected-pmsmw deletion completed in 6.098890337s

• [SLOW TEST:8.178 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:37:55.893: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
May 11 00:37:57.963: INFO: Pod pod-hostip-04c578d3-7385-11e9-9c46-760f9b3dbd5d has hostIP: 70.0.51.31
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:37:57.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hhs9h" for this suite.
May 11 00:38:19.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:38:20.002: INFO: namespace: e2e-tests-pods-hhs9h, resource: bindings, ignored listing per whitelist
May 11 00:38:20.037: INFO: namespace e2e-tests-pods-hhs9h deletion completed in 22.069735622s

• [SLOW TEST:24.144 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:38:20.038: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
May 11 00:38:20.078: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-594220555 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:38:20.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5wn7m" for this suite.
May 11 00:38:26.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:38:26.201: INFO: namespace: e2e-tests-kubectl-5wn7m, resource: bindings, ignored listing per whitelist
May 11 00:38:26.232: INFO: namespace e2e-tests-kubectl-5wn7m deletion completed in 6.065627989s

• [SLOW TEST:6.195 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:38:26.233: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 11 00:38:34.367: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:34.373: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:36.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:36.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:38.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:38.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:40.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:40.377: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:42.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:42.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:44.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:44.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:46.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:46.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:48.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:48.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:50.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:50.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:52.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:52.393: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:54.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:54.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:56.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:56.376: INFO: Pod pod-with-poststart-exec-hook still exists
May 11 00:38:58.373: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 11 00:38:58.560: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:38:58.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pmbf8" for this suite.
May 11 00:39:20.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:39:20.920: INFO: namespace: e2e-tests-container-lifecycle-hook-pmbf8, resource: bindings, ignored listing per whitelist
May 11 00:39:20.922: INFO: namespace e2e-tests-container-lifecycle-hook-pmbf8 deletion completed in 22.319783607s

• [SLOW TEST:54.689 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:39:20.922: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-f2p7j/secret-test-377d4f19-7385-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 00:39:21.043: INFO: Waiting up to 5m0s for pod "pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-f2p7j" to be "success or failure"
May 11 00:39:21.049: INFO: Pod "pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.156665ms
May 11 00:39:23.059: INFO: Pod "pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015864438s
May 11 00:39:25.061: INFO: Pod "pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018277468s
May 11 00:39:27.064: INFO: Pod "pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02060995s
STEP: Saw pod success
May 11 00:39:27.064: INFO: Pod "pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:39:27.065: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d container env-test: <nil>
STEP: delete the pod
May 11 00:39:27.081: INFO: Waiting for pod pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:39:27.083: INFO: Pod pod-configmaps-377dadad-7385-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:39:27.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-f2p7j" for this suite.
May 11 00:39:33.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:39:33.144: INFO: namespace: e2e-tests-secrets-f2p7j, resource: bindings, ignored listing per whitelist
May 11 00:39:33.145: INFO: namespace e2e-tests-secrets-f2p7j deletion completed in 6.058824924s

• [SLOW TEST:12.223 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:39:33.145: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 11 00:39:42.992: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:39:44.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-kx698" for this suite.
May 11 00:40:06.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:40:06.224: INFO: namespace: e2e-tests-replicaset-kx698, resource: bindings, ignored listing per whitelist
May 11 00:40:06.230: INFO: namespace e2e-tests-replicaset-kx698 deletion completed in 22.076068563s

• [SLOW TEST:33.085 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:40:06.230: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0511 00:40:46.547572      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 11 00:40:46.547: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:40:46.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gj828" for this suite.
May 11 00:40:52.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:40:52.702: INFO: namespace: e2e-tests-gc-gj828, resource: bindings, ignored listing per whitelist
May 11 00:40:52.758: INFO: namespace e2e-tests-gc-gj828 deletion completed in 6.207073816s

• [SLOW TEST:46.528 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:40:52.758: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 11 00:40:53.137: INFO: Pod name wrapped-volume-race-6e616cb4-7385-11e9-9c46-760f9b3dbd5d: Found 0 pods out of 5
May 11 00:40:58.141: INFO: Pod name wrapped-volume-race-6e616cb4-7385-11e9-9c46-760f9b3dbd5d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6e616cb4-7385-11e9-9c46-760f9b3dbd5d in namespace e2e-tests-emptydir-wrapper-vfg69, will wait for the garbage collector to delete the pods
May 11 00:41:08.213: INFO: Deleting ReplicationController wrapped-volume-race-6e616cb4-7385-11e9-9c46-760f9b3dbd5d took: 5.81517ms
May 11 00:41:08.313: INFO: Terminating ReplicationController wrapped-volume-race-6e616cb4-7385-11e9-9c46-760f9b3dbd5d pods took: 100.346124ms
STEP: Creating RC which spawns configmap-volume pods
May 11 00:41:47.425: INFO: Pod name wrapped-volume-race-8ebd8d6c-7385-11e9-9c46-760f9b3dbd5d: Found 0 pods out of 5
May 11 00:41:52.429: INFO: Pod name wrapped-volume-race-8ebd8d6c-7385-11e9-9c46-760f9b3dbd5d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8ebd8d6c-7385-11e9-9c46-760f9b3dbd5d in namespace e2e-tests-emptydir-wrapper-vfg69, will wait for the garbage collector to delete the pods
May 11 00:42:02.495: INFO: Deleting ReplicationController wrapped-volume-race-8ebd8d6c-7385-11e9-9c46-760f9b3dbd5d took: 3.788268ms
May 11 00:42:02.595: INFO: Terminating ReplicationController wrapped-volume-race-8ebd8d6c-7385-11e9-9c46-760f9b3dbd5d pods took: 100.181306ms
STEP: Creating RC which spawns configmap-volume pods
May 11 00:42:40.210: INFO: Pod name wrapped-volume-race-ae336b9c-7385-11e9-9c46-760f9b3dbd5d: Found 0 pods out of 5
May 11 00:42:45.215: INFO: Pod name wrapped-volume-race-ae336b9c-7385-11e9-9c46-760f9b3dbd5d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ae336b9c-7385-11e9-9c46-760f9b3dbd5d in namespace e2e-tests-emptydir-wrapper-vfg69, will wait for the garbage collector to delete the pods
May 11 00:42:57.290: INFO: Deleting ReplicationController wrapped-volume-race-ae336b9c-7385-11e9-9c46-760f9b3dbd5d took: 9.90135ms
May 11 00:42:57.490: INFO: Terminating ReplicationController wrapped-volume-race-ae336b9c-7385-11e9-9c46-760f9b3dbd5d pods took: 200.255568ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:43:38.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-vfg69" for this suite.
May 11 00:43:44.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:43:44.592: INFO: namespace: e2e-tests-emptydir-wrapper-vfg69, resource: bindings, ignored listing per whitelist
May 11 00:43:44.609: INFO: namespace e2e-tests-emptydir-wrapper-vfg69 deletion completed in 6.075277026s

• [SLOW TEST:171.851 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:43:44.609: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 11 00:43:44.659: INFO: Waiting up to 5m0s for pod "pod-d49f5177-7385-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-948rq" to be "success or failure"
May 11 00:43:44.662: INFO: Pod "pod-d49f5177-7385-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.238273ms
May 11 00:43:46.664: INFO: Pod "pod-d49f5177-7385-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004724327s
STEP: Saw pod success
May 11 00:43:46.664: INFO: Pod "pod-d49f5177-7385-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:43:46.666: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-d49f5177-7385-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 00:43:46.677: INFO: Waiting for pod pod-d49f5177-7385-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:43:46.678: INFO: Pod pod-d49f5177-7385-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:43:46.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-948rq" for this suite.
May 11 00:43:52.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:43:52.715: INFO: namespace: e2e-tests-emptydir-948rq, resource: bindings, ignored listing per whitelist
May 11 00:43:52.751: INFO: namespace e2e-tests-emptydir-948rq deletion completed in 6.070461919s

• [SLOW TEST:8.142 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:43:52.752: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4nfnl
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 11 00:43:52.796: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 11 00:44:12.851: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.91.221:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4nfnl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:44:12.851: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:44:13.065: INFO: Found all expected endpoints: [netserver-0]
May 11 00:44:13.067: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.122.238:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4nfnl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:44:13.067: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:44:13.274: INFO: Found all expected endpoints: [netserver-1]
May 11 00:44:13.276: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.124.151:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4nfnl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:44:13.276: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:44:13.488: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:44:13.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4nfnl" for this suite.
May 11 00:44:35.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:44:35.548: INFO: namespace: e2e-tests-pod-network-test-4nfnl, resource: bindings, ignored listing per whitelist
May 11 00:44:35.558: INFO: namespace e2e-tests-pod-network-test-4nfnl deletion completed in 22.065880109s

• [SLOW TEST:42.806 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:44:35.558: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 11 00:44:35.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-g8lrn'
May 11 00:44:35.905: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 11 00:44:35.906: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
May 11 00:44:35.911: INFO: scanned /root for discovery docs: <nil>
May 11 00:44:35.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-g8lrn'
May 11 00:44:51.663: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 11 00:44:51.663: INFO: stdout: "Created e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25\nScaling up e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 11 00:44:51.663: INFO: stdout: "Created e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25\nScaling up e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 11 00:44:51.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g8lrn'
May 11 00:44:51.757: INFO: stderr: ""
May 11 00:44:51.757: INFO: stdout: "e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25-ch8sg "
May 11 00:44:51.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25-ch8sg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8lrn'
May 11 00:44:51.855: INFO: stderr: ""
May 11 00:44:51.855: INFO: stdout: "true"
May 11 00:44:51.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25-ch8sg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8lrn'
May 11 00:44:51.960: INFO: stderr: ""
May 11 00:44:51.960: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 11 00:44:51.960: INFO: e2e-test-nginx-rc-e87245c258017fba8d19a6710c130b25-ch8sg is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
May 11 00:44:51.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g8lrn'
May 11 00:44:52.055: INFO: stderr: ""
May 11 00:44:52.055: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:44:52.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g8lrn" for this suite.
May 11 00:44:58.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:44:58.089: INFO: namespace: e2e-tests-kubectl-g8lrn, resource: bindings, ignored listing per whitelist
May 11 00:44:58.127: INFO: namespace e2e-tests-kubectl-g8lrn deletion completed in 6.068493429s

• [SLOW TEST:22.569 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:44:58.127: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-xn8l
STEP: Creating a pod to test atomic-volume-subpath
May 11 00:44:58.181: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-xn8l" in namespace "e2e-tests-subpath-7fkb5" to be "success or failure"
May 11 00:44:58.184: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Pending", Reason="", readiness=false. Elapsed: 3.08668ms
May 11 00:45:00.186: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005450588s
May 11 00:45:02.189: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 4.00817103s
May 11 00:45:04.192: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 6.011041332s
May 11 00:45:06.194: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 8.013596378s
May 11 00:45:08.197: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 10.016542684s
May 11 00:45:10.200: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 12.019681758s
May 11 00:45:12.256: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 14.074911198s
May 11 00:45:14.258: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 16.077508184s
May 11 00:45:16.262: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 18.081298301s
May 11 00:45:18.264: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 20.083646919s
May 11 00:45:20.267: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Running", Reason="", readiness=false. Elapsed: 22.086497131s
May 11 00:45:22.271: INFO: Pod "pod-subpath-test-secret-xn8l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.089823149s
STEP: Saw pod success
May 11 00:45:22.271: INFO: Pod "pod-subpath-test-secret-xn8l" satisfied condition "success or failure"
May 11 00:45:22.273: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-subpath-test-secret-xn8l container test-container-subpath-secret-xn8l: <nil>
STEP: delete the pod
May 11 00:45:22.286: INFO: Waiting for pod pod-subpath-test-secret-xn8l to disappear
May 11 00:45:22.294: INFO: Pod pod-subpath-test-secret-xn8l no longer exists
STEP: Deleting pod pod-subpath-test-secret-xn8l
May 11 00:45:22.294: INFO: Deleting pod "pod-subpath-test-secret-xn8l" in namespace "e2e-tests-subpath-7fkb5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:45:22.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7fkb5" for this suite.
May 11 00:45:30.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:45:30.331: INFO: namespace: e2e-tests-subpath-7fkb5, resource: bindings, ignored listing per whitelist
May 11 00:45:30.361: INFO: namespace e2e-tests-subpath-7fkb5 deletion completed in 8.062724626s

• [SLOW TEST:32.233 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:45:30.361: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:45:30.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13a734a7-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-slwn9" to be "success or failure"
May 11 00:45:30.412: INFO: Pod "downwardapi-volume-13a734a7-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037511ms
May 11 00:45:32.415: INFO: Pod "downwardapi-volume-13a734a7-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005015757s
STEP: Saw pod success
May 11 00:45:32.415: INFO: Pod "downwardapi-volume-13a734a7-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:45:32.418: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod downwardapi-volume-13a734a7-7386-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:45:32.430: INFO: Waiting for pod downwardapi-volume-13a734a7-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:45:32.432: INFO: Pod downwardapi-volume-13a734a7-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:45:32.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-slwn9" for this suite.
May 11 00:45:40.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:45:40.503: INFO: namespace: e2e-tests-projected-slwn9, resource: bindings, ignored listing per whitelist
May 11 00:45:40.505: INFO: namespace e2e-tests-projected-slwn9 deletion completed in 8.070443601s

• [SLOW TEST:10.144 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:45:40.506: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:45:40.808: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:45:46.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ntrh9" for this suite.
May 11 00:46:26.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:46:26.891: INFO: namespace: e2e-tests-pods-ntrh9, resource: bindings, ignored listing per whitelist
May 11 00:46:26.903: INFO: namespace e2e-tests-pods-ntrh9 deletion completed in 40.058117648s

• [SLOW TEST:46.397 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:46:26.903: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-355c20a6-7386-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 00:46:26.970: INFO: Waiting up to 5m0s for pod "pod-secrets-355c8051-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-w2knq" to be "success or failure"
May 11 00:46:26.973: INFO: Pod "pod-secrets-355c8051-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.75916ms
May 11 00:46:29.091: INFO: Pod "pod-secrets-355c8051-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.120475168s
May 11 00:46:31.093: INFO: Pod "pod-secrets-355c8051-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.122889693s
STEP: Saw pod success
May 11 00:46:31.093: INFO: Pod "pod-secrets-355c8051-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:46:31.095: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-secrets-355c8051-7386-11e9-9c46-760f9b3dbd5d container secret-volume-test: <nil>
STEP: delete the pod
May 11 00:46:31.110: INFO: Waiting for pod pod-secrets-355c8051-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:46:31.112: INFO: Pod pod-secrets-355c8051-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:46:31.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w2knq" for this suite.
May 11 00:46:37.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:46:37.171: INFO: namespace: e2e-tests-secrets-w2knq, resource: bindings, ignored listing per whitelist
May 11 00:46:37.183: INFO: namespace e2e-tests-secrets-w2knq deletion completed in 6.063558131s

• [SLOW TEST:10.281 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:46:37.184: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
May 11 00:46:37.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-474gt'
May 11 00:46:37.546: INFO: stderr: ""
May 11 00:46:37.546: INFO: stdout: "pod/pause created\n"
May 11 00:46:37.546: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 11 00:46:37.546: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-474gt" to be "running and ready"
May 11 00:46:37.548: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 1.929661ms
May 11 00:46:39.550: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004449844s
May 11 00:46:41.553: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.006754193s
May 11 00:46:41.553: INFO: Pod "pause" satisfied condition "running and ready"
May 11 00:46:41.553: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
May 11 00:46:41.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-474gt'
May 11 00:46:41.653: INFO: stderr: ""
May 11 00:46:41.653: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 11 00:46:41.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pod pause -L testing-label --namespace=e2e-tests-kubectl-474gt'
May 11 00:46:41.753: INFO: stderr: ""
May 11 00:46:41.753: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 11 00:46:41.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 label pods pause testing-label- --namespace=e2e-tests-kubectl-474gt'
May 11 00:46:41.845: INFO: stderr: ""
May 11 00:46:41.845: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 11 00:46:41.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pod pause -L testing-label --namespace=e2e-tests-kubectl-474gt'
May 11 00:46:41.935: INFO: stderr: ""
May 11 00:46:41.935: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
May 11 00:46:41.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-474gt'
May 11 00:46:42.028: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 00:46:42.028: INFO: stdout: "pod \"pause\" force deleted\n"
May 11 00:46:42.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-474gt'
May 11 00:46:42.130: INFO: stderr: "No resources found.\n"
May 11 00:46:42.130: INFO: stdout: ""
May 11 00:46:42.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -l name=pause --namespace=e2e-tests-kubectl-474gt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 11 00:46:42.214: INFO: stderr: ""
May 11 00:46:42.214: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:46:42.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-474gt" for this suite.
May 11 00:46:48.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:46:48.249: INFO: namespace: e2e-tests-kubectl-474gt, resource: bindings, ignored listing per whitelist
May 11 00:46:48.277: INFO: namespace e2e-tests-kubectl-474gt deletion completed in 6.06052467s

• [SLOW TEST:11.094 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:46:48.278: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 11 00:46:48.316: INFO: PodSpec: initContainers in spec.initContainers
May 11 00:47:38.272: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-4217a169-7386-11e9-9c46-760f9b3dbd5d", GenerateName:"", Namespace:"e2e-tests-init-container-hb6ch", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-hb6ch/pods/pod-init-4217a169-7386-11e9-9c46-760f9b3dbd5d", UID:"41a29e8f-7386-11e9-9f3c-000c29c278ce", ResourceVersion:"10580", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693132407, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"316764726"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-m8vg5", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0023857c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m8vg5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m8vg5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m8vg5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001e79228), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"craig-k8s-certification-1-stellar-hand-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001b3c000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001e792a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001e792c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001e792c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001e792cc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693132408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693132408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693132408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693132407, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"70.0.51.47", PodIP:"10.233.124.153", StartTime:(*v1.Time)(0xc0018444a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000565c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000565c70)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://bf2577ea6f3c8a0fcacdb996b2db19caf75b2f16474b974e90cc522db26ed82c"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0018444e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0018444c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:47:38.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hb6ch" for this suite.
May 11 00:48:00.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:48:00.390: INFO: namespace: e2e-tests-init-container-hb6ch, resource: bindings, ignored listing per whitelist
May 11 00:48:00.420: INFO: namespace e2e-tests-init-container-hb6ch deletion completed in 22.088806443s

• [SLOW TEST:72.142 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:48:00.420: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-6d555df9-7386-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 00:48:01.044: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6d571b4d-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-8r5jb" to be "success or failure"
May 11 00:48:01.049: INFO: Pod "pod-projected-secrets-6d571b4d-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.426213ms
May 11 00:48:03.051: INFO: Pod "pod-projected-secrets-6d571b4d-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006677266s
May 11 00:48:05.053: INFO: Pod "pod-projected-secrets-6d571b4d-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008963775s
STEP: Saw pod success
May 11 00:48:05.053: INFO: Pod "pod-projected-secrets-6d571b4d-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:48:05.055: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-projected-secrets-6d571b4d-7386-11e9-9c46-760f9b3dbd5d container projected-secret-volume-test: <nil>
STEP: delete the pod
May 11 00:48:05.075: INFO: Waiting for pod pod-projected-secrets-6d571b4d-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:48:05.077: INFO: Pod pod-projected-secrets-6d571b4d-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:48:05.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8r5jb" for this suite.
May 11 00:48:11.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:48:12.517: INFO: namespace: e2e-tests-projected-8r5jb, resource: bindings, ignored listing per whitelist
May 11 00:48:12.563: INFO: namespace e2e-tests-projected-8r5jb deletion completed in 7.482088063s

• [SLOW TEST:12.143 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:48:12.563: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:48:14.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-pxhjz" for this suite.
May 11 00:48:58.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:48:58.653: INFO: namespace: e2e-tests-kubelet-test-pxhjz, resource: bindings, ignored listing per whitelist
May 11 00:48:58.695: INFO: namespace e2e-tests-kubelet-test-pxhjz deletion completed in 44.056233552s

• [SLOW TEST:46.132 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:48:58.695: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
May 11 00:48:58.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 api-versions'
May 11 00:48:58.818: INFO: stderr: ""
May 11 00:48:58.818: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nportworx.io/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nstork.libopenstorage.org/v1alpha1\nv1\nvolumesnapshot.external-storage.k8s.io/v1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:48:58.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-895gs" for this suite.
May 11 00:49:04.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:49:04.889: INFO: namespace: e2e-tests-kubectl-895gs, resource: bindings, ignored listing per whitelist
May 11 00:49:04.890: INFO: namespace e2e-tests-kubectl-895gs deletion completed in 6.069708089s

• [SLOW TEST:6.195 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:49:04.890: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9385d9db-7386-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 00:49:04.939: INFO: Waiting up to 5m0s for pod "pod-secrets-9386209e-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-hxs44" to be "success or failure"
May 11 00:49:04.941: INFO: Pod "pod-secrets-9386209e-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.940369ms
May 11 00:49:06.945: INFO: Pod "pod-secrets-9386209e-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005617365s
STEP: Saw pod success
May 11 00:49:06.945: INFO: Pod "pod-secrets-9386209e-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:49:06.947: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-secrets-9386209e-7386-11e9-9c46-760f9b3dbd5d container secret-volume-test: <nil>
STEP: delete the pod
May 11 00:49:06.958: INFO: Waiting for pod pod-secrets-9386209e-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:49:06.959: INFO: Pod pod-secrets-9386209e-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:49:06.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hxs44" for this suite.
May 11 00:49:12.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:49:13.011: INFO: namespace: e2e-tests-secrets-hxs44, resource: bindings, ignored listing per whitelist
May 11 00:49:13.022: INFO: namespace e2e-tests-secrets-hxs44 deletion completed in 6.059809445s

• [SLOW TEST:8.132 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:49:13.022: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
May 11 00:49:13.074: INFO: Waiting up to 5m0s for pod "client-containers-985efdd8-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-containers-s2gtv" to be "success or failure"
May 11 00:49:13.076: INFO: Pod "client-containers-985efdd8-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.842154ms
May 11 00:49:15.081: INFO: Pod "client-containers-985efdd8-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007462639s
May 11 00:49:17.084: INFO: Pod "client-containers-985efdd8-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010040764s
STEP: Saw pod success
May 11 00:49:17.084: INFO: Pod "client-containers-985efdd8-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:49:17.086: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod client-containers-985efdd8-7386-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 00:49:17.104: INFO: Waiting for pod client-containers-985efdd8-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:49:17.106: INFO: Pod client-containers-985efdd8-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:49:17.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-s2gtv" for this suite.
May 11 00:49:23.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:49:23.157: INFO: namespace: e2e-tests-containers-s2gtv, resource: bindings, ignored listing per whitelist
May 11 00:49:23.175: INFO: namespace e2e-tests-containers-s2gtv deletion completed in 6.066700313s

• [SLOW TEST:10.153 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:49:23.175: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:49:23.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e73b2a1-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-fs8kw" to be "success or failure"
May 11 00:49:23.278: INFO: Pod "downwardapi-volume-9e73b2a1-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.148983ms
May 11 00:49:25.281: INFO: Pod "downwardapi-volume-9e73b2a1-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006164899s
May 11 00:49:27.284: INFO: Pod "downwardapi-volume-9e73b2a1-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008762461s
STEP: Saw pod success
May 11 00:49:27.284: INFO: Pod "downwardapi-volume-9e73b2a1-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:49:27.286: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-9e73b2a1-7386-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:49:27.296: INFO: Waiting for pod downwardapi-volume-9e73b2a1-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:49:27.299: INFO: Pod downwardapi-volume-9e73b2a1-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:49:27.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fs8kw" for this suite.
May 11 00:49:33.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:49:33.328: INFO: namespace: e2e-tests-downward-api-fs8kw, resource: bindings, ignored listing per whitelist
May 11 00:49:33.369: INFO: namespace e2e-tests-downward-api-fs8kw deletion completed in 6.067827082s

• [SLOW TEST:10.194 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:49:33.369: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 11 00:49:33.424: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gqcn5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gqcn5/configmaps/e2e-watch-test-label-changed,UID:a40a7b59-7386-11e9-9f3c-000c29c278ce,ResourceVersion:11117,Generation:0,CreationTimestamp:2019-05-11 00:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 11 00:49:33.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gqcn5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gqcn5/configmaps/e2e-watch-test-label-changed,UID:a40a7b59-7386-11e9-9f3c-000c29c278ce,ResourceVersion:11118,Generation:0,CreationTimestamp:2019-05-11 00:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 11 00:49:33.424: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gqcn5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gqcn5/configmaps/e2e-watch-test-label-changed,UID:a40a7b59-7386-11e9-9f3c-000c29c278ce,ResourceVersion:11119,Generation:0,CreationTimestamp:2019-05-11 00:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 11 00:49:43.442: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gqcn5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gqcn5/configmaps/e2e-watch-test-label-changed,UID:a40a7b59-7386-11e9-9f3c-000c29c278ce,ResourceVersion:11146,Generation:0,CreationTimestamp:2019-05-11 00:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 11 00:49:43.443: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gqcn5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gqcn5/configmaps/e2e-watch-test-label-changed,UID:a40a7b59-7386-11e9-9f3c-000c29c278ce,ResourceVersion:11147,Generation:0,CreationTimestamp:2019-05-11 00:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 11 00:49:43.443: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gqcn5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gqcn5/configmaps/e2e-watch-test-label-changed,UID:a40a7b59-7386-11e9-9f3c-000c29c278ce,ResourceVersion:11148,Generation:0,CreationTimestamp:2019-05-11 00:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:49:43.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gqcn5" for this suite.
May 11 00:49:49.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:49:49.482: INFO: namespace: e2e-tests-watch-gqcn5, resource: bindings, ignored listing per whitelist
May 11 00:49:49.518: INFO: namespace e2e-tests-watch-gqcn5 deletion completed in 6.072686171s

• [SLOW TEST:16.149 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:49:49.518: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 11 00:49:49.570: INFO: Waiting up to 5m0s for pod "pod-ae200a11-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-bzhr9" to be "success or failure"
May 11 00:49:49.573: INFO: Pod "pod-ae200a11-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.093689ms
May 11 00:49:51.575: INFO: Pod "pod-ae200a11-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00547175s
May 11 00:49:53.577: INFO: Pod "pod-ae200a11-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007797466s
STEP: Saw pod success
May 11 00:49:53.577: INFO: Pod "pod-ae200a11-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:49:53.579: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-ae200a11-7386-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 00:49:53.589: INFO: Waiting for pod pod-ae200a11-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:49:53.591: INFO: Pod pod-ae200a11-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:49:53.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bzhr9" for this suite.
May 11 00:49:59.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:49:59.623: INFO: namespace: e2e-tests-emptydir-bzhr9, resource: bindings, ignored listing per whitelist
May 11 00:49:59.652: INFO: namespace e2e-tests-emptydir-bzhr9 deletion completed in 6.059050812s

• [SLOW TEST:10.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:49:59.652: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 11 00:49:59.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-24n9b'
May 11 00:49:59.832: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 11 00:49:59.832: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
May 11 00:49:59.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-24n9b'
May 11 00:49:59.935: INFO: stderr: ""
May 11 00:49:59.935: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:49:59.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-24n9b" for this suite.
May 11 00:50:21.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:50:21.996: INFO: namespace: e2e-tests-kubectl-24n9b, resource: bindings, ignored listing per whitelist
May 11 00:50:22.010: INFO: namespace e2e-tests-kubectl-24n9b deletion completed in 22.072789496s

• [SLOW TEST:22.357 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:50:22.010: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:50:22.067: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-8br9n" to be "success or failure"
May 11 00:50:22.069: INFO: Pod "downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.750956ms
May 11 00:50:24.072: INFO: Pod "downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004498491s
May 11 00:50:26.075: INFO: Pod "downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007220788s
May 11 00:50:28.385: INFO: Pod "downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.31813735s
STEP: Saw pod success
May 11 00:50:28.385: INFO: Pod "downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:50:29.264: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:50:29.841: INFO: Waiting for pod downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:50:30.119: INFO: Pod downwardapi-volume-c17ec4d3-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:50:30.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8br9n" for this suite.
May 11 00:50:36.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:50:36.214: INFO: namespace: e2e-tests-projected-8br9n, resource: bindings, ignored listing per whitelist
May 11 00:50:36.219: INFO: namespace e2e-tests-projected-8br9n deletion completed in 6.096731965s

• [SLOW TEST:14.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:50:36.219: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:50:36.274: INFO: (0) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.453429ms)
May 11 00:50:36.277: INFO: (1) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.495483ms)
May 11 00:50:36.279: INFO: (2) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.214065ms)
May 11 00:50:36.281: INFO: (3) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.17247ms)
May 11 00:50:36.283: INFO: (4) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.063108ms)
May 11 00:50:36.285: INFO: (5) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.072047ms)
May 11 00:50:36.288: INFO: (6) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.198843ms)
May 11 00:50:36.290: INFO: (7) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.943861ms)
May 11 00:50:36.292: INFO: (8) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.271046ms)
May 11 00:50:36.294: INFO: (9) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.132992ms)
May 11 00:50:36.297: INFO: (10) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.65982ms)
May 11 00:50:36.299: INFO: (11) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.255263ms)
May 11 00:50:36.302: INFO: (12) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.717322ms)
May 11 00:50:36.304: INFO: (13) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.075379ms)
May 11 00:50:36.308: INFO: (14) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.219648ms)
May 11 00:50:36.310: INFO: (15) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.215136ms)
May 11 00:50:36.312: INFO: (16) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.109315ms)
May 11 00:50:36.314: INFO: (17) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.96595ms)
May 11 00:50:36.317: INFO: (18) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.12406ms)
May 11 00:50:36.319: INFO: (19) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.072918ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:50:36.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-d9bvb" for this suite.
May 11 00:50:42.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:50:42.343: INFO: namespace: e2e-tests-proxy-d9bvb, resource: bindings, ignored listing per whitelist
May 11 00:50:42.379: INFO: namespace e2e-tests-proxy-d9bvb deletion completed in 6.05797513s

• [SLOW TEST:6.159 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:50:42.379: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 11 00:50:42.425: INFO: Waiting up to 5m0s for pod "pod-cda12feb-7386-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-724tg" to be "success or failure"
May 11 00:50:42.435: INFO: Pod "pod-cda12feb-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.361889ms
May 11 00:50:44.438: INFO: Pod "pod-cda12feb-7386-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013457564s
May 11 00:50:46.440: INFO: Pod "pod-cda12feb-7386-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015554593s
STEP: Saw pod success
May 11 00:50:46.440: INFO: Pod "pod-cda12feb-7386-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:50:46.442: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-cda12feb-7386-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 00:50:46.701: INFO: Waiting for pod pod-cda12feb-7386-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:50:46.703: INFO: Pod pod-cda12feb-7386-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:50:46.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-724tg" for this suite.
May 11 00:50:52.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:50:52.746: INFO: namespace: e2e-tests-emptydir-724tg, resource: bindings, ignored listing per whitelist
May 11 00:50:52.765: INFO: namespace e2e-tests-emptydir-724tg deletion completed in 6.058532632s

• [SLOW TEST:10.386 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:50:52.765: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:50:53.464: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d3bd5259-7386-11e9-9f3c-000c29c278ce", Controller:(*bool)(0xc002129b8e), BlockOwnerDeletion:(*bool)(0xc002129b8f)}}
May 11 00:50:53.495: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d3bbfa9c-7386-11e9-9f3c-000c29c278ce", Controller:(*bool)(0xc0020e0456), BlockOwnerDeletion:(*bool)(0xc0020e0457)}}
May 11 00:50:53.547: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d3bc77e0-7386-11e9-9f3c-000c29c278ce", Controller:(*bool)(0xc0020e0636), BlockOwnerDeletion:(*bool)(0xc0020e0637)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:50:58.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-n6dgn" for this suite.
May 11 00:51:04.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:51:04.643: INFO: namespace: e2e-tests-gc-n6dgn, resource: bindings, ignored listing per whitelist
May 11 00:51:04.671: INFO: namespace e2e-tests-gc-n6dgn deletion completed in 6.064625507s

• [SLOW TEST:11.905 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:51:04.671: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:51:11.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-k5p4j" for this suite.
May 11 00:51:33.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:51:33.787: INFO: namespace: e2e-tests-replication-controller-k5p4j, resource: bindings, ignored listing per whitelist
May 11 00:51:33.810: INFO: namespace e2e-tests-replication-controller-k5p4j deletion completed in 22.068254164s

• [SLOW TEST:29.140 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:51:33.810: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2qlsf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 11 00:51:34.176: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 11 00:52:00.537: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.249:8080/dial?request=hostName&protocol=http&host=10.233.122.248&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-2qlsf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:52:00.537: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:52:00.721: INFO: Waiting for endpoints: map[]
May 11 00:52:00.724: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.249:8080/dial?request=hostName&protocol=http&host=10.233.91.226&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-2qlsf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:52:00.724: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:52:00.909: INFO: Waiting for endpoints: map[]
May 11 00:52:00.911: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.249:8080/dial?request=hostName&protocol=http&host=10.233.124.157&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-2qlsf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:52:00.911: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:52:01.136: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:52:01.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2qlsf" for this suite.
May 11 00:52:23.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:52:23.192: INFO: namespace: e2e-tests-pod-network-test-2qlsf, resource: bindings, ignored listing per whitelist
May 11 00:52:23.218: INFO: namespace e2e-tests-pod-network-test-2qlsf deletion completed in 22.077564094s

• [SLOW TEST:49.408 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:52:23.218: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:52:23.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 version --client'
May 11 00:52:23.335: INFO: stderr: ""
May 11 00:52:23.335: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 11 00:52:23.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-4g6lp'
May 11 00:52:23.535: INFO: stderr: ""
May 11 00:52:23.535: INFO: stdout: "replicationcontroller/redis-master created\n"
May 11 00:52:23.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-4g6lp'
May 11 00:52:23.729: INFO: stderr: ""
May 11 00:52:23.729: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 11 00:52:24.731: INFO: Selector matched 1 pods for map[app:redis]
May 11 00:52:24.732: INFO: Found 1 / 1
May 11 00:52:24.732: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 11 00:52:24.733: INFO: Selector matched 1 pods for map[app:redis]
May 11 00:52:24.733: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 11 00:52:24.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 describe pod redis-master-l9djh --namespace=e2e-tests-kubectl-4g6lp'
May 11 00:52:24.831: INFO: stderr: ""
May 11 00:52:24.831: INFO: stdout: "Name:               redis-master-l9djh\nNamespace:          e2e-tests-kubectl-4g6lp\nPriority:           0\nPriorityClassName:  <none>\nNode:               craig-k8s-certification-1-stellar-hand-0/70.0.51.31\nStart Time:         Sat, 11 May 2019 00:52:23 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.233.122.250\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://de3442f3ea3ad643e3761494f7ff74be56d3dc11aa9ff386ed1cd0737899fc69\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 11 May 2019 00:52:24 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fh7rk (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-fh7rk:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-fh7rk\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                               Message\n  ----    ------     ----  ----                                               -------\n  Normal  Scheduled  2s    default-scheduler                                  Successfully assigned e2e-tests-kubectl-4g6lp/redis-master-l9djh to craig-k8s-certification-1-stellar-hand-0\n  Normal  Pulled     1s    kubelet, craig-k8s-certification-1-stellar-hand-0  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, craig-k8s-certification-1-stellar-hand-0  Created container\n  Normal  Started    0s    kubelet, craig-k8s-certification-1-stellar-hand-0  Started container\n"
May 11 00:52:24.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 describe rc redis-master --namespace=e2e-tests-kubectl-4g6lp'
May 11 00:52:24.947: INFO: stderr: ""
May 11 00:52:24.947: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-4g6lp\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-l9djh\n"
May 11 00:52:24.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 describe service redis-master --namespace=e2e-tests-kubectl-4g6lp'
May 11 00:52:25.049: INFO: stderr: ""
May 11 00:52:25.049: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-4g6lp\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.233.40.252\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.233.122.250:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 11 00:52:25.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 describe node craig-k8s-certification-1-stellar-hand-0'
May 11 00:52:25.165: INFO: stderr: ""
May 11 00:52:25.165: INFO: stdout: "Name:               craig-k8s-certification-1-stellar-hand-0\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=craig-k8s-certification-1-stellar-hand-0\n                    node-role.kubernetes.io/node=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 11 May 2019 00:11:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 11 May 2019 00:52:17 +0000   Sat, 11 May 2019 00:11:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 11 May 2019 00:52:17 +0000   Sat, 11 May 2019 00:11:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 11 May 2019 00:52:17 +0000   Sat, 11 May 2019 00:11:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 11 May 2019 00:52:17 +0000   Sat, 11 May 2019 00:12:47 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  70.0.51.31\n  Hostname:    craig-k8s-certification-1-stellar-hand-0\nCapacity:\n cpu:                4\n ephemeral-storage:  20507216Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8009764Ki\n pods:               110\nAllocatable:\n cpu:                3900m\n ephemeral-storage:  18899450235\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7657364Ki\n pods:               110\nSystem Info:\n Machine ID:                 7656e291d27f4b47a0968369c19b523e\n System UUID:                564DF40C-A00E-BA0B-D943-1BED9D1027F0\n Boot ID:                    5514670d-ccfa-4227-8d7c-5db048d8b466\n Kernel Version:             3.10.0-862.3.2.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.6\n Kubelet Version:            v1.13.2\n Kube-Proxy Version:         v1.13.2\nPodCIDR:                     10.233.67.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-4g6lp    redis-master-l9djh                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-2csqh    0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                calico-node-hh8j6                                          150m (3%)     300m (7%)   64M (0%)         500M (6%)      39m\n  kube-system                kube-proxy-k5lk8                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\n  kube-system                kubernetes-dashboard-8457c55f89-wl2rw                      50m (1%)      100m (2%)   64M (0%)         256M (3%)      38m\n  kube-system                nginx-proxy-craig-k8s-certification-1-stellar-hand-0       25m (0%)      300m (7%)   32M (0%)         512M (6%)      40m\n  kube-system                portworx-znwr7                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         38m\n  kube-system                stork-d8fc784c7-84cjw                                      100m (2%)     0 (0%)      0 (0%)           0 (0%)         38m\n  kube-system                stork-scheduler-75b8f4d565-6ntdx                           100m (2%)     0 (0%)      0 (0%)           0 (0%)         38m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                425m (10%)  700m (17%)\n  memory             160M (2%)   1268M (16%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                                                  Message\n  ----    ------                   ----               ----                                                  -------\n  Normal  Starting                 40m                kubelet, craig-k8s-certification-1-stellar-hand-0     Starting kubelet.\n  Normal  NodeHasSufficientMemory  40m (x2 over 40m)  kubelet, craig-k8s-certification-1-stellar-hand-0     Node craig-k8s-certification-1-stellar-hand-0 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    40m (x2 over 40m)  kubelet, craig-k8s-certification-1-stellar-hand-0     Node craig-k8s-certification-1-stellar-hand-0 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     40m (x2 over 40m)  kubelet, craig-k8s-certification-1-stellar-hand-0     Node craig-k8s-certification-1-stellar-hand-0 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  40m                kubelet, craig-k8s-certification-1-stellar-hand-0     Updated Node Allocatable limit across pods\n  Normal  Starting                 40m                kube-proxy, craig-k8s-certification-1-stellar-hand-0  Starting kube-proxy.\n  Normal  Starting                 39m                kubelet, craig-k8s-certification-1-stellar-hand-0     Starting kubelet.\n  Normal  NodeHasSufficientMemory  39m                kubelet, craig-k8s-certification-1-stellar-hand-0     Node craig-k8s-certification-1-stellar-hand-0 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    39m                kubelet, craig-k8s-certification-1-stellar-hand-0     Node craig-k8s-certification-1-stellar-hand-0 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     39m                kubelet, craig-k8s-certification-1-stellar-hand-0     Node craig-k8s-certification-1-stellar-hand-0 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  39m                kubelet, craig-k8s-certification-1-stellar-hand-0     Updated Node Allocatable limit across pods\n  Normal  NodeReady                39m                kubelet, craig-k8s-certification-1-stellar-hand-0     Node craig-k8s-certification-1-stellar-hand-0 status is now: NodeReady\n"
May 11 00:52:25.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 describe namespace e2e-tests-kubectl-4g6lp'
May 11 00:52:25.265: INFO: stderr: ""
May 11 00:52:25.265: INFO: stdout: "Name:         e2e-tests-kubectl-4g6lp\nLabels:       e2e-framework=kubectl\n              e2e-run=4dcc6f86-7383-11e9-9c46-760f9b3dbd5d\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:52:25.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4g6lp" for this suite.
May 11 00:52:47.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:52:47.376: INFO: namespace: e2e-tests-kubectl-4g6lp, resource: bindings, ignored listing per whitelist
May 11 00:52:47.376: INFO: namespace e2e-tests-kubectl-4g6lp deletion completed in 22.107603565s

• [SLOW TEST:24.157 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:52:47.376: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 11 00:52:47.503: INFO: Waiting up to 5m0s for pod "pod-182daca3-7387-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-pdg75" to be "success or failure"
May 11 00:52:47.540: INFO: Pod "pod-182daca3-7387-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 37.154862ms
May 11 00:52:49.650: INFO: Pod "pod-182daca3-7387-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.146506579s
STEP: Saw pod success
May 11 00:52:49.650: INFO: Pod "pod-182daca3-7387-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:52:49.663: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-182daca3-7387-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 00:52:49.688: INFO: Waiting for pod pod-182daca3-7387-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:52:49.852: INFO: Pod pod-182daca3-7387-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:52:49.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pdg75" for this suite.
May 11 00:52:56.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:52:56.199: INFO: namespace: e2e-tests-emptydir-pdg75, resource: bindings, ignored listing per whitelist
May 11 00:52:56.247: INFO: namespace e2e-tests-emptydir-pdg75 deletion completed in 6.391637566s

• [SLOW TEST:8.871 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:52:56.247: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 11 00:53:01.122: INFO: Successfully updated pod "labelsupdate1d8ace49-7387-11e9-9c46-760f9b3dbd5d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:53:03.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n4c55" for this suite.
May 11 00:53:25.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:53:25.606: INFO: namespace: e2e-tests-projected-n4c55, resource: bindings, ignored listing per whitelist
May 11 00:53:25.609: INFO: namespace e2e-tests-projected-n4c55 deletion completed in 22.328542506s

• [SLOW TEST:29.362 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:53:25.610: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:53:25.789: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2f008c5d-7387-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-55ll5" to be "success or failure"
May 11 00:53:25.793: INFO: Pod "downwardapi-volume-2f008c5d-7387-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.626724ms
May 11 00:53:27.799: INFO: Pod "downwardapi-volume-2f008c5d-7387-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010169169s
May 11 00:53:29.801: INFO: Pod "downwardapi-volume-2f008c5d-7387-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012445548s
STEP: Saw pod success
May 11 00:53:29.801: INFO: Pod "downwardapi-volume-2f008c5d-7387-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:53:29.803: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-2f008c5d-7387-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:53:29.818: INFO: Waiting for pod downwardapi-volume-2f008c5d-7387-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:53:29.820: INFO: Pod downwardapi-volume-2f008c5d-7387-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:53:29.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-55ll5" for this suite.
May 11 00:53:35.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:53:35.841: INFO: namespace: e2e-tests-projected-55ll5, resource: bindings, ignored listing per whitelist
May 11 00:53:35.900: INFO: namespace e2e-tests-projected-55ll5 deletion completed in 6.077274782s

• [SLOW TEST:10.290 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:53:35.900: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 11 00:53:44.042: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:44.042: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:44.230: INFO: Exec stderr: ""
May 11 00:53:44.230: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:44.230: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:44.436: INFO: Exec stderr: ""
May 11 00:53:44.436: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:44.436: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:44.597: INFO: Exec stderr: ""
May 11 00:53:44.597: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:44.597: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:44.775: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 11 00:53:44.775: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:44.775: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:44.938: INFO: Exec stderr: ""
May 11 00:53:44.939: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:44.939: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:45.106: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 11 00:53:45.106: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:45.106: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:45.279: INFO: Exec stderr: ""
May 11 00:53:45.279: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:45.279: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:45.469: INFO: Exec stderr: ""
May 11 00:53:45.469: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:45.469: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:45.627: INFO: Exec stderr: ""
May 11 00:53:45.627: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mnpt2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 00:53:45.627: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 00:53:45.790: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:53:45.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-mnpt2" for this suite.
May 11 00:54:23.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:54:23.808: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-mnpt2, resource: bindings, ignored listing per whitelist
May 11 00:54:23.856: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-mnpt2 deletion completed in 38.06217084s

• [SLOW TEST:47.956 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:54:23.856: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 11 00:54:23.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-g27th'
May 11 00:54:24.060: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 11 00:54:24.060: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
May 11 00:54:28.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-g27th'
May 11 00:54:28.256: INFO: stderr: ""
May 11 00:54:28.256: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:54:28.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g27th" for this suite.
May 11 00:55:50.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:55:50.346: INFO: namespace: e2e-tests-kubectl-g27th, resource: bindings, ignored listing per whitelist
May 11 00:55:50.367: INFO: namespace e2e-tests-kubectl-g27th deletion completed in 1m22.096470923s

• [SLOW TEST:86.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:55:50.367: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:55:50.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-cw4gl" for this suite.
May 11 00:56:04.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:56:04.495: INFO: namespace: e2e-tests-kubelet-test-cw4gl, resource: bindings, ignored listing per whitelist
May 11 00:56:04.507: INFO: namespace e2e-tests-kubelet-test-cw4gl deletion completed in 14.07375476s

• [SLOW TEST:14.140 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:56:04.507: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-wc92c in namespace e2e-tests-proxy-krn4c
I0511 00:56:04.555343      16 runners.go:184] Created replication controller with name: proxy-service-wc92c, namespace: e2e-tests-proxy-krn4c, replica count: 1
I0511 00:56:05.605900      16 runners.go:184] proxy-service-wc92c Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0511 00:56:06.606130      16 runners.go:184] proxy-service-wc92c Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0511 00:56:07.606319      16 runners.go:184] proxy-service-wc92c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0511 00:56:08.606517      16 runners.go:184] proxy-service-wc92c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0511 00:56:09.606820      16 runners.go:184] proxy-service-wc92c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0511 00:56:10.607118      16 runners.go:184] proxy-service-wc92c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0511 00:56:11.607474      16 runners.go:184] proxy-service-wc92c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0511 00:56:12.607757      16 runners.go:184] proxy-service-wc92c Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 11 00:56:12.610: INFO: setup took 8.063770364s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 11 00:56:12.613: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 3.134862ms)
May 11 00:56:12.618: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 7.710741ms)
May 11 00:56:12.618: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 7.729852ms)
May 11 00:56:12.619: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 7.892298ms)
May 11 00:56:12.619: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 7.859133ms)
May 11 00:56:12.619: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 7.901648ms)
May 11 00:56:12.619: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 7.826397ms)
May 11 00:56:12.623: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 12.457135ms)
May 11 00:56:12.623: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 12.509504ms)
May 11 00:56:12.623: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 12.591666ms)
May 11 00:56:12.623: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 12.192785ms)
May 11 00:56:12.625: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 14.359382ms)
May 11 00:56:12.625: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 14.795071ms)
May 11 00:56:12.626: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 15.286816ms)
May 11 00:56:12.628: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 17.093951ms)
May 11 00:56:12.628: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 17.746374ms)
May 11 00:56:12.632: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 3.766097ms)
May 11 00:56:12.634: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 6.391982ms)
May 11 00:56:12.634: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 5.775805ms)
May 11 00:56:12.634: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 6.580644ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 6.301163ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 6.11515ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 6.519962ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 6.257099ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 6.210363ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 6.119669ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 6.134844ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 6.652847ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.330615ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.994343ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 6.551499ms)
May 11 00:56:12.635: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 7.150006ms)
May 11 00:56:12.638: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 2.286077ms)
May 11 00:56:12.638: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 2.416707ms)
May 11 00:56:12.640: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 3.742568ms)
May 11 00:56:12.640: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 4.298446ms)
May 11 00:56:12.640: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 4.854696ms)
May 11 00:56:12.640: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 4.008004ms)
May 11 00:56:12.640: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 4.423586ms)
May 11 00:56:12.641: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 4.404229ms)
May 11 00:56:12.641: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 4.369152ms)
May 11 00:56:12.641: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 4.145749ms)
May 11 00:56:12.643: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.37288ms)
May 11 00:56:12.643: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 7.859752ms)
May 11 00:56:12.644: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 7.655323ms)
May 11 00:56:12.644: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.9291ms)
May 11 00:56:12.644: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 7.466541ms)
May 11 00:56:12.644: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 8.299303ms)
May 11 00:56:12.647: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 2.619771ms)
May 11 00:56:12.649: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 3.7557ms)
May 11 00:56:12.649: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 4.54643ms)
May 11 00:56:12.649: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 4.502073ms)
May 11 00:56:12.650: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 4.861026ms)
May 11 00:56:12.650: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 5.266223ms)
May 11 00:56:12.650: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 5.592974ms)
May 11 00:56:12.650: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.340021ms)
May 11 00:56:12.650: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.43767ms)
May 11 00:56:12.650: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.037071ms)
May 11 00:56:12.652: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 6.303771ms)
May 11 00:56:12.652: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 7.144591ms)
May 11 00:56:12.652: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 7.838761ms)
May 11 00:56:12.652: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.609179ms)
May 11 00:56:12.652: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 7.18109ms)
May 11 00:56:12.652: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 7.217036ms)
May 11 00:56:12.657: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 4.367583ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 7.056009ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 6.771803ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 7.18247ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 6.52022ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 6.617412ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 7.109046ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 7.061849ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 6.757786ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 7.018229ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.976303ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 6.747926ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 6.951912ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 6.668697ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 7.368887ms)
May 11 00:56:12.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 6.885612ms)
May 11 00:56:12.663: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 3.052206ms)
May 11 00:56:12.666: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 6.200105ms)
May 11 00:56:12.666: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 6.012095ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 6.404024ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 6.289004ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 6.274357ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.281098ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 6.685371ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 6.626209ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 6.842711ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 6.620624ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 7.019258ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 6.770724ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 6.633619ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.280877ms)
May 11 00:56:12.667: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.808051ms)
May 11 00:56:12.670: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 2.596032ms)
May 11 00:56:12.671: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 3.861227ms)
May 11 00:56:12.672: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 4.078103ms)
May 11 00:56:12.672: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 4.070507ms)
May 11 00:56:12.672: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 4.355142ms)
May 11 00:56:12.672: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 3.936198ms)
May 11 00:56:12.672: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 4.458956ms)
May 11 00:56:12.672: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 4.23063ms)
May 11 00:56:12.673: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 4.412453ms)
May 11 00:56:12.673: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 4.939602ms)
May 11 00:56:12.673: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 5.284714ms)
May 11 00:56:12.673: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 5.21331ms)
May 11 00:56:12.673: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 5.555191ms)
May 11 00:56:12.673: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 5.384739ms)
May 11 00:56:12.673: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 5.473028ms)
May 11 00:56:12.673: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 5.574525ms)
May 11 00:56:12.676: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 2.148528ms)
May 11 00:56:12.677: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 3.520824ms)
May 11 00:56:12.677: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 3.54839ms)
May 11 00:56:12.677: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 3.281ms)
May 11 00:56:12.677: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 3.46555ms)
May 11 00:56:12.678: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 3.534775ms)
May 11 00:56:12.678: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 3.790783ms)
May 11 00:56:12.678: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 3.963853ms)
May 11 00:56:12.679: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.59918ms)
May 11 00:56:12.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.090828ms)
May 11 00:56:12.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 5.865449ms)
May 11 00:56:12.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 5.985805ms)
May 11 00:56:12.681: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.482105ms)
May 11 00:56:12.682: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 7.551075ms)
May 11 00:56:12.682: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 8.014988ms)
May 11 00:56:12.682: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 8.226582ms)
May 11 00:56:12.684: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 2.00948ms)
May 11 00:56:12.688: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 5.550899ms)
May 11 00:56:12.688: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 5.87401ms)
May 11 00:56:12.688: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.139066ms)
May 11 00:56:12.688: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 5.919526ms)
May 11 00:56:12.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 5.417362ms)
May 11 00:56:12.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.796876ms)
May 11 00:56:12.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.995462ms)
May 11 00:56:12.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 6.246288ms)
May 11 00:56:12.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.504358ms)
May 11 00:56:12.691: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 8.389901ms)
May 11 00:56:12.691: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 7.780468ms)
May 11 00:56:12.691: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 8.156246ms)
May 11 00:56:12.691: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 7.959349ms)
May 11 00:56:12.691: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.897131ms)
May 11 00:56:12.691: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 7.787181ms)
May 11 00:56:12.694: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 3.484568ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 3.680339ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 3.371454ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 3.950157ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 3.943128ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 3.883567ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 3.924728ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 4.218199ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 3.949614ms)
May 11 00:56:12.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 4.129061ms)
May 11 00:56:12.697: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.133949ms)
May 11 00:56:12.697: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 6.32663ms)
May 11 00:56:12.698: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.299185ms)
May 11 00:56:12.698: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 7.327793ms)
May 11 00:56:12.698: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.056754ms)
May 11 00:56:12.698: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 7.422583ms)
May 11 00:56:12.701: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 2.134515ms)
May 11 00:56:12.701: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 2.539173ms)
May 11 00:56:12.703: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 4.245342ms)
May 11 00:56:12.704: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 4.59924ms)
May 11 00:56:12.704: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 4.967431ms)
May 11 00:56:12.704: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 4.737398ms)
May 11 00:56:12.704: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.365685ms)
May 11 00:56:12.704: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 5.443777ms)
May 11 00:56:12.704: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 4.891278ms)
May 11 00:56:12.704: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 4.954615ms)
May 11 00:56:12.704: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.115195ms)
May 11 00:56:12.705: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 5.919552ms)
May 11 00:56:12.705: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 5.698259ms)
May 11 00:56:12.705: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 6.267771ms)
May 11 00:56:12.705: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 6.339069ms)
May 11 00:56:12.705: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.579587ms)
May 11 00:56:12.708: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 2.543698ms)
May 11 00:56:12.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 3.795458ms)
May 11 00:56:12.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 4.53881ms)
May 11 00:56:12.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 4.364223ms)
May 11 00:56:12.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 4.307023ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 7.3769ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 7.617672ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 7.565123ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 7.517487ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 7.848477ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 7.581517ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 7.939992ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 7.687607ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 8.024751ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 7.544974ms)
May 11 00:56:12.713: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.839095ms)
May 11 00:56:12.715: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 1.933875ms)
May 11 00:56:12.716: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 1.998006ms)
May 11 00:56:12.718: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 4.661344ms)
May 11 00:56:12.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 4.606553ms)
May 11 00:56:12.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 4.717662ms)
May 11 00:56:12.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 5.040172ms)
May 11 00:56:12.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.025995ms)
May 11 00:56:12.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.095295ms)
May 11 00:56:12.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.243665ms)
May 11 00:56:12.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 5.222568ms)
May 11 00:56:12.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 5.613196ms)
May 11 00:56:12.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 6.04406ms)
May 11 00:56:12.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 6.136078ms)
May 11 00:56:12.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 6.134478ms)
May 11 00:56:12.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.199833ms)
May 11 00:56:12.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.030139ms)
May 11 00:56:12.722: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 2.328432ms)
May 11 00:56:12.723: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 2.152204ms)
May 11 00:56:12.726: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 5.747277ms)
May 11 00:56:12.726: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.319454ms)
May 11 00:56:12.726: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 5.928063ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 7.181095ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 7.036993ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 7.078699ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 7.209576ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 7.393268ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 7.344845ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 7.565887ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 7.387732ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 7.557954ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.680908ms)
May 11 00:56:12.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 7.740033ms)
May 11 00:56:12.731: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 2.218316ms)
May 11 00:56:12.733: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 3.905658ms)
May 11 00:56:12.733: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 4.127891ms)
May 11 00:56:12.733: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 4.875332ms)
May 11 00:56:12.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 4.607179ms)
May 11 00:56:12.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 4.979415ms)
May 11 00:56:12.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 4.471924ms)
May 11 00:56:12.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 4.577734ms)
May 11 00:56:12.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 5.49951ms)
May 11 00:56:12.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 5.375511ms)
May 11 00:56:12.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 4.79226ms)
May 11 00:56:12.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.449143ms)
May 11 00:56:12.736: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 7.181276ms)
May 11 00:56:12.736: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 7.231583ms)
May 11 00:56:12.737: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.55546ms)
May 11 00:56:12.737: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 7.469936ms)
May 11 00:56:12.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 1.565295ms)
May 11 00:56:12.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 2.66376ms)
May 11 00:56:12.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 2.76448ms)
May 11 00:56:12.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 2.915452ms)
May 11 00:56:12.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 3.79572ms)
May 11 00:56:12.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 3.6968ms)
May 11 00:56:12.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 3.973052ms)
May 11 00:56:12.742: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 3.936918ms)
May 11 00:56:12.742: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 5.090869ms)
May 11 00:56:12.742: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 4.746786ms)
May 11 00:56:12.743: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.211416ms)
May 11 00:56:12.743: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 5.196715ms)
May 11 00:56:12.743: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 5.349502ms)
May 11 00:56:12.743: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 5.697833ms)
May 11 00:56:12.743: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 5.741597ms)
May 11 00:56:12.743: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 5.733262ms)
May 11 00:56:12.748: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 3.554629ms)
May 11 00:56:12.748: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 3.640765ms)
May 11 00:56:12.748: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 4.574621ms)
May 11 00:56:12.748: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 4.288337ms)
May 11 00:56:12.748: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 3.915187ms)
May 11 00:56:12.749: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.152223ms)
May 11 00:56:12.749: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.46046ms)
May 11 00:56:12.749: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.300545ms)
May 11 00:56:12.749: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.331498ms)
May 11 00:56:12.749: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 4.966164ms)
May 11 00:56:12.749: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 5.825932ms)
May 11 00:56:12.749: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 5.449952ms)
May 11 00:56:12.750: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 6.002323ms)
May 11 00:56:12.750: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 5.716143ms)
May 11 00:56:12.750: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 5.691265ms)
May 11 00:56:12.750: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 5.558977ms)
May 11 00:56:12.754: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 3.937631ms)
May 11 00:56:12.754: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 4.303516ms)
May 11 00:56:12.754: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 3.928154ms)
May 11 00:56:12.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 3.995402ms)
May 11 00:56:12.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 3.892247ms)
May 11 00:56:12.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 4.809473ms)
May 11 00:56:12.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 4.591815ms)
May 11 00:56:12.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 4.450485ms)
May 11 00:56:12.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 4.976727ms)
May 11 00:56:12.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 5.088068ms)
May 11 00:56:12.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 5.613305ms)
May 11 00:56:12.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.228216ms)
May 11 00:56:12.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 6.147869ms)
May 11 00:56:12.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 6.408083ms)
May 11 00:56:12.757: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 5.834758ms)
May 11 00:56:12.757: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 6.500044ms)
May 11 00:56:12.762: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 4.82864ms)
May 11 00:56:12.762: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 4.766237ms)
May 11 00:56:12.762: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.106476ms)
May 11 00:56:12.762: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 5.351978ms)
May 11 00:56:12.762: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 5.390458ms)
May 11 00:56:12.762: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 5.356029ms)
May 11 00:56:12.763: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 5.642509ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 7.217971ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 7.066108ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 7.420147ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.913704ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 6.98394ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 7.777924ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 7.919964ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 7.677503ms)
May 11 00:56:12.765: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 7.973731ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz/proxy/rewriteme"... (200; 6.497672ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:1080/proxy/... (200; 6.075328ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 5.59261ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:460/proxy/: tls baz (200; 6.400881ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:1080/proxy/rewri... (200; 5.723973ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/http:proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.461414ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:160/proxy/: foo (200; 6.000769ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname2/proxy/: tls qux (200; 5.881667ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:462/proxy/: tls qux (200; 6.384317ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/proxy-service-wc92c-9xgvz:162/proxy/: bar (200; 5.634592ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-krn4c/pods/https:proxy-service-wc92c-9xgvz:443/proxy/... (200; 5.449156ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname1/proxy/: foo (200; 6.304955ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/https:proxy-service-wc92c:tlsportname1/proxy/: tls baz (200; 6.178284ms)
May 11 00:56:12.772: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/http:proxy-service-wc92c:portname2/proxy/: bar (200; 5.571513ms)
May 11 00:56:12.773: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname1/proxy/: foo (200; 6.862642ms)
May 11 00:56:12.773: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-krn4c/services/proxy-service-wc92c:portname2/proxy/: bar (200; 6.091207ms)
STEP: deleting ReplicationController proxy-service-wc92c in namespace e2e-tests-proxy-krn4c, will wait for the garbage collector to delete the pods
May 11 00:56:12.829: INFO: Deleting ReplicationController proxy-service-wc92c took: 4.585966ms
May 11 00:56:12.929: INFO: Terminating ReplicationController proxy-service-wc92c pods took: 100.189601ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:56:17.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-krn4c" for this suite.
May 11 00:56:23.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:56:23.259: INFO: namespace: e2e-tests-proxy-krn4c, resource: bindings, ignored listing per whitelist
May 11 00:56:23.343: INFO: namespace e2e-tests-proxy-krn4c deletion completed in 6.109545689s

• [SLOW TEST:18.836 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:56:23.343: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 00:56:23.440: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98e31325-7387-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-mhhv4" to be "success or failure"
May 11 00:56:23.448: INFO: Pod "downwardapi-volume-98e31325-7387-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.459126ms
May 11 00:56:25.451: INFO: Pod "downwardapi-volume-98e31325-7387-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010715026s
May 11 00:56:27.453: INFO: Pod "downwardapi-volume-98e31325-7387-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012925529s
STEP: Saw pod success
May 11 00:56:27.453: INFO: Pod "downwardapi-volume-98e31325-7387-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:56:27.454: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-98e31325-7387-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 00:56:27.466: INFO: Waiting for pod downwardapi-volume-98e31325-7387-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:56:27.468: INFO: Pod downwardapi-volume-98e31325-7387-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:56:27.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mhhv4" for this suite.
May 11 00:56:33.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:56:33.491: INFO: namespace: e2e-tests-downward-api-mhhv4, resource: bindings, ignored listing per whitelist
May 11 00:56:33.553: INFO: namespace e2e-tests-downward-api-mhhv4 deletion completed in 6.082454338s

• [SLOW TEST:10.210 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:56:33.553: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-qfc6f.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qfc6f.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qfc6f.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-qfc6f.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qfc6f.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qfc6f.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 11 00:57:01.840: INFO: DNS probes using e2e-tests-dns-qfc6f/dns-test-9f0f71be-7387-11e9-9c46-760f9b3dbd5d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:57:01.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-qfc6f" for this suite.
May 11 00:57:07.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:57:07.949: INFO: namespace: e2e-tests-dns-qfc6f, resource: bindings, ignored listing per whitelist
May 11 00:57:07.966: INFO: namespace e2e-tests-dns-qfc6f deletion completed in 6.08236741s

• [SLOW TEST:34.413 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:57:07.966: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b37604f1-7387-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 00:57:08.019: INFO: Waiting up to 5m0s for pod "pod-configmaps-b376473a-7387-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-4n74j" to be "success or failure"
May 11 00:57:08.021: INFO: Pod "pod-configmaps-b376473a-7387-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.666226ms
May 11 00:57:10.024: INFO: Pod "pod-configmaps-b376473a-7387-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004544438s
May 11 00:57:12.026: INFO: Pod "pod-configmaps-b376473a-7387-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006909652s
STEP: Saw pod success
May 11 00:57:12.026: INFO: Pod "pod-configmaps-b376473a-7387-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 00:57:12.028: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-configmaps-b376473a-7387-11e9-9c46-760f9b3dbd5d container configmap-volume-test: <nil>
STEP: delete the pod
May 11 00:57:12.039: INFO: Waiting for pod pod-configmaps-b376473a-7387-11e9-9c46-760f9b3dbd5d to disappear
May 11 00:57:12.041: INFO: Pod pod-configmaps-b376473a-7387-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:57:12.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4n74j" for this suite.
May 11 00:57:18.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:57:18.082: INFO: namespace: e2e-tests-configmap-4n74j, resource: bindings, ignored listing per whitelist
May 11 00:57:18.108: INFO: namespace e2e-tests-configmap-4n74j deletion completed in 6.065153432s

• [SLOW TEST:10.142 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:57:18.109: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-mk9x
STEP: Creating a pod to test atomic-volume-subpath
May 11 00:57:18.174: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mk9x" in namespace "e2e-tests-subpath-rqvkj" to be "success or failure"
May 11 00:57:18.181: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Pending", Reason="", readiness=false. Elapsed: 7.071173ms
May 11 00:57:20.183: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009442879s
May 11 00:57:22.186: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 4.01214254s
May 11 00:57:24.188: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 6.014494547s
May 11 00:57:26.191: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 8.017051121s
May 11 00:57:28.194: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 10.0199918s
May 11 00:57:30.196: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 12.022192983s
May 11 00:57:32.199: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 14.025462698s
May 11 00:57:34.203: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 16.02878646s
May 11 00:57:36.205: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 18.031127088s
May 11 00:57:38.208: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 20.033927065s
May 11 00:57:40.211: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Running", Reason="", readiness=false. Elapsed: 22.037257925s
May 11 00:57:42.260: INFO: Pod "pod-subpath-test-configmap-mk9x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.085706867s
STEP: Saw pod success
May 11 00:57:42.260: INFO: Pod "pod-subpath-test-configmap-mk9x" satisfied condition "success or failure"
May 11 00:57:42.262: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-subpath-test-configmap-mk9x container test-container-subpath-configmap-mk9x: <nil>
STEP: delete the pod
May 11 00:57:42.928: INFO: Waiting for pod pod-subpath-test-configmap-mk9x to disappear
May 11 00:57:43.574: INFO: Pod pod-subpath-test-configmap-mk9x no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mk9x
May 11 00:57:43.575: INFO: Deleting pod "pod-subpath-test-configmap-mk9x" in namespace "e2e-tests-subpath-rqvkj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:57:43.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rqvkj" for this suite.
May 11 00:57:49.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:57:50.025: INFO: namespace: e2e-tests-subpath-rqvkj, resource: bindings, ignored listing per whitelist
May 11 00:57:50.025: INFO: namespace e2e-tests-subpath-rqvkj deletion completed in 6.110615404s

• [SLOW TEST:31.917 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:57:50.025: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 00:57:54.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-v9kjm" for this suite.
May 11 00:58:38.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 00:58:38.165: INFO: namespace: e2e-tests-kubelet-test-v9kjm, resource: bindings, ignored listing per whitelist
May 11 00:58:38.172: INFO: namespace e2e-tests-kubelet-test-v9kjm deletion completed in 44.075784525s

• [SLOW TEST:48.147 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 00:58:38.172: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 00:58:38.243: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 11 00:58:38.248: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:38.250: INFO: Number of nodes with available pods: 0
May 11 00:58:38.250: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 00:58:39.253: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:39.256: INFO: Number of nodes with available pods: 0
May 11 00:58:39.256: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 00:58:40.254: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:40.256: INFO: Number of nodes with available pods: 0
May 11 00:58:40.256: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 00:58:41.253: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:41.256: INFO: Number of nodes with available pods: 0
May 11 00:58:41.256: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 00:58:42.253: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:42.255: INFO: Number of nodes with available pods: 2
May 11 00:58:42.255: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 00:58:43.253: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:43.255: INFO: Number of nodes with available pods: 3
May 11 00:58:43.255: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 11 00:58:43.271: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:43.271: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:43.271: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:43.273: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:44.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:44.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:44.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:44.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:45.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:45.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:45.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:45.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:46.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:46.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:46.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:46.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:47.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:47.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:47.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:47.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:48.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:48.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:48.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:48.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:49.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:49.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:49.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:49.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:50.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:50.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:50.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:50.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:51.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:51.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:51.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:51.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:52.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:52.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:52.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:52.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:53.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:53.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:53.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:53.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:54.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:54.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:54.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:54.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:55.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:55.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:55.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:55.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:56.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:56.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:56.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:56.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:57.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:57.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:57.277: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:57.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:58.278: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:58.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:58.278: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:58.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:58:59.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:59.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:59.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:58:59.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:00.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:00.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:00.277: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:00.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:01.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:01.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:01.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:01.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:02.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:02.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:02.277: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:02.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:03.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:03.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:03.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:03.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:04.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:04.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:04.278: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:04.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:05.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:05.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:05.277: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:05.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:06.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:06.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:06.277: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:06.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:07.278: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:07.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:07.278: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:07.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:08.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:08.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:08.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:08.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:09.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:09.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:09.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:09.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:10.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:10.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:10.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:10.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:11.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:11.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:11.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:11.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:12.280: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:12.280: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:12.280: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:12.283: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:13.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:13.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:13.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:13.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:14.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:14.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:14.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:14.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:15.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:15.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:15.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:15.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:16.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:16.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:16.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:16.276: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:16.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:17.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:17.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:17.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:17.276: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:17.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:18.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:18.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:18.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:18.276: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:18.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:19.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:19.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:19.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:19.276: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:19.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:20.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:20.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:20.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:20.276: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:20.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:21.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:21.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:21.277: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:21.277: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:21.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:22.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:22.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:22.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:22.276: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:22.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:23.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:23.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:23.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:23.276: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:23.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:24.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:24.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:24.276: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:24.276: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:24.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:25.279: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:25.279: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:25.279: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:25.279: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:25.284: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:26.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:26.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:26.277: INFO: Wrong image for pod: daemon-set-w2gvl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:26.277: INFO: Pod daemon-set-w2gvl is not available
May 11 00:59:26.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:27.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:27.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:27.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:28.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:28.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:28.276: INFO: Pod daemon-set-xrlg8 is not available
May 11 00:59:28.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:29.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:29.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:29.276: INFO: Pod daemon-set-xrlg8 is not available
May 11 00:59:29.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:30.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:30.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:30.276: INFO: Pod daemon-set-xrlg8 is not available
May 11 00:59:30.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:31.278: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:31.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:31.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:32.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:32.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:32.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:33.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:33.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:33.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:34.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:34.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:34.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:35.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:35.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:35.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:36.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:36.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:36.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:37.278: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:37.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:37.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:38.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:38.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:38.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:39.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:39.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:39.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:40.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:40.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:40.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:41.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:41.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:41.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:42.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:42.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:42.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:43.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:43.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:43.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:44.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:44.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:44.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:45.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:45.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:45.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:46.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:46.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:46.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:47.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:47.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:47.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:48.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:48.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:48.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:49.278: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:49.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:49.282: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:50.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:50.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:50.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:51.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:51.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:51.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:52.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:52.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:52.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:53.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:53.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:53.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:54.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:54.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:54.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:55.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:55.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:55.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:56.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:56.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:56.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:57.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:57.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:57.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:58.283: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:58.283: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:58.286: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 00:59:59.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:59.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 00:59:59.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:00.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:00.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:00.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:01.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:01.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:01.282: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:02.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:02.276: INFO: Pod daemon-set-lsbkt is not available
May 11 01:00:02.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:02.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:03.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:03.276: INFO: Pod daemon-set-lsbkt is not available
May 11 01:00:03.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:03.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:04.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:04.277: INFO: Pod daemon-set-lsbkt is not available
May 11 01:00:04.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:04.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:05.276: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:05.276: INFO: Pod daemon-set-lsbkt is not available
May 11 01:00:05.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:05.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:06.277: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:06.277: INFO: Pod daemon-set-lsbkt is not available
May 11 01:00:06.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:06.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:07.678: INFO: Wrong image for pod: daemon-set-lsbkt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:07.678: INFO: Pod daemon-set-lsbkt is not available
May 11 01:00:07.678: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:07.683: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:08.656: INFO: Pod daemon-set-2zfpq is not available
May 11 01:00:08.656: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:08.660: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:09.276: INFO: Pod daemon-set-2zfpq is not available
May 11 01:00:09.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:09.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:10.278: INFO: Pod daemon-set-2zfpq is not available
May 11 01:00:10.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:10.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:11.441: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:11.444: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:12.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:12.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:13.289: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:13.291: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:14.306: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:14.309: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:15.507: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:15.512: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:16.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:16.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:17.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:17.278: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:18.385: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:18.387: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:19.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:19.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:20.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:20.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:21.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:21.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:22.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:22.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:23.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:23.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:24.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:24.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:25.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:25.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:26.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:26.281: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:27.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:27.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:28.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:28.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:29.410: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:29.413: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:30.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:30.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:31.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:31.282: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:32.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:32.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:33.330: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:33.404: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:34.278: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:34.283: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:35.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:35.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:36.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:36.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:37.283: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:37.288: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:38.418: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:38.421: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:39.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:39.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:40.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:40.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:41.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:41.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:42.277: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:42.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:43.276: INFO: Wrong image for pod: daemon-set-q8lws. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 11 01:00:43.276: INFO: Pod daemon-set-q8lws is not available
May 11 01:00:43.280: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:44.276: INFO: Pod daemon-set-xqf5b is not available
May 11 01:00:44.279: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May 11 01:00:44.282: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:44.284: INFO: Number of nodes with available pods: 2
May 11 01:00:44.284: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 01:00:45.292: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:45.294: INFO: Number of nodes with available pods: 2
May 11 01:00:45.294: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 01:00:46.289: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:00:46.292: INFO: Number of nodes with available pods: 3
May 11 01:00:46.292: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-bpdg7, will wait for the garbage collector to delete the pods
May 11 01:00:46.359: INFO: Deleting DaemonSet.extensions daemon-set took: 4.159693ms
May 11 01:00:46.459: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.319227ms
May 11 01:00:50.062: INFO: Number of nodes with available pods: 0
May 11 01:00:50.062: INFO: Number of running nodes: 0, number of available pods: 0
May 11 01:00:50.063: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bpdg7/daemonsets","resourceVersion":"13932"},"items":null}

May 11 01:00:50.065: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bpdg7/pods","resourceVersion":"13932"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:00:50.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bpdg7" for this suite.
May 11 01:00:56.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:00:56.139: INFO: namespace: e2e-tests-daemonsets-bpdg7, resource: bindings, ignored listing per whitelist
May 11 01:00:56.140: INFO: namespace e2e-tests-daemonsets-bpdg7 deletion completed in 6.064267797s

• [SLOW TEST:137.968 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:00:56.140: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
May 11 01:00:56.187: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-wqrtt" to be "success or failure"
May 11 01:00:56.188: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.620627ms
May 11 01:00:58.191: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004361469s
May 11 01:01:00.194: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00668748s
STEP: Saw pod success
May 11 01:01:00.194: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 11 01:01:00.195: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 11 01:01:00.208: INFO: Waiting for pod pod-host-path-test to disappear
May 11 01:01:00.210: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:01:00.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-wqrtt" for this suite.
May 11 01:01:06.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:01:06.225: INFO: namespace: e2e-tests-hostpath-wqrtt, resource: bindings, ignored listing per whitelist
May 11 01:01:06.274: INFO: namespace e2e-tests-hostpath-wqrtt deletion completed in 6.061492359s

• [SLOW TEST:10.134 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:01:06.274: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 11 01:01:10.327: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-417fe1a1-7388-11e9-9c46-760f9b3dbd5d,GenerateName:,Namespace:e2e-tests-events-t5wfk,SelfLink:/api/v1/namespaces/e2e-tests-events-t5wfk/pods/send-events-417fe1a1-7388-11e9-9c46-760f9b3dbd5d,UID:410ade66-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14085,Generation:0,CreationTimestamp:2019-05-11 01:01:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 315722328,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lrrrs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lrrrs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-lrrrs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ee3dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ee3de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:01:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:01:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:01:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:01:05 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:10.233.122.200,StartTime:2019-05-11 01:01:05 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-11 01:01:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://35358bdaef922b41fb45a8cc5e2e48ac5f2a94a934862c5e3ffd8a2b813851a9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 11 01:01:12.329: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 11 01:01:14.332: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:01:14.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-t5wfk" for this suite.
May 11 01:01:58.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:01:58.421: INFO: namespace: e2e-tests-events-t5wfk, resource: bindings, ignored listing per whitelist
May 11 01:01:58.442: INFO: namespace e2e-tests-events-t5wfk deletion completed in 44.102302511s

• [SLOW TEST:52.168 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:01:58.442: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 11 01:01:58.487: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:02:02.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8fxhz" for this suite.
May 11 01:02:24.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:02:24.709: INFO: namespace: e2e-tests-init-container-8fxhz, resource: bindings, ignored listing per whitelist
May 11 01:02:24.728: INFO: namespace e2e-tests-init-container-8fxhz deletion completed in 22.075228666s

• [SLOW TEST:26.286 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:02:24.729: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 01:02:24.785: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 11 01:02:29.787: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 11 01:02:29.787: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 11 01:02:29.798: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-vmzpd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vmzpd/deployments/test-cleanup-deployment,UID:72cbf344-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14380,Generation:1,CreationTimestamp:2019-05-11 01:02:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

May 11 01:02:29.801: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
May 11 01:02:29.801: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
May 11 01:02:29.801: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-vmzpd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vmzpd/replicasets/test-cleanup-controller,UID:6fcf8593-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14381,Generation:1,CreationTimestamp:2019-05-11 01:02:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 72cbf344-7388-11e9-9f3c-000c29c278ce 0xc0020ace27 0xc0020ace28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 11 01:02:29.804: INFO: Pod "test-cleanup-controller-2z7zc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-2z7zc,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-vmzpd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vmzpd/pods/test-cleanup-controller-2z7zc,UID:6fd078f9-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14371,Generation:0,CreationTimestamp:2019-05-11 01:02:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 6fcf8593-7388-11e9-9f3c-000c29c278ce 0xc0020ad3d7 0xc0020ad3d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pcr8g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pcr8g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pcr8g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ad440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ad460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:02:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:02:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:02:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:02:24 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:10.233.124.163,StartTime:2019-05-11 01:02:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:02:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c34cff76175ed3e9fa6085769495745258332456f44eea49b20337520926fcdf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:02:29.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vmzpd" for this suite.
May 11 01:02:35.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:02:35.901: INFO: namespace: e2e-tests-deployment-vmzpd, resource: bindings, ignored listing per whitelist
May 11 01:02:35.951: INFO: namespace e2e-tests-deployment-vmzpd deletion completed in 6.139474585s

• [SLOW TEST:11.223 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:02:35.951: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-76f44b2f-7388-11e9-9c46-760f9b3dbd5d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-76f44b2f-7388-11e9-9c46-760f9b3dbd5d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:04:06.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hx56v" for this suite.
May 11 01:04:28.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:04:28.413: INFO: namespace: e2e-tests-configmap-hx56v, resource: bindings, ignored listing per whitelist
May 11 01:04:28.447: INFO: namespace e2e-tests-configmap-hx56v deletion completed in 22.060892719s

• [SLOW TEST:112.495 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:04:28.447: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 01:04:28.495: INFO: (0) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.722213ms)
May 11 01:04:28.497: INFO: (1) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.499158ms)
May 11 01:04:28.500: INFO: (2) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.434583ms)
May 11 01:04:28.503: INFO: (3) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.849784ms)
May 11 01:04:28.505: INFO: (4) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.639455ms)
May 11 01:04:28.508: INFO: (5) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.381885ms)
May 11 01:04:28.510: INFO: (6) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.257195ms)
May 11 01:04:28.512: INFO: (7) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.209568ms)
May 11 01:04:28.516: INFO: (8) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.429861ms)
May 11 01:04:28.518: INFO: (9) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.536288ms)
May 11 01:04:28.521: INFO: (10) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.547635ms)
May 11 01:04:28.524: INFO: (11) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.992555ms)
May 11 01:04:28.527: INFO: (12) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.889247ms)
May 11 01:04:28.529: INFO: (13) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.189101ms)
May 11 01:04:28.531: INFO: (14) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.128236ms)
May 11 01:04:28.534: INFO: (15) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.351293ms)
May 11 01:04:28.536: INFO: (16) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.939715ms)
May 11 01:04:28.538: INFO: (17) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.36356ms)
May 11 01:04:28.540: INFO: (18) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.976996ms)
May 11 01:04:28.543: INFO: (19) /api/v1/nodes/craig-k8s-certification-1-stellar-hand-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.672773ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:04:28.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5vh97" for this suite.
May 11 01:04:34.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:04:34.569: INFO: namespace: e2e-tests-proxy-5vh97, resource: bindings, ignored listing per whitelist
May 11 01:04:34.607: INFO: namespace e2e-tests-proxy-5vh97 deletion completed in 6.061459616s

• [SLOW TEST:6.161 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:04:34.608: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 01:04:34.646: INFO: Creating deployment "nginx-deployment"
May 11 01:04:34.648: INFO: Waiting for observed generation 1
May 11 01:04:36.651: INFO: Waiting for all required pods to come up
May 11 01:04:36.654: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 11 01:04:38.659: INFO: Waiting for deployment "nginx-deployment" to complete
May 11 01:04:38.662: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 11 01:04:38.666: INFO: Updating deployment nginx-deployment
May 11 01:04:38.666: INFO: Waiting for observed generation 2
May 11 01:04:40.670: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 11 01:04:40.672: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 11 01:04:40.673: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 11 01:04:40.678: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 11 01:04:40.678: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 11 01:04:40.679: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 11 01:04:40.682: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 11 01:04:40.682: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 11 01:04:40.685: INFO: Updating deployment nginx-deployment
May 11 01:04:40.685: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 11 01:04:40.693: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 11 01:04:42.705: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 11 01:04:42.710: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g5jbw/deployments/nginx-deployment,UID:bd37712b-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15174,Generation:3,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-11 01:04:39 +0000 UTC 2019-05-11 01:04:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-11 01:04:40 +0000 UTC 2019-05-11 01:04:33 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 11 01:04:42.714: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g5jbw/replicasets/nginx-deployment-65bbdb5f8,UID:bf9cddfd-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15149,Generation:3,CreationTimestamp:2019-05-11 01:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bd37712b-7388-11e9-9f3c-000c29c278ce 0xc00110de17 0xc00110de18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 11 01:04:42.714: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 11 01:04:42.714: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g5jbw/replicasets/nginx-deployment-555b55d965,UID:bd383b5c-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15173,Generation:3,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bd37712b-7388-11e9-9f3c-000c29c278ce 0xc00110dd57 0xc00110dd58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 11 01:04:42.722: INFO: Pod "nginx-deployment-555b55d965-2pl9k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2pl9k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-2pl9k,UID:bd3a0634-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14974,Generation:0,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110c1e7 0xc00110c1e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110c250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110c270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:33 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:10.233.91.235,StartTime:2019-05-11 01:04:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:04:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://abac40e1b65578dad37ba02681565ce17c472e6ef301676fa66710e33ee0b1b6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.722: INFO: Pod "nginx-deployment-555b55d965-5d2pv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5d2pv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-5d2pv,UID:c0d6c8e6-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15158,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110c500 0xc00110c501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110c6c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110c6e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.723: INFO: Pod "nginx-deployment-555b55d965-68xp2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-68xp2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-68xp2,UID:c0d3ba43-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15142,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110c790 0xc00110c791}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110c850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110c870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.723: INFO: Pod "nginx-deployment-555b55d965-7dh9n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7dh9n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-7dh9n,UID:bd3ab5d9-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14983,Generation:0,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110c9c0 0xc00110c9c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110ca20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110ca40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:33 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:10.233.122.204,StartTime:2019-05-11 01:04:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:04:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://49191acc84153c0ea9097ab0b4804595f13ddf39ed1ce275f2ad8964cee9ccda}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.723: INFO: Pod "nginx-deployment-555b55d965-894tm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-894tm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-894tm,UID:c0d198f9-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15098,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110cb70 0xc00110cb71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110cc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110cc50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.723: INFO: Pod "nginx-deployment-555b55d965-dssq5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dssq5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-dssq5,UID:bd3c1260-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14964,Generation:0,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110cd10 0xc00110cd11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110cd70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110cda0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:33 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:10.233.124.166,StartTime:2019-05-11 01:04:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:04:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ab9590ca010bda253684226d5e07ae3a9e7ffb58cc10292ba6b6003069fe526e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.723: INFO: Pod "nginx-deployment-555b55d965-fxrvc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fxrvc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-fxrvc,UID:c0d25471-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15123,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110cec0 0xc00110cec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110cf20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110cf40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.723: INFO: Pod "nginx-deployment-555b55d965-hmk6m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hmk6m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-hmk6m,UID:bd3a0241-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14986,Generation:0,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110d220 0xc00110d221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110d2d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110d2f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:33 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:10.233.122.201,StartTime:2019-05-11 01:04:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:04:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c8750541b1196ec6bf805330a74bd58c04d98c24550bf51722abf2dd34bc0138}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.724: INFO: Pod "nginx-deployment-555b55d965-jrcst" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jrcst,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-jrcst,UID:c0d395d4-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15139,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110d3b0 0xc00110d3b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110d4d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110d4f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.724: INFO: Pod "nginx-deployment-555b55d965-k4cjl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k4cjl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-k4cjl,UID:c0d6be87-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15162,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc00110d5a0 0xc00110d5a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00110d600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00110d620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.724: INFO: Pod "nginx-deployment-555b55d965-lftlt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lftlt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-lftlt,UID:bd3ac5c7-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14970,Generation:0,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8e270 0xc001f8e271}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8e2e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8e300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:33 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:10.233.124.167,StartTime:2019-05-11 01:04:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:04:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f5bc23356603d31a941518afafa5de457698c2c284bad4cf5781cd3bd32daee7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.724: INFO: Pod "nginx-deployment-555b55d965-lh4sq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lh4sq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-lh4sq,UID:bd3aa37d-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14989,Generation:0,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8e490 0xc001f8e491}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8e4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8e510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:33 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:10.233.122.203,StartTime:2019-05-11 01:04:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:04:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ecca82c67af01de1871cbd8f810d16b322f9d3c653b036b5901db2acd30f0f90}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.724: INFO: Pod "nginx-deployment-555b55d965-lnlnd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lnlnd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-lnlnd,UID:bd3aaf0e-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14977,Generation:0,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8e5e0 0xc001f8e5e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8e6f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8e710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:33 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:10.233.91.234,StartTime:2019-05-11 01:04:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:04:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a7859be8af174d1bd925326496812c486c85a651e5487de34a12bb5da89f3c37}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.724: INFO: Pod "nginx-deployment-555b55d965-nj99k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nj99k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-nj99k,UID:c0d27806-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15127,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8e7e0 0xc001f8e7e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8e9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8ea10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.725: INFO: Pod "nginx-deployment-555b55d965-nz8pn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nz8pn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-nz8pn,UID:c0d6b3d6-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15166,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8ead0 0xc001f8ead1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8eb30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8eb50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.725: INFO: Pod "nginx-deployment-555b55d965-qs75t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qs75t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-qs75t,UID:c0d3c058-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15154,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8ed10 0xc001f8ed11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8ed80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8eda0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.725: INFO: Pod "nginx-deployment-555b55d965-tt6nd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tt6nd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-tt6nd,UID:c0d3b13b-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15136,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8eef0 0xc001f8eef1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8ef50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8ef70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.725: INFO: Pod "nginx-deployment-555b55d965-vhpm7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vhpm7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-vhpm7,UID:bd395370-7388-11e9-9f3c-000c29c278ce,ResourceVersion:14967,Generation:0,CreationTimestamp:2019-05-11 01:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8f030 0xc001f8f031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8f100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8f120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:33 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:10.233.124.164,StartTime:2019-05-11 01:04:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-11 01:04:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f9d791591197a0703e7a20a172f210200401e70326548ee2e4a42884cf622fae}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.725: INFO: Pod "nginx-deployment-555b55d965-wks2m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wks2m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-wks2m,UID:c0d6cf88-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15182,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8f1f0 0xc001f8f1f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8f250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8f330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.726: INFO: Pod "nginx-deployment-555b55d965-z5zjr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-z5zjr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-555b55d965-z5zjr,UID:c0d6c7ea-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15180,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bd383b5c-7388-11e9-9f3c-000c29c278ce 0xc001f8f3f0 0xc001f8f3f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8f450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8f470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.726: INFO: Pod "nginx-deployment-65bbdb5f8-8tj7t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8tj7t,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-8tj7t,UID:c0da5964-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15194,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001f8f580 0xc001f8f581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8f600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8f620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.726: INFO: Pod "nginx-deployment-65bbdb5f8-b9vvv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-b9vvv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-b9vvv,UID:c0d6c0d9-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15160,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001f8f6f0 0xc001f8f6f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8f760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8f780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.726: INFO: Pod "nginx-deployment-65bbdb5f8-c6hqz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-c6hqz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-c6hqz,UID:c0d3702f-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15128,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001f8f840 0xc001f8f841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8f8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8f8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.726: INFO: Pod "nginx-deployment-65bbdb5f8-gmblm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gmblm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-gmblm,UID:bf9e3b04-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15033,Generation:0,CreationTimestamp:2019-05-11 01:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001f8f990 0xc001f8f991}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8fa00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8fa20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:37 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:,StartTime:2019-05-11 01:04:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.727: INFO: Pod "nginx-deployment-65bbdb5f8-gws8q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gws8q,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-gws8q,UID:bfa2d1f0-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15047,Generation:0,CreationTimestamp:2019-05-11 01:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001f8fae0 0xc001f8fae1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8fb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8fb70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:37 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:,StartTime:2019-05-11 01:04:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.727: INFO: Pod "nginx-deployment-65bbdb5f8-h6whd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h6whd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-h6whd,UID:bf9d4572-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15024,Generation:0,CreationTimestamp:2019-05-11 01:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001f8fc30 0xc001f8fc31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8fca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8fcc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:37 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.727: INFO: Pod "nginx-deployment-65bbdb5f8-l7q58" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-l7q58,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-l7q58,UID:c0d3a7ed-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15135,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001f8fd80 0xc001f8fd81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8fdf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8fe10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.727: INFO: Pod "nginx-deployment-65bbdb5f8-phndw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-phndw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-phndw,UID:bf9e44b7-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15030,Generation:0,CreationTimestamp:2019-05-11 01:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001f8fed0 0xc001f8fed1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8ff40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8ff60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:37 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:,StartTime:2019-05-11 01:04:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.727: INFO: Pod "nginx-deployment-65bbdb5f8-sb4w2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-sb4w2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-sb4w2,UID:c0d285d6-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15126,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001d74020 0xc001d74021}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d740a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d740c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.48,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.727: INFO: Pod "nginx-deployment-65bbdb5f8-sx59j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-sx59j,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-sx59j,UID:bfa1efc0-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15044,Generation:0,CreationTimestamp:2019-05-11 01:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001d742a0 0xc001d742a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d74320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d74340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:37 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.728: INFO: Pod "nginx-deployment-65bbdb5f8-x2j9l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x2j9l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-x2j9l,UID:c0d6ce4a-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15155,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001d74530 0xc001d74531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d745a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d745c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.47,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.728: INFO: Pod "nginx-deployment-65bbdb5f8-z7m97" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z7m97,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-z7m97,UID:c0d6b37c-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15181,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001d74710 0xc001d74711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d74a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d74a20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 11 01:04:42.728: INFO: Pod "nginx-deployment-65bbdb5f8-zpczz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zpczz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-g5jbw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g5jbw/pods/nginx-deployment-65bbdb5f8-zpczz,UID:c0d6d7a6-7388-11e9-9f3c-000c29c278ce,ResourceVersion:15195,Generation:0,CreationTimestamp:2019-05-11 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bf9cddfd-7388-11e9-9f3c-000c29c278ce 0xc001d74bd0 0xc001d74bd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xwctq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xwctq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xwctq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d74d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d74d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:04:39 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:,StartTime:2019-05-11 01:04:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:04:42.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-g5jbw" for this suite.
May 11 01:04:48.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:04:48.802: INFO: namespace: e2e-tests-deployment-g5jbw, resource: bindings, ignored listing per whitelist
May 11 01:04:48.973: INFO: namespace e2e-tests-deployment-g5jbw deletion completed in 6.23898447s

• [SLOW TEST:14.366 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:04:48.974: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-c6657631-7388-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 01:04:49.308: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c667e05a-7388-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-m7rg8" to be "success or failure"
May 11 01:04:49.312: INFO: Pod "pod-projected-secrets-c667e05a-7388-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.716481ms
May 11 01:04:51.314: INFO: Pod "pod-projected-secrets-c667e05a-7388-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00646979s
STEP: Saw pod success
May 11 01:04:51.314: INFO: Pod "pod-projected-secrets-c667e05a-7388-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:04:51.316: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-projected-secrets-c667e05a-7388-11e9-9c46-760f9b3dbd5d container secret-volume-test: <nil>
STEP: delete the pod
May 11 01:04:51.346: INFO: Waiting for pod pod-projected-secrets-c667e05a-7388-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:04:51.349: INFO: Pod pod-projected-secrets-c667e05a-7388-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:04:51.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m7rg8" for this suite.
May 11 01:04:57.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:04:57.404: INFO: namespace: e2e-tests-projected-m7rg8, resource: bindings, ignored listing per whitelist
May 11 01:04:57.414: INFO: namespace e2e-tests-projected-m7rg8 deletion completed in 6.061720132s

• [SLOW TEST:8.440 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:04:57.414: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 11 01:04:57.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-85mkg'
May 11 01:04:57.759: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 11 01:04:57.759: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
May 11 01:04:59.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-85mkg'
May 11 01:04:59.845: INFO: stderr: ""
May 11 01:04:59.845: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:04:59.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-85mkg" for this suite.
May 11 01:05:21.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:05:21.893: INFO: namespace: e2e-tests-kubectl-85mkg, resource: bindings, ignored listing per whitelist
May 11 01:05:21.923: INFO: namespace e2e-tests-kubectl-85mkg deletion completed in 22.074810065s

• [SLOW TEST:24.508 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:05:21.923: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 11 01:05:24.492: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d9e216b9-7388-11e9-9c46-760f9b3dbd5d"
May 11 01:05:24.492: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d9e216b9-7388-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-pods-hlczp" to be "terminated due to deadline exceeded"
May 11 01:05:24.495: INFO: Pod "pod-update-activedeadlineseconds-d9e216b9-7388-11e9-9c46-760f9b3dbd5d": Phase="Running", Reason="", readiness=true. Elapsed: 2.883081ms
May 11 01:05:26.499: INFO: Pod "pod-update-activedeadlineseconds-d9e216b9-7388-11e9-9c46-760f9b3dbd5d": Phase="Running", Reason="", readiness=true. Elapsed: 2.006735176s
May 11 01:05:28.502: INFO: Pod "pod-update-activedeadlineseconds-d9e216b9-7388-11e9-9c46-760f9b3dbd5d": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009753573s
May 11 01:05:28.502: INFO: Pod "pod-update-activedeadlineseconds-d9e216b9-7388-11e9-9c46-760f9b3dbd5d" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:05:28.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hlczp" for this suite.
May 11 01:05:34.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:05:34.551: INFO: namespace: e2e-tests-pods-hlczp, resource: bindings, ignored listing per whitelist
May 11 01:05:34.575: INFO: namespace e2e-tests-pods-hlczp deletion completed in 6.069327692s

• [SLOW TEST:12.652 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:05:34.575: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0511 01:05:44.672659      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 11 01:05:44.672: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:05:44.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-46gtr" for this suite.
May 11 01:05:50.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:05:50.709: INFO: namespace: e2e-tests-gc-46gtr, resource: bindings, ignored listing per whitelist
May 11 01:05:50.733: INFO: namespace e2e-tests-gc-46gtr deletion completed in 6.058524838s

• [SLOW TEST:16.158 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:05:50.733: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 11 01:05:50.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-c2grf'
May 11 01:05:50.874: INFO: stderr: ""
May 11 01:05:50.874: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 11 01:05:55.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-c2grf -o json'
May 11 01:05:56.022: INFO: stderr: ""
May 11 01:05:56.022: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-11T01:05:50Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-c2grf\",\n        \"resourceVersion\": \"16256\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-c2grf/pods/e2e-test-nginx-pod\",\n        \"uid\": \"eaa45deb-7388-11e9-9f3c-000c29c278ce\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-hhq8b\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"craig-k8s-certification-1-stellar-hand-2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-hhq8b\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-hhq8b\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-11T01:05:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-11T01:05:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-11T01:05:52Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-11T01:05:50Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a11193c58f3a559eded9465630596762126959f3dd441058d684b7d763c457a9\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-11T01:05:51Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"70.0.51.47\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.124.180\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-11T01:05:50Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 11 01:05:56.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 replace -f - --namespace=e2e-tests-kubectl-c2grf'
May 11 01:05:56.262: INFO: stderr: ""
May 11 01:05:56.262: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
May 11 01:05:56.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-c2grf'
May 11 01:05:58.051: INFO: stderr: ""
May 11 01:05:58.051: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:05:58.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c2grf" for this suite.
May 11 01:06:04.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:06:04.076: INFO: namespace: e2e-tests-kubectl-c2grf, resource: bindings, ignored listing per whitelist
May 11 01:06:04.126: INFO: namespace e2e-tests-kubectl-c2grf deletion completed in 6.071825743s

• [SLOW TEST:13.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:06:04.126: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4kjnj
May 11 01:06:08.183: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4kjnj
STEP: checking the pod's current state and verifying that restartCount is present
May 11 01:06:08.185: INFO: Initial restart count of pod liveness-http is 0
May 11 01:06:26.213: INFO: Restart count of pod e2e-tests-container-probe-4kjnj/liveness-http is now 1 (18.027411559s elapsed)
May 11 01:06:46.241: INFO: Restart count of pod e2e-tests-container-probe-4kjnj/liveness-http is now 2 (38.055238667s elapsed)
May 11 01:07:06.267: INFO: Restart count of pod e2e-tests-container-probe-4kjnj/liveness-http is now 3 (58.082063248s elapsed)
May 11 01:07:28.295: INFO: Restart count of pod e2e-tests-container-probe-4kjnj/liveness-http is now 4 (1m20.109793433s elapsed)
May 11 01:08:28.382: INFO: Restart count of pod e2e-tests-container-probe-4kjnj/liveness-http is now 5 (2m20.196437615s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:08:28.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4kjnj" for this suite.
May 11 01:08:34.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:08:34.448: INFO: namespace: e2e-tests-container-probe-4kjnj, resource: bindings, ignored listing per whitelist
May 11 01:08:34.456: INFO: namespace e2e-tests-container-probe-4kjnj deletion completed in 6.064900193s

• [SLOW TEST:150.330 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:08:34.457: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 11 01:08:34.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:34.710: INFO: stderr: ""
May 11 01:08:34.710: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 11 01:08:34.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:34.806: INFO: stderr: ""
May 11 01:08:34.806: INFO: stdout: "update-demo-nautilus-8wzz9 update-demo-nautilus-lslrz "
May 11 01:08:34.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-8wzz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:34.883: INFO: stderr: ""
May 11 01:08:34.883: INFO: stdout: ""
May 11 01:08:34.883: INFO: update-demo-nautilus-8wzz9 is created but not running
May 11 01:08:39.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:39.978: INFO: stderr: ""
May 11 01:08:39.978: INFO: stdout: "update-demo-nautilus-8wzz9 update-demo-nautilus-lslrz "
May 11 01:08:39.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-8wzz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:40.074: INFO: stderr: ""
May 11 01:08:40.074: INFO: stdout: "true"
May 11 01:08:40.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-8wzz9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:40.169: INFO: stderr: ""
May 11 01:08:40.169: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:08:40.169: INFO: validating pod update-demo-nautilus-8wzz9
May 11 01:08:40.172: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:08:40.172: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:08:40.172: INFO: update-demo-nautilus-8wzz9 is verified up and running
May 11 01:08:40.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-lslrz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:40.261: INFO: stderr: ""
May 11 01:08:40.261: INFO: stdout: "true"
May 11 01:08:40.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-lslrz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:40.347: INFO: stderr: ""
May 11 01:08:40.347: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:08:40.347: INFO: validating pod update-demo-nautilus-lslrz
May 11 01:08:40.350: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:08:40.350: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:08:40.350: INFO: update-demo-nautilus-lslrz is verified up and running
STEP: using delete to clean up resources
May 11 01:08:40.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:40.444: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:08:40.444: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 11 01:08:40.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-2grtt'
May 11 01:08:40.536: INFO: stderr: "No resources found.\n"
May 11 01:08:40.536: INFO: stdout: ""
May 11 01:08:40.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -l name=update-demo --namespace=e2e-tests-kubectl-2grtt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 11 01:08:40.624: INFO: stderr: ""
May 11 01:08:40.624: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:08:40.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2grtt" for this suite.
May 11 01:09:02.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:09:02.679: INFO: namespace: e2e-tests-kubectl-2grtt, resource: bindings, ignored listing per whitelist
May 11 01:09:02.688: INFO: namespace e2e-tests-kubectl-2grtt deletion completed in 22.060382076s

• [SLOW TEST:28.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:09:02.688: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
May 11 01:09:02.737: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-594220555 proxy --unix-socket=/tmp/kubectl-proxy-unix583219694/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:09:02.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pv56g" for this suite.
May 11 01:09:08.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:09:08.850: INFO: namespace: e2e-tests-kubectl-pv56g, resource: bindings, ignored listing per whitelist
May 11 01:09:08.876: INFO: namespace e2e-tests-kubectl-pv56g deletion completed in 6.062561333s

• [SLOW TEST:6.188 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:09:08.876: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 11 01:09:11.444: INFO: Successfully updated pod "annotationupdate61275d19-7389-11e9-9c46-760f9b3dbd5d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:09:13.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x2fjp" for this suite.
May 11 01:09:35.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:09:35.533: INFO: namespace: e2e-tests-downward-api-x2fjp, resource: bindings, ignored listing per whitelist
May 11 01:09:35.533: INFO: namespace e2e-tests-downward-api-x2fjp deletion completed in 22.069166689s

• [SLOW TEST:26.657 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:09:35.533: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 11 01:09:40.121: INFO: Successfully updated pod "pod-update-710e71b4-7389-11e9-9c46-760f9b3dbd5d"
STEP: verifying the updated pod is in kubernetes
May 11 01:09:40.129: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:09:40.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pp596" for this suite.
May 11 01:10:02.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:10:02.193: INFO: namespace: e2e-tests-pods-pp596, resource: bindings, ignored listing per whitelist
May 11 01:10:02.197: INFO: namespace e2e-tests-pods-pp596 deletion completed in 22.065508045s

• [SLOW TEST:26.664 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:10:02.197: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-582rk
May 11 01:10:04.252: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-582rk
STEP: checking the pod's current state and verifying that restartCount is present
May 11 01:10:04.254: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:14:04.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-582rk" for this suite.
May 11 01:14:10.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:14:10.644: INFO: namespace: e2e-tests-container-probe-582rk, resource: bindings, ignored listing per whitelist
May 11 01:14:10.668: INFO: namespace e2e-tests-container-probe-582rk deletion completed in 6.066771329s

• [SLOW TEST:248.471 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:14:10.668: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-1509960f-738a-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:14:10.722: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1509e87d-738a-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-q6sw5" to be "success or failure"
May 11 01:14:10.724: INFO: Pod "pod-projected-configmaps-1509e87d-738a-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12483ms
May 11 01:14:12.726: INFO: Pod "pod-projected-configmaps-1509e87d-738a-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004450396s
May 11 01:14:14.729: INFO: Pod "pod-projected-configmaps-1509e87d-738a-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006979002s
STEP: Saw pod success
May 11 01:14:14.729: INFO: Pod "pod-projected-configmaps-1509e87d-738a-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:14:14.731: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-projected-configmaps-1509e87d-738a-11e9-9c46-760f9b3dbd5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 11 01:14:14.743: INFO: Waiting for pod pod-projected-configmaps-1509e87d-738a-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:14:14.745: INFO: Pod pod-projected-configmaps-1509e87d-738a-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:14:14.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q6sw5" for this suite.
May 11 01:14:20.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:14:20.776: INFO: namespace: e2e-tests-projected-q6sw5, resource: bindings, ignored listing per whitelist
May 11 01:14:20.808: INFO: namespace e2e-tests-projected-q6sw5 deletion completed in 6.059869564s

• [SLOW TEST:10.139 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:14:20.808: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0511 01:14:51.374305      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 11 01:14:51.374: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:14:51.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pvgns" for this suite.
May 11 01:14:57.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:14:57.426: INFO: namespace: e2e-tests-gc-pvgns, resource: bindings, ignored listing per whitelist
May 11 01:14:57.438: INFO: namespace e2e-tests-gc-pvgns deletion completed in 6.062064914s

• [SLOW TEST:36.631 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:14:57.439: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:15:01.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-htgp4" for this suite.
May 11 01:15:07.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:15:07.550: INFO: namespace: e2e-tests-emptydir-wrapper-htgp4, resource: bindings, ignored listing per whitelist
May 11 01:15:07.585: INFO: namespace e2e-tests-emptydir-wrapper-htgp4 deletion completed in 6.063937516s

• [SLOW TEST:10.147 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:15:07.585: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:15:28.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-pltzt" for this suite.
May 11 01:15:34.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:15:34.811: INFO: namespace: e2e-tests-container-runtime-pltzt, resource: bindings, ignored listing per whitelist
May 11 01:15:34.824: INFO: namespace e2e-tests-container-runtime-pltzt deletion completed in 6.062867638s

• [SLOW TEST:27.239 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:15:34.824: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:16:34.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-42tjk" for this suite.
May 11 01:16:56.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:16:56.897: INFO: namespace: e2e-tests-container-probe-42tjk, resource: bindings, ignored listing per whitelist
May 11 01:16:56.950: INFO: namespace e2e-tests-container-probe-42tjk deletion completed in 22.069326283s

• [SLOW TEST:82.125 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:16:56.950: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:16:56.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6bmzp" for this suite.
May 11 01:17:19.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:17:19.069: INFO: namespace: e2e-tests-pods-6bmzp, resource: bindings, ignored listing per whitelist
May 11 01:17:19.093: INFO: namespace e2e-tests-pods-6bmzp deletion completed in 22.092617933s

• [SLOW TEST:22.143 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:17:19.093: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:17:21.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qfd2j" for this suite.
May 11 01:18:11.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:18:11.220: INFO: namespace: e2e-tests-kubelet-test-qfd2j, resource: bindings, ignored listing per whitelist
May 11 01:18:11.262: INFO: namespace e2e-tests-kubelet-test-qfd2j deletion completed in 50.081730689s

• [SLOW TEST:52.169 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:18:11.262: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-h58j
STEP: Creating a pod to test atomic-volume-subpath
May 11 01:18:11.316: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-h58j" in namespace "e2e-tests-subpath-ddmm6" to be "success or failure"
May 11 01:18:11.319: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.357237ms
May 11 01:18:13.321: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004799414s
May 11 01:18:15.324: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 4.00724497s
May 11 01:18:17.326: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 6.00966409s
May 11 01:18:19.329: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 8.012918184s
May 11 01:18:21.332: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 10.015681699s
May 11 01:18:23.334: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 12.017967468s
May 11 01:18:25.339: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 14.022481479s
May 11 01:18:27.342: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 16.025300302s
May 11 01:18:29.344: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 18.027799737s
May 11 01:18:31.348: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 20.031863228s
May 11 01:18:33.351: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Running", Reason="", readiness=false. Elapsed: 22.034674376s
May 11 01:18:35.354: INFO: Pod "pod-subpath-test-configmap-h58j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.038108655s
STEP: Saw pod success
May 11 01:18:35.354: INFO: Pod "pod-subpath-test-configmap-h58j" satisfied condition "success or failure"
May 11 01:18:35.356: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-subpath-test-configmap-h58j container test-container-subpath-configmap-h58j: <nil>
STEP: delete the pod
May 11 01:18:35.372: INFO: Waiting for pod pod-subpath-test-configmap-h58j to disappear
May 11 01:18:35.374: INFO: Pod pod-subpath-test-configmap-h58j no longer exists
STEP: Deleting pod pod-subpath-test-configmap-h58j
May 11 01:18:35.374: INFO: Deleting pod "pod-subpath-test-configmap-h58j" in namespace "e2e-tests-subpath-ddmm6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:18:35.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ddmm6" for this suite.
May 11 01:18:41.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:18:41.433: INFO: namespace: e2e-tests-subpath-ddmm6, resource: bindings, ignored listing per whitelist
May 11 01:18:41.442: INFO: namespace e2e-tests-subpath-ddmm6 deletion completed in 6.061976542s

• [SLOW TEST:30.180 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:18:41.442: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b66f2786-738a-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:18:41.499: INFO: Waiting up to 5m0s for pod "pod-configmaps-b66f6e61-738a-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-w92bz" to be "success or failure"
May 11 01:18:41.501: INFO: Pod "pod-configmaps-b66f6e61-738a-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101853ms
May 11 01:18:43.504: INFO: Pod "pod-configmaps-b66f6e61-738a-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00454718s
STEP: Saw pod success
May 11 01:18:43.504: INFO: Pod "pod-configmaps-b66f6e61-738a-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:18:43.506: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-configmaps-b66f6e61-738a-11e9-9c46-760f9b3dbd5d container configmap-volume-test: <nil>
STEP: delete the pod
May 11 01:18:43.518: INFO: Waiting for pod pod-configmaps-b66f6e61-738a-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:18:43.519: INFO: Pod pod-configmaps-b66f6e61-738a-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:18:43.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w92bz" for this suite.
May 11 01:18:49.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:18:49.573: INFO: namespace: e2e-tests-configmap-w92bz, resource: bindings, ignored listing per whitelist
May 11 01:18:49.582: INFO: namespace e2e-tests-configmap-w92bz deletion completed in 6.059517289s

• [SLOW TEST:8.140 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:18:49.582: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 11 01:18:49.632: INFO: Waiting up to 5m0s for pod "pod-bb4897e4-738a-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-cj4xv" to be "success or failure"
May 11 01:18:49.634: INFO: Pod "pod-bb4897e4-738a-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.394365ms
May 11 01:18:51.637: INFO: Pod "pod-bb4897e4-738a-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004857779s
STEP: Saw pod success
May 11 01:18:51.637: INFO: Pod "pod-bb4897e4-738a-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:18:51.639: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-bb4897e4-738a-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:18:51.653: INFO: Waiting for pod pod-bb4897e4-738a-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:18:51.655: INFO: Pod pod-bb4897e4-738a-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:18:51.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cj4xv" for this suite.
May 11 01:18:57.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:18:57.698: INFO: namespace: e2e-tests-emptydir-cj4xv, resource: bindings, ignored listing per whitelist
May 11 01:18:57.772: INFO: namespace e2e-tests-emptydir-cj4xv deletion completed in 6.114198964s

• [SLOW TEST:8.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:18:57.772: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 11 01:19:01.836: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-c02a7347-738a-11e9-9c46-760f9b3dbd5d", GenerateName:"", Namespace:"e2e-tests-pods-mpv8d", SelfLink:"/api/v1/namespaces/e2e-tests-pods-mpv8d/pods/pod-submit-remove-c02a7347-738a-11e9-9c46-760f9b3dbd5d", UID:"bfb5d131-738a-11e9-9f3c-000c29c278ce", ResourceVersion:"19120", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693134337, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"819940865"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-rzlsw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0022e8900), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rzlsw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002bd2e98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"craig-k8s-certification-1-stellar-hand-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00234f140), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002bd2ed0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002bd2ef0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002bd2ef8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002bd2efc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693134337, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693134339, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693134339, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693134337, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"70.0.51.48", PodIP:"10.233.91.254", StartTime:(*v1.Time)(0xc001bd1b60), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001bd1ba0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://275f1b680528f3c1ef12c8092f8c93af4201ba6b614b816f27f4a8ac75aeccd5"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 11 01:19:06.848: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:19:06.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mpv8d" for this suite.
May 11 01:19:12.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:19:12.891: INFO: namespace: e2e-tests-pods-mpv8d, resource: bindings, ignored listing per whitelist
May 11 01:19:12.928: INFO: namespace e2e-tests-pods-mpv8d deletion completed in 6.073611876s

• [SLOW TEST:15.156 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:19:12.928: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 11 01:19:19.001: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 11 01:19:19.003: INFO: Pod pod-with-prestop-http-hook still exists
May 11 01:19:21.003: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 11 01:19:21.005: INFO: Pod pod-with-prestop-http-hook still exists
May 11 01:19:23.003: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 11 01:19:23.005: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:19:23.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gkrqt" for this suite.
May 11 01:19:45.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:19:45.067: INFO: namespace: e2e-tests-container-lifecycle-hook-gkrqt, resource: bindings, ignored listing per whitelist
May 11 01:19:45.084: INFO: namespace e2e-tests-container-lifecycle-hook-gkrqt deletion completed in 22.070358657s

• [SLOW TEST:32.157 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:19:45.085: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-58lpq
I0511 01:19:45.133711      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-58lpq, replica count: 1
I0511 01:19:46.184256      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0511 01:19:47.184434      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 11 01:19:47.290: INFO: Created: latency-svc-sztnb
May 11 01:19:47.297: INFO: Got endpoints: latency-svc-sztnb [12.528644ms]
May 11 01:19:47.303: INFO: Created: latency-svc-ql94l
May 11 01:19:47.306: INFO: Got endpoints: latency-svc-ql94l [9.148384ms]
May 11 01:19:47.307: INFO: Created: latency-svc-n2wxt
May 11 01:19:47.311: INFO: Got endpoints: latency-svc-n2wxt [13.932819ms]
May 11 01:19:47.313: INFO: Created: latency-svc-csgp7
May 11 01:19:47.317: INFO: Created: latency-svc-b29gz
May 11 01:19:47.320: INFO: Got endpoints: latency-svc-csgp7 [22.721198ms]
May 11 01:19:47.321: INFO: Got endpoints: latency-svc-b29gz [23.569792ms]
May 11 01:19:47.324: INFO: Created: latency-svc-6k6bv
May 11 01:19:47.329: INFO: Got endpoints: latency-svc-6k6bv [32.036208ms]
May 11 01:19:47.330: INFO: Created: latency-svc-4v4v7
May 11 01:19:47.338: INFO: Got endpoints: latency-svc-4v4v7 [40.59935ms]
May 11 01:19:47.338: INFO: Created: latency-svc-hh4qw
May 11 01:19:47.344: INFO: Got endpoints: latency-svc-hh4qw [46.513476ms]
May 11 01:19:47.344: INFO: Created: latency-svc-lkw24
May 11 01:19:47.348: INFO: Got endpoints: latency-svc-lkw24 [50.667627ms]
May 11 01:19:47.349: INFO: Created: latency-svc-s8r7t
May 11 01:19:47.352: INFO: Created: latency-svc-4kssc
May 11 01:19:47.354: INFO: Got endpoints: latency-svc-s8r7t [56.272227ms]
May 11 01:19:47.357: INFO: Created: latency-svc-88cbm
May 11 01:19:47.359: INFO: Created: latency-svc-gs8lv
May 11 01:19:47.359: INFO: Got endpoints: latency-svc-4kssc [61.722236ms]
May 11 01:19:47.364: INFO: Got endpoints: latency-svc-gs8lv [66.321059ms]
May 11 01:19:47.364: INFO: Got endpoints: latency-svc-88cbm [66.694427ms]
May 11 01:19:47.366: INFO: Created: latency-svc-jsqr6
May 11 01:19:47.370: INFO: Got endpoints: latency-svc-jsqr6 [72.176421ms]
May 11 01:19:47.370: INFO: Created: latency-svc-qr655
May 11 01:19:47.376: INFO: Got endpoints: latency-svc-qr655 [78.4582ms]
May 11 01:19:47.377: INFO: Created: latency-svc-2mzsg
May 11 01:19:47.379: INFO: Got endpoints: latency-svc-2mzsg [81.615978ms]
May 11 01:19:47.383: INFO: Created: latency-svc-vqftl
May 11 01:19:47.385: INFO: Got endpoints: latency-svc-vqftl [79.001546ms]
May 11 01:19:47.386: INFO: Created: latency-svc-26h65
May 11 01:19:47.389: INFO: Got endpoints: latency-svc-26h65 [77.261174ms]
May 11 01:19:47.392: INFO: Created: latency-svc-m2khn
May 11 01:19:47.396: INFO: Created: latency-svc-bsmtv
May 11 01:19:47.396: INFO: Got endpoints: latency-svc-m2khn [76.67553ms]
May 11 01:19:47.402: INFO: Got endpoints: latency-svc-bsmtv [81.492122ms]
May 11 01:19:47.403: INFO: Created: latency-svc-x4zpv
May 11 01:19:47.408: INFO: Got endpoints: latency-svc-x4zpv [78.698492ms]
May 11 01:19:47.409: INFO: Created: latency-svc-qgqws
May 11 01:19:47.414: INFO: Got endpoints: latency-svc-qgqws [76.100713ms]
May 11 01:19:47.417: INFO: Created: latency-svc-9wctx
May 11 01:19:47.420: INFO: Created: latency-svc-b9rjz
May 11 01:19:47.424: INFO: Got endpoints: latency-svc-9wctx [80.0877ms]
May 11 01:19:47.425: INFO: Got endpoints: latency-svc-b9rjz [76.917766ms]
May 11 01:19:47.426: INFO: Created: latency-svc-g989d
May 11 01:19:47.431: INFO: Got endpoints: latency-svc-g989d [77.621566ms]
May 11 01:19:47.432: INFO: Created: latency-svc-qwgf5
May 11 01:19:47.437: INFO: Got endpoints: latency-svc-qwgf5 [77.62314ms]
May 11 01:19:47.439: INFO: Created: latency-svc-p4lxr
May 11 01:19:47.441: INFO: Created: latency-svc-6cjck
May 11 01:19:47.446: INFO: Created: latency-svc-tcjbk
May 11 01:19:47.446: INFO: Got endpoints: latency-svc-6cjck [82.07233ms]
May 11 01:19:47.447: INFO: Got endpoints: latency-svc-p4lxr [82.697184ms]
May 11 01:19:47.451: INFO: Got endpoints: latency-svc-tcjbk [81.311947ms]
May 11 01:19:47.453: INFO: Created: latency-svc-h24lx
May 11 01:19:47.459: INFO: Got endpoints: latency-svc-h24lx [82.787685ms]
May 11 01:19:47.459: INFO: Created: latency-svc-5l2qd
May 11 01:19:47.466: INFO: Got endpoints: latency-svc-5l2qd [86.626543ms]
May 11 01:19:47.469: INFO: Created: latency-svc-p2ftz
May 11 01:19:47.472: INFO: Got endpoints: latency-svc-p2ftz [86.475628ms]
May 11 01:19:47.474: INFO: Created: latency-svc-lrtv8
May 11 01:19:47.478: INFO: Created: latency-svc-bw92f
May 11 01:19:47.479: INFO: Got endpoints: latency-svc-lrtv8 [90.005089ms]
May 11 01:19:47.482: INFO: Created: latency-svc-lqmk2
May 11 01:19:47.486: INFO: Created: latency-svc-82vxl
May 11 01:19:47.490: INFO: Created: latency-svc-ndxt4
May 11 01:19:47.494: INFO: Got endpoints: latency-svc-bw92f [97.013577ms]
May 11 01:19:47.494: INFO: Created: latency-svc-v57dl
May 11 01:19:47.499: INFO: Created: latency-svc-mb7xc
May 11 01:19:47.502: INFO: Created: latency-svc-lshnh
May 11 01:19:47.505: INFO: Created: latency-svc-wndkd
May 11 01:19:47.510: INFO: Created: latency-svc-5x8xb
May 11 01:19:47.528: INFO: Created: latency-svc-f2nft
May 11 01:19:47.531: INFO: Created: latency-svc-4hxb9
May 11 01:19:47.535: INFO: Created: latency-svc-2b8fm
May 11 01:19:47.539: INFO: Created: latency-svc-q9cl7
May 11 01:19:47.542: INFO: Got endpoints: latency-svc-lqmk2 [140.149967ms]
May 11 01:19:47.543: INFO: Created: latency-svc-tffkv
May 11 01:19:47.547: INFO: Created: latency-svc-bbfp4
May 11 01:19:47.551: INFO: Created: latency-svc-kxlh4
May 11 01:19:47.556: INFO: Created: latency-svc-zwwbm
May 11 01:19:47.593: INFO: Got endpoints: latency-svc-82vxl [184.572398ms]
May 11 01:19:47.599: INFO: Created: latency-svc-ddxvv
May 11 01:19:47.643: INFO: Got endpoints: latency-svc-ndxt4 [229.029607ms]
May 11 01:19:47.649: INFO: Created: latency-svc-4688p
May 11 01:19:47.693: INFO: Got endpoints: latency-svc-v57dl [268.837307ms]
May 11 01:19:47.699: INFO: Created: latency-svc-r6kmc
May 11 01:19:47.742: INFO: Got endpoints: latency-svc-mb7xc [317.299815ms]
May 11 01:19:47.750: INFO: Created: latency-svc-54vcq
May 11 01:19:47.793: INFO: Got endpoints: latency-svc-lshnh [361.996126ms]
May 11 01:19:47.799: INFO: Created: latency-svc-rrv5v
May 11 01:19:47.843: INFO: Got endpoints: latency-svc-wndkd [405.791637ms]
May 11 01:19:47.848: INFO: Created: latency-svc-pj4z4
May 11 01:19:47.893: INFO: Got endpoints: latency-svc-5x8xb [446.538732ms]
May 11 01:19:47.898: INFO: Created: latency-svc-zz48r
May 11 01:19:47.944: INFO: Got endpoints: latency-svc-f2nft [496.443931ms]
May 11 01:19:47.949: INFO: Created: latency-svc-c4jqm
May 11 01:19:47.998: INFO: Got endpoints: latency-svc-4hxb9 [546.463838ms]
May 11 01:19:48.008: INFO: Created: latency-svc-9ctd2
May 11 01:19:48.047: INFO: Got endpoints: latency-svc-2b8fm [588.058179ms]
May 11 01:19:48.055: INFO: Created: latency-svc-gqswm
May 11 01:19:48.092: INFO: Got endpoints: latency-svc-q9cl7 [626.538981ms]
May 11 01:19:48.099: INFO: Created: latency-svc-29rds
May 11 01:19:48.143: INFO: Got endpoints: latency-svc-tffkv [671.674474ms]
May 11 01:19:48.150: INFO: Created: latency-svc-q8nz9
May 11 01:19:48.193: INFO: Got endpoints: latency-svc-bbfp4 [714.035421ms]
May 11 01:19:48.200: INFO: Created: latency-svc-2qjc5
May 11 01:19:48.243: INFO: Got endpoints: latency-svc-kxlh4 [749.763163ms]
May 11 01:19:48.249: INFO: Created: latency-svc-ggmx6
May 11 01:19:48.293: INFO: Got endpoints: latency-svc-zwwbm [750.613192ms]
May 11 01:19:48.299: INFO: Created: latency-svc-h842j
May 11 01:19:48.348: INFO: Got endpoints: latency-svc-ddxvv [755.486955ms]
May 11 01:19:48.355: INFO: Created: latency-svc-xl4mq
May 11 01:19:48.394: INFO: Got endpoints: latency-svc-4688p [751.122615ms]
May 11 01:19:48.400: INFO: Created: latency-svc-jzmcd
May 11 01:19:48.442: INFO: Got endpoints: latency-svc-r6kmc [749.486036ms]
May 11 01:19:48.447: INFO: Created: latency-svc-r8zx4
May 11 01:19:48.493: INFO: Got endpoints: latency-svc-54vcq [750.994761ms]
May 11 01:19:48.501: INFO: Created: latency-svc-c29nv
May 11 01:19:48.543: INFO: Got endpoints: latency-svc-rrv5v [749.722299ms]
May 11 01:19:48.550: INFO: Created: latency-svc-nkzfc
May 11 01:19:48.593: INFO: Got endpoints: latency-svc-pj4z4 [750.199091ms]
May 11 01:19:48.599: INFO: Created: latency-svc-s864z
May 11 01:19:48.643: INFO: Got endpoints: latency-svc-zz48r [749.943377ms]
May 11 01:19:48.648: INFO: Created: latency-svc-nmvrx
May 11 01:19:48.693: INFO: Got endpoints: latency-svc-c4jqm [749.244282ms]
May 11 01:19:48.700: INFO: Created: latency-svc-trxnh
May 11 01:19:48.743: INFO: Got endpoints: latency-svc-9ctd2 [745.767051ms]
May 11 01:19:48.750: INFO: Created: latency-svc-w5s7n
May 11 01:19:48.793: INFO: Got endpoints: latency-svc-gqswm [745.837246ms]
May 11 01:19:48.798: INFO: Created: latency-svc-c9hlk
May 11 01:19:48.845: INFO: Got endpoints: latency-svc-29rds [752.343608ms]
May 11 01:19:48.851: INFO: Created: latency-svc-68tbv
May 11 01:19:48.892: INFO: Got endpoints: latency-svc-q8nz9 [749.009404ms]
May 11 01:19:48.897: INFO: Created: latency-svc-84l4n
May 11 01:19:48.945: INFO: Got endpoints: latency-svc-2qjc5 [752.021371ms]
May 11 01:19:48.950: INFO: Created: latency-svc-zx8hk
May 11 01:19:48.993: INFO: Got endpoints: latency-svc-ggmx6 [749.924834ms]
May 11 01:19:48.999: INFO: Created: latency-svc-hd5xf
May 11 01:19:49.045: INFO: Got endpoints: latency-svc-h842j [752.050698ms]
May 11 01:19:49.053: INFO: Created: latency-svc-jdp7x
May 11 01:19:49.092: INFO: Got endpoints: latency-svc-xl4mq [744.230547ms]
May 11 01:19:49.098: INFO: Created: latency-svc-vw4cv
May 11 01:19:49.143: INFO: Got endpoints: latency-svc-jzmcd [748.915109ms]
May 11 01:19:49.151: INFO: Created: latency-svc-5gl9z
May 11 01:19:49.193: INFO: Got endpoints: latency-svc-r8zx4 [750.615596ms]
May 11 01:19:49.200: INFO: Created: latency-svc-5lr7l
May 11 01:19:49.243: INFO: Got endpoints: latency-svc-c29nv [750.088881ms]
May 11 01:19:49.252: INFO: Created: latency-svc-hb94m
May 11 01:19:49.293: INFO: Got endpoints: latency-svc-nkzfc [749.703087ms]
May 11 01:19:49.299: INFO: Created: latency-svc-97zxv
May 11 01:19:49.343: INFO: Got endpoints: latency-svc-s864z [749.932679ms]
May 11 01:19:49.352: INFO: Created: latency-svc-xdg6s
May 11 01:19:49.393: INFO: Got endpoints: latency-svc-nmvrx [750.496713ms]
May 11 01:19:49.399: INFO: Created: latency-svc-txw85
May 11 01:19:49.443: INFO: Got endpoints: latency-svc-trxnh [749.640606ms]
May 11 01:19:49.450: INFO: Created: latency-svc-blwgd
May 11 01:19:49.493: INFO: Got endpoints: latency-svc-w5s7n [749.614932ms]
May 11 01:19:49.499: INFO: Created: latency-svc-grb5w
May 11 01:19:49.543: INFO: Got endpoints: latency-svc-c9hlk [749.671328ms]
May 11 01:19:49.548: INFO: Created: latency-svc-xz8jb
May 11 01:19:49.592: INFO: Got endpoints: latency-svc-68tbv [747.417825ms]
May 11 01:19:49.598: INFO: Created: latency-svc-g4lvr
May 11 01:19:49.643: INFO: Got endpoints: latency-svc-84l4n [750.493399ms]
May 11 01:19:49.654: INFO: Created: latency-svc-j25xd
May 11 01:19:49.693: INFO: Got endpoints: latency-svc-zx8hk [747.838562ms]
May 11 01:19:49.700: INFO: Created: latency-svc-8mswg
May 11 01:19:49.743: INFO: Got endpoints: latency-svc-hd5xf [749.341883ms]
May 11 01:19:49.750: INFO: Created: latency-svc-qngxj
May 11 01:19:49.793: INFO: Got endpoints: latency-svc-jdp7x [747.79834ms]
May 11 01:19:49.799: INFO: Created: latency-svc-vvbxl
May 11 01:19:49.843: INFO: Got endpoints: latency-svc-vw4cv [750.952477ms]
May 11 01:19:49.850: INFO: Created: latency-svc-4jwtr
May 11 01:19:49.893: INFO: Got endpoints: latency-svc-5gl9z [749.729412ms]
May 11 01:19:49.898: INFO: Created: latency-svc-f8tn7
May 11 01:19:49.942: INFO: Got endpoints: latency-svc-5lr7l [749.11439ms]
May 11 01:19:49.947: INFO: Created: latency-svc-wsnvq
May 11 01:19:49.993: INFO: Got endpoints: latency-svc-hb94m [749.319201ms]
May 11 01:19:49.999: INFO: Created: latency-svc-bcmq4
May 11 01:19:50.043: INFO: Got endpoints: latency-svc-97zxv [750.547008ms]
May 11 01:19:50.050: INFO: Created: latency-svc-h6nk7
May 11 01:19:50.093: INFO: Got endpoints: latency-svc-xdg6s [750.413043ms]
May 11 01:19:50.101: INFO: Created: latency-svc-9t28t
May 11 01:19:50.143: INFO: Got endpoints: latency-svc-txw85 [750.050704ms]
May 11 01:19:50.150: INFO: Created: latency-svc-xc5v7
May 11 01:19:50.193: INFO: Got endpoints: latency-svc-blwgd [749.538839ms]
May 11 01:19:50.198: INFO: Created: latency-svc-wr7v5
May 11 01:19:50.243: INFO: Got endpoints: latency-svc-grb5w [750.182643ms]
May 11 01:19:50.250: INFO: Created: latency-svc-mmql5
May 11 01:19:50.293: INFO: Got endpoints: latency-svc-xz8jb [750.505098ms]
May 11 01:19:50.300: INFO: Created: latency-svc-467wd
May 11 01:19:50.345: INFO: Got endpoints: latency-svc-g4lvr [752.808594ms]
May 11 01:19:50.351: INFO: Created: latency-svc-ghwjs
May 11 01:19:50.394: INFO: Got endpoints: latency-svc-j25xd [750.752563ms]
May 11 01:19:50.399: INFO: Created: latency-svc-rk2rt
May 11 01:19:50.444: INFO: Got endpoints: latency-svc-8mswg [751.32999ms]
May 11 01:19:50.450: INFO: Created: latency-svc-dvwdp
May 11 01:19:50.493: INFO: Got endpoints: latency-svc-qngxj [750.042214ms]
May 11 01:19:50.499: INFO: Created: latency-svc-ztsgc
May 11 01:19:50.544: INFO: Got endpoints: latency-svc-vvbxl [750.776494ms]
May 11 01:19:50.549: INFO: Created: latency-svc-nb49d
May 11 01:19:50.593: INFO: Got endpoints: latency-svc-4jwtr [749.173419ms]
May 11 01:19:50.598: INFO: Created: latency-svc-62pz9
May 11 01:19:50.643: INFO: Got endpoints: latency-svc-f8tn7 [750.43059ms]
May 11 01:19:50.649: INFO: Created: latency-svc-6gdsj
May 11 01:19:50.693: INFO: Got endpoints: latency-svc-wsnvq [750.850868ms]
May 11 01:19:50.700: INFO: Created: latency-svc-tzg59
May 11 01:19:50.743: INFO: Got endpoints: latency-svc-bcmq4 [750.408663ms]
May 11 01:19:50.748: INFO: Created: latency-svc-rzgpt
May 11 01:19:50.793: INFO: Got endpoints: latency-svc-h6nk7 [749.142047ms]
May 11 01:19:50.799: INFO: Created: latency-svc-6h8xf
May 11 01:19:50.844: INFO: Got endpoints: latency-svc-9t28t [750.504464ms]
May 11 01:19:50.851: INFO: Created: latency-svc-6w4hl
May 11 01:19:50.893: INFO: Got endpoints: latency-svc-xc5v7 [749.666538ms]
May 11 01:19:50.903: INFO: Created: latency-svc-6khc9
May 11 01:19:50.945: INFO: Got endpoints: latency-svc-wr7v5 [752.662283ms]
May 11 01:19:50.953: INFO: Created: latency-svc-grg88
May 11 01:19:50.993: INFO: Got endpoints: latency-svc-mmql5 [749.877213ms]
May 11 01:19:51.000: INFO: Created: latency-svc-f9824
May 11 01:19:51.043: INFO: Got endpoints: latency-svc-467wd [750.175012ms]
May 11 01:19:51.052: INFO: Created: latency-svc-4sjws
May 11 01:19:51.093: INFO: Got endpoints: latency-svc-ghwjs [747.966891ms]
May 11 01:19:51.099: INFO: Created: latency-svc-cxx6d
May 11 01:19:51.143: INFO: Got endpoints: latency-svc-rk2rt [749.226358ms]
May 11 01:19:51.151: INFO: Created: latency-svc-tvj86
May 11 01:19:51.193: INFO: Got endpoints: latency-svc-dvwdp [748.587358ms]
May 11 01:19:51.198: INFO: Created: latency-svc-pp8kj
May 11 01:19:51.244: INFO: Got endpoints: latency-svc-ztsgc [751.196655ms]
May 11 01:19:51.251: INFO: Created: latency-svc-kgrt9
May 11 01:19:51.293: INFO: Got endpoints: latency-svc-nb49d [749.042128ms]
May 11 01:19:51.298: INFO: Created: latency-svc-wjchp
May 11 01:19:51.343: INFO: Got endpoints: latency-svc-62pz9 [750.254407ms]
May 11 01:19:51.348: INFO: Created: latency-svc-p6k8d
May 11 01:19:51.393: INFO: Got endpoints: latency-svc-6gdsj [749.440326ms]
May 11 01:19:51.402: INFO: Created: latency-svc-lnh42
May 11 01:19:51.443: INFO: Got endpoints: latency-svc-tzg59 [750.307457ms]
May 11 01:19:51.453: INFO: Created: latency-svc-mm8jq
May 11 01:19:51.493: INFO: Got endpoints: latency-svc-rzgpt [749.163169ms]
May 11 01:19:51.501: INFO: Created: latency-svc-hstnl
May 11 01:19:51.544: INFO: Got endpoints: latency-svc-6h8xf [751.605186ms]
May 11 01:19:51.552: INFO: Created: latency-svc-tl6p9
May 11 01:19:51.594: INFO: Got endpoints: latency-svc-6w4hl [750.423073ms]
May 11 01:19:51.604: INFO: Created: latency-svc-9fxms
May 11 01:19:51.645: INFO: Got endpoints: latency-svc-6khc9 [751.56656ms]
May 11 01:19:51.654: INFO: Created: latency-svc-zgznk
May 11 01:19:51.693: INFO: Got endpoints: latency-svc-grg88 [747.918698ms]
May 11 01:19:51.701: INFO: Created: latency-svc-9ggcz
May 11 01:19:51.743: INFO: Got endpoints: latency-svc-f9824 [749.947965ms]
May 11 01:19:51.750: INFO: Created: latency-svc-czwjn
May 11 01:19:51.793: INFO: Got endpoints: latency-svc-4sjws [749.92154ms]
May 11 01:19:51.798: INFO: Created: latency-svc-5djh7
May 11 01:19:51.842: INFO: Got endpoints: latency-svc-cxx6d [749.307859ms]
May 11 01:19:51.850: INFO: Created: latency-svc-npg5x
May 11 01:19:51.893: INFO: Got endpoints: latency-svc-tvj86 [749.472218ms]
May 11 01:19:51.897: INFO: Created: latency-svc-vvl5b
May 11 01:19:51.942: INFO: Got endpoints: latency-svc-pp8kj [749.627087ms]
May 11 01:19:51.951: INFO: Created: latency-svc-fzdzq
May 11 01:19:51.993: INFO: Got endpoints: latency-svc-kgrt9 [749.266226ms]
May 11 01:19:52.000: INFO: Created: latency-svc-5cqtd
May 11 01:19:52.043: INFO: Got endpoints: latency-svc-wjchp [750.015037ms]
May 11 01:19:52.049: INFO: Created: latency-svc-vrj5x
May 11 01:19:52.093: INFO: Got endpoints: latency-svc-p6k8d [749.821781ms]
May 11 01:19:52.098: INFO: Created: latency-svc-65n59
May 11 01:19:52.147: INFO: Got endpoints: latency-svc-lnh42 [753.690868ms]
May 11 01:19:52.153: INFO: Created: latency-svc-x4tlq
May 11 01:19:52.192: INFO: Got endpoints: latency-svc-mm8jq [748.922894ms]
May 11 01:19:52.197: INFO: Created: latency-svc-g4q7x
May 11 01:19:52.243: INFO: Got endpoints: latency-svc-hstnl [750.492678ms]
May 11 01:19:52.251: INFO: Created: latency-svc-k68b9
May 11 01:19:52.293: INFO: Got endpoints: latency-svc-tl6p9 [748.404616ms]
May 11 01:19:52.299: INFO: Created: latency-svc-7k6gh
May 11 01:19:52.346: INFO: Got endpoints: latency-svc-9fxms [751.621449ms]
May 11 01:19:52.355: INFO: Created: latency-svc-hprzb
May 11 01:19:52.394: INFO: Got endpoints: latency-svc-zgznk [749.505225ms]
May 11 01:19:52.401: INFO: Created: latency-svc-bpzqb
May 11 01:19:52.444: INFO: Got endpoints: latency-svc-9ggcz [750.341595ms]
May 11 01:19:52.451: INFO: Created: latency-svc-j5xhg
May 11 01:19:52.493: INFO: Got endpoints: latency-svc-czwjn [749.60704ms]
May 11 01:19:52.499: INFO: Created: latency-svc-l85r2
May 11 01:19:52.544: INFO: Got endpoints: latency-svc-5djh7 [750.484226ms]
May 11 01:19:52.552: INFO: Created: latency-svc-jf7kg
May 11 01:19:52.593: INFO: Got endpoints: latency-svc-npg5x [750.582979ms]
May 11 01:19:52.600: INFO: Created: latency-svc-kzldm
May 11 01:19:52.644: INFO: Got endpoints: latency-svc-vvl5b [751.716547ms]
May 11 01:19:52.651: INFO: Created: latency-svc-mnnr6
May 11 01:19:52.692: INFO: Got endpoints: latency-svc-fzdzq [749.945855ms]
May 11 01:19:52.697: INFO: Created: latency-svc-qc9wh
May 11 01:19:52.743: INFO: Got endpoints: latency-svc-5cqtd [749.480674ms]
May 11 01:19:52.750: INFO: Created: latency-svc-vqh5t
May 11 01:19:52.793: INFO: Got endpoints: latency-svc-vrj5x [750.300454ms]
May 11 01:19:52.802: INFO: Created: latency-svc-q2xvt
May 11 01:19:52.844: INFO: Got endpoints: latency-svc-65n59 [751.474025ms]
May 11 01:19:52.849: INFO: Created: latency-svc-gkrwx
May 11 01:19:52.893: INFO: Got endpoints: latency-svc-x4tlq [746.25312ms]
May 11 01:19:52.899: INFO: Created: latency-svc-2gcpm
May 11 01:19:52.943: INFO: Got endpoints: latency-svc-g4q7x [750.547433ms]
May 11 01:19:52.950: INFO: Created: latency-svc-mtpbf
May 11 01:19:52.993: INFO: Got endpoints: latency-svc-k68b9 [749.941706ms]
May 11 01:19:52.998: INFO: Created: latency-svc-4trj2
May 11 01:19:53.043: INFO: Got endpoints: latency-svc-7k6gh [750.514293ms]
May 11 01:19:53.049: INFO: Created: latency-svc-j8bv7
May 11 01:19:53.094: INFO: Got endpoints: latency-svc-hprzb [747.719707ms]
May 11 01:19:53.098: INFO: Created: latency-svc-65rq9
May 11 01:19:53.143: INFO: Got endpoints: latency-svc-bpzqb [748.536826ms]
May 11 01:19:53.148: INFO: Created: latency-svc-xsfsf
May 11 01:19:53.194: INFO: Got endpoints: latency-svc-j5xhg [750.04252ms]
May 11 01:19:53.201: INFO: Created: latency-svc-jswgm
May 11 01:19:53.245: INFO: Got endpoints: latency-svc-l85r2 [752.613158ms]
May 11 01:19:53.251: INFO: Created: latency-svc-wbkjk
May 11 01:19:53.293: INFO: Got endpoints: latency-svc-jf7kg [749.161071ms]
May 11 01:19:53.301: INFO: Created: latency-svc-rqgrh
May 11 01:19:53.344: INFO: Got endpoints: latency-svc-kzldm [750.522519ms]
May 11 01:19:53.354: INFO: Created: latency-svc-dwsvf
May 11 01:19:53.395: INFO: Got endpoints: latency-svc-mnnr6 [750.413072ms]
May 11 01:19:53.401: INFO: Created: latency-svc-c84xb
May 11 01:19:53.442: INFO: Got endpoints: latency-svc-qc9wh [749.974746ms]
May 11 01:19:53.449: INFO: Created: latency-svc-dkjf7
May 11 01:19:53.494: INFO: Got endpoints: latency-svc-vqh5t [750.924577ms]
May 11 01:19:53.500: INFO: Created: latency-svc-pzrwb
May 11 01:19:53.543: INFO: Got endpoints: latency-svc-q2xvt [750.076229ms]
May 11 01:19:53.550: INFO: Created: latency-svc-t46xs
May 11 01:19:53.594: INFO: Got endpoints: latency-svc-gkrwx [749.39554ms]
May 11 01:19:53.602: INFO: Created: latency-svc-z4pgf
May 11 01:19:53.643: INFO: Got endpoints: latency-svc-2gcpm [749.759126ms]
May 11 01:19:53.649: INFO: Created: latency-svc-vxkwx
May 11 01:19:53.697: INFO: Got endpoints: latency-svc-mtpbf [753.698978ms]
May 11 01:19:53.703: INFO: Created: latency-svc-bkg6m
May 11 01:19:53.743: INFO: Got endpoints: latency-svc-4trj2 [749.662081ms]
May 11 01:19:53.750: INFO: Created: latency-svc-qt77n
May 11 01:19:53.794: INFO: Got endpoints: latency-svc-j8bv7 [750.239954ms]
May 11 01:19:53.798: INFO: Created: latency-svc-hfwxk
May 11 01:19:53.845: INFO: Got endpoints: latency-svc-65rq9 [751.142404ms]
May 11 01:19:53.853: INFO: Created: latency-svc-mrsdt
May 11 01:19:53.893: INFO: Got endpoints: latency-svc-xsfsf [750.176077ms]
May 11 01:19:53.901: INFO: Created: latency-svc-22lpx
May 11 01:19:53.942: INFO: Got endpoints: latency-svc-jswgm [748.226336ms]
May 11 01:19:53.950: INFO: Created: latency-svc-p8d6j
May 11 01:19:53.993: INFO: Got endpoints: latency-svc-wbkjk [747.662128ms]
May 11 01:19:53.998: INFO: Created: latency-svc-jgmsr
May 11 01:19:54.043: INFO: Got endpoints: latency-svc-rqgrh [749.942737ms]
May 11 01:19:54.049: INFO: Created: latency-svc-gqm8l
May 11 01:19:54.094: INFO: Got endpoints: latency-svc-dwsvf [749.860494ms]
May 11 01:19:54.098: INFO: Created: latency-svc-sf9xb
May 11 01:19:54.143: INFO: Got endpoints: latency-svc-c84xb [748.058105ms]
May 11 01:19:54.149: INFO: Created: latency-svc-lc2pz
May 11 01:19:54.193: INFO: Got endpoints: latency-svc-dkjf7 [750.292848ms]
May 11 01:19:54.198: INFO: Created: latency-svc-l46pb
May 11 01:19:54.243: INFO: Got endpoints: latency-svc-pzrwb [749.140583ms]
May 11 01:19:54.250: INFO: Created: latency-svc-7ngwj
May 11 01:19:54.294: INFO: Got endpoints: latency-svc-t46xs [750.555979ms]
May 11 01:19:54.301: INFO: Created: latency-svc-nrgzg
May 11 01:19:54.346: INFO: Got endpoints: latency-svc-z4pgf [752.10113ms]
May 11 01:19:54.352: INFO: Created: latency-svc-gplm7
May 11 01:19:54.393: INFO: Got endpoints: latency-svc-vxkwx [750.304123ms]
May 11 01:19:54.399: INFO: Created: latency-svc-nmmqf
May 11 01:19:54.443: INFO: Got endpoints: latency-svc-bkg6m [746.570637ms]
May 11 01:19:54.451: INFO: Created: latency-svc-mfvdq
May 11 01:19:54.493: INFO: Got endpoints: latency-svc-qt77n [749.876101ms]
May 11 01:19:54.500: INFO: Created: latency-svc-rfvn4
May 11 01:19:54.543: INFO: Got endpoints: latency-svc-hfwxk [749.598382ms]
May 11 01:19:54.550: INFO: Created: latency-svc-npnd5
May 11 01:19:54.592: INFO: Got endpoints: latency-svc-mrsdt [747.418685ms]
May 11 01:19:54.598: INFO: Created: latency-svc-jfv65
May 11 01:19:54.642: INFO: Got endpoints: latency-svc-22lpx [749.304428ms]
May 11 01:19:54.650: INFO: Created: latency-svc-9sjpw
May 11 01:19:54.693: INFO: Got endpoints: latency-svc-p8d6j [750.548159ms]
May 11 01:19:54.699: INFO: Created: latency-svc-tsplp
May 11 01:19:54.743: INFO: Got endpoints: latency-svc-jgmsr [749.773928ms]
May 11 01:19:54.750: INFO: Created: latency-svc-bgcfd
May 11 01:19:54.793: INFO: Got endpoints: latency-svc-gqm8l [750.207431ms]
May 11 01:19:54.799: INFO: Created: latency-svc-2r7fk
May 11 01:19:54.844: INFO: Got endpoints: latency-svc-sf9xb [750.172638ms]
May 11 01:19:54.850: INFO: Created: latency-svc-5ftjl
May 11 01:19:54.893: INFO: Got endpoints: latency-svc-lc2pz [749.846772ms]
May 11 01:19:54.902: INFO: Created: latency-svc-fgf6t
May 11 01:19:54.943: INFO: Got endpoints: latency-svc-l46pb [750.21517ms]
May 11 01:19:54.949: INFO: Created: latency-svc-shd9g
May 11 01:19:54.994: INFO: Got endpoints: latency-svc-7ngwj [751.012032ms]
May 11 01:19:55.003: INFO: Created: latency-svc-hx82n
May 11 01:19:55.043: INFO: Got endpoints: latency-svc-nrgzg [749.03868ms]
May 11 01:19:55.048: INFO: Created: latency-svc-2rsgn
May 11 01:19:55.093: INFO: Got endpoints: latency-svc-gplm7 [747.516494ms]
May 11 01:19:55.110: INFO: Created: latency-svc-n4zh5
May 11 01:19:55.144: INFO: Got endpoints: latency-svc-nmmqf [751.229106ms]
May 11 01:19:55.194: INFO: Got endpoints: latency-svc-mfvdq [750.352086ms]
May 11 01:19:55.243: INFO: Got endpoints: latency-svc-rfvn4 [750.573565ms]
May 11 01:19:55.293: INFO: Got endpoints: latency-svc-npnd5 [749.791391ms]
May 11 01:19:55.343: INFO: Got endpoints: latency-svc-jfv65 [750.627193ms]
May 11 01:19:55.393: INFO: Got endpoints: latency-svc-9sjpw [750.329976ms]
May 11 01:19:55.443: INFO: Got endpoints: latency-svc-tsplp [750.446404ms]
May 11 01:19:55.493: INFO: Got endpoints: latency-svc-bgcfd [750.206721ms]
May 11 01:19:55.543: INFO: Got endpoints: latency-svc-2r7fk [749.769435ms]
May 11 01:19:55.593: INFO: Got endpoints: latency-svc-5ftjl [749.229872ms]
May 11 01:19:55.643: INFO: Got endpoints: latency-svc-fgf6t [750.103516ms]
May 11 01:19:55.693: INFO: Got endpoints: latency-svc-shd9g [750.209296ms]
May 11 01:19:55.743: INFO: Got endpoints: latency-svc-hx82n [748.91644ms]
May 11 01:19:55.793: INFO: Got endpoints: latency-svc-2rsgn [749.900186ms]
May 11 01:19:55.843: INFO: Got endpoints: latency-svc-n4zh5 [749.238063ms]
May 11 01:19:55.843: INFO: Latencies: [9.148384ms 13.932819ms 22.721198ms 23.569792ms 32.036208ms 40.59935ms 46.513476ms 50.667627ms 56.272227ms 61.722236ms 66.321059ms 66.694427ms 72.176421ms 76.100713ms 76.67553ms 76.917766ms 77.261174ms 77.621566ms 77.62314ms 78.4582ms 78.698492ms 79.001546ms 80.0877ms 81.311947ms 81.492122ms 81.615978ms 82.07233ms 82.697184ms 82.787685ms 86.475628ms 86.626543ms 90.005089ms 97.013577ms 140.149967ms 184.572398ms 229.029607ms 268.837307ms 317.299815ms 361.996126ms 405.791637ms 446.538732ms 496.443931ms 546.463838ms 588.058179ms 626.538981ms 671.674474ms 714.035421ms 744.230547ms 745.767051ms 745.837246ms 746.25312ms 746.570637ms 747.417825ms 747.418685ms 747.516494ms 747.662128ms 747.719707ms 747.79834ms 747.838562ms 747.918698ms 747.966891ms 748.058105ms 748.226336ms 748.404616ms 748.536826ms 748.587358ms 748.915109ms 748.91644ms 748.922894ms 749.009404ms 749.03868ms 749.042128ms 749.11439ms 749.140583ms 749.142047ms 749.161071ms 749.163169ms 749.173419ms 749.226358ms 749.229872ms 749.238063ms 749.244282ms 749.266226ms 749.304428ms 749.307859ms 749.319201ms 749.341883ms 749.39554ms 749.440326ms 749.472218ms 749.480674ms 749.486036ms 749.505225ms 749.538839ms 749.598382ms 749.60704ms 749.614932ms 749.627087ms 749.640606ms 749.662081ms 749.666538ms 749.671328ms 749.703087ms 749.722299ms 749.729412ms 749.759126ms 749.763163ms 749.769435ms 749.773928ms 749.791391ms 749.821781ms 749.846772ms 749.860494ms 749.876101ms 749.877213ms 749.900186ms 749.92154ms 749.924834ms 749.932679ms 749.941706ms 749.942737ms 749.943377ms 749.945855ms 749.947965ms 749.974746ms 750.015037ms 750.042214ms 750.04252ms 750.050704ms 750.076229ms 750.088881ms 750.103516ms 750.172638ms 750.175012ms 750.176077ms 750.182643ms 750.199091ms 750.206721ms 750.207431ms 750.209296ms 750.21517ms 750.239954ms 750.254407ms 750.292848ms 750.300454ms 750.304123ms 750.307457ms 750.329976ms 750.341595ms 750.352086ms 750.408663ms 750.413043ms 750.413072ms 750.423073ms 750.43059ms 750.446404ms 750.484226ms 750.492678ms 750.493399ms 750.496713ms 750.504464ms 750.505098ms 750.514293ms 750.522519ms 750.547008ms 750.547433ms 750.548159ms 750.555979ms 750.573565ms 750.582979ms 750.613192ms 750.615596ms 750.627193ms 750.752563ms 750.776494ms 750.850868ms 750.924577ms 750.952477ms 750.994761ms 751.012032ms 751.122615ms 751.142404ms 751.196655ms 751.229106ms 751.32999ms 751.474025ms 751.56656ms 751.605186ms 751.621449ms 751.716547ms 752.021371ms 752.050698ms 752.10113ms 752.343608ms 752.613158ms 752.662283ms 752.808594ms 753.690868ms 753.698978ms 755.486955ms]
May 11 01:19:55.843: INFO: 50 %ile: 749.666538ms
May 11 01:19:55.843: INFO: 90 %ile: 751.122615ms
May 11 01:19:55.843: INFO: 99 %ile: 753.698978ms
May 11 01:19:55.843: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:19:55.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-58lpq" for this suite.
May 11 01:20:03.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:20:03.888: INFO: namespace: e2e-tests-svc-latency-58lpq, resource: bindings, ignored listing per whitelist
May 11 01:20:03.913: INFO: namespace e2e-tests-svc-latency-58lpq deletion completed in 8.067406093s

• [SLOW TEST:18.829 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:20:03.913: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 11 01:20:03.958: INFO: Waiting up to 5m0s for pod "downward-api-e795be91-738a-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-4nv4d" to be "success or failure"
May 11 01:20:03.963: INFO: Pod "downward-api-e795be91-738a-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.926598ms
May 11 01:20:05.965: INFO: Pod "downward-api-e795be91-738a-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007140283s
STEP: Saw pod success
May 11 01:20:05.965: INFO: Pod "downward-api-e795be91-738a-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:20:05.967: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downward-api-e795be91-738a-11e9-9c46-760f9b3dbd5d container dapi-container: <nil>
STEP: delete the pod
May 11 01:20:05.979: INFO: Waiting for pod downward-api-e795be91-738a-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:20:05.981: INFO: Pod downward-api-e795be91-738a-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:20:05.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4nv4d" for this suite.
May 11 01:20:11.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:20:12.040: INFO: namespace: e2e-tests-downward-api-4nv4d, resource: bindings, ignored listing per whitelist
May 11 01:20:12.044: INFO: namespace e2e-tests-downward-api-4nv4d deletion completed in 6.059898621s

• [SLOW TEST:8.131 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:20:12.045: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 11 01:20:12.594: INFO: Waiting up to 5m0s for pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9rxcr" in namespace "e2e-tests-svcaccounts-lgj9b" to be "success or failure"
May 11 01:20:12.596: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9rxcr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.377795ms
May 11 01:20:14.599: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9rxcr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004734157s
STEP: Saw pod success
May 11 01:20:14.599: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9rxcr" satisfied condition "success or failure"
May 11 01:20:14.600: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9rxcr container token-test: <nil>
STEP: delete the pod
May 11 01:20:14.612: INFO: Waiting for pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9rxcr to disappear
May 11 01:20:14.614: INFO: Pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9rxcr no longer exists
STEP: Creating a pod to test consume service account root CA
May 11 01:20:14.617: INFO: Waiting up to 5m0s for pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9lnr7" in namespace "e2e-tests-svcaccounts-lgj9b" to be "success or failure"
May 11 01:20:14.621: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9lnr7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.505247ms
May 11 01:20:16.623: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9lnr7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005380957s
STEP: Saw pod success
May 11 01:20:16.623: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9lnr7" satisfied condition "success or failure"
May 11 01:20:16.624: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9lnr7 container root-ca-test: <nil>
STEP: delete the pod
May 11 01:20:16.638: INFO: Waiting for pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9lnr7 to disappear
May 11 01:20:16.640: INFO: Pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-9lnr7 no longer exists
STEP: Creating a pod to test consume service account namespace
May 11 01:20:16.643: INFO: Waiting up to 5m0s for pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-bmh72" in namespace "e2e-tests-svcaccounts-lgj9b" to be "success or failure"
May 11 01:20:16.645: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-bmh72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.736415ms
May 11 01:20:18.648: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-bmh72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004878928s
STEP: Saw pod success
May 11 01:20:18.648: INFO: Pod "pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-bmh72" satisfied condition "success or failure"
May 11 01:20:18.649: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-bmh72 container namespace-test: <nil>
STEP: delete the pod
May 11 01:20:18.666: INFO: Waiting for pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-bmh72 to disappear
May 11 01:20:18.668: INFO: Pod pod-service-account-ecbb9641-738a-11e9-9c46-760f9b3dbd5d-bmh72 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:20:18.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-lgj9b" for this suite.
May 11 01:20:24.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:20:24.735: INFO: namespace: e2e-tests-svcaccounts-lgj9b, resource: bindings, ignored listing per whitelist
May 11 01:20:24.738: INFO: namespace e2e-tests-svcaccounts-lgj9b deletion completed in 6.067337996s

• [SLOW TEST:12.694 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:20:24.738: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kfxcs
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-kfxcs
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-kfxcs
May 11 01:20:24.787: INFO: Found 0 stateful pods, waiting for 1
May 11 01:20:34.791: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 11 01:20:34.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 01:20:35.069: INFO: stderr: ""
May 11 01:20:35.069: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 01:20:35.069: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 01:20:35.072: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 11 01:20:45.075: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 11 01:20:45.075: INFO: Waiting for statefulset status.replicas updated to 0
May 11 01:20:45.082: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:20:45.082: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:20:45.082: INFO: 
May 11 01:20:45.082: INFO: StatefulSet ss has not reached scale 3, at 1
May 11 01:20:46.085: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998119091s
May 11 01:20:47.088: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99551154s
May 11 01:20:48.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992377024s
May 11 01:20:49.094: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989482012s
May 11 01:20:50.097: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.986238157s
May 11 01:20:51.099: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9830442s
May 11 01:20:52.102: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.980674273s
May 11 01:20:53.104: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.978259454s
May 11 01:20:54.107: INFO: Verifying statefulset ss doesn't scale past 3 for another 975.61396ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-kfxcs
May 11 01:20:55.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:20:55.414: INFO: stderr: ""
May 11 01:20:55.414: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 01:20:55.414: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 01:20:55.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:20:55.717: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 11 01:20:55.717: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 01:20:55.717: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 01:20:55.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:20:55.990: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 11 01:20:55.990: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 01:20:55.990: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 01:20:55.993: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 11 01:21:05.996: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:21:05.996: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:21:05.996: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 11 01:21:05.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 01:21:06.289: INFO: stderr: ""
May 11 01:21:06.289: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 01:21:06.289: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 01:21:06.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 01:21:06.612: INFO: stderr: ""
May 11 01:21:06.612: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 01:21:06.612: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 01:21:06.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 01:21:06.908: INFO: stderr: ""
May 11 01:21:06.908: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 01:21:06.908: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 01:21:06.908: INFO: Waiting for statefulset status.replicas updated to 0
May 11 01:21:06.911: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 11 01:21:16.916: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 11 01:21:16.916: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 11 01:21:16.916: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 11 01:21:16.923: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:16.923: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:16.923: INFO: ss-1  craig-k8s-certification-1-stellar-hand-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:44 +0000 UTC  }]
May 11 01:21:16.923: INFO: ss-2  craig-k8s-certification-1-stellar-hand-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:44 +0000 UTC  }]
May 11 01:21:16.923: INFO: 
May 11 01:21:16.923: INFO: StatefulSet ss has not reached scale 0, at 3
May 11 01:21:17.929: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:17.929: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:17.929: INFO: ss-1  craig-k8s-certification-1-stellar-hand-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:44 +0000 UTC  }]
May 11 01:21:17.929: INFO: ss-2  craig-k8s-certification-1-stellar-hand-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:44 +0000 UTC  }]
May 11 01:21:17.929: INFO: 
May 11 01:21:17.929: INFO: StatefulSet ss has not reached scale 0, at 3
May 11 01:21:18.933: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:18.933: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:18.934: INFO: ss-1  craig-k8s-certification-1-stellar-hand-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:44 +0000 UTC  }]
May 11 01:21:18.934: INFO: ss-2  craig-k8s-certification-1-stellar-hand-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:44 +0000 UTC  }]
May 11 01:21:18.934: INFO: 
May 11 01:21:18.934: INFO: StatefulSet ss has not reached scale 0, at 3
May 11 01:21:19.937: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:19.937: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:19.937: INFO: 
May 11 01:21:19.937: INFO: StatefulSet ss has not reached scale 0, at 1
May 11 01:21:20.940: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:20.940: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:20.940: INFO: 
May 11 01:21:20.940: INFO: StatefulSet ss has not reached scale 0, at 1
May 11 01:21:21.944: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:21.944: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:21.944: INFO: 
May 11 01:21:21.944: INFO: StatefulSet ss has not reached scale 0, at 1
May 11 01:21:22.947: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:22.947: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:22.947: INFO: 
May 11 01:21:22.947: INFO: StatefulSet ss has not reached scale 0, at 1
May 11 01:21:23.950: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:23.950: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:23.950: INFO: 
May 11 01:21:23.950: INFO: StatefulSet ss has not reached scale 0, at 1
May 11 01:21:24.954: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:24.954: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:24.954: INFO: 
May 11 01:21:24.954: INFO: StatefulSet ss has not reached scale 0, at 1
May 11 01:21:25.957: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
May 11 01:21:25.957: INFO: ss-0  craig-k8s-certification-1-stellar-hand-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 01:20:24 +0000 UTC  }]
May 11 01:21:25.957: INFO: 
May 11 01:21:25.957: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-kfxcs
May 11 01:21:26.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:21:27.094: INFO: rc: 1
May 11 01:21:27.094: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0024bd890 exit status 1 <nil> <nil> true [0xc0011ad9a8 0xc0011ad9c0 0xc0011ad9d8] [0xc0011ad9a8 0xc0011ad9c0 0xc0011ad9d8] [0xc0011ad9b8 0xc0011ad9d0] [0x92f8e0 0x92f8e0] 0xc002242780 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

May 11 01:21:37.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:21:37.208: INFO: rc: 1
May 11 01:21:37.208: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ab84b0 exit status 1 <nil> <nil> true [0xc000ef2088 0xc000ef20a0 0xc000ef20b8] [0xc000ef2088 0xc000ef20a0 0xc000ef20b8] [0xc000ef2098 0xc000ef20b0] [0x92f8e0 0x92f8e0] 0xc002c7daa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:21:47.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:21:47.288: INFO: rc: 1
May 11 01:21:47.288: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001812570 exit status 1 <nil> <nil> true [0xc002550010 0xc002550028 0xc002550050] [0xc002550010 0xc002550028 0xc002550050] [0xc002550020 0xc002550038] [0x92f8e0 0x92f8e0] 0xc001fb6480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:21:57.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:21:57.390: INFO: rc: 1
May 11 01:21:57.390: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032663c0 exit status 1 <nil> <nil> true [0xc00000e028 0xc000332188 0xc0003322f8] [0xc00000e028 0xc000332188 0xc0003322f8] [0xc000332110 0xc000332298] [0x92f8e0 0x92f8e0] 0xc002c062a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:22:07.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:22:07.469: INFO: rc: 1
May 11 01:22:07.469: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018129c0 exit status 1 <nil> <nil> true [0xc002550058 0xc002550070 0xc002550088] [0xc002550058 0xc002550070 0xc002550088] [0xc002550068 0xc002550080] [0x92f8e0 0x92f8e0] 0xc001fb6960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:22:17.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:22:17.561: INFO: rc: 1
May 11 01:22:17.561: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031be690 exit status 1 <nil> <nil> true [0xc000152000 0xc000152a90 0xc000152ac8] [0xc000152000 0xc000152a90 0xc000152ac8] [0xc000152a80 0xc000152aa0] [0x92f8e0 0x92f8e0] 0xc00256c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:22:27.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:22:27.651: INFO: rc: 1
May 11 01:22:27.651: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001812d80 exit status 1 <nil> <nil> true [0xc002550090 0xc0025500a8 0xc0025500c0] [0xc002550090 0xc0025500a8 0xc0025500c0] [0xc0025500a0 0xc0025500b8] [0x92f8e0 0x92f8e0] 0xc001fb6cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:22:37.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:22:37.751: INFO: rc: 1
May 11 01:22:37.751: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018131d0 exit status 1 <nil> <nil> true [0xc0025500c8 0xc0025500e0 0xc0025500f8] [0xc0025500c8 0xc0025500e0 0xc0025500f8] [0xc0025500d8 0xc0025500f0] [0x92f8e0 0x92f8e0] 0xc001fb6fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:22:47.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:22:47.837: INFO: rc: 1
May 11 01:22:47.837: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002fda3c0 exit status 1 <nil> <nil> true [0xc0019de008 0xc0019de028 0xc0019de048] [0xc0019de008 0xc0019de028 0xc0019de048] [0xc0019de020 0xc0019de040] [0x92f8e0 0x92f8e0] 0xc002030540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:22:57.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:22:57.945: INFO: rc: 1
May 11 01:22:57.946: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001813590 exit status 1 <nil> <nil> true [0xc002550100 0xc002550120 0xc002550150] [0xc002550100 0xc002550120 0xc002550150] [0xc002550110 0xc002550148] [0x92f8e0 0x92f8e0] 0xc001fb72c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:23:07.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:23:08.061: INFO: rc: 1
May 11 01:23:08.061: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002fda7b0 exit status 1 <nil> <nil> true [0xc0019de058 0xc0019de070 0xc0019de098] [0xc0019de058 0xc0019de070 0xc0019de098] [0xc0019de068 0xc0019de090] [0x92f8e0 0x92f8e0] 0xc002030b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:23:18.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:23:18.150: INFO: rc: 1
May 11 01:23:18.150: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031beb10 exit status 1 <nil> <nil> true [0xc000152ae8 0xc000152b00 0xc000152b98] [0xc000152ae8 0xc000152b00 0xc000152b98] [0xc000152af8 0xc000152b90] [0x92f8e0 0x92f8e0] 0xc00256cf60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:23:28.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:23:28.249: INFO: rc: 1
May 11 01:23:28.249: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031bef60 exit status 1 <nil> <nil> true [0xc000152ba0 0xc000152bb8 0xc000152bd0] [0xc000152ba0 0xc000152bb8 0xc000152bd0] [0xc000152bb0 0xc000152bc8] [0x92f8e0 0x92f8e0] 0xc00256d6e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:23:38.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:23:38.326: INFO: rc: 1
May 11 01:23:38.327: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031bf350 exit status 1 <nil> <nil> true [0xc000152be0 0xc000152c20 0xc000152c60] [0xc000152be0 0xc000152c20 0xc000152c60] [0xc000152c18 0xc000152c58] [0x92f8e0 0x92f8e0] 0xc00256daa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:23:48.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:23:48.410: INFO: rc: 1
May 11 01:23:48.410: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001813b00 exit status 1 <nil> <nil> true [0xc002550158 0xc002550188 0xc0025501a0] [0xc002550158 0xc002550188 0xc0025501a0] [0xc002550180 0xc002550198] [0x92f8e0 0x92f8e0] 0xc001fb75c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:23:58.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:23:58.502: INFO: rc: 1
May 11 01:23:58.502: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031be6c0 exit status 1 <nil> <nil> true [0xc0019de008 0xc0019de028 0xc0019de048] [0xc0019de008 0xc0019de028 0xc0019de048] [0xc0019de020 0xc0019de040] [0x92f8e0 0x92f8e0] 0xc002030540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:24:08.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:24:08.582: INFO: rc: 1
May 11 01:24:08.582: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032663f0 exit status 1 <nil> <nil> true [0xc000152000 0xc000152a90 0xc000152ac8] [0xc000152000 0xc000152a90 0xc000152ac8] [0xc000152a80 0xc000152aa0] [0x92f8e0 0x92f8e0] 0xc00256c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:24:18.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:24:18.690: INFO: rc: 1
May 11 01:24:18.690: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002fda420 exit status 1 <nil> <nil> true [0xc00000e050 0xc0003321a8 0xc000332330] [0xc00000e050 0xc0003321a8 0xc000332330] [0xc000332188 0xc0003322f8] [0x92f8e0 0x92f8e0] 0xc002c062a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:24:28.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:24:28.771: INFO: rc: 1
May 11 01:24:28.772: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031beab0 exit status 1 <nil> <nil> true [0xc0019de058 0xc0019de070 0xc0019de098] [0xc0019de058 0xc0019de070 0xc0019de098] [0xc0019de068 0xc0019de090] [0x92f8e0 0x92f8e0] 0xc002030b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:24:38.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:24:38.857: INFO: rc: 1
May 11 01:24:38.857: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002fda840 exit status 1 <nil> <nil> true [0xc000332500 0xc000332850 0xc000332ab0] [0xc000332500 0xc000332850 0xc000332ab0] [0xc000332768 0xc0003329d0] [0x92f8e0 0x92f8e0] 0xc002c065a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:24:48.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:24:48.949: INFO: rc: 1
May 11 01:24:48.949: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031bef30 exit status 1 <nil> <nil> true [0xc0019de0b8 0xc0019de0e8 0xc0019de118] [0xc0019de0b8 0xc0019de0e8 0xc0019de118] [0xc0019de0e0 0xc0019de108] [0x92f8e0 0x92f8e0] 0xc002031140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:24:58.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:24:59.044: INFO: rc: 1
May 11 01:24:59.044: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002fdae40 exit status 1 <nil> <nil> true [0xc000332b30 0xc000332cd0 0xc000332d78] [0xc000332b30 0xc000332cd0 0xc000332d78] [0xc000332cb8 0xc000332d20] [0x92f8e0 0x92f8e0] 0xc002c068a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:25:09.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:25:09.136: INFO: rc: 1
May 11 01:25:09.136: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031bf3b0 exit status 1 <nil> <nil> true [0xc0019de120 0xc0019de150 0xc0019de168] [0xc0019de120 0xc0019de150 0xc0019de168] [0xc0019de148 0xc0019de160] [0x92f8e0 0x92f8e0] 0xc0020316e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:25:19.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:25:19.236: INFO: rc: 1
May 11 01:25:19.236: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002fdb200 exit status 1 <nil> <nil> true [0xc000332e30 0xc000332ec0 0xc000332f38] [0xc000332e30 0xc000332ec0 0xc000332f38] [0xc000332ea8 0xc000332ef8] [0x92f8e0 0x92f8e0] 0xc002c06c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:25:29.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:25:29.327: INFO: rc: 1
May 11 01:25:29.327: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002fdb5c0 exit status 1 <nil> <nil> true [0xc000332f68 0xc000333060 0xc0003330b8] [0xc000332f68 0xc000333060 0xc0003330b8] [0xc000333018 0xc0003330a8] [0x92f8e0 0x92f8e0] 0xc002c06f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:25:39.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:25:39.422: INFO: rc: 1
May 11 01:25:39.422: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031bf7a0 exit status 1 <nil> <nil> true [0xc0019de170 0xc0019de188 0xc0019de1a8] [0xc0019de170 0xc0019de188 0xc0019de1a8] [0xc0019de180 0xc0019de1a0] [0x92f8e0 0x92f8e0] 0xc001fb60c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:25:49.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:25:49.527: INFO: rc: 1
May 11 01:25:49.528: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003266750 exit status 1 <nil> <nil> true [0xc002550000 0xc002550020 0xc002550038] [0xc002550000 0xc002550020 0xc002550038] [0xc002550018 0xc002550030] [0x92f8e0 0x92f8e0] 0xc00256c720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:25:59.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:25:59.605: INFO: rc: 1
May 11 01:25:59.605: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031be690 exit status 1 <nil> <nil> true [0xc00000e050 0xc0019de020 0xc0019de040] [0xc00000e050 0xc0019de020 0xc0019de040] [0xc0019de010 0xc0019de030] [0x92f8e0 0x92f8e0] 0xc002030540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:26:09.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:26:09.697: INFO: rc: 1
May 11 01:26:09.697: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002fda3c0 exit status 1 <nil> <nil> true [0xc002550010 0xc002550060 0xc002550078] [0xc002550010 0xc002550060 0xc002550078] [0xc002550058 0xc002550070] [0x92f8e0 0x92f8e0] 0xc001fb6480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:26:19.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:26:19.797: INFO: rc: 1
May 11 01:26:19.797: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0031beb10 exit status 1 <nil> <nil> true [0xc0019de048 0xc0019de068 0xc0019de090] [0xc0019de048 0xc0019de068 0xc0019de090] [0xc0019de060 0xc0019de078] [0x92f8e0 0x92f8e0] 0xc002030b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 11 01:26:29.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-kfxcs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:26:29.897: INFO: rc: 1
May 11 01:26:29.897: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
May 11 01:26:29.897: INFO: Scaling statefulset ss to 0
May 11 01:26:29.903: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 11 01:26:29.904: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kfxcs
May 11 01:26:29.906: INFO: Scaling statefulset ss to 0
May 11 01:26:29.911: INFO: Waiting for statefulset status.replicas updated to 0
May 11 01:26:29.913: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:26:29.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kfxcs" for this suite.
May 11 01:26:35.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:26:35.943: INFO: namespace: e2e-tests-statefulset-kfxcs, resource: bindings, ignored listing per whitelist
May 11 01:26:35.985: INFO: namespace e2e-tests-statefulset-kfxcs deletion completed in 6.061566555s

• [SLOW TEST:371.246 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:26:35.985: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-sd75c/configmap-test-d146ed7c-738b-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:26:36.030: INFO: Waiting up to 5m0s for pod "pod-configmaps-d14736d0-738b-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-sd75c" to be "success or failure"
May 11 01:26:36.032: INFO: Pod "pod-configmaps-d14736d0-738b-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.940718ms
May 11 01:26:38.034: INFO: Pod "pod-configmaps-d14736d0-738b-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004340466s
STEP: Saw pod success
May 11 01:26:38.034: INFO: Pod "pod-configmaps-d14736d0-738b-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:26:38.036: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-configmaps-d14736d0-738b-11e9-9c46-760f9b3dbd5d container env-test: <nil>
STEP: delete the pod
May 11 01:26:38.048: INFO: Waiting for pod pod-configmaps-d14736d0-738b-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:26:38.051: INFO: Pod pod-configmaps-d14736d0-738b-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:26:38.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sd75c" for this suite.
May 11 01:26:44.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:26:44.095: INFO: namespace: e2e-tests-configmap-sd75c, resource: bindings, ignored listing per whitelist
May 11 01:26:44.119: INFO: namespace e2e-tests-configmap-sd75c deletion completed in 6.065502003s

• [SLOW TEST:8.134 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:26:44.119: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
May 11 01:26:44.163: INFO: Waiting up to 5m0s for pod "client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-containers-4zmfv" to be "success or failure"
May 11 01:26:44.165: INFO: Pod "client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.833642ms
May 11 01:26:46.168: INFO: Pod "client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005293441s
May 11 01:26:48.171: INFO: Pod "client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00765666s
May 11 01:26:50.173: INFO: Pod "client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010079526s
STEP: Saw pod success
May 11 01:26:50.173: INFO: Pod "client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:26:50.175: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:26:50.186: INFO: Waiting for pod client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:26:50.188: INFO: Pod client-containers-d62049e0-738b-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:26:50.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4zmfv" for this suite.
May 11 01:26:56.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:26:56.229: INFO: namespace: e2e-tests-containers-4zmfv, resource: bindings, ignored listing per whitelist
May 11 01:26:56.248: INFO: namespace e2e-tests-containers-4zmfv deletion completed in 6.057911696s

• [SLOW TEST:12.129 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:26:56.248: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
May 11 01:26:56.806: INFO: created pod pod-service-account-defaultsa
May 11 01:26:56.806: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 11 01:26:56.808: INFO: created pod pod-service-account-mountsa
May 11 01:26:56.808: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 11 01:26:56.811: INFO: created pod pod-service-account-nomountsa
May 11 01:26:56.811: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 11 01:26:56.814: INFO: created pod pod-service-account-defaultsa-mountspec
May 11 01:26:56.814: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 11 01:26:56.825: INFO: created pod pod-service-account-mountsa-mountspec
May 11 01:26:56.825: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 11 01:26:56.830: INFO: created pod pod-service-account-nomountsa-mountspec
May 11 01:26:56.830: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 11 01:26:56.835: INFO: created pod pod-service-account-defaultsa-nomountspec
May 11 01:26:56.835: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 11 01:26:56.842: INFO: created pod pod-service-account-mountsa-nomountspec
May 11 01:26:56.842: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 11 01:26:56.855: INFO: created pod pod-service-account-nomountsa-nomountspec
May 11 01:26:56.855: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:26:56.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-m5dlm" for this suite.
May 11 01:27:02.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:27:02.894: INFO: namespace: e2e-tests-svcaccounts-m5dlm, resource: bindings, ignored listing per whitelist
May 11 01:27:02.915: INFO: namespace e2e-tests-svcaccounts-m5dlm deletion completed in 6.055278984s

• [SLOW TEST:6.667 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:27:02.915: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 11 01:27:02.950: INFO: namespace e2e-tests-kubectl-9tvhq
May 11 01:27:02.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-9tvhq'
May 11 01:27:03.250: INFO: stderr: ""
May 11 01:27:03.250: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 11 01:27:04.253: INFO: Selector matched 1 pods for map[app:redis]
May 11 01:27:04.253: INFO: Found 0 / 1
May 11 01:27:05.252: INFO: Selector matched 1 pods for map[app:redis]
May 11 01:27:05.252: INFO: Found 1 / 1
May 11 01:27:05.252: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 11 01:27:05.254: INFO: Selector matched 1 pods for map[app:redis]
May 11 01:27:05.254: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 11 01:27:05.254: INFO: wait on redis-master startup in e2e-tests-kubectl-9tvhq 
May 11 01:27:05.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 logs redis-master-nswd8 redis-master --namespace=e2e-tests-kubectl-9tvhq'
May 11 01:27:05.344: INFO: stderr: ""
May 11 01:27:05.344: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 May 01:27:04.317 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 May 01:27:04.317 # Server started, Redis version 3.2.12\n1:M 11 May 01:27:04.317 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 May 01:27:04.317 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 11 01:27:05.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-9tvhq'
May 11 01:27:05.437: INFO: stderr: ""
May 11 01:27:05.437: INFO: stdout: "service/rm2 exposed\n"
May 11 01:27:05.439: INFO: Service rm2 in namespace e2e-tests-kubectl-9tvhq found.
STEP: exposing service
May 11 01:27:07.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-9tvhq'
May 11 01:27:07.536: INFO: stderr: ""
May 11 01:27:07.536: INFO: stdout: "service/rm3 exposed\n"
May 11 01:27:07.538: INFO: Service rm3 in namespace e2e-tests-kubectl-9tvhq found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:27:09.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9tvhq" for this suite.
May 11 01:27:31.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:27:31.587: INFO: namespace: e2e-tests-kubectl-9tvhq, resource: bindings, ignored listing per whitelist
May 11 01:27:31.611: INFO: namespace e2e-tests-kubectl-9tvhq deletion completed in 22.063659595s

• [SLOW TEST:28.696 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:27:31.611: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 11 01:27:31.655: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:27:35.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rz7tr" for this suite.
May 11 01:27:41.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:27:41.099: INFO: namespace: e2e-tests-init-container-rz7tr, resource: bindings, ignored listing per whitelist
May 11 01:27:41.115: INFO: namespace e2e-tests-init-container-rz7tr deletion completed in 6.059711469s

• [SLOW TEST:9.504 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:27:41.115: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-f81bddaf-738b-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 01:27:41.179: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f81c34cd-738b-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-vgwbh" to be "success or failure"
May 11 01:27:41.183: INFO: Pod "pod-projected-secrets-f81c34cd-738b-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.942481ms
May 11 01:27:43.186: INFO: Pod "pod-projected-secrets-f81c34cd-738b-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006721165s
STEP: Saw pod success
May 11 01:27:43.186: INFO: Pod "pod-projected-secrets-f81c34cd-738b-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:27:43.188: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-projected-secrets-f81c34cd-738b-11e9-9c46-760f9b3dbd5d container projected-secret-volume-test: <nil>
STEP: delete the pod
May 11 01:27:43.205: INFO: Waiting for pod pod-projected-secrets-f81c34cd-738b-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:27:43.208: INFO: Pod pod-projected-secrets-f81c34cd-738b-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:27:43.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vgwbh" for this suite.
May 11 01:27:49.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:27:49.249: INFO: namespace: e2e-tests-projected-vgwbh, resource: bindings, ignored listing per whitelist
May 11 01:27:49.292: INFO: namespace e2e-tests-projected-vgwbh deletion completed in 6.081367526s

• [SLOW TEST:8.176 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:27:49.292: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 01:27:49.344: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:27:50.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-6hklr" for this suite.
May 11 01:27:56.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:27:56.406: INFO: namespace: e2e-tests-custom-resource-definition-6hklr, resource: bindings, ignored listing per whitelist
May 11 01:27:56.443: INFO: namespace e2e-tests-custom-resource-definition-6hklr deletion completed in 6.062292655s

• [SLOW TEST:7.151 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:27:56.443: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-cl566
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
May 11 01:27:56.489: INFO: Found 0 stateful pods, waiting for 3
May 11 01:28:06.492: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:28:06.492: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:28:06.492: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:28:06.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-cl566 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 01:28:06.779: INFO: stderr: ""
May 11 01:28:06.779: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 01:28:06.779: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 11 01:28:16.806: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 11 01:28:26.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-cl566 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:28:27.129: INFO: stderr: ""
May 11 01:28:27.129: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 01:28:27.129: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 01:28:37.144: INFO: Waiting for StatefulSet e2e-tests-statefulset-cl566/ss2 to complete update
May 11 01:28:37.144: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 11 01:28:37.144: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 11 01:28:37.144: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 11 01:28:47.150: INFO: Waiting for StatefulSet e2e-tests-statefulset-cl566/ss2 to complete update
May 11 01:28:47.150: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 11 01:28:47.150: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 11 01:28:57.150: INFO: Waiting for StatefulSet e2e-tests-statefulset-cl566/ss2 to complete update
May 11 01:28:57.150: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
May 11 01:29:07.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-cl566 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 11 01:29:07.437: INFO: stderr: ""
May 11 01:29:07.437: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 11 01:29:07.437: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 11 01:29:17.461: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 11 01:29:27.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 exec --namespace=e2e-tests-statefulset-cl566 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 11 01:29:27.774: INFO: stderr: ""
May 11 01:29:27.774: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 11 01:29:27.774: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 11 01:29:37.791: INFO: Waiting for StatefulSet e2e-tests-statefulset-cl566/ss2 to complete update
May 11 01:29:37.791: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May 11 01:29:37.791: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
May 11 01:29:47.797: INFO: Waiting for StatefulSet e2e-tests-statefulset-cl566/ss2 to complete update
May 11 01:29:47.797: INFO: Waiting for Pod e2e-tests-statefulset-cl566/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May 11 01:29:57.797: INFO: Waiting for StatefulSet e2e-tests-statefulset-cl566/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 11 01:30:07.795: INFO: Deleting all statefulset in ns e2e-tests-statefulset-cl566
May 11 01:30:07.797: INFO: Scaling statefulset ss2 to 0
May 11 01:30:27.808: INFO: Waiting for statefulset status.replicas updated to 0
May 11 01:30:27.811: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:30:27.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-cl566" for this suite.
May 11 01:30:33.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:30:33.892: INFO: namespace: e2e-tests-statefulset-cl566, resource: bindings, ignored listing per whitelist
May 11 01:30:33.896: INFO: namespace e2e-tests-statefulset-cl566 deletion completed in 6.072566521s

• [SLOW TEST:157.453 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:30:33.896: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 11 01:30:33.948: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:30:38.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6hkx7" for this suite.
May 11 01:30:44.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:30:44.147: INFO: namespace: e2e-tests-init-container-6hkx7, resource: bindings, ignored listing per whitelist
May 11 01:30:44.155: INFO: namespace e2e-tests-init-container-6hkx7 deletion completed in 6.063598821s

• [SLOW TEST:10.258 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:30:44.155: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 01:30:44.199: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:30:48.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vbsl6" for this suite.
May 11 01:31:26.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:31:26.432: INFO: namespace: e2e-tests-pods-vbsl6, resource: bindings, ignored listing per whitelist
May 11 01:31:26.459: INFO: namespace e2e-tests-pods-vbsl6 deletion completed in 38.064462554s

• [SLOW TEST:42.304 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:31:26.459: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-7e6a87a8-738c-11e9-9c46-760f9b3dbd5d
May 11 01:31:26.508: INFO: Pod name my-hostname-basic-7e6a87a8-738c-11e9-9c46-760f9b3dbd5d: Found 0 pods out of 1
May 11 01:31:31.511: INFO: Pod name my-hostname-basic-7e6a87a8-738c-11e9-9c46-760f9b3dbd5d: Found 1 pods out of 1
May 11 01:31:31.511: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7e6a87a8-738c-11e9-9c46-760f9b3dbd5d" are running
May 11 01:31:31.512: INFO: Pod "my-hostname-basic-7e6a87a8-738c-11e9-9c46-760f9b3dbd5d-fpr57" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-11 01:31:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-11 01:31:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-11 01:31:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-11 01:31:25 +0000 UTC Reason: Message:}])
May 11 01:31:31.513: INFO: Trying to dial the pod
May 11 01:31:36.520: INFO: Controller my-hostname-basic-7e6a87a8-738c-11e9-9c46-760f9b3dbd5d: Got expected result from replica 1 [my-hostname-basic-7e6a87a8-738c-11e9-9c46-760f9b3dbd5d-fpr57]: "my-hostname-basic-7e6a87a8-738c-11e9-9c46-760f9b3dbd5d-fpr57", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:31:36.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8nrjp" for this suite.
May 11 01:31:42.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:31:42.584: INFO: namespace: e2e-tests-replication-controller-8nrjp, resource: bindings, ignored listing per whitelist
May 11 01:31:42.604: INFO: namespace e2e-tests-replication-controller-8nrjp deletion completed in 6.081911718s

• [SLOW TEST:16.145 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:31:42.604: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:31:48.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-rlvh2" for this suite.
May 11 01:31:54.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:31:54.750: INFO: namespace: e2e-tests-namespaces-rlvh2, resource: bindings, ignored listing per whitelist
May 11 01:31:54.782: INFO: namespace e2e-tests-namespaces-rlvh2 deletion completed in 6.076558364s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hrxmn" for this suite.
May 11 01:31:54.783: INFO: Namespace e2e-tests-nsdeletetest-hrxmn was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-9rs2b" for this suite.
May 11 01:32:00.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:32:00.844: INFO: namespace: e2e-tests-nsdeletetest-9rs2b, resource: bindings, ignored listing per whitelist
May 11 01:32:00.849: INFO: namespace e2e-tests-nsdeletetest-9rs2b deletion completed in 6.065299996s

• [SLOW TEST:18.244 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:32:00.849: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-92ebb4e6-738c-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:32:00.910: INFO: Waiting up to 5m0s for pod "pod-configmaps-92ec002e-738c-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-7nqqv" to be "success or failure"
May 11 01:32:00.912: INFO: Pod "pod-configmaps-92ec002e-738c-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.918566ms
May 11 01:32:02.915: INFO: Pod "pod-configmaps-92ec002e-738c-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004440036s
STEP: Saw pod success
May 11 01:32:02.915: INFO: Pod "pod-configmaps-92ec002e-738c-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:32:02.916: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-configmaps-92ec002e-738c-11e9-9c46-760f9b3dbd5d container configmap-volume-test: <nil>
STEP: delete the pod
May 11 01:32:02.928: INFO: Waiting for pod pod-configmaps-92ec002e-738c-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:32:02.930: INFO: Pod pod-configmaps-92ec002e-738c-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:32:02.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7nqqv" for this suite.
May 11 01:32:08.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:32:08.992: INFO: namespace: e2e-tests-configmap-7nqqv, resource: bindings, ignored listing per whitelist
May 11 01:32:09.033: INFO: namespace e2e-tests-configmap-7nqqv deletion completed in 6.100200183s

• [SLOW TEST:8.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:32:09.033: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 11 01:32:09.077: INFO: Waiting up to 5m0s for pod "downward-api-97ca3b90-738c-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-w7lvp" to be "success or failure"
May 11 01:32:09.079: INFO: Pod "downward-api-97ca3b90-738c-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.345235ms
May 11 01:32:11.082: INFO: Pod "downward-api-97ca3b90-738c-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005056658s
STEP: Saw pod success
May 11 01:32:11.082: INFO: Pod "downward-api-97ca3b90-738c-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:32:11.084: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downward-api-97ca3b90-738c-11e9-9c46-760f9b3dbd5d container dapi-container: <nil>
STEP: delete the pod
May 11 01:32:11.098: INFO: Waiting for pod downward-api-97ca3b90-738c-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:32:11.099: INFO: Pod downward-api-97ca3b90-738c-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:32:11.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w7lvp" for this suite.
May 11 01:32:17.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:32:17.153: INFO: namespace: e2e-tests-downward-api-w7lvp, resource: bindings, ignored listing per whitelist
May 11 01:32:17.164: INFO: namespace e2e-tests-downward-api-w7lvp deletion completed in 6.062627418s

• [SLOW TEST:8.131 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:32:17.164: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 11 01:32:17.217: INFO: Waiting up to 5m0s for pod "pod-9ca4371f-738c-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-xgm9t" to be "success or failure"
May 11 01:32:17.219: INFO: Pod "pod-9ca4371f-738c-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.908178ms
May 11 01:32:19.221: INFO: Pod "pod-9ca4371f-738c-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004013319s
May 11 01:32:21.223: INFO: Pod "pod-9ca4371f-738c-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006588263s
STEP: Saw pod success
May 11 01:32:21.223: INFO: Pod "pod-9ca4371f-738c-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:32:21.225: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-9ca4371f-738c-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:32:21.238: INFO: Waiting for pod pod-9ca4371f-738c-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:32:21.240: INFO: Pod pod-9ca4371f-738c-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:32:21.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xgm9t" for this suite.
May 11 01:32:27.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:32:27.284: INFO: namespace: e2e-tests-emptydir-xgm9t, resource: bindings, ignored listing per whitelist
May 11 01:32:27.317: INFO: namespace e2e-tests-emptydir-xgm9t deletion completed in 6.073813381s

• [SLOW TEST:10.153 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:32:27.317: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a2b17760-738c-11e9-9c46-760f9b3dbd5d
STEP: Creating secret with name s-test-opt-upd-a2b177a5-738c-11e9-9c46-760f9b3dbd5d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a2b17760-738c-11e9-9c46-760f9b3dbd5d
STEP: Updating secret s-test-opt-upd-a2b177a5-738c-11e9-9c46-760f9b3dbd5d
STEP: Creating secret with name s-test-opt-create-a2b177c0-738c-11e9-9c46-760f9b3dbd5d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:32:31.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9g98v" for this suite.
May 11 01:32:53.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:32:53.470: INFO: namespace: e2e-tests-projected-9g98v, resource: bindings, ignored listing per whitelist
May 11 01:32:53.493: INFO: namespace e2e-tests-projected-9g98v deletion completed in 22.059313154s

• [SLOW TEST:26.175 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:32:53.493: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-b24aaff0-738c-11e9-9c46-760f9b3dbd5d
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:32:55.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wh2jb" for this suite.
May 11 01:33:17.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:33:17.602: INFO: namespace: e2e-tests-configmap-wh2jb, resource: bindings, ignored listing per whitelist
May 11 01:33:17.634: INFO: namespace e2e-tests-configmap-wh2jb deletion completed in 22.072766516s

• [SLOW TEST:24.141 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:33:17.634: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c0aedbd3-738c-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:33:17.687: INFO: Waiting up to 5m0s for pod "pod-configmaps-c0af2c89-738c-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-9b4nc" to be "success or failure"
May 11 01:33:17.690: INFO: Pod "pod-configmaps-c0af2c89-738c-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.661362ms
May 11 01:33:19.693: INFO: Pod "pod-configmaps-c0af2c89-738c-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005467014s
STEP: Saw pod success
May 11 01:33:19.693: INFO: Pod "pod-configmaps-c0af2c89-738c-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:33:19.695: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-configmaps-c0af2c89-738c-11e9-9c46-760f9b3dbd5d container configmap-volume-test: <nil>
STEP: delete the pod
May 11 01:33:19.709: INFO: Waiting for pod pod-configmaps-c0af2c89-738c-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:33:19.710: INFO: Pod pod-configmaps-c0af2c89-738c-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:33:19.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9b4nc" for this suite.
May 11 01:33:25.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:33:25.732: INFO: namespace: e2e-tests-configmap-9b4nc, resource: bindings, ignored listing per whitelist
May 11 01:33:25.780: INFO: namespace e2e-tests-configmap-9b4nc deletion completed in 6.067485425s

• [SLOW TEST:8.146 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:33:25.780: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xtwsf A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-xtwsf;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xtwsf A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-xtwsf;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xtwsf.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-xtwsf.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xtwsf.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xtwsf.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-xtwsf.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xtwsf.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-xtwsf.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xtwsf.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 86.63.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.63.86_udp@PTR;check="$$(dig +tcp +noall +answer +search 86.63.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.63.86_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xtwsf A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-xtwsf;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xtwsf A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xtwsf.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xtwsf.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xtwsf.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-xtwsf.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xtwsf.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-xtwsf.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xtwsf.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 86.63.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.63.86_udp@PTR;check="$$(dig +tcp +noall +answer +search 86.63.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.63.86_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 11 01:33:29.846: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.849: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.858: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.860: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.873: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.875: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.886: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.888: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.890: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.892: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:29.903: INFO: Lookups using e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc]

May 11 01:33:34.907: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.910: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.921: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.923: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.937: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.939: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.945: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.947: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.949: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.951: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:34.962: INFO: Lookups using e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc]

May 11 01:33:39.907: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.911: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.924: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.927: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.956: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.959: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.975: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.981: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.990: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:39.994: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:40.018: INFO: Lookups using e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc]

May 11 01:33:44.906: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.909: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.918: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.920: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.932: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.934: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.939: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.941: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.942: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.944: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:44.956: INFO: Lookups using e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc]

May 11 01:33:49.906: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.909: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.920: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.922: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.937: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.939: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.946: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.948: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.950: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.951: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:49.962: INFO: Lookups using e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc]

May 11 01:33:54.907: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.911: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.926: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.928: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.941: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.944: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.951: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.954: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.957: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.959: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc from pod e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d: the server could not find the requested resource (get pods dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d)
May 11 01:33:54.971: INFO: Lookups using e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@dns-test-service.e2e-tests-dns-xtwsf.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xtwsf.svc]

May 11 01:33:59.966: INFO: DNS probes using e2e-tests-dns-xtwsf/dns-test-c58a1e41-738c-11e9-9c46-760f9b3dbd5d succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:33:59.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-xtwsf" for this suite.
May 11 01:34:06.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:34:06.063: INFO: namespace: e2e-tests-dns-xtwsf, resource: bindings, ignored listing per whitelist
May 11 01:34:06.076: INFO: namespace e2e-tests-dns-xtwsf deletion completed in 6.073719376s

• [SLOW TEST:40.295 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:34:06.076: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
May 11 01:34:06.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:06.301: INFO: stderr: ""
May 11 01:34:06.301: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 11 01:34:06.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:06.401: INFO: stderr: ""
May 11 01:34:06.401: INFO: stdout: "update-demo-nautilus-2lj28 update-demo-nautilus-v4nn8 "
May 11 01:34:06.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-2lj28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:06.498: INFO: stderr: ""
May 11 01:34:06.498: INFO: stdout: ""
May 11 01:34:06.498: INFO: update-demo-nautilus-2lj28 is created but not running
May 11 01:34:11.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:11.611: INFO: stderr: ""
May 11 01:34:11.611: INFO: stdout: "update-demo-nautilus-2lj28 update-demo-nautilus-v4nn8 "
May 11 01:34:11.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-2lj28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:11.706: INFO: stderr: ""
May 11 01:34:11.706: INFO: stdout: "true"
May 11 01:34:11.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-2lj28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:11.785: INFO: stderr: ""
May 11 01:34:11.785: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:34:11.785: INFO: validating pod update-demo-nautilus-2lj28
May 11 01:34:11.788: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:34:11.788: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:34:11.788: INFO: update-demo-nautilus-2lj28 is verified up and running
May 11 01:34:11.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-v4nn8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:11.881: INFO: stderr: ""
May 11 01:34:11.881: INFO: stdout: "true"
May 11 01:34:11.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-v4nn8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:11.982: INFO: stderr: ""
May 11 01:34:11.982: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:34:11.982: INFO: validating pod update-demo-nautilus-v4nn8
May 11 01:34:11.985: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:34:11.985: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:34:11.985: INFO: update-demo-nautilus-v4nn8 is verified up and running
STEP: rolling-update to new replication controller
May 11 01:34:11.987: INFO: scanned /root for discovery docs: <nil>
May 11 01:34:11.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:34.358: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 11 01:34:34.358: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 11 01:34:34.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:34.459: INFO: stderr: ""
May 11 01:34:34.459: INFO: stdout: "update-demo-kitten-7slqt update-demo-kitten-mf4fc "
May 11 01:34:34.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-kitten-7slqt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:34.580: INFO: stderr: ""
May 11 01:34:34.580: INFO: stdout: "true"
May 11 01:34:34.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-kitten-7slqt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:34.702: INFO: stderr: ""
May 11 01:34:34.702: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 11 01:34:34.702: INFO: validating pod update-demo-kitten-7slqt
May 11 01:34:34.706: INFO: got data: {
  "image": "kitten.jpg"
}

May 11 01:34:34.706: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 11 01:34:34.706: INFO: update-demo-kitten-7slqt is verified up and running
May 11 01:34:34.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-kitten-mf4fc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:34.810: INFO: stderr: ""
May 11 01:34:34.810: INFO: stdout: "true"
May 11 01:34:34.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-kitten-mf4fc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r6wqq'
May 11 01:34:34.914: INFO: stderr: ""
May 11 01:34:34.914: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 11 01:34:34.914: INFO: validating pod update-demo-kitten-mf4fc
May 11 01:34:34.918: INFO: got data: {
  "image": "kitten.jpg"
}

May 11 01:34:34.918: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 11 01:34:34.918: INFO: update-demo-kitten-mf4fc is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:34:34.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r6wqq" for this suite.
May 11 01:34:56.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:34:56.964: INFO: namespace: e2e-tests-kubectl-r6wqq, resource: bindings, ignored listing per whitelist
May 11 01:34:56.989: INFO: namespace e2e-tests-kubectl-r6wqq deletion completed in 22.068476628s

• [SLOW TEST:50.913 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:34:56.990: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-fbe7e941-738c-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:34:57.047: INFO: Waiting up to 5m0s for pod "pod-configmaps-fbe84432-738c-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-9pt88" to be "success or failure"
May 11 01:34:57.050: INFO: Pod "pod-configmaps-fbe84432-738c-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595373ms
May 11 01:34:59.053: INFO: Pod "pod-configmaps-fbe84432-738c-11e9-9c46-760f9b3dbd5d": Phase="Running", Reason="", readiness=true. Elapsed: 2.005345426s
May 11 01:35:01.059: INFO: Pod "pod-configmaps-fbe84432-738c-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011462467s
STEP: Saw pod success
May 11 01:35:01.059: INFO: Pod "pod-configmaps-fbe84432-738c-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:35:01.062: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-configmaps-fbe84432-738c-11e9-9c46-760f9b3dbd5d container configmap-volume-test: <nil>
STEP: delete the pod
May 11 01:35:01.077: INFO: Waiting for pod pod-configmaps-fbe84432-738c-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:35:01.078: INFO: Pod pod-configmaps-fbe84432-738c-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:35:01.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9pt88" for this suite.
May 11 01:35:07.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:35:07.113: INFO: namespace: e2e-tests-configmap-9pt88, resource: bindings, ignored listing per whitelist
May 11 01:35:07.157: INFO: namespace e2e-tests-configmap-9pt88 deletion completed in 6.075982832s

• [SLOW TEST:10.168 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:35:07.158: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4xfmg
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
May 11 01:35:07.211: INFO: Found 0 stateful pods, waiting for 3
May 11 01:35:17.214: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:35:17.214: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:35:17.214: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 11 01:35:17.236: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 11 01:35:27.263: INFO: Updating stateful set ss2
May 11 01:35:27.267: INFO: Waiting for Pod e2e-tests-statefulset-4xfmg/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 11 01:35:37.300: INFO: Found 1 stateful pods, waiting for 3
May 11 01:35:47.303: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:35:47.303: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 11 01:35:47.303: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 11 01:35:47.323: INFO: Updating stateful set ss2
May 11 01:35:47.328: INFO: Waiting for Pod e2e-tests-statefulset-4xfmg/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 11 01:35:57.332: INFO: Waiting for Pod e2e-tests-statefulset-4xfmg/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 11 01:36:07.349: INFO: Updating stateful set ss2
May 11 01:36:07.356: INFO: Waiting for StatefulSet e2e-tests-statefulset-4xfmg/ss2 to complete update
May 11 01:36:07.356: INFO: Waiting for Pod e2e-tests-statefulset-4xfmg/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 11 01:36:17.361: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4xfmg
May 11 01:36:17.363: INFO: Scaling statefulset ss2 to 0
May 11 01:36:27.372: INFO: Waiting for statefulset status.replicas updated to 0
May 11 01:36:27.374: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:36:27.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4xfmg" for this suite.
May 11 01:36:33.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:36:33.403: INFO: namespace: e2e-tests-statefulset-4xfmg, resource: bindings, ignored listing per whitelist
May 11 01:36:33.442: INFO: namespace e2e-tests-statefulset-4xfmg deletion completed in 6.058463599s

• [SLOW TEST:86.285 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:36:33.442: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 11 01:36:33.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:33.681: INFO: stderr: ""
May 11 01:36:33.681: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 11 01:36:33.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:33.772: INFO: stderr: ""
May 11 01:36:33.772: INFO: stdout: "update-demo-nautilus-cnvzl update-demo-nautilus-sncwh "
May 11 01:36:33.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-cnvzl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:33.872: INFO: stderr: ""
May 11 01:36:33.872: INFO: stdout: ""
May 11 01:36:33.873: INFO: update-demo-nautilus-cnvzl is created but not running
May 11 01:36:38.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:38.969: INFO: stderr: ""
May 11 01:36:38.969: INFO: stdout: "update-demo-nautilus-cnvzl update-demo-nautilus-sncwh "
May 11 01:36:38.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-cnvzl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:39.057: INFO: stderr: ""
May 11 01:36:39.057: INFO: stdout: "true"
May 11 01:36:39.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-cnvzl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:39.140: INFO: stderr: ""
May 11 01:36:39.140: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:36:39.140: INFO: validating pod update-demo-nautilus-cnvzl
May 11 01:36:39.144: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:36:39.144: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:36:39.144: INFO: update-demo-nautilus-cnvzl is verified up and running
May 11 01:36:39.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-sncwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:39.248: INFO: stderr: ""
May 11 01:36:39.248: INFO: stdout: "true"
May 11 01:36:39.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-sncwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:39.335: INFO: stderr: ""
May 11 01:36:39.336: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:36:39.336: INFO: validating pod update-demo-nautilus-sncwh
May 11 01:36:39.338: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:36:39.339: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:36:39.339: INFO: update-demo-nautilus-sncwh is verified up and running
STEP: scaling down the replication controller
May 11 01:36:39.340: INFO: scanned /root for discovery docs: <nil>
May 11 01:36:39.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:40.449: INFO: stderr: ""
May 11 01:36:40.449: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 11 01:36:40.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:40.546: INFO: stderr: ""
May 11 01:36:40.546: INFO: stdout: "update-demo-nautilus-cnvzl update-demo-nautilus-sncwh "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 11 01:36:45.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:45.661: INFO: stderr: ""
May 11 01:36:45.661: INFO: stdout: "update-demo-nautilus-cnvzl update-demo-nautilus-sncwh "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 11 01:36:50.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:50.762: INFO: stderr: ""
May 11 01:36:50.762: INFO: stdout: "update-demo-nautilus-sncwh "
May 11 01:36:50.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-sncwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:50.862: INFO: stderr: ""
May 11 01:36:50.862: INFO: stdout: "true"
May 11 01:36:50.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-sncwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:50.946: INFO: stderr: ""
May 11 01:36:50.946: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:36:50.946: INFO: validating pod update-demo-nautilus-sncwh
May 11 01:36:50.948: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:36:50.948: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:36:50.948: INFO: update-demo-nautilus-sncwh is verified up and running
STEP: scaling up the replication controller
May 11 01:36:50.950: INFO: scanned /root for discovery docs: <nil>
May 11 01:36:50.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:52.069: INFO: stderr: ""
May 11 01:36:52.069: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 11 01:36:52.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:52.186: INFO: stderr: ""
May 11 01:36:52.186: INFO: stdout: "update-demo-nautilus-4j2dr update-demo-nautilus-sncwh "
May 11 01:36:52.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-4j2dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:52.294: INFO: stderr: ""
May 11 01:36:52.294: INFO: stdout: ""
May 11 01:36:52.294: INFO: update-demo-nautilus-4j2dr is created but not running
May 11 01:36:57.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:57.400: INFO: stderr: ""
May 11 01:36:57.400: INFO: stdout: "update-demo-nautilus-4j2dr update-demo-nautilus-sncwh "
May 11 01:36:57.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-4j2dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:57.507: INFO: stderr: ""
May 11 01:36:57.507: INFO: stdout: "true"
May 11 01:36:57.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-4j2dr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:57.605: INFO: stderr: ""
May 11 01:36:57.605: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:36:57.605: INFO: validating pod update-demo-nautilus-4j2dr
May 11 01:36:57.610: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:36:57.610: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:36:57.610: INFO: update-demo-nautilus-4j2dr is verified up and running
May 11 01:36:57.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-sncwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:57.723: INFO: stderr: ""
May 11 01:36:57.723: INFO: stdout: "true"
May 11 01:36:57.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods update-demo-nautilus-sncwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:57.830: INFO: stderr: ""
May 11 01:36:57.830: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 11 01:36:57.830: INFO: validating pod update-demo-nautilus-sncwh
May 11 01:36:57.833: INFO: got data: {
  "image": "nautilus.jpg"
}

May 11 01:36:57.833: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 11 01:36:57.833: INFO: update-demo-nautilus-sncwh is verified up and running
STEP: using delete to clean up resources
May 11 01:36:57.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:57.932: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:36:57.932: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 11 01:36:57.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bh8wd'
May 11 01:36:58.034: INFO: stderr: "No resources found.\n"
May 11 01:36:58.034: INFO: stdout: ""
May 11 01:36:58.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -l name=update-demo --namespace=e2e-tests-kubectl-bh8wd -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 11 01:36:58.131: INFO: stderr: ""
May 11 01:36:58.131: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:36:58.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bh8wd" for this suite.
May 11 01:37:20.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:37:20.168: INFO: namespace: e2e-tests-kubectl-bh8wd, resource: bindings, ignored listing per whitelist
May 11 01:37:20.210: INFO: namespace e2e-tests-kubectl-bh8wd deletion completed in 22.075522148s

• [SLOW TEST:46.767 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:37:20.210: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
May 11 01:37:20.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-8fpk5'
May 11 01:37:20.562: INFO: stderr: ""
May 11 01:37:20.562: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
May 11 01:37:21.565: INFO: Selector matched 1 pods for map[app:redis]
May 11 01:37:21.565: INFO: Found 0 / 1
May 11 01:37:22.564: INFO: Selector matched 1 pods for map[app:redis]
May 11 01:37:22.564: INFO: Found 0 / 1
May 11 01:37:23.565: INFO: Selector matched 1 pods for map[app:redis]
May 11 01:37:23.565: INFO: Found 1 / 1
May 11 01:37:23.565: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 11 01:37:23.567: INFO: Selector matched 1 pods for map[app:redis]
May 11 01:37:23.567: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 11 01:37:23.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 logs redis-master-8hjlt redis-master --namespace=e2e-tests-kubectl-8fpk5'
May 11 01:37:23.677: INFO: stderr: ""
May 11 01:37:23.677: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 May 01:37:21.638 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 May 01:37:21.638 # Server started, Redis version 3.2.12\n1:M 11 May 01:37:21.638 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 May 01:37:21.638 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 11 01:37:23.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 log redis-master-8hjlt redis-master --namespace=e2e-tests-kubectl-8fpk5 --tail=1'
May 11 01:37:23.771: INFO: stderr: ""
May 11 01:37:23.771: INFO: stdout: "1:M 11 May 01:37:21.638 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 11 01:37:23.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 log redis-master-8hjlt redis-master --namespace=e2e-tests-kubectl-8fpk5 --limit-bytes=1'
May 11 01:37:23.860: INFO: stderr: ""
May 11 01:37:23.860: INFO: stdout: " "
STEP: exposing timestamps
May 11 01:37:23.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 log redis-master-8hjlt redis-master --namespace=e2e-tests-kubectl-8fpk5 --tail=1 --timestamps'
May 11 01:37:23.957: INFO: stderr: ""
May 11 01:37:23.957: INFO: stdout: "2019-05-11T01:37:21.638919506Z 1:M 11 May 01:37:21.638 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 11 01:37:26.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 log redis-master-8hjlt redis-master --namespace=e2e-tests-kubectl-8fpk5 --since=1s'
May 11 01:37:26.561: INFO: stderr: ""
May 11 01:37:26.562: INFO: stdout: ""
May 11 01:37:26.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 log redis-master-8hjlt redis-master --namespace=e2e-tests-kubectl-8fpk5 --since=24h'
May 11 01:37:26.655: INFO: stderr: ""
May 11 01:37:26.655: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 May 01:37:21.638 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 May 01:37:21.638 # Server started, Redis version 3.2.12\n1:M 11 May 01:37:21.638 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 May 01:37:21.638 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
May 11 01:37:26.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-8fpk5'
May 11 01:37:26.760: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:37:26.760: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 11 01:37:26.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-8fpk5'
May 11 01:37:26.864: INFO: stderr: "No resources found.\n"
May 11 01:37:26.864: INFO: stdout: ""
May 11 01:37:26.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 get pods -l name=nginx --namespace=e2e-tests-kubectl-8fpk5 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 11 01:37:26.956: INFO: stderr: ""
May 11 01:37:26.956: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:37:26.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8fpk5" for this suite.
May 11 01:37:48.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:37:48.985: INFO: namespace: e2e-tests-kubectl-8fpk5, resource: bindings, ignored listing per whitelist
May 11 01:37:49.034: INFO: namespace e2e-tests-kubectl-8fpk5 deletion completed in 22.074425277s

• [SLOW TEST:28.823 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:37:49.034: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
May 11 01:37:49.086: INFO: Waiting up to 5m0s for pod "var-expansion-62736595-738d-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-var-expansion-t55xz" to be "success or failure"
May 11 01:37:49.088: INFO: Pod "var-expansion-62736595-738d-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.499774ms
May 11 01:37:51.091: INFO: Pod "var-expansion-62736595-738d-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004798818s
STEP: Saw pod success
May 11 01:37:51.091: INFO: Pod "var-expansion-62736595-738d-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:37:51.092: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod var-expansion-62736595-738d-11e9-9c46-760f9b3dbd5d container dapi-container: <nil>
STEP: delete the pod
May 11 01:37:51.107: INFO: Waiting for pod var-expansion-62736595-738d-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:37:51.108: INFO: Pod var-expansion-62736595-738d-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:37:51.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-t55xz" for this suite.
May 11 01:37:57.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:37:57.132: INFO: namespace: e2e-tests-var-expansion-t55xz, resource: bindings, ignored listing per whitelist
May 11 01:37:57.177: INFO: namespace e2e-tests-var-expansion-t55xz deletion completed in 6.066250436s

• [SLOW TEST:8.144 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:37:57.177: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xgqjv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 11 01:37:57.216: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 11 01:38:21.267: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.233.91.217 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-xgqjv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 01:38:21.267: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 01:38:22.451: INFO: Found all expected endpoints: [netserver-0]
May 11 01:38:22.454: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.233.122.250 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-xgqjv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 01:38:22.454: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 01:38:23.671: INFO: Found all expected endpoints: [netserver-1]
May 11 01:38:23.673: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.233.124.144 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-xgqjv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 01:38:23.673: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 01:38:24.894: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:38:24.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xgqjv" for this suite.
May 11 01:38:46.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:38:46.971: INFO: namespace: e2e-tests-pod-network-test-xgqjv, resource: bindings, ignored listing per whitelist
May 11 01:38:46.981: INFO: namespace e2e-tests-pod-network-test-xgqjv deletion completed in 22.082517626s

• [SLOW TEST:49.804 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:38:46.982: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-84fe3eb1-738d-11e9-9c46-760f9b3dbd5d
STEP: Creating secret with name s-test-opt-upd-84fe3eea-738d-11e9-9c46-760f9b3dbd5d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-84fe3eb1-738d-11e9-9c46-760f9b3dbd5d
STEP: Updating secret s-test-opt-upd-84fe3eea-738d-11e9-9c46-760f9b3dbd5d
STEP: Creating secret with name s-test-opt-create-84fe3eff-738d-11e9-9c46-760f9b3dbd5d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:38:51.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g9845" for this suite.
May 11 01:39:13.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:39:13.138: INFO: namespace: e2e-tests-secrets-g9845, resource: bindings, ignored listing per whitelist
May 11 01:39:13.190: INFO: namespace e2e-tests-secrets-g9845 deletion completed in 22.078261943s

• [SLOW TEST:26.208 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:39:13.190: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
May 11 01:39:13.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 --namespace=e2e-tests-kubectl-j5gdc run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 11 01:39:15.252: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 11 01:39:15.252: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:39:17.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j5gdc" for this suite.
May 11 01:39:29.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:39:29.279: INFO: namespace: e2e-tests-kubectl-j5gdc, resource: bindings, ignored listing per whitelist
May 11 01:39:29.328: INFO: namespace e2e-tests-kubectl-j5gdc deletion completed in 12.069007751s

• [SLOW TEST:16.138 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:39:29.328: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 11 01:39:29.373: INFO: Pod name pod-release: Found 0 pods out of 1
May 11 01:39:34.376: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:39:34.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8sfsr" for this suite.
May 11 01:39:40.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:39:40.411: INFO: namespace: e2e-tests-replication-controller-8sfsr, resource: bindings, ignored listing per whitelist
May 11 01:39:40.455: INFO: namespace e2e-tests-replication-controller-8sfsr deletion completed in 6.068681675s

• [SLOW TEST:11.127 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:39:40.455: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 11 01:39:40.498: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 11 01:39:40.503: INFO: Waiting for terminating namespaces to be deleted...
May 11 01:39:40.504: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-0 before test
May 11 01:39:40.509: INFO: stork-d8fc784c7-84cjw from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.509: INFO: 	Container stork ready: true, restart count 0
May 11 01:39:40.509: INFO: kubernetes-dashboard-8457c55f89-wl2rw from kube-system started at 2019-05-11 00:13:40 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.509: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 11 01:39:40.509: INFO: stork-scheduler-75b8f4d565-6ntdx from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.509: INFO: 	Container stork-scheduler ready: true, restart count 0
May 11 01:39:40.509: INFO: portworx-znwr7 from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.509: INFO: 	Container portworx ready: true, restart count 0
May 11 01:39:40.509: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-0 from kube-system started at <nil> (0 container statuses recorded)
May 11 01:39:40.509: INFO: calico-node-hh8j6 from kube-system started at 2019-05-11 00:12:38 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.509: INFO: 	Container calico-node ready: true, restart count 0
May 11 01:39:40.509: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-2csqh from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 01:39:40.509: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 11 01:39:40.509: INFO: 	Container systemd-logs ready: true, restart count 1
May 11 01:39:40.509: INFO: kube-proxy-k5lk8 from kube-system started at 2019-05-11 00:12:47 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.509: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 01:39:40.509: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-1 before test
May 11 01:39:40.514: INFO: calico-node-rk5xw from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.514: INFO: 	Container calico-node ready: true, restart count 0
May 11 01:39:40.514: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-s7lkz from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 01:39:40.514: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 11 01:39:40.514: INFO: 	Container systemd-logs ready: true, restart count 1
May 11 01:39:40.514: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-1 from kube-system started at <nil> (0 container statuses recorded)
May 11 01:39:40.514: INFO: stork-d8fc784c7-rtqlm from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.514: INFO: 	Container stork ready: true, restart count 1
May 11 01:39:40.515: INFO: kube-proxy-6bcpz from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.515: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 01:39:40.515: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-11 00:23:59 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.515: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 11 01:39:40.515: INFO: coredns-6fd7dbf94c-xsrcc from kube-system started at 2019-05-11 00:13:40 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.515: INFO: 	Container coredns ready: true, restart count 0
May 11 01:39:40.515: INFO: portworx-d7vtl from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.515: INFO: 	Container portworx ready: true, restart count 0
May 11 01:39:40.515: INFO: stork-scheduler-75b8f4d565-fwzgd from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.515: INFO: 	Container stork-scheduler ready: true, restart count 1
May 11 01:39:40.515: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-2 before test
May 11 01:39:40.519: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-2 from kube-system started at <nil> (0 container statuses recorded)
May 11 01:39:40.519: INFO: dns-autoscaler-5b4847c446-k4mz5 from kube-system started at 2019-05-11 00:13:38 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.519: INFO: 	Container autoscaler ready: true, restart count 0
May 11 01:39:40.519: INFO: stork-scheduler-75b8f4d565-ppzzv from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.519: INFO: 	Container stork-scheduler ready: true, restart count 0
May 11 01:39:40.519: INFO: sonobuoy-e2e-job-898060709b084e53 from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 01:39:40.519: INFO: 	Container e2e ready: true, restart count 0
May 11 01:39:40.519: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 11 01:39:40.519: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-9g4dc from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 01:39:40.519: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 11 01:39:40.519: INFO: 	Container systemd-logs ready: true, restart count 1
May 11 01:39:40.519: INFO: kube-proxy-b5r9f from kube-system started at 2019-05-11 00:12:35 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.519: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 01:39:40.519: INFO: calico-node-27v4g from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.519: INFO: 	Container calico-node ready: true, restart count 0
May 11 01:39:40.519: INFO: stork-d8fc784c7-lhpp4 from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.519: INFO: 	Container stork ready: true, restart count 1
May 11 01:39:40.519: INFO: portworx-76nlv from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 01:39:40.519: INFO: 	Container portworx ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159d7d449bae7484], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:39:41.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mgb6v" for this suite.
May 11 01:39:47.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:39:47.595: INFO: namespace: e2e-tests-sched-pred-mgb6v, resource: bindings, ignored listing per whitelist
May 11 01:39:47.599: INFO: namespace e2e-tests-sched-pred-mgb6v deletion completed in 6.063253869s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.144 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:39:47.600: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-ndtf
STEP: Creating a pod to test atomic-volume-subpath
May 11 01:39:47.651: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ndtf" in namespace "e2e-tests-subpath-86xzx" to be "success or failure"
May 11 01:39:47.655: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.693536ms
May 11 01:39:49.658: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006573554s
May 11 01:39:51.661: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 4.010045798s
May 11 01:39:53.664: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 6.012426161s
May 11 01:39:55.666: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 8.014930909s
May 11 01:39:57.669: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 10.017573134s
May 11 01:39:59.671: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 12.019984422s
May 11 01:40:01.674: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 14.022708236s
May 11 01:40:03.679: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 16.027563129s
May 11 01:40:05.681: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 18.030073798s
May 11 01:40:07.685: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 20.033891901s
May 11 01:40:09.689: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Running", Reason="", readiness=false. Elapsed: 22.037824649s
May 11 01:40:11.692: INFO: Pod "pod-subpath-test-downwardapi-ndtf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.040284231s
STEP: Saw pod success
May 11 01:40:11.692: INFO: Pod "pod-subpath-test-downwardapi-ndtf" satisfied condition "success or failure"
May 11 01:40:11.693: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-subpath-test-downwardapi-ndtf container test-container-subpath-downwardapi-ndtf: <nil>
STEP: delete the pod
May 11 01:40:11.705: INFO: Waiting for pod pod-subpath-test-downwardapi-ndtf to disappear
May 11 01:40:11.707: INFO: Pod pod-subpath-test-downwardapi-ndtf no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ndtf
May 11 01:40:11.707: INFO: Deleting pod "pod-subpath-test-downwardapi-ndtf" in namespace "e2e-tests-subpath-86xzx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:40:11.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-86xzx" for this suite.
May 11 01:40:17.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:40:17.725: INFO: namespace: e2e-tests-subpath-86xzx, resource: bindings, ignored listing per whitelist
May 11 01:40:17.773: INFO: namespace e2e-tests-subpath-86xzx deletion completed in 6.061556008s

• [SLOW TEST:30.174 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:40:17.774: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 11 01:40:25.841: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:25.843: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:27.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:27.846: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:29.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:29.845: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:31.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:31.845: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:33.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:33.846: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:35.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:35.846: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:37.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:37.846: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:39.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:39.847: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:41.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:41.848: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:43.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:43.845: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:45.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:45.847: INFO: Pod pod-with-prestop-exec-hook still exists
May 11 01:40:47.843: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 11 01:40:47.846: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:40:47.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-crr44" for this suite.
May 11 01:41:03.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:41:03.876: INFO: namespace: e2e-tests-container-lifecycle-hook-crr44, resource: bindings, ignored listing per whitelist
May 11 01:41:03.928: INFO: namespace e2e-tests-container-lifecycle-hook-crr44 deletion completed in 16.070376614s

• [SLOW TEST:46.154 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:41:03.929: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
May 11 01:41:03.983: INFO: Waiting up to 5m0s for pod "pod-d69e6b6b-738d-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-2vtxn" to be "success or failure"
May 11 01:41:03.987: INFO: Pod "pod-d69e6b6b-738d-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.766187ms
May 11 01:41:05.990: INFO: Pod "pod-d69e6b6b-738d-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006517743s
STEP: Saw pod success
May 11 01:41:05.990: INFO: Pod "pod-d69e6b6b-738d-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:41:05.991: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-d69e6b6b-738d-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:41:06.006: INFO: Waiting for pod pod-d69e6b6b-738d-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:41:06.008: INFO: Pod pod-d69e6b6b-738d-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:41:06.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2vtxn" for this suite.
May 11 01:41:12.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:41:12.068: INFO: namespace: e2e-tests-emptydir-2vtxn, resource: bindings, ignored listing per whitelist
May 11 01:41:12.078: INFO: namespace e2e-tests-emptydir-2vtxn deletion completed in 6.067396211s

• [SLOW TEST:8.150 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:41:12.079: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-db78c0cb-738d-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 01:41:12.127: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db790d3b-738d-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-pgd2b" to be "success or failure"
May 11 01:41:12.132: INFO: Pod "pod-projected-secrets-db790d3b-738d-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.985883ms
May 11 01:41:14.134: INFO: Pod "pod-projected-secrets-db790d3b-738d-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006486006s
STEP: Saw pod success
May 11 01:41:14.134: INFO: Pod "pod-projected-secrets-db790d3b-738d-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:41:14.136: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-projected-secrets-db790d3b-738d-11e9-9c46-760f9b3dbd5d container projected-secret-volume-test: <nil>
STEP: delete the pod
May 11 01:41:14.146: INFO: Waiting for pod pod-projected-secrets-db790d3b-738d-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:41:14.148: INFO: Pod pod-projected-secrets-db790d3b-738d-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:41:14.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pgd2b" for this suite.
May 11 01:41:20.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:41:20.221: INFO: namespace: e2e-tests-projected-pgd2b, resource: bindings, ignored listing per whitelist
May 11 01:41:20.230: INFO: namespace e2e-tests-projected-pgd2b deletion completed in 6.077646893s

• [SLOW TEST:8.152 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:41:20.231: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e055964d-738d-11e9-9c46-760f9b3dbd5d
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e055964d-738d-11e9-9c46-760f9b3dbd5d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:41:24.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n8jrx" for this suite.
May 11 01:41:46.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:41:46.370: INFO: namespace: e2e-tests-projected-n8jrx, resource: bindings, ignored listing per whitelist
May 11 01:41:46.382: INFO: namespace e2e-tests-projected-n8jrx deletion completed in 22.064703607s

• [SLOW TEST:26.151 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:41:46.382: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
May 11 01:41:46.434: INFO: Waiting up to 5m0s for pod "client-containers-efec0462-738d-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-containers-krtvv" to be "success or failure"
May 11 01:41:46.437: INFO: Pod "client-containers-efec0462-738d-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.057533ms
May 11 01:41:48.440: INFO: Pod "client-containers-efec0462-738d-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005538386s
STEP: Saw pod success
May 11 01:41:48.440: INFO: Pod "client-containers-efec0462-738d-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:41:48.441: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod client-containers-efec0462-738d-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:41:48.454: INFO: Waiting for pod client-containers-efec0462-738d-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:41:48.455: INFO: Pod client-containers-efec0462-738d-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:41:48.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-krtvv" for this suite.
May 11 01:41:54.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:41:54.526: INFO: namespace: e2e-tests-containers-krtvv, resource: bindings, ignored listing per whitelist
May 11 01:41:54.526: INFO: namespace e2e-tests-containers-krtvv deletion completed in 6.068054426s

• [SLOW TEST:8.144 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:41:54.527: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 11 01:41:54.571: INFO: Waiting up to 5m0s for pod "pod-f4c56de1-738d-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-xgkw9" to be "success or failure"
May 11 01:41:54.573: INFO: Pod "pod-f4c56de1-738d-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.624441ms
May 11 01:41:56.576: INFO: Pod "pod-f4c56de1-738d-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005337005s
STEP: Saw pod success
May 11 01:41:56.576: INFO: Pod "pod-f4c56de1-738d-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:41:56.579: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-f4c56de1-738d-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:41:56.592: INFO: Waiting for pod pod-f4c56de1-738d-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:41:56.594: INFO: Pod pod-f4c56de1-738d-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:41:56.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xgkw9" for this suite.
May 11 01:42:02.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:42:02.645: INFO: namespace: e2e-tests-emptydir-xgkw9, resource: bindings, ignored listing per whitelist
May 11 01:42:02.655: INFO: namespace e2e-tests-emptydir-xgkw9 deletion completed in 6.058359885s

• [SLOW TEST:8.128 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:42:02.655: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 11 01:42:02.713: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:42:02.715: INFO: Number of nodes with available pods: 0
May 11 01:42:02.715: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 01:42:03.719: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:42:03.721: INFO: Number of nodes with available pods: 0
May 11 01:42:03.721: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 01:42:04.718: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:42:04.720: INFO: Number of nodes with available pods: 3
May 11 01:42:04.720: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 11 01:42:04.730: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:42:04.733: INFO: Number of nodes with available pods: 2
May 11 01:42:04.733: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:42:05.736: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:42:05.738: INFO: Number of nodes with available pods: 2
May 11 01:42:05.738: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:42:06.737: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:42:06.739: INFO: Number of nodes with available pods: 3
May 11 01:42:06.739: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-svlsm, will wait for the garbage collector to delete the pods
May 11 01:42:06.797: INFO: Deleting DaemonSet.extensions daemon-set took: 4.342805ms
May 11 01:42:06.898: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.22121ms
May 11 01:42:47.400: INFO: Number of nodes with available pods: 0
May 11 01:42:47.400: INFO: Number of running nodes: 0, number of available pods: 0
May 11 01:42:47.402: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-svlsm/daemonsets","resourceVersion":"27175"},"items":null}

May 11 01:42:47.403: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-svlsm/pods","resourceVersion":"27175"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:42:47.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-svlsm" for this suite.
May 11 01:42:53.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:42:53.473: INFO: namespace: e2e-tests-daemonsets-svlsm, resource: bindings, ignored listing per whitelist
May 11 01:42:53.486: INFO: namespace e2e-tests-daemonsets-svlsm deletion completed in 6.072931013s

• [SLOW TEST:50.831 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:42:53.486: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 11 01:42:53.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hksj4'
May 11 01:42:53.624: INFO: stderr: ""
May 11 01:42:53.624: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
May 11 01:42:53.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hksj4'
May 11 01:42:57.223: INFO: stderr: ""
May 11 01:42:57.223: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:42:57.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hksj4" for this suite.
May 11 01:43:03.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:43:03.290: INFO: namespace: e2e-tests-kubectl-hksj4, resource: bindings, ignored listing per whitelist
May 11 01:43:03.294: INFO: namespace e2e-tests-kubectl-hksj4 deletion completed in 6.068691912s

• [SLOW TEST:9.808 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:43:03.294: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1dc36d67-738e-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 01:43:03.347: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1dc3c4f1-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-r2jnx" to be "success or failure"
May 11 01:43:03.349: INFO: Pod "pod-projected-secrets-1dc3c4f1-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.795057ms
May 11 01:43:05.352: INFO: Pod "pod-projected-secrets-1dc3c4f1-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005609935s
STEP: Saw pod success
May 11 01:43:05.352: INFO: Pod "pod-projected-secrets-1dc3c4f1-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:43:05.354: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-projected-secrets-1dc3c4f1-738e-11e9-9c46-760f9b3dbd5d container projected-secret-volume-test: <nil>
STEP: delete the pod
May 11 01:43:05.371: INFO: Waiting for pod pod-projected-secrets-1dc3c4f1-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:43:05.374: INFO: Pod pod-projected-secrets-1dc3c4f1-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:43:05.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r2jnx" for this suite.
May 11 01:43:11.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:43:11.449: INFO: namespace: e2e-tests-projected-r2jnx, resource: bindings, ignored listing per whitelist
May 11 01:43:11.451: INFO: namespace e2e-tests-projected-r2jnx deletion completed in 6.074183028s

• [SLOW TEST:8.156 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:43:11.451: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0511 01:43:21.515116      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 11 01:43:21.515: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:43:21.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xhlr9" for this suite.
May 11 01:43:27.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:43:27.539: INFO: namespace: e2e-tests-gc-xhlr9, resource: bindings, ignored listing per whitelist
May 11 01:43:27.586: INFO: namespace e2e-tests-gc-xhlr9 deletion completed in 6.068517511s

• [SLOW TEST:16.136 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:43:27.587: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 01:43:27.644: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c3f592a-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-9xmtt" to be "success or failure"
May 11 01:43:27.647: INFO: Pod "downwardapi-volume-2c3f592a-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.417887ms
May 11 01:43:29.649: INFO: Pod "downwardapi-volume-2c3f592a-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004790988s
STEP: Saw pod success
May 11 01:43:29.649: INFO: Pod "downwardapi-volume-2c3f592a-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:43:29.651: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-2c3f592a-738e-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 01:43:29.664: INFO: Waiting for pod downwardapi-volume-2c3f592a-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:43:29.666: INFO: Pod downwardapi-volume-2c3f592a-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:43:29.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9xmtt" for this suite.
May 11 01:43:35.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:43:35.733: INFO: namespace: e2e-tests-downward-api-9xmtt, resource: bindings, ignored listing per whitelist
May 11 01:43:35.733: INFO: namespace e2e-tests-downward-api-9xmtt deletion completed in 6.063617482s

• [SLOW TEST:8.147 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:43:35.733: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 01:43:35.781: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3118f529-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-7tkvs" to be "success or failure"
May 11 01:43:35.784: INFO: Pod "downwardapi-volume-3118f529-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.079283ms
May 11 01:43:37.787: INFO: Pod "downwardapi-volume-3118f529-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005544903s
STEP: Saw pod success
May 11 01:43:37.787: INFO: Pod "downwardapi-volume-3118f529-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:43:37.788: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-3118f529-738e-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 01:43:37.801: INFO: Waiting for pod downwardapi-volume-3118f529-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:43:37.803: INFO: Pod downwardapi-volume-3118f529-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:43:37.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7tkvs" for this suite.
May 11 01:43:43.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:43:43.832: INFO: namespace: e2e-tests-downward-api-7tkvs, resource: bindings, ignored listing per whitelist
May 11 01:43:43.862: INFO: namespace e2e-tests-downward-api-7tkvs deletion completed in 6.0559557s

• [SLOW TEST:8.128 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:43:43.862: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-cjk69
May 11 01:43:47.912: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-cjk69
STEP: checking the pod's current state and verifying that restartCount is present
May 11 01:43:47.914: INFO: Initial restart count of pod liveness-exec is 0
May 11 01:44:31.980: INFO: Restart count of pod e2e-tests-container-probe-cjk69/liveness-exec is now 1 (44.066593426s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:44:31.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cjk69" for this suite.
May 11 01:44:37.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:44:38.012: INFO: namespace: e2e-tests-container-probe-cjk69, resource: bindings, ignored listing per whitelist
May 11 01:44:38.060: INFO: namespace e2e-tests-container-probe-cjk69 deletion completed in 6.071152941s

• [SLOW TEST:54.199 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:44:38.061: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
May 11 01:44:38.121: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 11 01:44:38.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:44:38.326: INFO: stderr: ""
May 11 01:44:38.326: INFO: stdout: "service/redis-slave created\n"
May 11 01:44:38.326: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 11 01:44:38.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:44:38.544: INFO: stderr: ""
May 11 01:44:38.544: INFO: stdout: "service/redis-master created\n"
May 11 01:44:38.544: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 11 01:44:38.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:44:38.749: INFO: stderr: ""
May 11 01:44:38.749: INFO: stdout: "service/frontend created\n"
May 11 01:44:38.749: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 11 01:44:38.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:44:38.938: INFO: stderr: ""
May 11 01:44:38.938: INFO: stdout: "deployment.extensions/frontend created\n"
May 11 01:44:38.938: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 11 01:44:38.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:44:39.132: INFO: stderr: ""
May 11 01:44:39.132: INFO: stdout: "deployment.extensions/redis-master created\n"
May 11 01:44:39.132: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 11 01:44:39.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 create -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:44:39.329: INFO: stderr: ""
May 11 01:44:39.329: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 11 01:44:39.329: INFO: Waiting for all frontend pods to be Running.
May 11 01:45:29.381: INFO: Waiting for frontend to serve content.
May 11 01:45:30.411: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

May 11 01:45:35.421: INFO: Trying to add a new entry to the guestbook.
May 11 01:45:35.433: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 11 01:45:35.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:45:35.527: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:45:35.527: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 11 01:45:35.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:45:35.639: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:45:35.639: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 11 01:45:35.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:45:35.740: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:45:35.740: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 11 01:45:35.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:45:35.839: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:45:35.839: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 11 01:45:35.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:45:35.936: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:45:35.936: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 11 01:45:35.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j4n9m'
May 11 01:45:36.023: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 11 01:45:36.023: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:45:36.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j4n9m" for this suite.
May 11 01:46:20.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:46:20.055: INFO: namespace: e2e-tests-kubectl-j4n9m, resource: bindings, ignored listing per whitelist
May 11 01:46:20.094: INFO: namespace e2e-tests-kubectl-j4n9m deletion completed in 44.067099835s

• [SLOW TEST:102.034 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:46:20.094: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 01:46:20.142: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93107e67-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-tzqcm" to be "success or failure"
May 11 01:46:20.144: INFO: Pod "downwardapi-volume-93107e67-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.433777ms
May 11 01:46:22.146: INFO: Pod "downwardapi-volume-93107e67-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003785891s
STEP: Saw pod success
May 11 01:46:22.146: INFO: Pod "downwardapi-volume-93107e67-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:46:22.148: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-93107e67-738e-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 01:46:22.160: INFO: Waiting for pod downwardapi-volume-93107e67-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:46:22.161: INFO: Pod downwardapi-volume-93107e67-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:46:22.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tzqcm" for this suite.
May 11 01:46:28.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:46:28.216: INFO: namespace: e2e-tests-projected-tzqcm, resource: bindings, ignored listing per whitelist
May 11 01:46:28.240: INFO: namespace e2e-tests-projected-tzqcm deletion completed in 6.076665932s

• [SLOW TEST:8.146 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:46:28.240: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 01:46:28.288: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97eb6290-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-r88gz" to be "success or failure"
May 11 01:46:28.289: INFO: Pod "downwardapi-volume-97eb6290-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.53082ms
May 11 01:46:30.292: INFO: Pod "downwardapi-volume-97eb6290-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00411389s
STEP: Saw pod success
May 11 01:46:30.292: INFO: Pod "downwardapi-volume-97eb6290-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:46:30.294: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-97eb6290-738e-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 01:46:30.307: INFO: Waiting for pod downwardapi-volume-97eb6290-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:46:30.309: INFO: Pod downwardapi-volume-97eb6290-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:46:30.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r88gz" for this suite.
May 11 01:46:36.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:46:36.355: INFO: namespace: e2e-tests-projected-r88gz, resource: bindings, ignored listing per whitelist
May 11 01:46:36.373: INFO: namespace e2e-tests-projected-r88gz deletion completed in 6.061751999s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:46:36.373: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 11 01:46:36.418: INFO: Waiting up to 5m0s for pod "pod-9cc3fd0c-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-7j2xs" to be "success or failure"
May 11 01:46:36.424: INFO: Pod "pod-9cc3fd0c-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.376619ms
May 11 01:46:38.427: INFO: Pod "pod-9cc3fd0c-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008877341s
STEP: Saw pod success
May 11 01:46:38.427: INFO: Pod "pod-9cc3fd0c-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:46:38.429: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-9cc3fd0c-738e-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:46:38.441: INFO: Waiting for pod pod-9cc3fd0c-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:46:38.444: INFO: Pod pod-9cc3fd0c-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:46:38.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7j2xs" for this suite.
May 11 01:46:44.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:46:44.490: INFO: namespace: e2e-tests-emptydir-7j2xs, resource: bindings, ignored listing per whitelist
May 11 01:46:44.508: INFO: namespace e2e-tests-emptydir-7j2xs deletion completed in 6.061261976s

• [SLOW TEST:8.135 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:46:44.508: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-rl72n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rl72n to expose endpoints map[]
May 11 01:46:44.559: INFO: Get endpoints failed (1.668038ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 11 01:46:45.563: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rl72n exposes endpoints map[] (1.00561768s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rl72n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rl72n to expose endpoints map[pod1:[80]]
May 11 01:46:47.586: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rl72n exposes endpoints map[pod1:[80]] (2.016260885s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rl72n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rl72n to expose endpoints map[pod1:[80] pod2:[80]]
May 11 01:46:49.608: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rl72n exposes endpoints map[pod1:[80] pod2:[80]] (2.018562456s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rl72n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rl72n to expose endpoints map[pod2:[80]]
May 11 01:46:50.618: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rl72n exposes endpoints map[pod2:[80]] (1.007526996s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rl72n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rl72n to expose endpoints map[]
May 11 01:46:50.624: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rl72n exposes endpoints map[] (1.750902ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:46:50.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rl72n" for this suite.
May 11 01:47:12.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:47:12.708: INFO: namespace: e2e-tests-services-rl72n, resource: bindings, ignored listing per whitelist
May 11 01:47:12.722: INFO: namespace e2e-tests-services-rl72n deletion completed in 22.075287935s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.214 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:47:12.722: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 01:47:12.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b26f671c-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-cjtmh" to be "success or failure"
May 11 01:47:12.776: INFO: Pod "downwardapi-volume-b26f671c-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091564ms
May 11 01:47:14.778: INFO: Pod "downwardapi-volume-b26f671c-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004449985s
May 11 01:47:16.780: INFO: Pod "downwardapi-volume-b26f671c-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006686338s
STEP: Saw pod success
May 11 01:47:16.780: INFO: Pod "downwardapi-volume-b26f671c-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:47:16.782: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod downwardapi-volume-b26f671c-738e-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 01:47:16.794: INFO: Waiting for pod downwardapi-volume-b26f671c-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:47:16.796: INFO: Pod downwardapi-volume-b26f671c-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:47:16.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cjtmh" for this suite.
May 11 01:47:22.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:47:22.856: INFO: namespace: e2e-tests-downward-api-cjtmh, resource: bindings, ignored listing per whitelist
May 11 01:47:22.874: INFO: namespace e2e-tests-downward-api-cjtmh deletion completed in 6.075423623s

• [SLOW TEST:10.152 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:47:22.874: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 11 01:47:22.928: INFO: Waiting up to 5m0s for pod "pod-b87cc59a-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-dhq2w" to be "success or failure"
May 11 01:47:22.930: INFO: Pod "pod-b87cc59a-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.13957ms
May 11 01:47:24.933: INFO: Pod "pod-b87cc59a-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0050309s
May 11 01:47:26.935: INFO: Pod "pod-b87cc59a-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007321125s
STEP: Saw pod success
May 11 01:47:26.935: INFO: Pod "pod-b87cc59a-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:47:26.937: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-b87cc59a-738e-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:47:26.948: INFO: Waiting for pod pod-b87cc59a-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:47:26.950: INFO: Pod pod-b87cc59a-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:47:26.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dhq2w" for this suite.
May 11 01:47:32.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:47:32.998: INFO: namespace: e2e-tests-emptydir-dhq2w, resource: bindings, ignored listing per whitelist
May 11 01:47:33.007: INFO: namespace e2e-tests-emptydir-dhq2w deletion completed in 6.054504204s

• [SLOW TEST:10.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:47:33.008: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-be85aace-738e-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 01:47:33.057: INFO: Waiting up to 5m0s for pod "pod-secrets-be8600d7-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-gwhcs" to be "success or failure"
May 11 01:47:33.059: INFO: Pod "pod-secrets-be8600d7-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.581997ms
May 11 01:47:35.061: INFO: Pod "pod-secrets-be8600d7-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00391159s
STEP: Saw pod success
May 11 01:47:35.061: INFO: Pod "pod-secrets-be8600d7-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:47:35.063: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-secrets-be8600d7-738e-11e9-9c46-760f9b3dbd5d container secret-volume-test: <nil>
STEP: delete the pod
May 11 01:47:35.075: INFO: Waiting for pod pod-secrets-be8600d7-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:47:35.077: INFO: Pod pod-secrets-be8600d7-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:47:35.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gwhcs" for this suite.
May 11 01:47:41.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:47:41.109: INFO: namespace: e2e-tests-secrets-gwhcs, resource: bindings, ignored listing per whitelist
May 11 01:47:41.161: INFO: namespace e2e-tests-secrets-gwhcs deletion completed in 6.081572543s

• [SLOW TEST:8.154 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:47:41.161: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 11 01:47:41.217: INFO: Waiting up to 5m0s for pod "pod-c3633918-738e-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-7hrxl" to be "success or failure"
May 11 01:47:41.219: INFO: Pod "pod-c3633918-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.637388ms
May 11 01:47:43.222: INFO: Pod "pod-c3633918-738e-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004988819s
May 11 01:47:45.225: INFO: Pod "pod-c3633918-738e-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008477733s
STEP: Saw pod success
May 11 01:47:45.225: INFO: Pod "pod-c3633918-738e-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:47:45.227: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-c3633918-738e-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:47:45.243: INFO: Waiting for pod pod-c3633918-738e-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:47:45.244: INFO: Pod pod-c3633918-738e-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:47:45.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7hrxl" for this suite.
May 11 01:47:51.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:47:51.273: INFO: namespace: e2e-tests-emptydir-7hrxl, resource: bindings, ignored listing per whitelist
May 11 01:47:51.314: INFO: namespace e2e-tests-emptydir-7hrxl deletion completed in 6.065374593s

• [SLOW TEST:10.153 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:47:51.314: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 11 01:47:51.380: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:51.381: INFO: Number of nodes with available pods: 0
May 11 01:47:51.381: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 01:47:52.385: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:52.388: INFO: Number of nodes with available pods: 0
May 11 01:47:52.388: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 01:47:53.385: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:53.387: INFO: Number of nodes with available pods: 2
May 11 01:47:53.387: INFO: Node craig-k8s-certification-1-stellar-hand-2 is running more than one daemon pod
May 11 01:47:54.385: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:54.387: INFO: Number of nodes with available pods: 3
May 11 01:47:54.387: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 11 01:47:54.395: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:54.397: INFO: Number of nodes with available pods: 2
May 11 01:47:54.397: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:47:55.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:55.403: INFO: Number of nodes with available pods: 2
May 11 01:47:55.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:47:56.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:56.404: INFO: Number of nodes with available pods: 2
May 11 01:47:56.404: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:47:57.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:57.403: INFO: Number of nodes with available pods: 2
May 11 01:47:57.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:47:58.400: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:58.402: INFO: Number of nodes with available pods: 2
May 11 01:47:58.402: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:47:59.400: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:47:59.402: INFO: Number of nodes with available pods: 2
May 11 01:47:59.402: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:00.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:00.403: INFO: Number of nodes with available pods: 2
May 11 01:48:00.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:01.403: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:01.406: INFO: Number of nodes with available pods: 2
May 11 01:48:01.406: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:02.400: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:02.402: INFO: Number of nodes with available pods: 2
May 11 01:48:02.402: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:03.405: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:03.408: INFO: Number of nodes with available pods: 2
May 11 01:48:03.408: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:04.402: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:04.405: INFO: Number of nodes with available pods: 2
May 11 01:48:04.405: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:05.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:05.403: INFO: Number of nodes with available pods: 2
May 11 01:48:05.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:06.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:06.403: INFO: Number of nodes with available pods: 2
May 11 01:48:06.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:07.402: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:07.406: INFO: Number of nodes with available pods: 2
May 11 01:48:07.406: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:08.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:08.403: INFO: Number of nodes with available pods: 2
May 11 01:48:08.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:09.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:09.403: INFO: Number of nodes with available pods: 2
May 11 01:48:09.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:10.404: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:10.408: INFO: Number of nodes with available pods: 2
May 11 01:48:10.408: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:11.402: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:11.405: INFO: Number of nodes with available pods: 2
May 11 01:48:11.405: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:12.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:12.403: INFO: Number of nodes with available pods: 2
May 11 01:48:12.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:13.400: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:13.403: INFO: Number of nodes with available pods: 2
May 11 01:48:13.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:14.400: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:14.402: INFO: Number of nodes with available pods: 2
May 11 01:48:14.402: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:15.400: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:15.403: INFO: Number of nodes with available pods: 2
May 11 01:48:15.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:16.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:16.404: INFO: Number of nodes with available pods: 2
May 11 01:48:16.404: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:17.402: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:17.406: INFO: Number of nodes with available pods: 2
May 11 01:48:17.406: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:18.400: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:18.403: INFO: Number of nodes with available pods: 2
May 11 01:48:18.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:19.402: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:19.405: INFO: Number of nodes with available pods: 2
May 11 01:48:19.405: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:20.402: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:20.405: INFO: Number of nodes with available pods: 2
May 11 01:48:20.405: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:21.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:21.403: INFO: Number of nodes with available pods: 2
May 11 01:48:21.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:22.405: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:22.408: INFO: Number of nodes with available pods: 2
May 11 01:48:22.408: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:23.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:23.403: INFO: Number of nodes with available pods: 2
May 11 01:48:23.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:24.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:24.404: INFO: Number of nodes with available pods: 2
May 11 01:48:24.404: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:25.402: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:25.405: INFO: Number of nodes with available pods: 2
May 11 01:48:25.405: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:26.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:26.403: INFO: Number of nodes with available pods: 2
May 11 01:48:26.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:27.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:27.403: INFO: Number of nodes with available pods: 2
May 11 01:48:27.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:28.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:28.403: INFO: Number of nodes with available pods: 2
May 11 01:48:28.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:29.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:29.403: INFO: Number of nodes with available pods: 2
May 11 01:48:29.403: INFO: Node craig-k8s-certification-1-stellar-hand-1 is running more than one daemon pod
May 11 01:48:30.401: INFO: DaemonSet pods can't tolerate node craig-k8s-certification-1-stellar-hand-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 11 01:48:30.403: INFO: Number of nodes with available pods: 3
May 11 01:48:30.403: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-z6vlg, will wait for the garbage collector to delete the pods
May 11 01:48:30.462: INFO: Deleting DaemonSet.extensions daemon-set took: 5.116266ms
May 11 01:48:30.562: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.284838ms
May 11 01:49:07.367: INFO: Number of nodes with available pods: 0
May 11 01:49:07.367: INFO: Number of running nodes: 0, number of available pods: 0
May 11 01:49:07.372: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-z6vlg/daemonsets","resourceVersion":"29113"},"items":null}

May 11 01:49:07.379: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-z6vlg/pods","resourceVersion":"29114"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:49:07.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-z6vlg" for this suite.
May 11 01:49:13.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:49:13.433: INFO: namespace: e2e-tests-daemonsets-z6vlg, resource: bindings, ignored listing per whitelist
May 11 01:49:13.453: INFO: namespace e2e-tests-daemonsets-z6vlg deletion completed in 6.06357115s

• [SLOW TEST:82.139 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:49:13.454: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-bppk
STEP: Creating a pod to test atomic-volume-subpath
May 11 01:49:13.511: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bppk" in namespace "e2e-tests-subpath-9v8j4" to be "success or failure"
May 11 01:49:13.514: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.483742ms
May 11 01:49:15.517: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005965294s
May 11 01:49:17.519: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 4.008314229s
May 11 01:49:19.522: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 6.010654247s
May 11 01:49:21.525: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 8.014021149s
May 11 01:49:23.528: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 10.016661314s
May 11 01:49:25.531: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 12.019778871s
May 11 01:49:27.536: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 14.024796875s
May 11 01:49:29.538: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 16.027422735s
May 11 01:49:31.541: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 18.030294261s
May 11 01:49:33.546: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 20.035369137s
May 11 01:49:35.549: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Running", Reason="", readiness=false. Elapsed: 22.037991829s
May 11 01:49:37.552: INFO: Pod "pod-subpath-test-projected-bppk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.04128031s
STEP: Saw pod success
May 11 01:49:37.552: INFO: Pod "pod-subpath-test-projected-bppk" satisfied condition "success or failure"
May 11 01:49:37.555: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-subpath-test-projected-bppk container test-container-subpath-projected-bppk: <nil>
STEP: delete the pod
May 11 01:49:37.575: INFO: Waiting for pod pod-subpath-test-projected-bppk to disappear
May 11 01:49:37.577: INFO: Pod pod-subpath-test-projected-bppk no longer exists
STEP: Deleting pod pod-subpath-test-projected-bppk
May 11 01:49:37.577: INFO: Deleting pod "pod-subpath-test-projected-bppk" in namespace "e2e-tests-subpath-9v8j4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:49:37.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9v8j4" for this suite.
May 11 01:49:43.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:49:43.611: INFO: namespace: e2e-tests-subpath-9v8j4, resource: bindings, ignored listing per whitelist
May 11 01:49:43.651: INFO: namespace e2e-tests-subpath-9v8j4 deletion completed in 6.068618226s

• [SLOW TEST:30.197 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:49:43.651: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 01:49:43.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c65a75f-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-chrdw" to be "success or failure"
May 11 01:49:43.708: INFO: Pod "downwardapi-volume-0c65a75f-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.018887ms
May 11 01:49:45.712: INFO: Pod "downwardapi-volume-0c65a75f-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007063206s
May 11 01:49:47.715: INFO: Pod "downwardapi-volume-0c65a75f-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009718023s
STEP: Saw pod success
May 11 01:49:47.715: INFO: Pod "downwardapi-volume-0c65a75f-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:49:47.716: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-0c65a75f-738f-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 01:49:47.729: INFO: Waiting for pod downwardapi-volume-0c65a75f-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:49:47.730: INFO: Pod downwardapi-volume-0c65a75f-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:49:47.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-chrdw" for this suite.
May 11 01:49:53.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:49:53.775: INFO: namespace: e2e-tests-projected-chrdw, resource: bindings, ignored listing per whitelist
May 11 01:49:53.795: INFO: namespace e2e-tests-projected-chrdw deletion completed in 6.062294743s

• [SLOW TEST:10.144 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:49:53.796: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 11 01:49:53.839: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 11 01:49:53.843: INFO: Waiting for terminating namespaces to be deleted...
May 11 01:49:53.844: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-0 before test
May 11 01:49:53.851: INFO: stork-scheduler-75b8f4d565-6ntdx from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.851: INFO: 	Container stork-scheduler ready: true, restart count 0
May 11 01:49:53.851: INFO: portworx-znwr7 from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.851: INFO: 	Container portworx ready: true, restart count 0
May 11 01:49:53.851: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-0 from kube-system started at <nil> (0 container statuses recorded)
May 11 01:49:53.851: INFO: kubernetes-dashboard-8457c55f89-wl2rw from kube-system started at 2019-05-11 00:13:40 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.851: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 11 01:49:53.851: INFO: calico-node-hh8j6 from kube-system started at 2019-05-11 00:12:38 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.851: INFO: 	Container calico-node ready: true, restart count 0
May 11 01:49:53.851: INFO: kube-proxy-k5lk8 from kube-system started at 2019-05-11 00:12:47 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.851: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 01:49:53.851: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-2csqh from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 01:49:53.851: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 11 01:49:53.851: INFO: 	Container systemd-logs ready: true, restart count 1
May 11 01:49:53.851: INFO: stork-d8fc784c7-84cjw from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.851: INFO: 	Container stork ready: true, restart count 0
May 11 01:49:53.851: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-1 before test
May 11 01:49:53.856: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-1 from kube-system started at <nil> (0 container statuses recorded)
May 11 01:49:53.856: INFO: calico-node-rk5xw from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.856: INFO: 	Container calico-node ready: true, restart count 0
May 11 01:49:53.856: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-s7lkz from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 01:49:53.856: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 11 01:49:53.856: INFO: 	Container systemd-logs ready: true, restart count 1
May 11 01:49:53.856: INFO: coredns-6fd7dbf94c-xsrcc from kube-system started at 2019-05-11 00:13:40 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.856: INFO: 	Container coredns ready: true, restart count 0
May 11 01:49:53.856: INFO: stork-d8fc784c7-rtqlm from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.856: INFO: 	Container stork ready: true, restart count 1
May 11 01:49:53.856: INFO: kube-proxy-6bcpz from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.856: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 01:49:53.856: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-11 00:23:59 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.856: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 11 01:49:53.856: INFO: portworx-d7vtl from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.856: INFO: 	Container portworx ready: true, restart count 0
May 11 01:49:53.856: INFO: stork-scheduler-75b8f4d565-fwzgd from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.856: INFO: 	Container stork-scheduler ready: true, restart count 1
May 11 01:49:53.856: INFO: 
Logging pods the kubelet thinks is on node craig-k8s-certification-1-stellar-hand-2 before test
May 11 01:49:53.865: INFO: dns-autoscaler-5b4847c446-k4mz5 from kube-system started at 2019-05-11 00:13:38 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.865: INFO: 	Container autoscaler ready: true, restart count 0
May 11 01:49:53.865: INFO: stork-scheduler-75b8f4d565-ppzzv from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.865: INFO: 	Container stork-scheduler ready: true, restart count 0
May 11 01:49:53.865: INFO: sonobuoy-e2e-job-898060709b084e53 from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 01:49:53.865: INFO: 	Container e2e ready: true, restart count 0
May 11 01:49:53.865: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 11 01:49:53.865: INFO: sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-9g4dc from heptio-sonobuoy started at 2019-05-11 00:24:06 +0000 UTC (2 container statuses recorded)
May 11 01:49:53.865: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 11 01:49:53.865: INFO: 	Container systemd-logs ready: true, restart count 1
May 11 01:49:53.865: INFO: nginx-proxy-craig-k8s-certification-1-stellar-hand-2 from kube-system started at <nil> (0 container statuses recorded)
May 11 01:49:53.865: INFO: calico-node-27v4g from kube-system started at 2019-05-11 00:12:39 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.865: INFO: 	Container calico-node ready: true, restart count 0
May 11 01:49:53.865: INFO: kube-proxy-b5r9f from kube-system started at 2019-05-11 00:12:35 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.865: INFO: 	Container kube-proxy ready: true, restart count 0
May 11 01:49:53.865: INFO: portworx-76nlv from kube-system started at 2019-05-11 00:13:52 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.865: INFO: 	Container portworx ready: true, restart count 0
May 11 01:49:53.865: INFO: stork-d8fc784c7-lhpp4 from kube-system started at 2019-05-11 00:13:51 +0000 UTC (1 container statuses recorded)
May 11 01:49:53.865: INFO: 	Container stork ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node craig-k8s-certification-1-stellar-hand-0
STEP: verifying the node has the label node craig-k8s-certification-1-stellar-hand-1
STEP: verifying the node has the label node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod sonobuoy requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod sonobuoy-e2e-job-898060709b084e53 requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-2csqh requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-0
May 11 01:49:53.896: INFO: Pod sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-9g4dc requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod sonobuoy-systemd-logs-daemon-set-9191e30cfc974584-s7lkz requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod calico-node-27v4g requesting resource cpu=150m on Node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod calico-node-hh8j6 requesting resource cpu=150m on Node craig-k8s-certification-1-stellar-hand-0
May 11 01:49:53.896: INFO: Pod calico-node-rk5xw requesting resource cpu=150m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod coredns-6fd7dbf94c-xsrcc requesting resource cpu=100m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod dns-autoscaler-5b4847c446-k4mz5 requesting resource cpu=20m on Node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod kube-proxy-6bcpz requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod kube-proxy-b5r9f requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod kube-proxy-k5lk8 requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-0
May 11 01:49:53.896: INFO: Pod kubernetes-dashboard-8457c55f89-wl2rw requesting resource cpu=50m on Node craig-k8s-certification-1-stellar-hand-0
May 11 01:49:53.896: INFO: Pod nginx-proxy-craig-k8s-certification-1-stellar-hand-0 requesting resource cpu=25m on Node craig-k8s-certification-1-stellar-hand-0
May 11 01:49:53.896: INFO: Pod nginx-proxy-craig-k8s-certification-1-stellar-hand-1 requesting resource cpu=25m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod nginx-proxy-craig-k8s-certification-1-stellar-hand-2 requesting resource cpu=25m on Node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod portworx-76nlv requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod portworx-d7vtl requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod portworx-znwr7 requesting resource cpu=0m on Node craig-k8s-certification-1-stellar-hand-0
May 11 01:49:53.896: INFO: Pod stork-d8fc784c7-84cjw requesting resource cpu=100m on Node craig-k8s-certification-1-stellar-hand-0
May 11 01:49:53.896: INFO: Pod stork-d8fc784c7-lhpp4 requesting resource cpu=100m on Node craig-k8s-certification-1-stellar-hand-2
May 11 01:49:53.896: INFO: Pod stork-d8fc784c7-rtqlm requesting resource cpu=100m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod stork-scheduler-75b8f4d565-6ntdx requesting resource cpu=100m on Node craig-k8s-certification-1-stellar-hand-0
May 11 01:49:53.896: INFO: Pod stork-scheduler-75b8f4d565-fwzgd requesting resource cpu=100m on Node craig-k8s-certification-1-stellar-hand-1
May 11 01:49:53.896: INFO: Pod stork-scheduler-75b8f4d565-ppzzv requesting resource cpu=100m on Node craig-k8s-certification-1-stellar-hand-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1279355d-738f-11e9-9c46-760f9b3dbd5d.159d7dd36bafcb88], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-s2wzm/filler-pod-1279355d-738f-11e9-9c46-760f9b3dbd5d to craig-k8s-certification-1-stellar-hand-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1279355d-738f-11e9-9c46-760f9b3dbd5d.159d7dd3cbf0ef2f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1279355d-738f-11e9-9c46-760f9b3dbd5d.159d7dd3ce3fbbff], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1279355d-738f-11e9-9c46-760f9b3dbd5d.159d7dd3da9287e3], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1279c673-738f-11e9-9c46-760f9b3dbd5d.159d7dd36babfaaa], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-s2wzm/filler-pod-1279c673-738f-11e9-9c46-760f9b3dbd5d to craig-k8s-certification-1-stellar-hand-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1279c673-738f-11e9-9c46-760f9b3dbd5d.159d7dd3b9198488], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1279c673-738f-11e9-9c46-760f9b3dbd5d.159d7dd3ba8f60a1], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1279c673-738f-11e9-9c46-760f9b3dbd5d.159d7dd3c766f8b6], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-127a3165-738f-11e9-9c46-760f9b3dbd5d.159d7dd36c20406b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-s2wzm/filler-pod-127a3165-738f-11e9-9c46-760f9b3dbd5d to craig-k8s-certification-1-stellar-hand-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-127a3165-738f-11e9-9c46-760f9b3dbd5d.159d7dd3d134b68c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-127a3165-738f-11e9-9c46-760f9b3dbd5d.159d7dd3d2f2a930], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-127a3165-738f-11e9-9c46-760f9b3dbd5d.159d7dd3de452b81], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159d7dd45b89497f], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node craig-k8s-certification-1-stellar-hand-0
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node craig-k8s-certification-1-stellar-hand-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node craig-k8s-certification-1-stellar-hand-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:49:58.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-s2wzm" for this suite.
May 11 01:50:04.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:50:04.993: INFO: namespace: e2e-tests-sched-pred-s2wzm, resource: bindings, ignored listing per whitelist
May 11 01:50:05.027: INFO: namespace e2e-tests-sched-pred-s2wzm deletion completed in 6.059129326s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.231 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:50:05.027: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 01:50:05.073: INFO: Creating ReplicaSet my-hostname-basic-1922c511-738f-11e9-9c46-760f9b3dbd5d
May 11 01:50:05.077: INFO: Pod name my-hostname-basic-1922c511-738f-11e9-9c46-760f9b3dbd5d: Found 0 pods out of 1
May 11 01:50:10.080: INFO: Pod name my-hostname-basic-1922c511-738f-11e9-9c46-760f9b3dbd5d: Found 1 pods out of 1
May 11 01:50:10.080: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-1922c511-738f-11e9-9c46-760f9b3dbd5d" is running
May 11 01:50:10.082: INFO: Pod "my-hostname-basic-1922c511-738f-11e9-9c46-760f9b3dbd5d-mv2sp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-11 01:50:05 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-11 01:50:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-11 01:50:06 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-11 01:50:04 +0000 UTC Reason: Message:}])
May 11 01:50:10.082: INFO: Trying to dial the pod
May 11 01:50:15.090: INFO: Controller my-hostname-basic-1922c511-738f-11e9-9c46-760f9b3dbd5d: Got expected result from replica 1 [my-hostname-basic-1922c511-738f-11e9-9c46-760f9b3dbd5d-mv2sp]: "my-hostname-basic-1922c511-738f-11e9-9c46-760f9b3dbd5d-mv2sp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:50:15.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-2wq4m" for this suite.
May 11 01:50:21.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:50:21.159: INFO: namespace: e2e-tests-replicaset-2wq4m, resource: bindings, ignored listing per whitelist
May 11 01:50:21.162: INFO: namespace e2e-tests-replicaset-2wq4m deletion completed in 6.068579595s

• [SLOW TEST:16.135 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:50:21.162: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 11 01:50:21.222: INFO: Waiting up to 5m0s for pod "downward-api-22c214dd-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-7lcd8" to be "success or failure"
May 11 01:50:21.225: INFO: Pod "downward-api-22c214dd-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.290874ms
May 11 01:50:23.228: INFO: Pod "downward-api-22c214dd-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00613937s
STEP: Saw pod success
May 11 01:50:23.228: INFO: Pod "downward-api-22c214dd-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:50:23.229: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downward-api-22c214dd-738f-11e9-9c46-760f9b3dbd5d container dapi-container: <nil>
STEP: delete the pod
May 11 01:50:23.243: INFO: Waiting for pod downward-api-22c214dd-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:50:23.245: INFO: Pod downward-api-22c214dd-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:50:23.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7lcd8" for this suite.
May 11 01:50:29.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:50:29.307: INFO: namespace: e2e-tests-downward-api-7lcd8, resource: bindings, ignored listing per whitelist
May 11 01:50:29.316: INFO: namespace e2e-tests-downward-api-7lcd8 deletion completed in 6.067093986s

• [SLOW TEST:8.154 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:50:29.316: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0511 01:50:30.393827      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 11 01:50:30.393: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:50:30.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cjzl8" for this suite.
May 11 01:50:36.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:50:36.424: INFO: namespace: e2e-tests-gc-cjzl8, resource: bindings, ignored listing per whitelist
May 11 01:50:36.457: INFO: namespace e2e-tests-gc-cjzl8 deletion completed in 6.06133485s

• [SLOW TEST:7.141 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:50:36.457: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 11 01:50:36.513: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-a,UID:2b6a9e7c-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29666,Generation:0,CreationTimestamp:2019-05-11 01:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 11 01:50:36.513: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-a,UID:2b6a9e7c-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29666,Generation:0,CreationTimestamp:2019-05-11 01:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 11 01:50:46.519: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-a,UID:2b6a9e7c-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29692,Generation:0,CreationTimestamp:2019-05-11 01:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 11 01:50:46.519: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-a,UID:2b6a9e7c-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29692,Generation:0,CreationTimestamp:2019-05-11 01:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 11 01:50:56.524: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-a,UID:2b6a9e7c-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29718,Generation:0,CreationTimestamp:2019-05-11 01:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 11 01:50:56.524: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-a,UID:2b6a9e7c-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29718,Generation:0,CreationTimestamp:2019-05-11 01:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 11 01:51:06.531: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-a,UID:2b6a9e7c-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29744,Generation:0,CreationTimestamp:2019-05-11 01:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 11 01:51:06.531: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-a,UID:2b6a9e7c-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29744,Generation:0,CreationTimestamp:2019-05-11 01:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 11 01:51:16.536: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-b,UID:43454d0e-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29771,Generation:0,CreationTimestamp:2019-05-11 01:51:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 11 01:51:16.536: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-b,UID:43454d0e-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29771,Generation:0,CreationTimestamp:2019-05-11 01:51:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 11 01:51:26.541: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-b,UID:43454d0e-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29797,Generation:0,CreationTimestamp:2019-05-11 01:51:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 11 01:51:26.541: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b7kcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7kcx/configmaps/e2e-watch-test-configmap-b,UID:43454d0e-738f-11e9-9f3c-000c29c278ce,ResourceVersion:29797,Generation:0,CreationTimestamp:2019-05-11 01:51:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:51:36.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-b7kcx" for this suite.
May 11 01:51:42.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:51:42.601: INFO: namespace: e2e-tests-watch-b7kcx, resource: bindings, ignored listing per whitelist
May 11 01:51:42.633: INFO: namespace e2e-tests-watch-b7kcx deletion completed in 6.085321157s

• [SLOW TEST:66.176 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:51:42.634: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5353cede-738f-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 01:51:42.735: INFO: Waiting up to 5m0s for pod "pod-secrets-53582bf8-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-8jfqk" to be "success or failure"
May 11 01:51:42.736: INFO: Pod "pod-secrets-53582bf8-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.737697ms
May 11 01:51:44.739: INFO: Pod "pod-secrets-53582bf8-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004108538s
STEP: Saw pod success
May 11 01:51:44.739: INFO: Pod "pod-secrets-53582bf8-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:51:44.740: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-secrets-53582bf8-738f-11e9-9c46-760f9b3dbd5d container secret-volume-test: <nil>
STEP: delete the pod
May 11 01:51:44.751: INFO: Waiting for pod pod-secrets-53582bf8-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:51:44.753: INFO: Pod pod-secrets-53582bf8-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:51:44.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8jfqk" for this suite.
May 11 01:51:50.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:51:50.807: INFO: namespace: e2e-tests-secrets-8jfqk, resource: bindings, ignored listing per whitelist
May 11 01:51:50.818: INFO: namespace e2e-tests-secrets-8jfqk deletion completed in 6.063022584s
STEP: Destroying namespace "e2e-tests-secret-namespace-4t6h4" for this suite.
May 11 01:51:56.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:51:56.864: INFO: namespace: e2e-tests-secret-namespace-4t6h4, resource: bindings, ignored listing per whitelist
May 11 01:51:56.877: INFO: namespace e2e-tests-secret-namespace-4t6h4 deletion completed in 6.058849767s

• [SLOW TEST:14.243 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:51:56.877: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
May 11 01:51:56.921: INFO: Waiting up to 5m0s for pod "pod-5bccd190-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-7wcxr" to be "success or failure"
May 11 01:51:56.924: INFO: Pod "pod-5bccd190-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.747396ms
May 11 01:51:58.926: INFO: Pod "pod-5bccd190-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005393834s
STEP: Saw pod success
May 11 01:51:58.926: INFO: Pod "pod-5bccd190-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:51:58.928: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-5bccd190-738f-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:51:58.942: INFO: Waiting for pod pod-5bccd190-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:51:58.944: INFO: Pod pod-5bccd190-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:51:58.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7wcxr" for this suite.
May 11 01:52:04.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:52:04.967: INFO: namespace: e2e-tests-emptydir-7wcxr, resource: bindings, ignored listing per whitelist
May 11 01:52:05.011: INFO: namespace e2e-tests-emptydir-7wcxr deletion completed in 6.064863533s

• [SLOW TEST:8.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:52:05.011: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-jjrnj/configmap-test-60a5f3e1-738f-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:52:05.057: INFO: Waiting up to 5m0s for pod "pod-configmaps-60a63e8a-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-jjrnj" to be "success or failure"
May 11 01:52:05.060: INFO: Pod "pod-configmaps-60a63e8a-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.00425ms
May 11 01:52:07.062: INFO: Pod "pod-configmaps-60a63e8a-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005607055s
STEP: Saw pod success
May 11 01:52:07.062: INFO: Pod "pod-configmaps-60a63e8a-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:52:07.064: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-configmaps-60a63e8a-738f-11e9-9c46-760f9b3dbd5d container env-test: <nil>
STEP: delete the pod
May 11 01:52:07.076: INFO: Waiting for pod pod-configmaps-60a63e8a-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:52:07.078: INFO: Pod pod-configmaps-60a63e8a-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:52:07.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jjrnj" for this suite.
May 11 01:52:13.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:52:13.115: INFO: namespace: e2e-tests-configmap-jjrnj, resource: bindings, ignored listing per whitelist
May 11 01:52:13.153: INFO: namespace e2e-tests-configmap-jjrnj deletion completed in 6.073241334s

• [SLOW TEST:8.142 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:52:13.153: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-w5wqz
May 11 01:52:15.204: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-w5wqz
STEP: checking the pod's current state and verifying that restartCount is present
May 11 01:52:15.205: INFO: Initial restart count of pod liveness-http is 0
May 11 01:52:39.252: INFO: Restart count of pod e2e-tests-container-probe-w5wqz/liveness-http is now 1 (24.046341841s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:52:39.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-w5wqz" for this suite.
May 11 01:52:45.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:52:45.294: INFO: namespace: e2e-tests-container-probe-w5wqz, resource: bindings, ignored listing per whitelist
May 11 01:52:45.328: INFO: namespace e2e-tests-container-probe-w5wqz deletion completed in 6.066728691s

• [SLOW TEST:32.174 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:52:45.328: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-78af34b4-738f-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:52:45.384: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-78af900e-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-9bg2p" to be "success or failure"
May 11 01:52:45.387: INFO: Pod "pod-projected-configmaps-78af900e-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.637434ms
May 11 01:52:47.389: INFO: Pod "pod-projected-configmaps-78af900e-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005139935s
STEP: Saw pod success
May 11 01:52:47.389: INFO: Pod "pod-projected-configmaps-78af900e-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:52:47.391: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-projected-configmaps-78af900e-738f-11e9-9c46-760f9b3dbd5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 11 01:52:47.407: INFO: Waiting for pod pod-projected-configmaps-78af900e-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:52:47.410: INFO: Pod pod-projected-configmaps-78af900e-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:52:47.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9bg2p" for this suite.
May 11 01:52:53.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:52:53.455: INFO: namespace: e2e-tests-projected-9bg2p, resource: bindings, ignored listing per whitelist
May 11 01:52:53.485: INFO: namespace e2e-tests-projected-9bg2p deletion completed in 6.072178664s

• [SLOW TEST:8.157 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:52:53.485: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 01:53:13.541: INFO: Container started at 2019-05-11 01:52:56 +0000 UTC, pod became ready at 2019-05-11 01:53:12 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:53:13.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5rcqf" for this suite.
May 11 01:53:35.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:53:35.582: INFO: namespace: e2e-tests-container-probe-5rcqf, resource: bindings, ignored listing per whitelist
May 11 01:53:35.602: INFO: namespace e2e-tests-container-probe-5rcqf deletion completed in 22.057711973s

• [SLOW TEST:42.116 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:53:35.602: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 01:53:35.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-96a4c8ec-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-rgdsg" to be "success or failure"
May 11 01:53:35.649: INFO: Pod "downwardapi-volume-96a4c8ec-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.43901ms
May 11 01:53:37.652: INFO: Pod "downwardapi-volume-96a4c8ec-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006685737s
STEP: Saw pod success
May 11 01:53:37.652: INFO: Pod "downwardapi-volume-96a4c8ec-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:53:37.653: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-96a4c8ec-738f-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 01:53:37.667: INFO: Waiting for pod downwardapi-volume-96a4c8ec-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:53:37.669: INFO: Pod downwardapi-volume-96a4c8ec-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:53:37.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rgdsg" for this suite.
May 11 01:53:43.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:53:43.695: INFO: namespace: e2e-tests-projected-rgdsg, resource: bindings, ignored listing per whitelist
May 11 01:53:43.730: INFO: namespace e2e-tests-projected-rgdsg deletion completed in 6.058671256s

• [SLOW TEST:8.128 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:53:43.730: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 11 01:53:43.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-4q6tz'
May 11 01:53:44.040: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 11 01:53:44.040: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 11 01:53:44.046: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-hkpgj]
May 11 01:53:44.046: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-hkpgj" in namespace "e2e-tests-kubectl-4q6tz" to be "running and ready"
May 11 01:53:44.050: INFO: Pod "e2e-test-nginx-rc-hkpgj": Phase="Pending", Reason="", readiness=false. Elapsed: 3.447828ms
May 11 01:53:46.052: INFO: Pod "e2e-test-nginx-rc-hkpgj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005472413s
May 11 01:53:48.055: INFO: Pod "e2e-test-nginx-rc-hkpgj": Phase="Running", Reason="", readiness=true. Elapsed: 4.00872993s
May 11 01:53:48.055: INFO: Pod "e2e-test-nginx-rc-hkpgj" satisfied condition "running and ready"
May 11 01:53:48.055: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-hkpgj]
May 11 01:53:48.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4q6tz'
May 11 01:53:48.179: INFO: stderr: ""
May 11 01:53:48.179: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
May 11 01:53:48.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-594220555 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4q6tz'
May 11 01:53:48.297: INFO: stderr: ""
May 11 01:53:48.297: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:53:48.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4q6tz" for this suite.
May 11 01:54:10.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:54:10.374: INFO: namespace: e2e-tests-kubectl-4q6tz, resource: bindings, ignored listing per whitelist
May 11 01:54:10.378: INFO: namespace e2e-tests-kubectl-4q6tz deletion completed in 22.078700157s

• [SLOW TEST:26.648 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:54:10.378: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mp2xk
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 11 01:54:10.424: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 11 01:54:34.479: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.218:8080/dial?request=hostName&protocol=udp&host=10.233.91.237&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-mp2xk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 01:54:34.479: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 01:54:34.666: INFO: Waiting for endpoints: map[]
May 11 01:54:34.669: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.218:8080/dial?request=hostName&protocol=udp&host=10.233.122.215&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-mp2xk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 01:54:34.669: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 01:54:34.886: INFO: Waiting for endpoints: map[]
May 11 01:54:34.888: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.218:8080/dial?request=hostName&protocol=udp&host=10.233.124.160&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-mp2xk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 11 01:54:34.888: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
May 11 01:54:35.119: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:54:35.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mp2xk" for this suite.
May 11 01:54:57.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:54:57.173: INFO: namespace: e2e-tests-pod-network-test-mp2xk, resource: bindings, ignored listing per whitelist
May 11 01:54:57.185: INFO: namespace e2e-tests-pod-network-test-mp2xk deletion completed in 22.062856339s

• [SLOW TEST:46.807 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:54:57.186: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
May 11 01:54:57.229: INFO: Waiting up to 5m0s for pod "client-containers-c745bd3c-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-containers-8qv7x" to be "success or failure"
May 11 01:54:57.231: INFO: Pod "client-containers-c745bd3c-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.604842ms
May 11 01:54:59.235: INFO: Pod "client-containers-c745bd3c-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005564954s
May 11 01:55:01.238: INFO: Pod "client-containers-c745bd3c-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008292411s
STEP: Saw pod success
May 11 01:55:01.238: INFO: Pod "client-containers-c745bd3c-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:55:01.240: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod client-containers-c745bd3c-738f-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 01:55:01.257: INFO: Waiting for pod client-containers-c745bd3c-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:55:01.258: INFO: Pod client-containers-c745bd3c-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:55:01.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8qv7x" for this suite.
May 11 01:55:07.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:55:07.299: INFO: namespace: e2e-tests-containers-8qv7x, resource: bindings, ignored listing per whitelist
May 11 01:55:07.322: INFO: namespace e2e-tests-containers-8qv7x deletion completed in 6.060521032s

• [SLOW TEST:10.137 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:55:07.322: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 01:55:09.385: INFO: Waiting up to 5m0s for pod "client-envvars-ce84a749-738f-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-pods-56wp9" to be "success or failure"
May 11 01:55:09.387: INFO: Pod "client-envvars-ce84a749-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.099928ms
May 11 01:55:11.390: INFO: Pod "client-envvars-ce84a749-738f-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004647603s
May 11 01:55:13.392: INFO: Pod "client-envvars-ce84a749-738f-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007038813s
STEP: Saw pod success
May 11 01:55:13.392: INFO: Pod "client-envvars-ce84a749-738f-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:55:13.394: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod client-envvars-ce84a749-738f-11e9-9c46-760f9b3dbd5d container env3cont: <nil>
STEP: delete the pod
May 11 01:55:13.406: INFO: Waiting for pod client-envvars-ce84a749-738f-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:55:13.408: INFO: Pod client-envvars-ce84a749-738f-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:55:13.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-56wp9" for this suite.
May 11 01:56:03.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:56:03.442: INFO: namespace: e2e-tests-pods-56wp9, resource: bindings, ignored listing per whitelist
May 11 01:56:03.477: INFO: namespace e2e-tests-pods-56wp9 deletion completed in 50.066091304s

• [SLOW TEST:56.154 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:56:03.477: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-eecc2d97-738f-11e9-9c46-760f9b3dbd5d
STEP: Creating configMap with name cm-test-opt-upd-eecc2dda-738f-11e9-9c46-760f9b3dbd5d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-eecc2d97-738f-11e9-9c46-760f9b3dbd5d
STEP: Updating configmap cm-test-opt-upd-eecc2dda-738f-11e9-9c46-760f9b3dbd5d
STEP: Creating configMap with name cm-test-opt-create-eecc2dfb-738f-11e9-9c46-760f9b3dbd5d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:56:07.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p4l4b" for this suite.
May 11 01:56:29.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:56:29.653: INFO: namespace: e2e-tests-configmap-p4l4b, resource: bindings, ignored listing per whitelist
May 11 01:56:29.670: INFO: namespace e2e-tests-configmap-p4l4b deletion completed in 22.064402514s

• [SLOW TEST:26.193 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:56:29.670: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:56:29.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9x7qs" for this suite.
May 11 01:56:35.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:56:35.744: INFO: namespace: e2e-tests-services-9x7qs, resource: bindings, ignored listing per whitelist
May 11 01:56:35.783: INFO: namespace e2e-tests-services-9x7qs deletion completed in 6.062507981s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.113 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:56:35.783: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
May 11 01:56:35.831: INFO: Waiting up to 5m0s for pod "var-expansion-020b1ef5-7390-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-var-expansion-ws9tq" to be "success or failure"
May 11 01:56:35.835: INFO: Pod "var-expansion-020b1ef5-7390-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.585743ms
May 11 01:56:37.838: INFO: Pod "var-expansion-020b1ef5-7390-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00663742s
STEP: Saw pod success
May 11 01:56:37.838: INFO: Pod "var-expansion-020b1ef5-7390-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:56:37.840: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod var-expansion-020b1ef5-7390-11e9-9c46-760f9b3dbd5d container dapi-container: <nil>
STEP: delete the pod
May 11 01:56:37.851: INFO: Waiting for pod var-expansion-020b1ef5-7390-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:56:37.853: INFO: Pod var-expansion-020b1ef5-7390-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:56:37.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ws9tq" for this suite.
May 11 01:56:43.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:56:43.905: INFO: namespace: e2e-tests-var-expansion-ws9tq, resource: bindings, ignored listing per whitelist
May 11 01:56:43.920: INFO: namespace e2e-tests-var-expansion-ws9tq deletion completed in 6.064822916s

• [SLOW TEST:8.137 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:56:43.920: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 11 01:56:43.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06e49182-7390-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-downward-api-cwrhn" to be "success or failure"
May 11 01:56:43.969: INFO: Pod "downwardapi-volume-06e49182-7390-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.147966ms
May 11 01:56:45.973: INFO: Pod "downwardapi-volume-06e49182-7390-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006027318s
STEP: Saw pod success
May 11 01:56:45.973: INFO: Pod "downwardapi-volume-06e49182-7390-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:56:45.974: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod downwardapi-volume-06e49182-7390-11e9-9c46-760f9b3dbd5d container client-container: <nil>
STEP: delete the pod
May 11 01:56:45.986: INFO: Waiting for pod downwardapi-volume-06e49182-7390-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:56:45.988: INFO: Pod downwardapi-volume-06e49182-7390-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:56:45.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cwrhn" for this suite.
May 11 01:56:51.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:56:52.028: INFO: namespace: e2e-tests-downward-api-cwrhn, resource: bindings, ignored listing per whitelist
May 11 01:56:52.046: INFO: namespace e2e-tests-downward-api-cwrhn deletion completed in 6.055530851s

• [SLOW TEST:8.126 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:56:52.046: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
May 11 01:56:54.118: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:57:16.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-487fm" for this suite.
May 11 01:57:22.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:57:22.184: INFO: namespace: e2e-tests-namespaces-487fm, resource: bindings, ignored listing per whitelist
May 11 01:57:22.226: INFO: namespace e2e-tests-namespaces-487fm deletion completed in 6.06614018s
STEP: Destroying namespace "e2e-tests-nsdeletetest-cxgdh" for this suite.
May 11 01:57:22.228: INFO: Namespace e2e-tests-nsdeletetest-cxgdh was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-vbkg6" for this suite.
May 11 01:57:28.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:57:28.264: INFO: namespace: e2e-tests-nsdeletetest-vbkg6, resource: bindings, ignored listing per whitelist
May 11 01:57:28.298: INFO: namespace e2e-tests-nsdeletetest-vbkg6 deletion completed in 6.07062328s

• [SLOW TEST:36.252 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:57:28.298: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-21579223-7390-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume configMaps
May 11 01:57:28.343: INFO: Waiting up to 5m0s for pod "pod-configmaps-2157dc38-7390-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-configmap-vsl99" to be "success or failure"
May 11 01:57:28.345: INFO: Pod "pod-configmaps-2157dc38-7390-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.257796ms
May 11 01:57:30.348: INFO: Pod "pod-configmaps-2157dc38-7390-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005024542s
STEP: Saw pod success
May 11 01:57:30.348: INFO: Pod "pod-configmaps-2157dc38-7390-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 01:57:30.350: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-configmaps-2157dc38-7390-11e9-9c46-760f9b3dbd5d container configmap-volume-test: <nil>
STEP: delete the pod
May 11 01:57:30.364: INFO: Waiting for pod pod-configmaps-2157dc38-7390-11e9-9c46-760f9b3dbd5d to disappear
May 11 01:57:30.366: INFO: Pod pod-configmaps-2157dc38-7390-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 01:57:30.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vsl99" for this suite.
May 11 01:57:36.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 01:57:36.385: INFO: namespace: e2e-tests-configmap-vsl99, resource: bindings, ignored listing per whitelist
May 11 01:57:36.442: INFO: namespace e2e-tests-configmap-vsl99 deletion completed in 6.07333464s

• [SLOW TEST:8.144 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 01:57:36.442: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-jn5cc
May 11 01:57:38.490: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-jn5cc
STEP: checking the pod's current state and verifying that restartCount is present
May 11 01:57:38.491: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 02:01:38.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jn5cc" for this suite.
May 11 02:01:44.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 02:01:44.906: INFO: namespace: e2e-tests-container-probe-jn5cc, resource: bindings, ignored listing per whitelist
May 11 02:01:44.937: INFO: namespace e2e-tests-container-probe-jn5cc deletion completed in 6.059518514s

• [SLOW TEST:248.495 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 02:01:44.938: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 02:01:44.992: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 11 02:01:44.996: INFO: Number of nodes with available pods: 0
May 11 02:01:44.996: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 11 02:01:45.008: INFO: Number of nodes with available pods: 0
May 11 02:01:45.008: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:46.011: INFO: Number of nodes with available pods: 0
May 11 02:01:46.011: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:47.010: INFO: Number of nodes with available pods: 1
May 11 02:01:47.010: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 11 02:01:47.024: INFO: Number of nodes with available pods: 1
May 11 02:01:47.024: INFO: Number of running nodes: 0, number of available pods: 1
May 11 02:01:48.027: INFO: Number of nodes with available pods: 0
May 11 02:01:48.027: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 11 02:01:48.032: INFO: Number of nodes with available pods: 0
May 11 02:01:48.032: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:49.034: INFO: Number of nodes with available pods: 0
May 11 02:01:49.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:50.034: INFO: Number of nodes with available pods: 0
May 11 02:01:50.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:51.034: INFO: Number of nodes with available pods: 0
May 11 02:01:51.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:52.035: INFO: Number of nodes with available pods: 0
May 11 02:01:52.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:53.033: INFO: Number of nodes with available pods: 0
May 11 02:01:53.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:54.035: INFO: Number of nodes with available pods: 0
May 11 02:01:54.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:55.035: INFO: Number of nodes with available pods: 0
May 11 02:01:55.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:56.034: INFO: Number of nodes with available pods: 0
May 11 02:01:56.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:57.035: INFO: Number of nodes with available pods: 0
May 11 02:01:57.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:58.035: INFO: Number of nodes with available pods: 0
May 11 02:01:58.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:01:59.035: INFO: Number of nodes with available pods: 0
May 11 02:01:59.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:00.034: INFO: Number of nodes with available pods: 0
May 11 02:02:00.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:01.034: INFO: Number of nodes with available pods: 0
May 11 02:02:01.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:02.034: INFO: Number of nodes with available pods: 0
May 11 02:02:02.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:03.035: INFO: Number of nodes with available pods: 0
May 11 02:02:03.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:04.035: INFO: Number of nodes with available pods: 0
May 11 02:02:04.036: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:05.035: INFO: Number of nodes with available pods: 0
May 11 02:02:05.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:06.034: INFO: Number of nodes with available pods: 0
May 11 02:02:06.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:07.037: INFO: Number of nodes with available pods: 0
May 11 02:02:07.037: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:08.034: INFO: Number of nodes with available pods: 0
May 11 02:02:08.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:09.034: INFO: Number of nodes with available pods: 0
May 11 02:02:09.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:10.034: INFO: Number of nodes with available pods: 0
May 11 02:02:10.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:11.035: INFO: Number of nodes with available pods: 0
May 11 02:02:11.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:12.034: INFO: Number of nodes with available pods: 0
May 11 02:02:12.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:13.035: INFO: Number of nodes with available pods: 0
May 11 02:02:13.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:14.035: INFO: Number of nodes with available pods: 0
May 11 02:02:14.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:15.034: INFO: Number of nodes with available pods: 0
May 11 02:02:15.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:16.035: INFO: Number of nodes with available pods: 0
May 11 02:02:16.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:17.035: INFO: Number of nodes with available pods: 0
May 11 02:02:17.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:18.034: INFO: Number of nodes with available pods: 0
May 11 02:02:18.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:19.036: INFO: Number of nodes with available pods: 0
May 11 02:02:19.036: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:20.035: INFO: Number of nodes with available pods: 0
May 11 02:02:20.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:21.034: INFO: Number of nodes with available pods: 0
May 11 02:02:21.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:22.034: INFO: Number of nodes with available pods: 0
May 11 02:02:22.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:23.035: INFO: Number of nodes with available pods: 0
May 11 02:02:23.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:24.035: INFO: Number of nodes with available pods: 0
May 11 02:02:24.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:25.035: INFO: Number of nodes with available pods: 0
May 11 02:02:25.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:26.034: INFO: Number of nodes with available pods: 0
May 11 02:02:26.034: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:27.035: INFO: Number of nodes with available pods: 0
May 11 02:02:27.035: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:28.036: INFO: Number of nodes with available pods: 0
May 11 02:02:28.036: INFO: Node craig-k8s-certification-1-stellar-hand-0 is running more than one daemon pod
May 11 02:02:29.034: INFO: Number of nodes with available pods: 1
May 11 02:02:29.034: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-kcwxt, will wait for the garbage collector to delete the pods
May 11 02:02:29.093: INFO: Deleting DaemonSet.extensions daemon-set took: 3.951028ms
May 11 02:02:29.193: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.163017ms
May 11 02:03:07.398: INFO: Number of nodes with available pods: 0
May 11 02:03:07.398: INFO: Number of running nodes: 0, number of available pods: 0
May 11 02:03:07.400: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kcwxt/daemonsets","resourceVersion":"32532"},"items":null}

May 11 02:03:07.403: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kcwxt/pods","resourceVersion":"32532"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 02:03:07.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kcwxt" for this suite.
May 11 02:03:15.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 02:03:15.574: INFO: namespace: e2e-tests-daemonsets-kcwxt, resource: bindings, ignored listing per whitelist
May 11 02:03:15.579: INFO: namespace e2e-tests-daemonsets-kcwxt deletion completed in 8.115305144s

• [SLOW TEST:90.641 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 02:03:15.579: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 11 02:03:16.339: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 11 02:03:21.342: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 11 02:03:21.342: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 11 02:03:23.345: INFO: Creating deployment "test-rollover-deployment"
May 11 02:03:23.403: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 11 02:03:25.565: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 11 02:03:25.601: INFO: Ensure that both replica sets have 1 created replica
May 11 02:03:25.604: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 11 02:03:25.649: INFO: Updating deployment test-rollover-deployment
May 11 02:03:25.649: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 11 02:03:27.665: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 11 02:03:27.668: INFO: Make sure deployment "test-rollover-deployment" is complete
May 11 02:03:27.671: INFO: all replica sets need to contain the pod-template-hash label
May 11 02:03:27.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137005, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 11 02:03:29.676: INFO: all replica sets need to contain the pod-template-hash label
May 11 02:03:29.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137008, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 11 02:03:31.702: INFO: all replica sets need to contain the pod-template-hash label
May 11 02:03:31.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137008, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 11 02:03:33.681: INFO: all replica sets need to contain the pod-template-hash label
May 11 02:03:33.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137008, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 11 02:03:35.691: INFO: all replica sets need to contain the pod-template-hash label
May 11 02:03:35.691: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137008, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 11 02:03:37.676: INFO: all replica sets need to contain the pod-template-hash label
May 11 02:03:37.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137008, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693137002, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 11 02:03:39.695: INFO: 
May 11 02:03:39.695: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 11 02:03:39.701: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-427xt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-427xt/deployments/test-rollover-deployment,UID:f47c293d-7390-11e9-9f3c-000c29c278ce,ResourceVersion:32721,Generation:2,CreationTimestamp:2019-05-11 02:03:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-11 02:03:22 +0000 UTC 2019-05-11 02:03:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-11 02:03:38 +0000 UTC 2019-05-11 02:03:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 11 02:03:39.703: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-427xt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-427xt/replicasets/test-rollover-deployment-6b7f9d6597,UID:f5dbdd74-7390-11e9-9f3c-000c29c278ce,ResourceVersion:32711,Generation:2,CreationTimestamp:2019-05-11 02:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f47c293d-7390-11e9-9f3c-000c29c278ce 0xc002b68527 0xc002b68528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 11 02:03:39.703: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 11 02:03:39.703: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-427xt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-427xt/replicasets/test-rollover-controller,UID:f045b55c-7390-11e9-9f3c-000c29c278ce,ResourceVersion:32720,Generation:2,CreationTimestamp:2019-05-11 02:03:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f47c293d-7390-11e9-9f3c-000c29c278ce 0xc002b68397 0xc002b68398}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 11 02:03:39.704: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-427xt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-427xt/replicasets/test-rollover-deployment-6586df867b,UID:f485b681-7390-11e9-9f3c-000c29c278ce,ResourceVersion:32653,Generation:2,CreationTimestamp:2019-05-11 02:03:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f47c293d-7390-11e9-9f3c-000c29c278ce 0xc002b68457 0xc002b68458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 11 02:03:39.706: INFO: Pod "test-rollover-deployment-6b7f9d6597-dvn5r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-dvn5r,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-427xt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-427xt/pods/test-rollover-deployment-6b7f9d6597-dvn5r,UID:f604dcb3-7390-11e9-9f3c-000c29c278ce,ResourceVersion:32684,Generation:0,CreationTimestamp:2019-05-11 02:03:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 f5dbdd74-7390-11e9-9f3c-000c29c278ce 0xc002b69067 0xc002b69068}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fh4mz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fh4mz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fh4mz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:craig-k8s-certification-1-stellar-hand-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b690d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b690f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 02:03:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 02:03:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 02:03:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-11 02:03:25 +0000 UTC  }],Message:,Reason:,HostIP:70.0.51.31,PodIP:10.233.122.223,StartTime:2019-05-11 02:03:25 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-11 02:03:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://aacb9e73233a3851d65555b0d6fe0d9fab6eebf400f4cc223176dc7256973f89}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 02:03:39.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-427xt" for this suite.
May 11 02:03:47.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 02:03:47.921: INFO: namespace: e2e-tests-deployment-427xt, resource: bindings, ignored listing per whitelist
May 11 02:03:47.930: INFO: namespace e2e-tests-deployment-427xt deletion completed in 8.221829615s

• [SLOW TEST:32.351 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 02:03:47.930: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-03af3fae-7391-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 02:03:48.092: INFO: Waiting up to 5m0s for pod "pod-secrets-03b0270d-7391-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-z9m48" to be "success or failure"
May 11 02:03:48.096: INFO: Pod "pod-secrets-03b0270d-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.740086ms
May 11 02:03:50.098: INFO: Pod "pod-secrets-03b0270d-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006141687s
May 11 02:03:52.101: INFO: Pod "pod-secrets-03b0270d-7391-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009111599s
STEP: Saw pod success
May 11 02:03:52.101: INFO: Pod "pod-secrets-03b0270d-7391-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 02:03:52.103: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod pod-secrets-03b0270d-7391-11e9-9c46-760f9b3dbd5d container secret-volume-test: <nil>
STEP: delete the pod
May 11 02:03:52.177: INFO: Waiting for pod pod-secrets-03b0270d-7391-11e9-9c46-760f9b3dbd5d to disappear
May 11 02:03:52.185: INFO: Pod pod-secrets-03b0270d-7391-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 02:03:52.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-z9m48" for this suite.
May 11 02:03:58.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 02:03:58.275: INFO: namespace: e2e-tests-secrets-z9m48, resource: bindings, ignored listing per whitelist
May 11 02:03:58.284: INFO: namespace e2e-tests-secrets-z9m48 deletion completed in 6.095382846s

• [SLOW TEST:10.354 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 02:03:58.284: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-09dea095-7391-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test consume secrets
May 11 02:03:58.515: INFO: Waiting up to 5m0s for pod "pod-secrets-09e3f67a-7391-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-secrets-85cbn" to be "success or failure"
May 11 02:03:58.547: INFO: Pod "pod-secrets-09e3f67a-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 31.958511ms
May 11 02:04:00.549: INFO: Pod "pod-secrets-09e3f67a-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034326152s
May 11 02:04:02.552: INFO: Pod "pod-secrets-09e3f67a-7391-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036653009s
STEP: Saw pod success
May 11 02:04:02.552: INFO: Pod "pod-secrets-09e3f67a-7391-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 02:04:02.553: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-0 pod pod-secrets-09e3f67a-7391-11e9-9c46-760f9b3dbd5d container secret-env-test: <nil>
STEP: delete the pod
May 11 02:04:02.609: INFO: Waiting for pod pod-secrets-09e3f67a-7391-11e9-9c46-760f9b3dbd5d to disappear
May 11 02:04:02.633: INFO: Pod pod-secrets-09e3f67a-7391-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 02:04:02.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-85cbn" for this suite.
May 11 02:04:08.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 02:04:08.671: INFO: namespace: e2e-tests-secrets-85cbn, resource: bindings, ignored listing per whitelist
May 11 02:04:08.699: INFO: namespace e2e-tests-secrets-85cbn deletion completed in 6.06359836s

• [SLOW TEST:10.416 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 02:04:08.699: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 11 02:04:08.747: INFO: Waiting up to 5m0s for pod "pod-1000a68c-7391-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-emptydir-jhkz8" to be "success or failure"
May 11 02:04:08.749: INFO: Pod "pod-1000a68c-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.755672ms
May 11 02:04:10.754: INFO: Pod "pod-1000a68c-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007502616s
May 11 02:04:12.757: INFO: Pod "pod-1000a68c-7391-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010241428s
STEP: Saw pod success
May 11 02:04:12.757: INFO: Pod "pod-1000a68c-7391-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 02:04:12.760: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-1 pod pod-1000a68c-7391-11e9-9c46-760f9b3dbd5d container test-container: <nil>
STEP: delete the pod
May 11 02:04:12.772: INFO: Waiting for pod pod-1000a68c-7391-11e9-9c46-760f9b3dbd5d to disappear
May 11 02:04:12.774: INFO: Pod pod-1000a68c-7391-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 02:04:12.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jhkz8" for this suite.
May 11 02:04:18.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 02:04:18.807: INFO: namespace: e2e-tests-emptydir-jhkz8, resource: bindings, ignored listing per whitelist
May 11 02:04:18.847: INFO: namespace e2e-tests-emptydir-jhkz8 deletion completed in 6.071221241s

• [SLOW TEST:10.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 11 02:04:18.847: INFO: >>> kubeConfig: /tmp/kubeconfig-594220555
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-1633edc5-7391-11e9-9c46-760f9b3dbd5d
STEP: Creating secret with name secret-projected-all-test-volume-1633edb2-7391-11e9-9c46-760f9b3dbd5d
STEP: Creating a pod to test Check all projections for projected volume plugin
May 11 02:04:19.292: INFO: Waiting up to 5m0s for pod "projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d" in namespace "e2e-tests-projected-xf7z6" to be "success or failure"
May 11 02:04:19.333: INFO: Pod "projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 41.006716ms
May 11 02:04:21.356: INFO: Pod "projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064373517s
May 11 02:04:23.359: INFO: Pod "projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.066657336s
May 11 02:04:25.361: INFO: Pod "projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.069461775s
STEP: Saw pod success
May 11 02:04:25.361: INFO: Pod "projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d" satisfied condition "success or failure"
May 11 02:04:25.363: INFO: Trying to get logs from node craig-k8s-certification-1-stellar-hand-2 pod projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d container projected-all-volume-test: <nil>
STEP: delete the pod
May 11 02:04:25.468: INFO: Waiting for pod projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d to disappear
May 11 02:04:25.480: INFO: Pod projected-volume-1633ed39-7391-11e9-9c46-760f9b3dbd5d no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 11 02:04:25.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xf7z6" for this suite.
May 11 02:04:31.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 11 02:04:31.559: INFO: namespace: e2e-tests-projected-xf7z6, resource: bindings, ignored listing per whitelist
May 11 02:04:31.594: INFO: namespace e2e-tests-projected-xf7z6 deletion completed in 6.111354529s

• [SLOW TEST:12.747 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSMay 11 02:04:31.595: INFO: Running AfterSuite actions on all nodes
May 11 02:04:31.595: INFO: Running AfterSuite actions on node 1
May 11 02:04:31.595: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5931.462 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h38m52.220749998s
Test Suite Passed

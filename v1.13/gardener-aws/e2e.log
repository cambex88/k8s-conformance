Conformance test: not doing test setup.
I0220 18:10:19.276571   30217 e2e.go:224] Starting e2e run "c7c4244a-353a-11e9-96fe-8e2b2e6369d7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550686218 - Will randomize all specs
Will run 201 of 2161 specs

Feb 20 18:10:19.452: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:10:19.454: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 20 18:10:19.635: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 20 18:10:19.860: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 20 18:10:19.860: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Feb 20 18:10:19.860: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 20 18:10:19.909: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 20 18:10:19.909: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 20 18:10:19.909: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Feb 20 18:10:19.909: INFO: e2e test version: v1.13.3
Feb 20 18:10:19.950: INFO: kube-apiserver version: v1.13.3
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:10:19.950: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
Feb 20 18:10:21.478: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 20 18:10:21.608: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mr28h
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c9a934bd-353a-11e9-96fe-8e2b2e6369d7
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c9a934bd-353a-11e9-96fe-8e2b2e6369d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:11:34.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mr28h" for this suite.
Feb 20 18:11:56.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:11:57.277: INFO: namespace: e2e-tests-projected-mr28h, resource: bindings, ignored listing per whitelist
Feb 20 18:11:57.990: INFO: namespace e2e-tests-projected-mr28h deletion completed in 23.785530083s

• [SLOW TEST:98.040 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:11:57.990: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-b2rst
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-03eb5ce7-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 18:11:59.747: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-03f1c541-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-b2rst" to be "success or failure"
Feb 20 18:11:59.789: INFO: Pod "pod-projected-secrets-03f1c541-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.00182ms
Feb 20 18:12:01.831: INFO: Pod "pod-projected-secrets-03f1c541-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084541782s
STEP: Saw pod success
Feb 20 18:12:01.831: INFO: Pod "pod-projected-secrets-03f1c541-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:12:01.873: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-secrets-03f1c541-353b-11e9-96fe-8e2b2e6369d7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:12:01.967: INFO: Waiting for pod pod-projected-secrets-03f1c541-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:12:02.009: INFO: Pod pod-projected-secrets-03f1c541-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:12:02.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b2rst" for this suite.
Feb 20 18:12:08.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:12:09.441: INFO: namespace: e2e-tests-projected-b2rst, resource: bindings, ignored listing per whitelist
Feb 20 18:12:09.819: INFO: namespace e2e-tests-projected-b2rst deletion completed in 7.767482549s

• [SLOW TEST:11.829 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:12:09.820: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2rrhw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0b03a87e-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 18:12:11.650: INFO: Waiting up to 5m0s for pod "pod-configmaps-0b0a1684-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-2rrhw" to be "success or failure"
Feb 20 18:12:11.694: INFO: Pod "pod-configmaps-0b0a1684-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 43.024267ms
Feb 20 18:12:13.736: INFO: Pod "pod-configmaps-0b0a1684-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085219944s
STEP: Saw pod success
Feb 20 18:12:13.736: INFO: Pod "pod-configmaps-0b0a1684-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:12:13.778: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-0b0a1684-353b-11e9-96fe-8e2b2e6369d7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:12:13.869: INFO: Waiting for pod pod-configmaps-0b0a1684-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:12:13.911: INFO: Pod pod-configmaps-0b0a1684-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:12:13.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2rrhw" for this suite.
Feb 20 18:12:20.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:12:21.463: INFO: namespace: e2e-tests-configmap-2rrhw, resource: bindings, ignored listing per whitelist
Feb 20 18:12:21.672: INFO: namespace e2e-tests-configmap-2rrhw deletion completed in 7.718441504s

• [SLOW TEST:11.853 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:12:21.672: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2jrxf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 20 18:12:23.429: INFO: Waiting up to 5m0s for pod "pod-120f7b65-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-2jrxf" to be "success or failure"
Feb 20 18:12:23.471: INFO: Pod "pod-120f7b65-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.793479ms
Feb 20 18:12:25.514: INFO: Pod "pod-120f7b65-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084198546s
Feb 20 18:12:27.556: INFO: Pod "pod-120f7b65-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.126814714s
STEP: Saw pod success
Feb 20 18:12:27.556: INFO: Pod "pod-120f7b65-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:12:27.598: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-120f7b65-353b-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 18:12:27.690: INFO: Waiting for pod pod-120f7b65-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:12:27.732: INFO: Pod pod-120f7b65-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:12:27.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2jrxf" for this suite.
Feb 20 18:12:33.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:12:34.280: INFO: namespace: e2e-tests-emptydir-2jrxf, resource: bindings, ignored listing per whitelist
Feb 20 18:12:35.538: INFO: namespace e2e-tests-emptydir-2jrxf deletion completed in 7.763781215s

• [SLOW TEST:13.866 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:12:35.538: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-r2vtg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 20 18:12:37.398: INFO: Waiting up to 5m0s for pod "pod-1a62f9e8-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-r2vtg" to be "success or failure"
Feb 20 18:12:37.440: INFO: Pod "pod-1a62f9e8-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.761641ms
Feb 20 18:12:39.483: INFO: Pod "pod-1a62f9e8-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084895822s
STEP: Saw pod success
Feb 20 18:12:39.483: INFO: Pod "pod-1a62f9e8-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:12:39.525: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-1a62f9e8-353b-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 18:12:39.619: INFO: Waiting for pod pod-1a62f9e8-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:12:39.661: INFO: Pod pod-1a62f9e8-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:12:39.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r2vtg" for this suite.
Feb 20 18:12:45.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:12:46.464: INFO: namespace: e2e-tests-emptydir-r2vtg, resource: bindings, ignored listing per whitelist
Feb 20 18:12:47.474: INFO: namespace e2e-tests-emptydir-r2vtg deletion completed in 7.771006769s

• [SLOW TEST:11.936 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:12:47.474: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-fzbb4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-fzbb4.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-fzbb4.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-fzbb4.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-fzbb4.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-fzbb4.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-fzbb4.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 18:13:08.326: INFO: DNS probes using e2e-tests-dns-fzbb4/dns-test-216d0e1c-353b-11e9-96fe-8e2b2e6369d7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:13:08.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-fzbb4" for this suite.
Feb 20 18:13:14.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:13:15.518: INFO: namespace: e2e-tests-dns-fzbb4, resource: bindings, ignored listing per whitelist
Feb 20 18:13:16.156: INFO: namespace e2e-tests-dns-fzbb4 deletion completed in 7.740971282s

• [SLOW TEST:28.682 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:13:16.156: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-pxzql
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-328820a3-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 18:13:17.949: INFO: Waiting up to 5m0s for pod "pod-secrets-328e95ba-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-pxzql" to be "success or failure"
Feb 20 18:13:17.991: INFO: Pod "pod-secrets-328e95ba-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.596672ms
Feb 20 18:13:20.034: INFO: Pod "pod-secrets-328e95ba-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084046094s
STEP: Saw pod success
Feb 20 18:13:20.034: INFO: Pod "pod-secrets-328e95ba-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:13:20.076: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-secrets-328e95ba-353b-11e9-96fe-8e2b2e6369d7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:13:20.171: INFO: Waiting for pod pod-secrets-328e95ba-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:13:20.213: INFO: Pod pod-secrets-328e95ba-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:13:20.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pxzql" for this suite.
Feb 20 18:13:26.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:13:26.636: INFO: namespace: e2e-tests-secrets-pxzql, resource: bindings, ignored listing per whitelist
Feb 20 18:13:27.987: INFO: namespace e2e-tests-secrets-pxzql deletion completed in 7.731527285s

• [SLOW TEST:11.831 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:13:27.988: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dnsgs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 18:13:29.707: INFO: Waiting up to 5m0s for pod "downward-api-3990c424-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-dnsgs" to be "success or failure"
Feb 20 18:13:29.749: INFO: Pod "downward-api-3990c424-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.788676ms
Feb 20 18:13:31.792: INFO: Pod "downward-api-3990c424-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084338188s
Feb 20 18:13:33.834: INFO: Pod "downward-api-3990c424-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.126890813s
STEP: Saw pod success
Feb 20 18:13:33.834: INFO: Pod "downward-api-3990c424-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:13:33.876: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downward-api-3990c424-353b-11e9-96fe-8e2b2e6369d7 container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:13:33.968: INFO: Waiting for pod downward-api-3990c424-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:13:34.010: INFO: Pod downward-api-3990c424-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:13:34.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dnsgs" for this suite.
Feb 20 18:13:40.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:13:40.934: INFO: namespace: e2e-tests-downward-api-dnsgs, resource: bindings, ignored listing per whitelist
Feb 20 18:13:41.778: INFO: namespace e2e-tests-downward-api-dnsgs deletion completed in 7.724758233s

• [SLOW TEST:13.791 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:13:41.778: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gsrdx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:13:43.564: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-gsrdx'
Feb 20 18:13:43.905: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 18:13:43.905: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 20 18:13:43.947: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-gsrdx'
Feb 20 18:13:44.231: INFO: stderr: ""
Feb 20 18:13:44.231: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:13:44.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gsrdx" for this suite.
Feb 20 18:14:06.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:14:07.203: INFO: namespace: e2e-tests-kubectl-gsrdx, resource: bindings, ignored listing per whitelist
Feb 20 18:14:07.999: INFO: namespace e2e-tests-kubectl-gsrdx deletion completed in 23.725426427s

• [SLOW TEST:26.221 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:14:07.999: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9v5cn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:14:09.966: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-9v5cn'
Feb 20 18:14:10.247: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 18:14:10.247: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb 20 18:14:10.289: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-9v5cn'
Feb 20 18:14:10.561: INFO: stderr: ""
Feb 20 18:14:10.561: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:14:10.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9v5cn" for this suite.
Feb 20 18:14:16.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:14:16.857: INFO: namespace: e2e-tests-kubectl-9v5cn, resource: bindings, ignored listing per whitelist
Feb 20 18:14:18.325: INFO: namespace e2e-tests-kubectl-9v5cn deletion completed in 7.720975687s

• [SLOW TEST:10.325 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:14:18.325: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tv5rn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-tv5rn/configmap-test-579cb080-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 18:14:20.159: INFO: Waiting up to 5m0s for pod "pod-configmaps-57a316a0-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-tv5rn" to be "success or failure"
Feb 20 18:14:20.201: INFO: Pod "pod-configmaps-57a316a0-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.663338ms
Feb 20 18:14:22.244: INFO: Pod "pod-configmaps-57a316a0-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084110638s
STEP: Saw pod success
Feb 20 18:14:22.244: INFO: Pod "pod-configmaps-57a316a0-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:14:22.285: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-57a316a0-353b-11e9-96fe-8e2b2e6369d7 container env-test: <nil>
STEP: delete the pod
Feb 20 18:14:22.377: INFO: Waiting for pod pod-configmaps-57a316a0-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:14:22.419: INFO: Pod pod-configmaps-57a316a0-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:14:22.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tv5rn" for this suite.
Feb 20 18:14:28.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:14:29.547: INFO: namespace: e2e-tests-configmap-tv5rn, resource: bindings, ignored listing per whitelist
Feb 20 18:14:30.241: INFO: namespace e2e-tests-configmap-tv5rn deletion completed in 7.779443333s

• [SLOW TEST:11.916 seconds]
[sig-node] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:14:30.241: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-d859w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-sbmn
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 18:14:32.091: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sbmn" in namespace "e2e-tests-subpath-d859w" to be "success or failure"
Feb 20 18:14:32.134: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Pending", Reason="", readiness=false. Elapsed: 42.709083ms
Feb 20 18:14:34.176: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085128982s
Feb 20 18:14:36.220: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 4.128678206s
Feb 20 18:14:38.264: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 6.172479794s
Feb 20 18:14:40.306: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 8.215116477s
Feb 20 18:14:42.349: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 10.257577074s
Feb 20 18:14:44.394: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 12.302434306s
Feb 20 18:14:46.440: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 14.348591689s
Feb 20 18:14:48.482: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 16.39108075s
Feb 20 18:14:50.525: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 18.433429528s
Feb 20 18:14:52.567: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 20.475988264s
Feb 20 18:14:54.610: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Running", Reason="", readiness=false. Elapsed: 22.518594949s
Feb 20 18:14:56.653: INFO: Pod "pod-subpath-test-configmap-sbmn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.561571925s
STEP: Saw pod success
Feb 20 18:14:56.653: INFO: Pod "pod-subpath-test-configmap-sbmn" satisfied condition "success or failure"
Feb 20 18:14:56.695: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-subpath-test-configmap-sbmn container test-container-subpath-configmap-sbmn: <nil>
STEP: delete the pod
Feb 20 18:14:56.788: INFO: Waiting for pod pod-subpath-test-configmap-sbmn to disappear
Feb 20 18:14:56.831: INFO: Pod pod-subpath-test-configmap-sbmn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-sbmn
Feb 20 18:14:56.831: INFO: Deleting pod "pod-subpath-test-configmap-sbmn" in namespace "e2e-tests-subpath-d859w"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:14:56.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-d859w" for this suite.
Feb 20 18:15:03.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:15:03.256: INFO: namespace: e2e-tests-subpath-d859w, resource: bindings, ignored listing per whitelist
Feb 20 18:15:04.644: INFO: namespace e2e-tests-subpath-d859w deletion completed in 7.728469925s

• [SLOW TEST:34.403 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:15:04.644: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2vdwz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7333bf32-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 18:15:06.449: INFO: Waiting up to 5m0s for pod "pod-configmaps-733a24ce-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-2vdwz" to be "success or failure"
Feb 20 18:15:06.491: INFO: Pod "pod-configmaps-733a24ce-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.836444ms
Feb 20 18:15:08.533: INFO: Pod "pod-configmaps-733a24ce-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084616872s
STEP: Saw pod success
Feb 20 18:15:08.533: INFO: Pod "pod-configmaps-733a24ce-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:15:08.576: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-733a24ce-353b-11e9-96fe-8e2b2e6369d7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:15:08.670: INFO: Waiting for pod pod-configmaps-733a24ce-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:15:08.711: INFO: Pod pod-configmaps-733a24ce-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:15:08.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2vdwz" for this suite.
Feb 20 18:15:14.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:15:15.608: INFO: namespace: e2e-tests-configmap-2vdwz, resource: bindings, ignored listing per whitelist
Feb 20 18:15:16.499: INFO: namespace e2e-tests-configmap-2vdwz deletion completed in 7.744735686s

• [SLOW TEST:11.854 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:15:16.499: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6n62l
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7a449bd1-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating secret with name s-test-opt-upd-7a449c14-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7a449bd1-353b-11e9-96fe-8e2b2e6369d7
STEP: Updating secret s-test-opt-upd-7a449c14-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating secret with name s-test-opt-create-7a449c2a-353b-11e9-96fe-8e2b2e6369d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:15:24.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6n62l" for this suite.
Feb 20 18:15:47.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:15:47.745: INFO: namespace: e2e-tests-secrets-6n62l, resource: bindings, ignored listing per whitelist
Feb 20 18:15:48.805: INFO: namespace e2e-tests-secrets-6n62l deletion completed in 23.776415337s

• [SLOW TEST:32.307 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:15:48.805: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2vcgz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:15:50.561: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml version'
Feb 20 18:15:50.864: INFO: stderr: ""
Feb 20 18:15:50.864: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"archive\", BuildDate:\"2019-02-20T18:08:14Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:15:50.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2vcgz" for this suite.
Feb 20 18:15:57.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:15:57.204: INFO: namespace: e2e-tests-kubectl-2vcgz, resource: bindings, ignored listing per whitelist
Feb 20 18:15:58.630: INFO: namespace e2e-tests-kubectl-2vcgz deletion completed in 7.723388488s

• [SLOW TEST:9.825 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:15:58.630: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-7jzsw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-7jzsw
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-7jzsw
STEP: Deleting pre-stop pod
Feb 20 18:16:11.931: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:16:11.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-7jzsw" for this suite.
Feb 20 18:16:52.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:16:52.940: INFO: namespace: e2e-tests-prestop-7jzsw, resource: bindings, ignored listing per whitelist
Feb 20 18:16:53.738: INFO: namespace e2e-tests-prestop-7jzsw deletion completed in 41.720661477s

• [SLOW TEST:55.108 seconds]
[k8s.io] [sig-node] PreStop
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:16:53.738: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-zxt8z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b43bd255-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 18:16:55.553: INFO: Waiting up to 5m0s for pod "pod-secrets-b44240e3-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-zxt8z" to be "success or failure"
Feb 20 18:16:55.595: INFO: Pod "pod-secrets-b44240e3-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.815468ms
Feb 20 18:16:57.637: INFO: Pod "pod-secrets-b44240e3-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084252846s
STEP: Saw pod success
Feb 20 18:16:57.637: INFO: Pod "pod-secrets-b44240e3-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:16:57.679: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-secrets-b44240e3-353b-11e9-96fe-8e2b2e6369d7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:16:57.773: INFO: Waiting for pod pod-secrets-b44240e3-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:16:57.815: INFO: Pod pod-secrets-b44240e3-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:16:57.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zxt8z" for this suite.
Feb 20 18:17:03.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:17:04.535: INFO: namespace: e2e-tests-secrets-zxt8z, resource: bindings, ignored listing per whitelist
Feb 20 18:17:05.584: INFO: namespace e2e-tests-secrets-zxt8z deletion completed in 7.726435391s

• [SLOW TEST:11.846 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:17:05.584: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-cnhhs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 20 18:17:07.307: INFO: Waiting up to 5m0s for pod "var-expansion-bb43c98f-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-var-expansion-cnhhs" to be "success or failure"
Feb 20 18:17:07.349: INFO: Pod "var-expansion-bb43c98f-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.885231ms
Feb 20 18:17:09.392: INFO: Pod "var-expansion-bb43c98f-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084592393s
STEP: Saw pod success
Feb 20 18:17:09.392: INFO: Pod "var-expansion-bb43c98f-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:17:09.434: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod var-expansion-bb43c98f-353b-11e9-96fe-8e2b2e6369d7 container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:17:09.526: INFO: Waiting for pod var-expansion-bb43c98f-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:17:09.567: INFO: Pod var-expansion-bb43c98f-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:17:09.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-cnhhs" for this suite.
Feb 20 18:17:15.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:17:17.232: INFO: namespace: e2e-tests-var-expansion-cnhhs, resource: bindings, ignored listing per whitelist
Feb 20 18:17:17.402: INFO: namespace e2e-tests-var-expansion-cnhhs deletion completed in 7.791571621s

• [SLOW TEST:11.818 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:17:17.402: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-8slrz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8slrz
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 20 18:17:19.287: INFO: Found 1 stateful pods, waiting for 3
Feb 20 18:17:29.330: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:17:29.330: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:17:29.330: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 20 18:17:29.552: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 20 18:17:29.788: INFO: Updating stateful set ss2
Feb 20 18:17:29.873: INFO: Waiting for Pod e2e-tests-statefulset-8slrz/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 20 18:17:39.958: INFO: Waiting for Pod e2e-tests-statefulset-8slrz/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 20 18:17:50.089: INFO: Found 2 stateful pods, waiting for 3
Feb 20 18:18:00.132: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:18:00.132: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:18:00.132: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 20 18:18:00.364: INFO: Updating stateful set ss2
Feb 20 18:18:00.448: INFO: Waiting for Pod e2e-tests-statefulset-8slrz/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 20 18:18:10.628: INFO: Updating stateful set ss2
Feb 20 18:18:10.713: INFO: Waiting for StatefulSet e2e-tests-statefulset-8slrz/ss2 to complete update
Feb 20 18:18:10.713: INFO: Waiting for Pod e2e-tests-statefulset-8slrz/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 18:18:20.798: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8slrz
Feb 20 18:18:20.840: INFO: Scaling statefulset ss2 to 0
Feb 20 18:18:41.010: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:18:41.052: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:18:41.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8slrz" for this suite.
Feb 20 18:18:47.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:18:48.827: INFO: namespace: e2e-tests-statefulset-8slrz, resource: bindings, ignored listing per whitelist
Feb 20 18:18:48.994: INFO: namespace e2e-tests-statefulset-8slrz deletion completed in 7.759528604s

• [SLOW TEST:91.592 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:18:48.994: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-652hx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:18:50.708: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8e58d07-353b-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-652hx" to be "success or failure"
Feb 20 18:18:50.751: INFO: Pod "downwardapi-volume-f8e58d07-353b-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.232994ms
Feb 20 18:18:52.793: INFO: Pod "downwardapi-volume-f8e58d07-353b-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084787614s
STEP: Saw pod success
Feb 20 18:18:52.793: INFO: Pod "downwardapi-volume-f8e58d07-353b-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:18:52.835: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-f8e58d07-353b-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 18:18:52.928: INFO: Waiting for pod downwardapi-volume-f8e58d07-353b-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:18:52.970: INFO: Pod downwardapi-volume-f8e58d07-353b-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:18:52.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-652hx" for this suite.
Feb 20 18:18:59.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:18:59.642: INFO: namespace: e2e-tests-projected-652hx, resource: bindings, ignored listing per whitelist
Feb 20 18:19:00.774: INFO: namespace e2e-tests-projected-652hx deletion completed in 7.761852417s

• [SLOW TEST:11.780 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:19:00.774: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-588sx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-vtv8v
STEP: Creating secret with name secret-test-ffed3bea-353b-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 18:19:02.855: INFO: Waiting up to 5m0s for pod "pod-secrets-002306ae-353c-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-588sx" to be "success or failure"
Feb 20 18:19:02.898: INFO: Pod "pod-secrets-002306ae-353c-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.288003ms
Feb 20 18:19:04.940: INFO: Pod "pod-secrets-002306ae-353c-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084963885s
STEP: Saw pod success
Feb 20 18:19:04.940: INFO: Pod "pod-secrets-002306ae-353c-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:19:04.982: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-secrets-002306ae-353c-11e9-96fe-8e2b2e6369d7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:19:05.078: INFO: Waiting for pod pod-secrets-002306ae-353c-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:19:05.120: INFO: Pod pod-secrets-002306ae-353c-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:19:05.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-588sx" for this suite.
Feb 20 18:19:11.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:19:12.638: INFO: namespace: e2e-tests-secrets-588sx, resource: bindings, ignored listing per whitelist
Feb 20 18:19:12.931: INFO: namespace e2e-tests-secrets-588sx deletion completed in 7.768492311s
STEP: Destroying namespace "e2e-tests-secret-namespace-vtv8v" for this suite.
Feb 20 18:19:19.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:19:19.691: INFO: namespace: e2e-tests-secret-namespace-vtv8v, resource: bindings, ignored listing per whitelist
Feb 20 18:19:20.699: INFO: namespace e2e-tests-secret-namespace-vtv8v deletion completed in 7.767866127s

• [SLOW TEST:19.925 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:19:20.700: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-dfpr8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0220 18:19:28.675030   30217 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 18:19:28.675: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:19:28.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-dfpr8" for this suite.
Feb 20 18:19:34.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:19:35.264: INFO: namespace: e2e-tests-gc-dfpr8, resource: bindings, ignored listing per whitelist
Feb 20 18:19:36.436: INFO: namespace e2e-tests-gc-dfpr8 deletion completed in 7.719031686s

• [SLOW TEST:15.736 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:19:36.436: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ndbnm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 20 18:19:41.011: INFO: Successfully updated pod "annotationupdate15354263-353c-11e9-96fe-8e2b2e6369d7"
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:19:43.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ndbnm" for this suite.
Feb 20 18:20:05.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:20:06.372: INFO: namespace: e2e-tests-projected-ndbnm, resource: bindings, ignored listing per whitelist
Feb 20 18:20:06.919: INFO: namespace e2e-tests-projected-ndbnm deletion completed in 23.766366434s

• [SLOW TEST:30.483 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:20:06.919: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qcs57
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:20:08.707: INFO: Waiting up to 5m0s for pod "downwardapi-volume-27632ccf-353c-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-qcs57" to be "success or failure"
Feb 20 18:20:08.749: INFO: Pod "downwardapi-volume-27632ccf-353c-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.006794ms
Feb 20 18:20:10.792: INFO: Pod "downwardapi-volume-27632ccf-353c-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084692873s
STEP: Saw pod success
Feb 20 18:20:10.792: INFO: Pod "downwardapi-volume-27632ccf-353c-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:20:10.834: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-27632ccf-353c-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 18:20:10.927: INFO: Waiting for pod downwardapi-volume-27632ccf-353c-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:20:10.969: INFO: Pod downwardapi-volume-27632ccf-353c-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:20:10.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qcs57" for this suite.
Feb 20 18:20:17.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:20:17.690: INFO: namespace: e2e-tests-downward-api-qcs57, resource: bindings, ignored listing per whitelist
Feb 20 18:20:18.743: INFO: namespace e2e-tests-downward-api-qcs57 deletion completed in 7.731761092s

• [SLOW TEST:11.824 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:20:18.743: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-xkhnt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 20 18:20:20.457: INFO: PodSpec: initContainers in spec.initContainers
Feb 20 18:21:09.151: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-2e6ae342-353c-11e9-96fe-8e2b2e6369d7", GenerateName:"", Namespace:"e2e-tests-init-container-xkhnt", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-xkhnt/pods/pod-init-2e6ae342-353c-11e9-96fe-8e2b2e6369d7", UID:"2e6d7f48-353c-11e9-a8b6-5a3f4013d0a1", ResourceVersion:"4574", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686283620, loc:(*time.Location)(0x791ea40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"457805750"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.36/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-dsjc6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001c96000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dsjc6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dsjc6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dsjc6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001c9c098), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-250-0-144.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001d22840), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001c9c110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001c9c130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001c9c138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001c9c13c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686283620, loc:(*time.Location)(0x791ea40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686283620, loc:(*time.Location)(0x791ea40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686283620, loc:(*time.Location)(0x791ea40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686283620, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.144", PodIP:"100.96.1.36", StartTime:(*v1.Time)(0xc001c9e040), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0005a8b60)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0005a8c40)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://f462c565533721c153b63b7ee7d6b353b37b1546798c161c08f3750da4747313"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001c9e080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001c9e060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:21:09.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xkhnt" for this suite.
Feb 20 18:21:31.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:21:32.735: INFO: namespace: e2e-tests-init-container-xkhnt, resource: bindings, ignored listing per whitelist
Feb 20 18:21:32.985: INFO: namespace e2e-tests-init-container-xkhnt deletion completed in 23.791572897s

• [SLOW TEST:74.242 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:21:32.985: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-g7dkp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:21:34.976: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 18:21:35.103: INFO: Number of nodes with available pods: 0
Feb 20 18:21:35.103: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:21:36.188: INFO: Number of nodes with available pods: 0
Feb 20 18:21:36.188: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:21:37.188: INFO: Number of nodes with available pods: 0
Feb 20 18:21:37.188: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:21:38.187: INFO: Number of nodes with available pods: 1
Feb 20 18:21:38.187: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:21:39.188: INFO: Number of nodes with available pods: 2
Feb 20 18:21:39.188: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 20 18:21:39.442: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:39.442: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:40.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:40.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:41.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:41.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:42.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:42.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:43.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:43.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:44.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:44.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:45.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:45.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:46.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:46.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:47.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:47.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:48.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:48.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:49.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:49.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:50.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:50.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:51.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:51.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:52.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:52.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:53.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:53.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:54.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:54.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:55.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:55.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:56.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:56.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:57.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:57.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:58.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:58.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:59.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:21:59.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:00.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:00.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:01.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:01.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:02.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:02.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:03.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:03.526: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:04.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:04.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:05.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:05.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:06.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:06.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:07.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:07.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:08.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:08.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:09.534: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:09.534: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:10.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:10.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:11.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:11.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:11.527: INFO: Pod daemon-set-fwwff is not available
Feb 20 18:22:12.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:12.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:12.527: INFO: Pod daemon-set-fwwff is not available
Feb 20 18:22:13.535: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:13.535: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:13.535: INFO: Pod daemon-set-fwwff is not available
Feb 20 18:22:14.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:14.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:14.527: INFO: Pod daemon-set-fwwff is not available
Feb 20 18:22:15.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:15.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:15.527: INFO: Pod daemon-set-fwwff is not available
Feb 20 18:22:16.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:16.527: INFO: Wrong image for pod: daemon-set-fwwff. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:16.527: INFO: Pod daemon-set-fwwff is not available
Feb 20 18:22:17.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:17.526: INFO: Pod daemon-set-k24fq is not available
Feb 20 18:22:18.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:18.526: INFO: Pod daemon-set-k24fq is not available
Feb 20 18:22:19.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:19.527: INFO: Pod daemon-set-k24fq is not available
Feb 20 18:22:20.532: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:21.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:22.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:23.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:24.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:25.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:26.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:27.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:28.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:29.528: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:30.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:31.528: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:32.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:33.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:34.534: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:35.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:36.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:37.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:38.529: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:39.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:40.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:41.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:42.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:43.531: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:44.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:45.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:46.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:47.531: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:48.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:49.526: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:50.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:51.527: INFO: Wrong image for pod: daemon-set-ftf9r. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:22:51.527: INFO: Pod daemon-set-ftf9r is not available
Feb 20 18:22:52.527: INFO: Pod daemon-set-gnwqw is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 20 18:22:52.654: INFO: Number of nodes with available pods: 1
Feb 20 18:22:52.654: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:22:53.739: INFO: Number of nodes with available pods: 1
Feb 20 18:22:53.739: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:22:54.739: INFO: Number of nodes with available pods: 1
Feb 20 18:22:54.739: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:22:55.739: INFO: Number of nodes with available pods: 2
Feb 20 18:22:55.739: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-g7dkp, will wait for the garbage collector to delete the pods
Feb 20 18:22:56.087: INFO: Deleting DaemonSet.extensions daemon-set took: 43.551096ms
Feb 20 18:22:56.187: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.263122ms
Feb 20 18:23:01.429: INFO: Number of nodes with available pods: 0
Feb 20 18:23:01.429: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 18:23:01.472: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-g7dkp/daemonsets","resourceVersion":"4850"},"items":null}

Feb 20 18:23:01.515: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-g7dkp/pods","resourceVersion":"4850"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:23:01.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-g7dkp" for this suite.
Feb 20 18:23:07.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:07.939: INFO: namespace: e2e-tests-daemonsets-g7dkp, resource: bindings, ignored listing per whitelist
Feb 20 18:23:09.405: INFO: namespace e2e-tests-daemonsets-g7dkp deletion completed in 7.7211627s

• [SLOW TEST:96.420 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:23:09.405: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lg99z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:23:11.120: INFO: Waiting up to 5m0s for pod "downwardapi-volume-941d244d-353c-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-lg99z" to be "success or failure"
Feb 20 18:23:11.162: INFO: Pod "downwardapi-volume-941d244d-353c-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.407441ms
Feb 20 18:23:13.204: INFO: Pod "downwardapi-volume-941d244d-353c-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084649425s
STEP: Saw pod success
Feb 20 18:23:13.204: INFO: Pod "downwardapi-volume-941d244d-353c-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:23:13.247: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-941d244d-353c-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 18:23:13.340: INFO: Waiting for pod downwardapi-volume-941d244d-353c-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:23:13.382: INFO: Pod downwardapi-volume-941d244d-353c-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:23:13.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lg99z" for this suite.
Feb 20 18:23:19.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:20.982: INFO: namespace: e2e-tests-projected-lg99z, resource: bindings, ignored listing per whitelist
Feb 20 18:23:21.150: INFO: namespace e2e-tests-projected-lg99z deletion completed in 7.725577338s

• [SLOW TEST:11.745 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:23:21.150: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7vcpn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9b2385b0-353c-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 18:23:22.948: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b29ed34-353c-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-7vcpn" to be "success or failure"
Feb 20 18:23:22.990: INFO: Pod "pod-configmaps-9b29ed34-353c-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011217ms
Feb 20 18:23:25.032: INFO: Pod "pod-configmaps-9b29ed34-353c-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084626762s
STEP: Saw pod success
Feb 20 18:23:25.032: INFO: Pod "pod-configmaps-9b29ed34-353c-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:23:25.074: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-9b29ed34-353c-11e9-96fe-8e2b2e6369d7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:23:25.173: INFO: Waiting for pod pod-configmaps-9b29ed34-353c-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:23:25.215: INFO: Pod pod-configmaps-9b29ed34-353c-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:23:25.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7vcpn" for this suite.
Feb 20 18:23:31.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:32.815: INFO: namespace: e2e-tests-configmap-7vcpn, resource: bindings, ignored listing per whitelist
Feb 20 18:23:33.024: INFO: namespace e2e-tests-configmap-7vcpn deletion completed in 7.765537056s

• [SLOW TEST:11.874 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:23:33.024: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lx262
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 20 18:23:34.760: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml api-versions'
Feb 20 18:23:35.146: INFO: stderr: ""
Feb 20 18:23:35.146: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:23:35.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lx262" for this suite.
Feb 20 18:23:41.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:42.535: INFO: namespace: e2e-tests-kubectl-lx262, resource: bindings, ignored listing per whitelist
Feb 20 18:23:42.912: INFO: namespace e2e-tests-kubectl-lx262 deletion completed in 7.723442365s

• [SLOW TEST:9.888 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:23:42.912: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-b2h6b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a8168a23-353c-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 18:23:44.673: INFO: Waiting up to 5m0s for pod "pod-secrets-a81cf498-353c-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-b2h6b" to be "success or failure"
Feb 20 18:23:44.715: INFO: Pod "pod-secrets-a81cf498-353c-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.160519ms
Feb 20 18:23:46.758: INFO: Pod "pod-secrets-a81cf498-353c-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084952734s
STEP: Saw pod success
Feb 20 18:23:46.758: INFO: Pod "pod-secrets-a81cf498-353c-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:23:46.799: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-secrets-a81cf498-353c-11e9-96fe-8e2b2e6369d7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:23:46.892: INFO: Waiting for pod pod-secrets-a81cf498-353c-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:23:46.934: INFO: Pod pod-secrets-a81cf498-353c-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:23:46.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-b2h6b" for this suite.
Feb 20 18:23:53.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:53.609: INFO: namespace: e2e-tests-secrets-b2h6b, resource: bindings, ignored listing per whitelist
Feb 20 18:23:54.698: INFO: namespace e2e-tests-secrets-b2h6b deletion completed in 7.721790053s

• [SLOW TEST:11.786 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:23:54.699: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-hxkkw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 20 18:24:02.820: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:24:02.862: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 18:24:04.863: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:24:04.905: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 18:24:06.863: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:24:06.905: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 18:24:08.863: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:24:08.905: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 18:24:10.863: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:24:10.905: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 18:24:12.863: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:24:12.905: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:24:12.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hxkkw" for this suite.
Feb 20 18:24:35.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:24:35.876: INFO: namespace: e2e-tests-container-lifecycle-hook-hxkkw, resource: bindings, ignored listing per whitelist
Feb 20 18:24:36.678: INFO: namespace e2e-tests-container-lifecycle-hook-hxkkw deletion completed in 23.731141204s

• [SLOW TEST:41.980 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:24:36.679: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9zhz8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:24:38.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8278e62-353c-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-9zhz8" to be "success or failure"
Feb 20 18:24:38.471: INFO: Pod "downwardapi-volume-c8278e62-353c-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.871557ms
Feb 20 18:24:40.514: INFO: Pod "downwardapi-volume-c8278e62-353c-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08471273s
STEP: Saw pod success
Feb 20 18:24:40.514: INFO: Pod "downwardapi-volume-c8278e62-353c-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:24:40.556: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-c8278e62-353c-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 18:24:40.648: INFO: Waiting for pod downwardapi-volume-c8278e62-353c-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:24:40.690: INFO: Pod downwardapi-volume-c8278e62-353c-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:24:40.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9zhz8" for this suite.
Feb 20 18:24:46.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:24:47.123: INFO: namespace: e2e-tests-downward-api-9zhz8, resource: bindings, ignored listing per whitelist
Feb 20 18:24:48.470: INFO: namespace e2e-tests-downward-api-9zhz8 deletion completed in 7.737612386s

• [SLOW TEST:11.792 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:24:48.471: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sgd8w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:24:50.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf2da27e-353c-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-sgd8w" to be "success or failure"
Feb 20 18:24:50.255: INFO: Pod "downwardapi-volume-cf2da27e-353c-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.954682ms
Feb 20 18:24:52.298: INFO: Pod "downwardapi-volume-cf2da27e-353c-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084696904s
STEP: Saw pod success
Feb 20 18:24:52.298: INFO: Pod "downwardapi-volume-cf2da27e-353c-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:24:52.340: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-cf2da27e-353c-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 18:24:52.434: INFO: Waiting for pod downwardapi-volume-cf2da27e-353c-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:24:52.476: INFO: Pod downwardapi-volume-cf2da27e-353c-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:24:52.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sgd8w" for this suite.
Feb 20 18:24:58.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:24:59.991: INFO: namespace: e2e-tests-projected-sgd8w, resource: bindings, ignored listing per whitelist
Feb 20 18:25:00.251: INFO: namespace e2e-tests-projected-sgd8w deletion completed in 7.732489279s

• [SLOW TEST:11.780 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:25:00.252: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hcpx5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 20 18:25:04.768: INFO: Successfully updated pod "labelsupdated6356a2e-353c-11e9-96fe-8e2b2e6369d7"
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:25:08.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hcpx5" for this suite.
Feb 20 18:25:31.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:25:31.374: INFO: namespace: e2e-tests-projected-hcpx5, resource: bindings, ignored listing per whitelist
Feb 20 18:25:32.677: INFO: namespace e2e-tests-projected-hcpx5 deletion completed in 23.722665913s

• [SLOW TEST:32.426 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:25:32.678: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-gc2cb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:25:34.455: INFO: (0) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.674769ms)
Feb 20 18:25:34.499: INFO: (1) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.503483ms)
Feb 20 18:25:34.543: INFO: (2) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.758172ms)
Feb 20 18:25:34.587: INFO: (3) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.022856ms)
Feb 20 18:25:34.631: INFO: (4) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.934782ms)
Feb 20 18:25:34.675: INFO: (5) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.820185ms)
Feb 20 18:25:34.719: INFO: (6) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.781879ms)
Feb 20 18:25:34.763: INFO: (7) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.245769ms)
Feb 20 18:25:34.807: INFO: (8) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.691419ms)
Feb 20 18:25:34.851: INFO: (9) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.020505ms)
Feb 20 18:25:34.895: INFO: (10) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.905134ms)
Feb 20 18:25:34.940: INFO: (11) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.50901ms)
Feb 20 18:25:34.983: INFO: (12) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.471235ms)
Feb 20 18:25:35.027: INFO: (13) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.806282ms)
Feb 20 18:25:35.071: INFO: (14) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.695376ms)
Feb 20 18:25:35.117: INFO: (15) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.844936ms)
Feb 20 18:25:35.163: INFO: (16) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.342011ms)
Feb 20 18:25:35.208: INFO: (17) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.596123ms)
Feb 20 18:25:35.252: INFO: (18) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.034463ms)
Feb 20 18:25:35.295: INFO: (19) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.409314ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:25:35.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-gc2cb" for this suite.
Feb 20 18:25:41.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:25:42.098: INFO: namespace: e2e-tests-proxy-gc2cb, resource: bindings, ignored listing per whitelist
Feb 20 18:25:43.061: INFO: namespace e2e-tests-proxy-gc2cb deletion completed in 7.723044816s

• [SLOW TEST:10.384 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:25:43.062: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jvplk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 20 18:25:44.782: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:25:47.287: INFO: stderr: ""
Feb 20 18:25:47.287: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 18:25:47.287: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:25:47.569: INFO: stderr: ""
Feb 20 18:25:47.569: INFO: stdout: "update-demo-nautilus-rkjcl update-demo-nautilus-wm6vt "
Feb 20 18:25:47.569: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-rkjcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:25:47.811: INFO: stderr: ""
Feb 20 18:25:47.811: INFO: stdout: ""
Feb 20 18:25:47.811: INFO: update-demo-nautilus-rkjcl is created but not running
Feb 20 18:25:52.811: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:25:53.054: INFO: stderr: ""
Feb 20 18:25:53.055: INFO: stdout: "update-demo-nautilus-rkjcl update-demo-nautilus-wm6vt "
Feb 20 18:25:53.055: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-rkjcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:25:53.285: INFO: stderr: ""
Feb 20 18:25:53.285: INFO: stdout: "true"
Feb 20 18:25:53.285: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-rkjcl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:25:53.545: INFO: stderr: ""
Feb 20 18:25:53.545: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:25:53.545: INFO: validating pod update-demo-nautilus-rkjcl
Feb 20 18:25:53.678: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:25:53.678: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:25:53.678: INFO: update-demo-nautilus-rkjcl is verified up and running
Feb 20 18:25:53.678: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-wm6vt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:25:53.906: INFO: stderr: ""
Feb 20 18:25:53.906: INFO: stdout: "true"
Feb 20 18:25:53.906: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-wm6vt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:25:54.135: INFO: stderr: ""
Feb 20 18:25:54.135: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:25:54.135: INFO: validating pod update-demo-nautilus-wm6vt
Feb 20 18:25:54.266: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:25:54.266: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:25:54.266: INFO: update-demo-nautilus-wm6vt is verified up and running
STEP: rolling-update to new replication controller
Feb 20 18:25:54.271: INFO: scanned /root for discovery docs: <nil>
Feb 20 18:25:54.271: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:26:10.495: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 20 18:26:10.495: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 18:26:10.495: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:26:10.740: INFO: stderr: ""
Feb 20 18:26:10.740: INFO: stdout: "update-demo-kitten-r9g62 update-demo-kitten-vq54c update-demo-nautilus-wm6vt "
STEP: Replicas for name=update-demo: expected=2 actual=3
Feb 20 18:26:15.741: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:26:16.131: INFO: stderr: ""
Feb 20 18:26:16.131: INFO: stdout: "update-demo-kitten-r9g62 update-demo-kitten-vq54c "
Feb 20 18:26:16.131: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-kitten-r9g62 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:26:16.380: INFO: stderr: ""
Feb 20 18:26:16.380: INFO: stdout: "true"
Feb 20 18:26:16.381: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-kitten-r9g62 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:26:16.675: INFO: stderr: ""
Feb 20 18:26:16.675: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 20 18:26:16.675: INFO: validating pod update-demo-kitten-r9g62
Feb 20 18:26:16.805: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 20 18:26:16.805: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 20 18:26:16.805: INFO: update-demo-kitten-r9g62 is verified up and running
Feb 20 18:26:16.805: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-kitten-vq54c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:26:17.071: INFO: stderr: ""
Feb 20 18:26:17.072: INFO: stdout: "true"
Feb 20 18:26:17.072: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-kitten-vq54c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jvplk'
Feb 20 18:26:17.323: INFO: stderr: ""
Feb 20 18:26:17.323: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 20 18:26:17.323: INFO: validating pod update-demo-kitten-vq54c
Feb 20 18:26:17.454: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 20 18:26:17.454: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 20 18:26:17.454: INFO: update-demo-kitten-vq54c is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:26:17.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jvplk" for this suite.
Feb 20 18:26:39.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:26:40.714: INFO: namespace: e2e-tests-kubectl-jvplk, resource: bindings, ignored listing per whitelist
Feb 20 18:26:41.263: INFO: namespace e2e-tests-kubectl-jvplk deletion completed in 23.766432656s

• [SLOW TEST:58.201 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:26:41.263: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-crdbp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 20 18:26:43.008: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-crdbp" to be "success or failure"
Feb 20 18:26:43.051: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 42.2046ms
Feb 20 18:26:45.093: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084918039s
STEP: Saw pod success
Feb 20 18:26:45.093: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 20 18:26:45.137: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 20 18:26:45.237: INFO: Waiting for pod pod-host-path-test to disappear
Feb 20 18:26:45.278: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:26:45.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-crdbp" for this suite.
Feb 20 18:26:51.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:26:52.246: INFO: namespace: e2e-tests-hostpath-crdbp, resource: bindings, ignored listing per whitelist
Feb 20 18:26:53.042: INFO: namespace e2e-tests-hostpath-crdbp deletion completed in 7.720532138s

• [SLOW TEST:11.779 seconds]
[sig-storage] HostPath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:26:53.042: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-8vbjr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8vbjr
[It] Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-8vbjr
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-8vbjr
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-8vbjr
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-8vbjr
Feb 20 18:26:57.057: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8vbjr, name: ss-0, uid: 1ac7b4f8-353d-11e9-a8b6-5a3f4013d0a1, status phase: Failed. Waiting for statefulset controller to delete.
Feb 20 18:26:57.131: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8vbjr, name: ss-0, uid: 1ac7b4f8-353d-11e9-a8b6-5a3f4013d0a1, status phase: Failed. Waiting for statefulset controller to delete.
Feb 20 18:26:57.132: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-8vbjr
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-8vbjr
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-8vbjr and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 18:26:59.260: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8vbjr
Feb 20 18:26:59.302: INFO: Scaling statefulset ss to 0
Feb 20 18:27:19.471: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:27:19.514: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:27:19.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8vbjr" for this suite.
Feb 20 18:27:25.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:27:27.033: INFO: namespace: e2e-tests-statefulset-8vbjr, resource: bindings, ignored listing per whitelist
Feb 20 18:27:27.409: INFO: namespace e2e-tests-statefulset-8vbjr deletion completed in 7.724617169s

• [SLOW TEST:34.367 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:27:27.409: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-wbkm2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 20 18:27:33.505: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:33.505: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:34.040: INFO: Exec stderr: ""
Feb 20 18:27:34.040: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:34.040: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:34.661: INFO: Exec stderr: ""
Feb 20 18:27:34.661: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:34.661: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:35.298: INFO: Exec stderr: ""
Feb 20 18:27:35.298: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:35.298: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:35.954: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 20 18:27:35.954: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:35.954: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:36.553: INFO: Exec stderr: ""
Feb 20 18:27:36.553: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:36.553: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:37.151: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 20 18:27:37.151: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:37.151: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:37.730: INFO: Exec stderr: ""
Feb 20 18:27:37.730: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:37.730: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:38.327: INFO: Exec stderr: ""
Feb 20 18:27:38.327: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:38.327: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:38.990: INFO: Exec stderr: ""
Feb 20 18:27:38.990: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wbkm2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:27:38.990: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:27:39.584: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:27:39.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-wbkm2" for this suite.
Feb 20 18:28:23.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:28:24.342: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-wbkm2, resource: bindings, ignored listing per whitelist
Feb 20 18:28:25.352: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-wbkm2 deletion completed in 45.725551553s

• [SLOW TEST:57.944 seconds]
[k8s.io] KubeletManagedEtcHosts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:28:25.353: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8q5t9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:28:27.063: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8q5t9'
Feb 20 18:28:27.425: INFO: stderr: ""
Feb 20 18:28:27.425: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 20 18:28:32.475: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8q5t9 -o json'
Feb 20 18:28:32.712: INFO: stderr: ""
Feb 20 18:28:32.712: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.1.53/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-02-20T18:28:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-8q5t9\",\n        \"resourceVersion\": \"5908\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-8q5t9/pods/e2e-test-nginx-pod\",\n        \"uid\": \"50a739ab-353d-11e9-a8b6-5a3f4013d0a1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-pm6cg\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-250-0-144.eu-west-1.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-pm6cg\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-pm6cg\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-20T18:28:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-20T18:28:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-20T18:28:28Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-20T18:28:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://fb46c410ebb7b2aede435eccb3b7fbbeed5eb3d51f52b9fc1cf9ae2f0877c786\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-20T18:28:28Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.144\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.53\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-20T18:28:27Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 20 18:28:32.712: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml replace -f - --namespace=e2e-tests-kubectl-8q5t9'
Feb 20 18:28:33.116: INFO: stderr: ""
Feb 20 18:28:33.116: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb 20 18:28:33.158: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8q5t9'
Feb 20 18:28:41.316: INFO: stderr: ""
Feb 20 18:28:41.316: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:28:41.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8q5t9" for this suite.
Feb 20 18:28:47.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:28:48.243: INFO: namespace: e2e-tests-kubectl-8q5t9, resource: bindings, ignored listing per whitelist
Feb 20 18:28:49.082: INFO: namespace e2e-tests-kubectl-8q5t9 deletion completed in 7.722827297s

• [SLOW TEST:23.730 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:28:49.083: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7hbtx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 20 18:28:50.805: INFO: Waiting up to 5m0s for pod "pod-5e9524b8-353d-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-7hbtx" to be "success or failure"
Feb 20 18:28:50.847: INFO: Pod "pod-5e9524b8-353d-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.871352ms
Feb 20 18:28:52.890: INFO: Pod "pod-5e9524b8-353d-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084871311s
STEP: Saw pod success
Feb 20 18:28:52.890: INFO: Pod "pod-5e9524b8-353d-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:28:52.932: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-5e9524b8-353d-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 18:28:53.028: INFO: Waiting for pod pod-5e9524b8-353d-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:28:53.070: INFO: Pod pod-5e9524b8-353d-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:28:53.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7hbtx" for this suite.
Feb 20 18:28:59.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:28:59.452: INFO: namespace: e2e-tests-emptydir-7hbtx, resource: bindings, ignored listing per whitelist
Feb 20 18:29:00.837: INFO: namespace e2e-tests-emptydir-7hbtx deletion completed in 7.724153212s

• [SLOW TEST:11.754 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:29:00.837: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-w5lcz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-w5lcz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 18:29:02.560: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 18:29:25.323: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.96.1.55 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-w5lcz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:29:25.323: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:29:26.947: INFO: Found all expected endpoints: [netserver-0]
Feb 20 18:29:26.989: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.96.0.20 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-w5lcz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:29:26.989: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:29:28.636: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:29:28.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-w5lcz" for this suite.
Feb 20 18:29:50.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:29:52.105: INFO: namespace: e2e-tests-pod-network-test-w5lcz, resource: bindings, ignored listing per whitelist
Feb 20 18:29:52.443: INFO: namespace e2e-tests-pod-network-test-w5lcz deletion completed in 23.764766521s

• [SLOW TEST:51.606 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:29:52.443: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-dllgw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:29:54.341: INFO: (0) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.794859ms)
Feb 20 18:29:54.385: INFO: (1) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.726521ms)
Feb 20 18:29:54.429: INFO: (2) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.970417ms)
Feb 20 18:29:54.473: INFO: (3) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.696709ms)
Feb 20 18:29:54.517: INFO: (4) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.211507ms)
Feb 20 18:29:54.561: INFO: (5) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.730814ms)
Feb 20 18:29:54.605: INFO: (6) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.906097ms)
Feb 20 18:29:54.649: INFO: (7) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.930186ms)
Feb 20 18:29:54.693: INFO: (8) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.000508ms)
Feb 20 18:29:54.737: INFO: (9) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.758029ms)
Feb 20 18:29:54.781: INFO: (10) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.934127ms)
Feb 20 18:29:54.825: INFO: (11) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.169009ms)
Feb 20 18:29:54.872: INFO: (12) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 47.28199ms)
Feb 20 18:29:54.919: INFO: (13) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 46.414684ms)
Feb 20 18:29:54.964: INFO: (14) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.035218ms)
Feb 20 18:29:55.012: INFO: (15) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 47.805032ms)
Feb 20 18:29:55.059: INFO: (16) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 47.416792ms)
Feb 20 18:29:55.112: INFO: (17) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 52.298637ms)
Feb 20 18:29:55.163: INFO: (18) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 51.728137ms)
Feb 20 18:29:55.211: INFO: (19) /api/v1/nodes/ip-10-250-0-144.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 48.076515ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:29:55.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-dllgw" for this suite.
Feb 20 18:30:01.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:30:02.416: INFO: namespace: e2e-tests-proxy-dllgw, resource: bindings, ignored listing per whitelist
Feb 20 18:30:03.049: INFO: namespace e2e-tests-proxy-dllgw deletion completed in 7.795038207s

• [SLOW TEST:10.606 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:30:03.050: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t8ccw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 20 18:30:04.767: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml --namespace=e2e-tests-kubectl-t8ccw run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 20 18:30:07.753: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 20 18:30:07.753: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:30:09.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t8ccw" for this suite.
Feb 20 18:30:16.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:30:16.857: INFO: namespace: e2e-tests-kubectl-t8ccw, resource: bindings, ignored listing per whitelist
Feb 20 18:30:17.612: INFO: namespace e2e-tests-kubectl-t8ccw deletion completed in 7.732535972s

• [SLOW TEST:14.563 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:30:17.613: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-b9qsk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 20 18:30:23.752: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:23.794: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:25.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:25.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:27.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:27.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:29.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:29.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:31.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:31.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:33.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:33.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:35.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:35.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:37.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:37.836: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:39.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:39.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:41.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:41.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:43.798: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:43.841: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:45.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:45.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:47.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:47.836: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:49.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:49.837: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 18:30:51.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 18:30:51.836: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:30:51.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-b9qsk" for this suite.
Feb 20 18:31:14.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:31:14.184: INFO: namespace: e2e-tests-container-lifecycle-hook-b9qsk, resource: bindings, ignored listing per whitelist
Feb 20 18:31:15.650: INFO: namespace e2e-tests-container-lifecycle-hook-b9qsk deletion completed in 23.723221066s

• [SLOW TEST:58.038 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:31:15.650: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fxx8z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b5f65e5e-353d-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 18:31:17.447: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b5fccf98-353d-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-fxx8z" to be "success or failure"
Feb 20 18:31:17.489: INFO: Pod "pod-projected-configmaps-b5fccf98-353d-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.01224ms
Feb 20 18:31:19.531: INFO: Pod "pod-projected-configmaps-b5fccf98-353d-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084092409s
STEP: Saw pod success
Feb 20 18:31:19.531: INFO: Pod "pod-projected-configmaps-b5fccf98-353d-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:31:19.573: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-configmaps-b5fccf98-353d-11e9-96fe-8e2b2e6369d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:31:19.665: INFO: Waiting for pod pod-projected-configmaps-b5fccf98-353d-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:31:19.707: INFO: Pod pod-projected-configmaps-b5fccf98-353d-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:31:19.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fxx8z" for this suite.
Feb 20 18:31:25.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:31:26.631: INFO: namespace: e2e-tests-projected-fxx8z, resource: bindings, ignored listing per whitelist
Feb 20 18:31:27.480: INFO: namespace e2e-tests-projected-fxx8z deletion completed in 7.729576338s

• [SLOW TEST:11.829 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:31:27.480: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vsmlg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 20 18:31:29.205: INFO: Waiting up to 5m0s for pod "pod-bcff0f6c-353d-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-vsmlg" to be "success or failure"
Feb 20 18:31:29.247: INFO: Pod "pod-bcff0f6c-353d-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.947436ms
Feb 20 18:31:31.290: INFO: Pod "pod-bcff0f6c-353d-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08478565s
STEP: Saw pod success
Feb 20 18:31:31.290: INFO: Pod "pod-bcff0f6c-353d-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:31:31.332: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-bcff0f6c-353d-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 18:31:31.424: INFO: Waiting for pod pod-bcff0f6c-353d-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:31:31.466: INFO: Pod pod-bcff0f6c-353d-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:31:31.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vsmlg" for this suite.
Feb 20 18:31:37.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:31:38.942: INFO: namespace: e2e-tests-emptydir-vsmlg, resource: bindings, ignored listing per whitelist
Feb 20 18:31:39.234: INFO: namespace e2e-tests-emptydir-vsmlg deletion completed in 7.72474999s

• [SLOW TEST:11.754 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:31:39.234: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-6xbxv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:31:45.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6xbxv" for this suite.
Feb 20 18:31:51.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:31:52.019: INFO: namespace: e2e-tests-kubelet-test-6xbxv, resource: bindings, ignored listing per whitelist
Feb 20 18:31:52.864: INFO: namespace e2e-tests-kubelet-test-6xbxv deletion completed in 7.726762702s

• [SLOW TEST:13.630 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:31:52.864: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-gxvn4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:31:54.608: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc232a60-353d-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-gxvn4" to be "success or failure"
Feb 20 18:31:54.650: INFO: Pod "downwardapi-volume-cc232a60-353d-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.954034ms
Feb 20 18:31:56.693: INFO: Pod "downwardapi-volume-cc232a60-353d-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085143728s
STEP: Saw pod success
Feb 20 18:31:56.693: INFO: Pod "downwardapi-volume-cc232a60-353d-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:31:56.735: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-cc232a60-353d-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 18:31:56.829: INFO: Waiting for pod downwardapi-volume-cc232a60-353d-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:31:56.871: INFO: Pod downwardapi-volume-cc232a60-353d-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:31:56.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gxvn4" for this suite.
Feb 20 18:32:03.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:03.797: INFO: namespace: e2e-tests-downward-api-gxvn4, resource: bindings, ignored listing per whitelist
Feb 20 18:32:04.679: INFO: namespace e2e-tests-downward-api-gxvn4 deletion completed in 7.765817143s

• [SLOW TEST:11.815 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:32:04.679: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-8xpq5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 20 18:32:07.073: INFO: created pod pod-service-account-defaultsa
Feb 20 18:32:07.073: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 20 18:32:07.115: INFO: created pod pod-service-account-mountsa
Feb 20 18:32:07.115: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 20 18:32:07.158: INFO: created pod pod-service-account-nomountsa
Feb 20 18:32:07.158: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 20 18:32:07.200: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 20 18:32:07.201: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 20 18:32:07.243: INFO: created pod pod-service-account-mountsa-mountspec
Feb 20 18:32:07.244: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 20 18:32:07.286: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 20 18:32:07.286: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 20 18:32:07.328: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 20 18:32:07.329: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 20 18:32:07.371: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 20 18:32:07.371: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 20 18:32:07.415: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 20 18:32:07.415: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:32:07.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8xpq5" for this suite.
Feb 20 18:32:13.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:14.938: INFO: namespace: e2e-tests-svcaccounts-8xpq5, resource: bindings, ignored listing per whitelist
Feb 20 18:32:15.189: INFO: namespace e2e-tests-svcaccounts-8xpq5 deletion completed in 7.731823198s

• [SLOW TEST:10.510 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:32:15.190: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4bgj2
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 20 18:32:17.008: INFO: Waiting up to 5m0s for pod "pod-d97d2063-353d-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-4bgj2" to be "success or failure"
Feb 20 18:32:17.050: INFO: Pod "pod-d97d2063-353d-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.708682ms
Feb 20 18:32:19.093: INFO: Pod "pod-d97d2063-353d-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084659756s
STEP: Saw pod success
Feb 20 18:32:19.093: INFO: Pod "pod-d97d2063-353d-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:32:19.135: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-d97d2063-353d-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 18:32:19.227: INFO: Waiting for pod pod-d97d2063-353d-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:32:19.269: INFO: Pod pod-d97d2063-353d-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:32:19.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4bgj2" for this suite.
Feb 20 18:32:25.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:25.567: INFO: namespace: e2e-tests-emptydir-4bgj2, resource: bindings, ignored listing per whitelist
Feb 20 18:32:27.076: INFO: namespace e2e-tests-emptydir-4bgj2 deletion completed in 7.763218213s

• [SLOW TEST:11.886 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:32:27.076: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-wmrhx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 20 18:32:31.561: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e0857fa8-353d-11e9-96fe-8e2b2e6369d7"
Feb 20 18:32:31.561: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e0857fa8-353d-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-pods-wmrhx" to be "terminated due to deadline exceeded"
Feb 20 18:32:31.603: INFO: Pod "pod-update-activedeadlineseconds-e0857fa8-353d-11e9-96fe-8e2b2e6369d7": Phase="Running", Reason="", readiness=true. Elapsed: 41.918009ms
Feb 20 18:32:33.646: INFO: Pod "pod-update-activedeadlineseconds-e0857fa8-353d-11e9-96fe-8e2b2e6369d7": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.084392455s
Feb 20 18:32:33.646: INFO: Pod "pod-update-activedeadlineseconds-e0857fa8-353d-11e9-96fe-8e2b2e6369d7" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:32:33.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wmrhx" for this suite.
Feb 20 18:32:39.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:40.527: INFO: namespace: e2e-tests-pods-wmrhx, resource: bindings, ignored listing per whitelist
Feb 20 18:32:41.445: INFO: namespace e2e-tests-pods-wmrhx deletion completed in 7.756469439s

• [SLOW TEST:14.370 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:32:41.445: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-p4q2q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:32:43.162: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:32:45.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p4q2q" for this suite.
Feb 20 18:33:37.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:33:39.205: INFO: namespace: e2e-tests-pods-p4q2q, resource: bindings, ignored listing per whitelist
Feb 20 18:33:39.376: INFO: namespace e2e-tests-pods-p4q2q deletion completed in 53.717671175s

• [SLOW TEST:57.930 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:33:39.376: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gww5c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:33:41.066: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-gww5c'
Feb 20 18:33:41.460: INFO: stderr: ""
Feb 20 18:33:41.460: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb 20 18:33:41.503: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gww5c'
Feb 20 18:33:44.383: INFO: stderr: ""
Feb 20 18:33:44.383: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:33:44.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gww5c" for this suite.
Feb 20 18:33:50.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:33:52.351: INFO: namespace: e2e-tests-kubectl-gww5c, resource: bindings, ignored listing per whitelist
Feb 20 18:33:52.478: INFO: namespace e2e-tests-kubectl-gww5c deletion completed in 7.805906374s

• [SLOW TEST:13.102 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:33:52.478: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-nwwz5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:33:54.163: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 20 18:33:54.247: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 18:33:56.332: INFO: Creating deployment "test-rolling-update-deployment"
Feb 20 18:33:56.374: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 20 18:33:56.459: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 20 18:33:56.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686284436, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686284436, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686284436, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686284436, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 18:33:58.544: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 18:33:58.671: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-nwwz5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nwwz5/deployments/test-rolling-update-deployment,UID:14b9bfe0-353e-11e9-a8b6-5a3f4013d0a1,ResourceVersion:6925,Generation:1,CreationTimestamp:2019-02-20 18:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-20 18:33:56 +0000 UTC 2019-02-20 18:33:56 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-20 18:33:57 +0000 UTC 2019-02-20 18:33:56 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 18:33:58.714: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-nwwz5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nwwz5/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:14bb4283-353e-11e9-a8b6-5a3f4013d0a1,ResourceVersion:6918,Generation:1,CreationTimestamp:2019-02-20 18:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 14b9bfe0-353e-11e9-a8b6-5a3f4013d0a1 0xc0024d1357 0xc0024d1358}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 20 18:33:58.714: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 20 18:33:58.714: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-nwwz5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nwwz5/replicasets/test-rolling-update-controller,UID:136ed788-353e-11e9-a8b6-5a3f4013d0a1,ResourceVersion:6924,Generation:2,CreationTimestamp:2019-02-20 18:33:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 14b9bfe0-353e-11e9-a8b6-5a3f4013d0a1 0xc0024d128f 0xc0024d12a0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 18:33:58.757: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-d5x4j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-d5x4j,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-nwwz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nwwz5/pods/test-rolling-update-deployment-68b55d7bc6-d5x4j,UID:14bb8335-353e-11e9-a8b6-5a3f4013d0a1,ResourceVersion:6917,Generation:0,CreationTimestamp:2019-02-20 18:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.76/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 14bb4283-353e-11e9-a8b6-5a3f4013d0a1 0xc0024d1be7 0xc0024d1be8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2p4f6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2p4f6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2p4f6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d1c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d1c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:33:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:33:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:33:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.76,StartTime:2019-02-20 18:33:56 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-20 18:33:57 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://6485c4f6dbf4aa1a0f3fc4cb15855476f53d3d89ae2e88248ec62725bdb2cb4f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:33:58.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-nwwz5" for this suite.
Feb 20 18:34:04.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:34:05.853: INFO: namespace: e2e-tests-deployment-nwwz5, resource: bindings, ignored listing per whitelist
Feb 20 18:34:06.526: INFO: namespace e2e-tests-deployment-nwwz5 deletion completed in 7.726786844s

• [SLOW TEST:14.049 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:34:06.527: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-pbw44
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-1bdac06e-353e-11e9-96fe-8e2b2e6369d7
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1bdac06e-353e-11e9-96fe-8e2b2e6369d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:34:12.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pbw44" for this suite.
Feb 20 18:34:34.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:34:35.722: INFO: namespace: e2e-tests-configmap-pbw44, resource: bindings, ignored listing per whitelist
Feb 20 18:34:36.474: INFO: namespace e2e-tests-configmap-pbw44 deletion completed in 23.720773917s

• [SLOW TEST:29.947 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:34:36.474: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mwmh5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:34:38.255: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-mwmh5'
Feb 20 18:34:38.591: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 18:34:38.591: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 20 18:34:38.676: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-d5gtn]
Feb 20 18:34:38.676: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-d5gtn" in namespace "e2e-tests-kubectl-mwmh5" to be "running and ready"
Feb 20 18:34:38.718: INFO: Pod "e2e-test-nginx-rc-d5gtn": Phase="Pending", Reason="", readiness=false. Elapsed: 41.965084ms
Feb 20 18:34:40.760: INFO: Pod "e2e-test-nginx-rc-d5gtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.084845292s
Feb 20 18:34:40.761: INFO: Pod "e2e-test-nginx-rc-d5gtn" satisfied condition "running and ready"
Feb 20 18:34:40.761: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-d5gtn]
Feb 20 18:34:40.761: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-mwmh5'
Feb 20 18:34:41.095: INFO: stderr: ""
Feb 20 18:34:41.096: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb 20 18:34:41.096: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-mwmh5'
Feb 20 18:34:41.372: INFO: stderr: ""
Feb 20 18:34:41.372: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:34:41.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mwmh5" for this suite.
Feb 20 18:34:47.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:34:48.608: INFO: namespace: e2e-tests-kubectl-mwmh5, resource: bindings, ignored listing per whitelist
Feb 20 18:34:49.199: INFO: namespace e2e-tests-kubectl-mwmh5 deletion completed in 7.784371532s

• [SLOW TEST:12.725 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:34:49.200: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8lwnj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 20 18:34:51.008: INFO: Waiting up to 5m0s for pod "pod-3547a425-353e-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-8lwnj" to be "success or failure"
Feb 20 18:34:51.049: INFO: Pod "pod-3547a425-353e-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.940627ms
Feb 20 18:34:53.093: INFO: Pod "pod-3547a425-353e-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08514735s
STEP: Saw pod success
Feb 20 18:34:53.093: INFO: Pod "pod-3547a425-353e-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:34:53.135: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-3547a425-353e-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 18:34:53.226: INFO: Waiting for pod pod-3547a425-353e-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:34:53.268: INFO: Pod pod-3547a425-353e-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:34:53.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8lwnj" for this suite.
Feb 20 18:34:59.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:34:59.688: INFO: namespace: e2e-tests-emptydir-8lwnj, resource: bindings, ignored listing per whitelist
Feb 20 18:35:01.029: INFO: namespace e2e-tests-emptydir-8lwnj deletion completed in 7.717773225s

• [SLOW TEST:11.829 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:35:01.029: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-bgv6w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 18:35:02.966: INFO: Waiting up to 5m0s for pod "downward-api-3c684584-353e-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-bgv6w" to be "success or failure"
Feb 20 18:35:03.008: INFO: Pod "downward-api-3c684584-353e-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.969763ms
Feb 20 18:35:05.051: INFO: Pod "downward-api-3c684584-353e-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085116149s
STEP: Saw pod success
Feb 20 18:35:05.051: INFO: Pod "downward-api-3c684584-353e-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:35:05.093: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downward-api-3c684584-353e-11e9-96fe-8e2b2e6369d7 container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:35:05.192: INFO: Waiting for pod downward-api-3c684584-353e-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:35:05.234: INFO: Pod downward-api-3c684584-353e-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:35:05.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bgv6w" for this suite.
Feb 20 18:35:11.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:35:11.701: INFO: namespace: e2e-tests-downward-api-bgv6w, resource: bindings, ignored listing per whitelist
Feb 20 18:35:13.008: INFO: namespace e2e-tests-downward-api-bgv6w deletion completed in 7.731430804s

• [SLOW TEST:11.979 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:35:13.008: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-bx98s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-xsdfd
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-m5l4c
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:35:21.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-bx98s" for this suite.
Feb 20 18:35:27.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:35:28.657: INFO: namespace: e2e-tests-namespaces-bx98s, resource: bindings, ignored listing per whitelist
Feb 20 18:35:29.377: INFO: namespace e2e-tests-namespaces-bx98s deletion completed in 7.77043826s
STEP: Destroying namespace "e2e-tests-nsdeletetest-xsdfd" for this suite.
Feb 20 18:35:29.418: INFO: Namespace e2e-tests-nsdeletetest-xsdfd was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-m5l4c" for this suite.
Feb 20 18:35:35.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:35:36.342: INFO: namespace: e2e-tests-nsdeletetest-m5l4c, resource: bindings, ignored listing per whitelist
Feb 20 18:35:37.137: INFO: namespace e2e-tests-nsdeletetest-m5l4c deletion completed in 7.718216317s

• [SLOW TEST:24.129 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:35:37.137: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-th9gs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-lgvm5
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Feb 20 18:35:48.936: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-btgrz
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:36:05.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-th9gs" for this suite.
Feb 20 18:36:11.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:36:13.593: INFO: namespace: e2e-tests-namespaces-th9gs, resource: bindings, ignored listing per whitelist
Feb 20 18:36:13.636: INFO: namespace e2e-tests-namespaces-th9gs deletion completed in 7.774657219s
STEP: Destroying namespace "e2e-tests-nsdeletetest-lgvm5" for this suite.
Feb 20 18:36:13.680: INFO: Namespace e2e-tests-nsdeletetest-lgvm5 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-btgrz" for this suite.
Feb 20 18:36:19.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:36:20.188: INFO: namespace: e2e-tests-nsdeletetest-btgrz, resource: bindings, ignored listing per whitelist
Feb 20 18:36:21.408: INFO: namespace e2e-tests-nsdeletetest-btgrz deletion completed in 7.727942139s

• [SLOW TEST:44.271 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:36:21.408: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-7jwsr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6c3c20fc-353e-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 18:36:23.249: INFO: Waiting up to 5m0s for pod "pod-secrets-6c428a6b-353e-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-7jwsr" to be "success or failure"
Feb 20 18:36:23.291: INFO: Pod "pod-secrets-6c428a6b-353e-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.919618ms
Feb 20 18:36:25.334: INFO: Pod "pod-secrets-6c428a6b-353e-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084752281s
STEP: Saw pod success
Feb 20 18:36:25.334: INFO: Pod "pod-secrets-6c428a6b-353e-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:36:25.376: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-secrets-6c428a6b-353e-11e9-96fe-8e2b2e6369d7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:36:25.472: INFO: Waiting for pod pod-secrets-6c428a6b-353e-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:36:25.514: INFO: Pod pod-secrets-6c428a6b-353e-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:36:25.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7jwsr" for this suite.
Feb 20 18:36:31.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:36:32.103: INFO: namespace: e2e-tests-secrets-7jwsr, resource: bindings, ignored listing per whitelist
Feb 20 18:36:33.290: INFO: namespace e2e-tests-secrets-7jwsr deletion completed in 7.733739318s

• [SLOW TEST:11.882 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:36:33.290: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-sl44c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:36:37.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-sl44c" for this suite.
Feb 20 18:37:15.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:37:15.775: INFO: namespace: e2e-tests-kubelet-test-sl44c, resource: bindings, ignored listing per whitelist
Feb 20 18:37:16.949: INFO: namespace e2e-tests-kubelet-test-sl44c deletion completed in 39.720526252s

• [SLOW TEST:43.659 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:37:16.950: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-xgtcm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xgtcm
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-xgtcm
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-xgtcm
Feb 20 18:37:18.831: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 20 18:37:28.874: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 20 18:37:28.916: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 18:37:29.885: INFO: stderr: ""
Feb 20 18:37:29.885: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 18:37:29.885: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 18:37:29.927: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 20 18:37:39.970: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 18:37:39.970: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:37:40.141: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999301s
Feb 20 18:37:41.183: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.955825998s
Feb 20 18:37:42.226: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.913170013s
Feb 20 18:37:43.268: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.870378061s
Feb 20 18:37:44.311: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.828294834s
Feb 20 18:37:45.354: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.785443418s
Feb 20 18:37:46.397: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.742656483s
Feb 20 18:37:47.439: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.699811265s
Feb 20 18:37:48.482: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.657268885s
Feb 20 18:37:49.524: INFO: Verifying statefulset ss doesn't scale past 1 for another 614.383858ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-xgtcm
Feb 20 18:37:50.567: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:37:51.434: INFO: stderr: ""
Feb 20 18:37:51.434: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 18:37:51.434: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 18:37:51.476: INFO: Found 2 stateful pods, waiting for 3
Feb 20 18:38:01.519: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:38:01.520: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:38:01.520: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 20 18:38:01.604: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 18:38:02.573: INFO: stderr: ""
Feb 20 18:38:02.573: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 18:38:02.573: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 18:38:02.573: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 18:38:03.452: INFO: stderr: ""
Feb 20 18:38:03.452: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 18:38:03.452: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 18:38:03.452: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 18:38:04.309: INFO: stderr: ""
Feb 20 18:38:04.309: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 18:38:04.309: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 18:38:04.309: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:38:04.351: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 20 18:38:14.437: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 18:38:14.437: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 18:38:14.437: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 18:38:14.563: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999569s
Feb 20 18:38:15.606: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.957612111s
Feb 20 18:38:16.649: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.914873761s
Feb 20 18:38:17.692: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.872094526s
Feb 20 18:38:18.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.829306313s
Feb 20 18:38:19.777: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.78666137s
Feb 20 18:38:20.820: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.743893599s
Feb 20 18:38:21.862: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.701105382s
Feb 20 18:38:22.905: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.65846574s
Feb 20 18:38:23.948: INFO: Verifying statefulset ss doesn't scale past 3 for another 615.579653ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-xgtcm
Feb 20 18:38:24.991: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:38:25.848: INFO: stderr: ""
Feb 20 18:38:25.848: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 18:38:25.848: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 18:38:25.848: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:38:26.646: INFO: stderr: ""
Feb 20 18:38:26.646: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 18:38:26.646: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 18:38:26.646: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:38:27.150: INFO: rc: 1
Feb 20 18:38:27.150: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc000f4f410 exit status 1 <nil> <nil> true [0xc00018d288 0xc00018d350 0xc00018d418] [0xc00018d288 0xc00018d350 0xc00018d418] [0xc00018d2c0 0xc00018d3e8] [0x933040 0x933040] 0xc0014dd260 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 20 18:38:37.150: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:38:37.435: INFO: rc: 1
Feb 20 18:38:37.435: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000acc9f0 exit status 1 <nil> <nil> true [0xc0023e8550 0xc0023e8578 0xc0023e8608] [0xc0023e8550 0xc0023e8578 0xc0023e8608] [0xc0023e8570 0xc0023e85c0] [0x933040 0x933040] 0xc001d1bf80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:38:47.435: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:38:47.685: INFO: rc: 1
Feb 20 18:38:47.685: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000acccc0 exit status 1 <nil> <nil> true [0xc0023e8620 0xc0023e86c8 0xc0023e86f0] [0xc0023e8620 0xc0023e86c8 0xc0023e86f0] [0xc0023e86a8 0xc0023e86e8] [0x933040 0x933040] 0xc0014fc360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:38:57.686: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:38:57.908: INFO: rc: 1
Feb 20 18:38:57.908: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f4f680 exit status 1 <nil> <nil> true [0xc00018d440 0xc00018d4f0 0xc00018d560] [0xc00018d440 0xc00018d4f0 0xc00018d560] [0xc00018d4a8 0xc00018d540] [0x933040 0x933040] 0xc0014dd560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:39:07.908: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:39:08.129: INFO: rc: 1
Feb 20 18:39:08.130: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6ac90 exit status 1 <nil> <nil> true [0xc0002f8ee0 0xc0002f8f68 0xc0002f9038] [0xc0002f8ee0 0xc0002f8f68 0xc0002f9038] [0xc0002f8f20 0xc0002f9030] [0x933040 0x933040] 0xc0011152c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:39:18.130: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:39:18.359: INFO: rc: 1
Feb 20 18:39:18.359: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f4f920 exit status 1 <nil> <nil> true [0xc00018d568 0xc00018d5c8 0xc00018d660] [0xc00018d568 0xc00018d5c8 0xc00018d660] [0xc00018d590 0xc00018d630] [0x933040 0x933040] 0xc0014dd860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:39:28.360: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:39:28.581: INFO: rc: 1
Feb 20 18:39:28.581: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6b0e0 exit status 1 <nil> <nil> true [0xc0002f9050 0xc0002f9070 0xc0002f90a8] [0xc0002f9050 0xc0002f9070 0xc0002f90a8] [0xc0002f9060 0xc0002f90a0] [0x933040 0x933040] 0xc001115620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:39:38.581: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:39:38.875: INFO: rc: 1
Feb 20 18:39:38.875: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f4fb00 exit status 1 <nil> <nil> true [0xc0023e86f8 0xc00018d6b8 0xc00018d6f8] [0xc0023e86f8 0xc00018d6b8 0xc00018d6f8] [0xc00018d690 0xc00018d6e8] [0x933040 0x933040] 0xc0014ddb00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:39:48.875: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:39:49.137: INFO: rc: 1
Feb 20 18:39:49.137: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014882d0 exit status 1 <nil> <nil> true [0xc00018c1f8 0xc00018c7b8 0xc00018c820] [0xc00018c1f8 0xc00018c7b8 0xc00018c820] [0xc00018c3e8 0xc00018c810] [0x933040 0x933040] 0xc001d1a540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:39:59.138: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:39:59.371: INFO: rc: 1
Feb 20 18:39:59.371: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a0750 exit status 1 <nil> <nil> true [0xc00000e058 0xc00000e1b0 0xc00000e440] [0xc00000e058 0xc00000e1b0 0xc00000e440] [0xc00000e170 0xc00000e2d0] [0x933040 0x933040] 0xc002422540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:40:09.371: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:40:09.620: INFO: rc: 1
Feb 20 18:40:09.620: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a09f0 exit status 1 <nil> <nil> true [0xc00000e4e8 0xc00000e758 0xc00000e998] [0xc00000e4e8 0xc00000e758 0xc00000e998] [0xc00000e6b8 0xc00000e948] [0x933040 0x933040] 0xc0024239e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:40:19.621: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:40:19.842: INFO: rc: 1
Feb 20 18:40:19.842: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a0c60 exit status 1 <nil> <nil> true [0xc00000eaa8 0xc00000eb68 0xc00000ec00] [0xc00000eaa8 0xc00000eb68 0xc00000ec00] [0xc00000eb28 0xc00000ebd0] [0x933040 0x933040] 0xc002423ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:40:29.843: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:40:30.065: INFO: rc: 1
Feb 20 18:40:30.066: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017682a0 exit status 1 <nil> <nil> true [0xc0023e8000 0xc0023e8028 0xc0023e8060] [0xc0023e8000 0xc0023e8028 0xc0023e8060] [0xc0023e8018 0xc0023e8038] [0x933040 0x933040] 0xc0019339e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:40:40.066: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:40:40.312: INFO: rc: 1
Feb 20 18:40:40.312: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a0f90 exit status 1 <nil> <nil> true [0xc00000ec10 0xc00000edd0 0xc00000ee48] [0xc00000ec10 0xc00000edd0 0xc00000ee48] [0xc00000ed00 0xc00000ee18] [0x933040 0x933040] 0xc00196a480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:40:50.313: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:40:50.537: INFO: rc: 1
Feb 20 18:40:50.537: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488570 exit status 1 <nil> <nil> true [0xc00018c8a0 0xc00018caf0 0xc00018cb98] [0xc00018c8a0 0xc00018caf0 0xc00018cb98] [0xc00018ca18 0xc00018cb70] [0x933040 0x933040] 0xc001d1ac00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:41:00.538: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:00.782: INFO: rc: 1
Feb 20 18:41:00.782: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001768570 exit status 1 <nil> <nil> true [0xc0023e8068 0xc0023e8098 0xc0023e80b8] [0xc0023e8068 0xc0023e8098 0xc0023e80b8] [0xc0023e8090 0xc0023e80a8] [0x933040 0x933040] 0xc001933d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:41:10.783: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:11.012: INFO: rc: 1
Feb 20 18:41:11.012: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a12c0 exit status 1 <nil> <nil> true [0xc00000ee90 0xc00000efb0 0xc00000f0c8] [0xc00000ee90 0xc00000efb0 0xc00000f0c8] [0xc00000ef38 0xc00000f078] [0x933040 0x933040] 0xc00196a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:41:21.012: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:21.254: INFO: rc: 1
Feb 20 18:41:21.254: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488810 exit status 1 <nil> <nil> true [0xc00018cbc0 0xc00018cc98 0xc00018cd40] [0xc00018cbc0 0xc00018cc98 0xc00018cd40] [0xc00018cc18 0xc00018ccf0] [0x933040 0x933040] 0xc001d1b260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:41:31.254: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:31.521: INFO: rc: 1
Feb 20 18:41:31.521: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a1560 exit status 1 <nil> <nil> true [0xc00000f110 0xc00000f1f0 0xc00000f2e8] [0xc00000f110 0xc00000f1f0 0xc00000f2e8] [0xc00000f1c0 0xc00000f2c0] [0x933040 0x933040] 0xc00196acc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:41:41.521: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:41.896: INFO: rc: 1
Feb 20 18:41:41.896: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a17d0 exit status 1 <nil> <nil> true [0xc00000f350 0xc00000f3c0 0xc00000f488] [0xc00000f350 0xc00000f3c0 0xc00000f488] [0xc00000f378 0xc00000f468] [0x933040 0x933040] 0xc00196bc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:41:51.897: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:52.127: INFO: rc: 1
Feb 20 18:41:52.127: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a07b0 exit status 1 <nil> <nil> true [0xc00000e0d0 0xc00000e240 0xc00000e4e8] [0xc00000e0d0 0xc00000e240 0xc00000e4e8] [0xc00000e1b0 0xc00000e440] [0x933040 0x933040] 0xc00196a480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:02.128: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:02.351: INFO: rc: 1
Feb 20 18:42:02.351: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a5a270 exit status 1 <nil> <nil> true [0xc00018c000 0xc00018c3e8 0xc00018c810] [0xc00018c000 0xc00018c3e8 0xc00018c810] [0xc00018c248 0xc00018c7f0] [0x933040 0x933040] 0xc002422540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:12.352: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:12.677: INFO: rc: 1
Feb 20 18:42:12.677: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a5a4e0 exit status 1 <nil> <nil> true [0xc00018c820 0xc00018ca18 0xc00018cb70] [0xc00018c820 0xc00018ca18 0xc00018cb70] [0xc00018c9f8 0xc00018cb68] [0x933040 0x933040] 0xc0024239e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:22.677: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:22.901: INFO: rc: 1
Feb 20 18:42:22.901: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001768270 exit status 1 <nil> <nil> true [0xc0023e8000 0xc0023e8028 0xc0023e8060] [0xc0023e8000 0xc0023e8028 0xc0023e8060] [0xc0023e8018 0xc0023e8038] [0x933040 0x933040] 0xc0019339e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:32.901: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:33.128: INFO: rc: 1
Feb 20 18:42:33.128: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488300 exit status 1 <nil> <nil> true [0xc0002f80e8 0xc0002f81f0 0xc0002f8228] [0xc0002f80e8 0xc0002f81f0 0xc0002f8228] [0xc0002f81b0 0xc0002f8218] [0x933040 0x933040] 0xc001d1a540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:43.128: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:43.355: INFO: rc: 1
Feb 20 18:42:43.355: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014885d0 exit status 1 <nil> <nil> true [0xc0002f8320 0xc0002f8358 0xc0002f8420] [0xc0002f8320 0xc0002f8358 0xc0002f8420] [0xc0002f8350 0xc0002f83b8] [0x933040 0x933040] 0xc001d1ac00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:53.363: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:53.599: INFO: rc: 1
Feb 20 18:42:53.599: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488870 exit status 1 <nil> <nil> true [0xc0002f8448 0xc0002f84a8 0xc0002f84d8] [0xc0002f8448 0xc0002f84a8 0xc0002f84d8] [0xc0002f8490 0xc0002f84c0] [0x933040 0x933040] 0xc001d1b260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:03.600: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:03.825: INFO: rc: 1
Feb 20 18:43:03.825: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a0a80 exit status 1 <nil> <nil> true [0xc00000e608 0xc00000e878 0xc00000eaa8] [0xc00000e608 0xc00000e878 0xc00000eaa8] [0xc00000e758 0xc00000e998] [0x933040 0x933040] 0xc00196a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:13.825: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:14.090: INFO: rc: 1
Feb 20 18:43:14.090: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488b10 exit status 1 <nil> <nil> true [0xc0002f84e0 0xc0002f8520 0xc0002f85f0] [0xc0002f84e0 0xc0002f8520 0xc0002f85f0] [0xc0002f8500 0xc0002f85e8] [0x933040 0x933040] 0xc001d1baa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:24.090: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:24.313: INFO: rc: 1
Feb 20 18:43:24.313: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a5a7e0 exit status 1 <nil> <nil> true [0xc00018cb98 0xc00018cc18 0xc00018ccf0] [0xc00018cb98 0xc00018cc18 0xc00018ccf0] [0xc00018cc10 0xc00018cce8] [0x933040 0x933040] 0xc002423ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:34.313: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-xgtcm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:34.535: INFO: rc: 1
Feb 20 18:43:34.535: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 20 18:43:34.535: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 18:43:34.662: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xgtcm
Feb 20 18:43:34.703: INFO: Scaling statefulset ss to 0
Feb 20 18:43:34.830: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:43:34.872: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:43:34.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xgtcm" for this suite.
Feb 20 18:43:41.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:43:42.724: INFO: namespace: e2e-tests-statefulset-xgtcm, resource: bindings, ignored listing per whitelist
Feb 20 18:43:42.807: INFO: namespace e2e-tests-statefulset-xgtcm deletion completed in 7.765350774s

• [SLOW TEST:385.858 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:43:42.807: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-h9p62
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:43:44.697: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 20 18:43:44.782: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-h9p62/daemonsets","resourceVersion":"8329"},"items":null}

Feb 20 18:43:44.824: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-h9p62/pods","resourceVersion":"8329"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:43:44.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-h9p62" for this suite.
Feb 20 18:43:51.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:43:51.957: INFO: namespace: e2e-tests-daemonsets-h9p62, resource: bindings, ignored listing per whitelist
Feb 20 18:43:52.711: INFO: namespace e2e-tests-daemonsets-h9p62 deletion completed in 7.717130501s

S [SKIPPING] [9.903 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 20 18:43:44.697: Requires at least 2 nodes (not -1)

  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:43:52.711: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-79lxd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 18:43:54.506: INFO: Waiting up to 5m0s for pod "downward-api-793af59b-353f-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-79lxd" to be "success or failure"
Feb 20 18:43:54.548: INFO: Pod "downward-api-793af59b-353f-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.959527ms
Feb 20 18:43:56.591: INFO: Pod "downward-api-793af59b-353f-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084486643s
STEP: Saw pod success
Feb 20 18:43:56.591: INFO: Pod "downward-api-793af59b-353f-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:43:56.633: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downward-api-793af59b-353f-11e9-96fe-8e2b2e6369d7 container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:43:56.727: INFO: Waiting for pod downward-api-793af59b-353f-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:43:56.769: INFO: Pod downward-api-793af59b-353f-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:43:56.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-79lxd" for this suite.
Feb 20 18:44:02.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:44:04.448: INFO: namespace: e2e-tests-downward-api-79lxd, resource: bindings, ignored listing per whitelist
Feb 20 18:44:04.574: INFO: namespace e2e-tests-downward-api-79lxd deletion completed in 7.76237581s

• [SLOW TEST:11.863 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:44:04.574: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-xs5rp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 20 18:44:08.552: INFO: Pod name wrapped-volume-race-818913cf-353f-11e9-96fe-8e2b2e6369d7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-818913cf-353f-11e9-96fe-8e2b2e6369d7 in namespace e2e-tests-emptydir-wrapper-xs5rp, will wait for the garbage collector to delete the pods
Feb 20 18:44:12.943: INFO: Deleting ReplicationController wrapped-volume-race-818913cf-353f-11e9-96fe-8e2b2e6369d7 took: 43.377813ms
Feb 20 18:44:13.043: INFO: Terminating ReplicationController wrapped-volume-race-818913cf-353f-11e9-96fe-8e2b2e6369d7 pods took: 100.389862ms
STEP: Creating RC which spawns configmap-volume pods
Feb 20 18:44:51.576: INFO: Pod name wrapped-volume-race-9b3199ac-353f-11e9-96fe-8e2b2e6369d7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9b3199ac-353f-11e9-96fe-8e2b2e6369d7 in namespace e2e-tests-emptydir-wrapper-xs5rp, will wait for the garbage collector to delete the pods
Feb 20 18:44:55.968: INFO: Deleting ReplicationController wrapped-volume-race-9b3199ac-353f-11e9-96fe-8e2b2e6369d7 took: 43.724078ms
Feb 20 18:44:56.069: INFO: Terminating ReplicationController wrapped-volume-race-9b3199ac-353f-11e9-96fe-8e2b2e6369d7 pods took: 100.217815ms
STEP: Creating RC which spawns configmap-volume pods
Feb 20 18:45:31.559: INFO: Pod name wrapped-volume-race-b2fdc02b-353f-11e9-96fe-8e2b2e6369d7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b2fdc02b-353f-11e9-96fe-8e2b2e6369d7 in namespace e2e-tests-emptydir-wrapper-xs5rp, will wait for the garbage collector to delete the pods
Feb 20 18:45:36.007: INFO: Deleting ReplicationController wrapped-volume-race-b2fdc02b-353f-11e9-96fe-8e2b2e6369d7 took: 45.048769ms
Feb 20 18:45:36.107: INFO: Terminating ReplicationController wrapped-volume-race-b2fdc02b-353f-11e9-96fe-8e2b2e6369d7 pods took: 100.233836ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:46:23.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-xs5rp" for this suite.
Feb 20 18:46:29.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:46:30.549: INFO: namespace: e2e-tests-emptydir-wrapper-xs5rp, resource: bindings, ignored listing per whitelist
Feb 20 18:46:31.535: INFO: namespace e2e-tests-emptydir-wrapper-xs5rp deletion completed in 7.796769623s

• [SLOW TEST:146.960 seconds]
[sig-storage] EmptyDir wrapper volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:46:31.535: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vkkxt
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-d7f700e7-353f-11e9-96fe-8e2b2e6369d7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:46:35.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vkkxt" for this suite.
Feb 20 18:46:57.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:46:59.356: INFO: namespace: e2e-tests-configmap-vkkxt, resource: bindings, ignored listing per whitelist
Feb 20 18:46:59.482: INFO: namespace e2e-tests-configmap-vkkxt deletion completed in 23.726808991s

• [SLOW TEST:27.947 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:46:59.482: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-k7w2k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-k7w2k
Feb 20 18:47:03.293: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-k7w2k
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 18:47:03.335: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:51:04.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-k7w2k" for this suite.
Feb 20 18:51:10.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:51:10.983: INFO: namespace: e2e-tests-container-probe-k7w2k, resource: bindings, ignored listing per whitelist
Feb 20 18:51:12.343: INFO: namespace e2e-tests-container-probe-k7w2k deletion completed in 7.853669764s

• [SLOW TEST:252.861 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:51:12.343: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-8k5lk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7
Feb 20 18:51:14.150: INFO: Pod name my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7: Found 1 pods out of 1
Feb 20 18:51:14.150: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7" are running
Feb 20 18:51:16.235: INFO: Pod "my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7-dn64b" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 18:51:14 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 18:51:14 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 18:51:14 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 18:51:14 +0000 UTC Reason: Message:}])
Feb 20 18:51:16.235: INFO: Trying to dial the pod
Feb 20 18:51:21.456: INFO: Controller my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7: Got expected result from replica 1 [my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7-dn64b]: "my-hostname-basic-7f40fc78-3540-11e9-96fe-8e2b2e6369d7-dn64b", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:51:21.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8k5lk" for this suite.
Feb 20 18:51:27.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:51:28.506: INFO: namespace: e2e-tests-replication-controller-8k5lk, resource: bindings, ignored listing per whitelist
Feb 20 18:51:29.274: INFO: namespace e2e-tests-replication-controller-8k5lk deletion completed in 7.774393814s

• [SLOW TEST:16.931 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:51:29.275: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-n2nx8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-895e6c36-3540-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 18:51:31.122: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8964e1c4-3540-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-n2nx8" to be "success or failure"
Feb 20 18:51:31.164: INFO: Pod "pod-projected-configmaps-8964e1c4-3540-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.99848ms
Feb 20 18:51:33.208: INFO: Pod "pod-projected-configmaps-8964e1c4-3540-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085950877s
STEP: Saw pod success
Feb 20 18:51:33.208: INFO: Pod "pod-projected-configmaps-8964e1c4-3540-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:51:33.250: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-configmaps-8964e1c4-3540-11e9-96fe-8e2b2e6369d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:51:33.350: INFO: Waiting for pod pod-projected-configmaps-8964e1c4-3540-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:51:33.392: INFO: Pod pod-projected-configmaps-8964e1c4-3540-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:51:33.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n2nx8" for this suite.
Feb 20 18:51:39.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:51:41.037: INFO: namespace: e2e-tests-projected-n2nx8, resource: bindings, ignored listing per whitelist
Feb 20 18:51:41.257: INFO: namespace e2e-tests-projected-n2nx8 deletion completed in 7.822104907s

• [SLOW TEST:11.983 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:51:41.258: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-gggll
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 20 18:51:43.703: INFO: Waiting up to 5m0s for pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-t2xbt" in namespace "e2e-tests-svcaccounts-gggll" to be "success or failure"
Feb 20 18:51:43.745: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-t2xbt": Phase="Pending", Reason="", readiness=false. Elapsed: 41.904753ms
Feb 20 18:51:45.788: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-t2xbt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084776202s
STEP: Saw pod success
Feb 20 18:51:45.788: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-t2xbt" satisfied condition "success or failure"
Feb 20 18:51:45.830: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-t2xbt container token-test: <nil>
STEP: delete the pod
Feb 20 18:51:45.926: INFO: Waiting for pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-t2xbt to disappear
Feb 20 18:51:45.968: INFO: Pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-t2xbt no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 20 18:51:46.012: INFO: Waiting up to 5m0s for pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-r9vdv" in namespace "e2e-tests-svcaccounts-gggll" to be "success or failure"
Feb 20 18:51:46.054: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-r9vdv": Phase="Pending", Reason="", readiness=false. Elapsed: 41.733031ms
Feb 20 18:51:48.098: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-r9vdv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085571684s
STEP: Saw pod success
Feb 20 18:51:48.098: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-r9vdv" satisfied condition "success or failure"
Feb 20 18:51:48.140: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-r9vdv container root-ca-test: <nil>
STEP: delete the pod
Feb 20 18:51:48.232: INFO: Waiting for pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-r9vdv to disappear
Feb 20 18:51:48.276: INFO: Pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-r9vdv no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 20 18:51:48.322: INFO: Waiting up to 5m0s for pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-bs2zn" in namespace "e2e-tests-svcaccounts-gggll" to be "success or failure"
Feb 20 18:51:48.365: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-bs2zn": Phase="Pending", Reason="", readiness=false. Elapsed: 42.81665ms
Feb 20 18:51:50.411: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-bs2zn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088251553s
Feb 20 18:51:52.453: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-bs2zn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.13085689s
STEP: Saw pod success
Feb 20 18:51:52.453: INFO: Pod "pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-bs2zn" satisfied condition "success or failure"
Feb 20 18:51:52.495: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-bs2zn container namespace-test: <nil>
STEP: delete the pod
Feb 20 18:51:52.589: INFO: Waiting for pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-bs2zn to disappear
Feb 20 18:51:52.630: INFO: Pod pod-service-account-90e498fa-3540-11e9-96fe-8e2b2e6369d7-bs2zn no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:51:52.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-gggll" for this suite.
Feb 20 18:51:58.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:51:59.978: INFO: namespace: e2e-tests-svcaccounts-gggll, resource: bindings, ignored listing per whitelist
Feb 20 18:52:00.453: INFO: namespace e2e-tests-svcaccounts-gggll deletion completed in 7.77977029s

• [SLOW TEST:19.196 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:52:00.453: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-l9xwq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9bee13a2-3540-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 18:52:02.263: INFO: Waiting up to 5m0s for pod "pod-secrets-9bf4a1fc-3540-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-l9xwq" to be "success or failure"
Feb 20 18:52:02.306: INFO: Pod "pod-secrets-9bf4a1fc-3540-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.573509ms
Feb 20 18:52:04.348: INFO: Pod "pod-secrets-9bf4a1fc-3540-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085185956s
STEP: Saw pod success
Feb 20 18:52:04.348: INFO: Pod "pod-secrets-9bf4a1fc-3540-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:52:04.393: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-secrets-9bf4a1fc-3540-11e9-96fe-8e2b2e6369d7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:52:04.485: INFO: Waiting for pod pod-secrets-9bf4a1fc-3540-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:52:04.528: INFO: Pod pod-secrets-9bf4a1fc-3540-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:52:04.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l9xwq" for this suite.
Feb 20 18:52:10.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:10.870: INFO: namespace: e2e-tests-secrets-l9xwq, resource: bindings, ignored listing per whitelist
Feb 20 18:52:12.371: INFO: namespace e2e-tests-secrets-l9xwq deletion completed in 7.799465378s

• [SLOW TEST:11.917 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:52:12.371: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tx6sn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:52:14.121: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a305dccc-3540-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-tx6sn" to be "success or failure"
Feb 20 18:52:14.163: INFO: Pod "downwardapi-volume-a305dccc-3540-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.960104ms
Feb 20 18:52:16.221: INFO: Pod "downwardapi-volume-a305dccc-3540-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.100323845s
STEP: Saw pod success
Feb 20 18:52:16.221: INFO: Pod "downwardapi-volume-a305dccc-3540-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:52:16.265: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-a305dccc-3540-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 18:52:16.357: INFO: Waiting for pod downwardapi-volume-a305dccc-3540-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:52:16.400: INFO: Pod downwardapi-volume-a305dccc-3540-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:52:16.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tx6sn" for this suite.
Feb 20 18:52:22.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:22.767: INFO: namespace: e2e-tests-projected-tx6sn, resource: bindings, ignored listing per whitelist
Feb 20 18:52:24.538: INFO: namespace e2e-tests-projected-tx6sn deletion completed in 8.083712607s

• [SLOW TEST:12.168 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:52:24.539: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dk8gj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 18:52:26.357: INFO: Waiting up to 5m0s for pod "downward-api-aa510270-3540-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-dk8gj" to be "success or failure"
Feb 20 18:52:26.399: INFO: Pod "downward-api-aa510270-3540-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.249551ms
Feb 20 18:52:28.477: INFO: Pod "downward-api-aa510270-3540-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.120682778s
STEP: Saw pod success
Feb 20 18:52:28.477: INFO: Pod "downward-api-aa510270-3540-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:52:28.520: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downward-api-aa510270-3540-11e9-96fe-8e2b2e6369d7 container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:52:28.615: INFO: Waiting for pod downward-api-aa510270-3540-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:52:28.669: INFO: Pod downward-api-aa510270-3540-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:52:28.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dk8gj" for this suite.
Feb 20 18:52:34.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:35.016: INFO: namespace: e2e-tests-downward-api-dk8gj, resource: bindings, ignored listing per whitelist
Feb 20 18:52:36.531: INFO: namespace e2e-tests-downward-api-dk8gj deletion completed in 7.816261319s

• [SLOW TEST:11.992 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:52:36.531: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-bwrhx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:52:38.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-bwrhx" for this suite.
Feb 20 18:52:44.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:44.957: INFO: namespace: e2e-tests-kubelet-test-bwrhx, resource: bindings, ignored listing per whitelist
Feb 20 18:52:46.222: INFO: namespace e2e-tests-kubelet-test-bwrhx deletion completed in 7.82516476s

• [SLOW TEST:9.691 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:52:46.222: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-4scjl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 20 18:52:48.109: INFO: Waiting up to 5m0s for pod "client-containers-b748569b-3540-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-containers-4scjl" to be "success or failure"
Feb 20 18:52:48.151: INFO: Pod "client-containers-b748569b-3540-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.595285ms
Feb 20 18:52:50.194: INFO: Pod "client-containers-b748569b-3540-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08510153s
Feb 20 18:52:52.237: INFO: Pod "client-containers-b748569b-3540-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.127561867s
STEP: Saw pod success
Feb 20 18:52:52.237: INFO: Pod "client-containers-b748569b-3540-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:52:52.279: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod client-containers-b748569b-3540-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 18:52:52.375: INFO: Waiting for pod client-containers-b748569b-3540-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:52:52.417: INFO: Pod client-containers-b748569b-3540-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:52:52.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4scjl" for this suite.
Feb 20 18:52:58.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:59.180: INFO: namespace: e2e-tests-containers-4scjl, resource: bindings, ignored listing per whitelist
Feb 20 18:53:00.207: INFO: namespace e2e-tests-containers-4scjl deletion completed in 7.747120187s

• [SLOW TEST:13.985 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:53:00.208: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-cqz9b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 20 18:53:01.961: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:53:04.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cqz9b" for this suite.
Feb 20 18:53:10.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:53:11.275: INFO: namespace: e2e-tests-init-container-cqz9b, resource: bindings, ignored listing per whitelist
Feb 20 18:53:12.035: INFO: namespace e2e-tests-init-container-cqz9b deletion completed in 7.733542703s

• [SLOW TEST:11.828 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:53:12.036: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-pn98r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 20 18:53:13.771: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:53:17.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pn98r" for this suite.
Feb 20 18:53:23.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:53:23.881: INFO: namespace: e2e-tests-init-container-pn98r, resource: bindings, ignored listing per whitelist
Feb 20 18:53:25.267: INFO: namespace e2e-tests-init-container-pn98r deletion completed in 7.765004344s

• [SLOW TEST:13.231 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:53:25.267: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-64fx2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 20 18:53:26.961: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 18:53:27.046: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 18:53:27.088: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-0-144.eu-west-1.compute.internal before test
Feb 20 18:53:27.135: INFO: node-exporter-v62ww from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.135: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 18:53:27.135: INFO: kube-proxy-ckxln from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.135: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 18:53:27.135: INFO: calico-node-gwqtg from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.135: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 18:53:27.135: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-10-87.eu-west-1.compute.internal before test
Feb 20 18:53:27.330: INFO: calico-node-hbf5r from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.330: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 18:53:27.330: INFO: addons-kube-lego-69bbdc96b6-tg58h from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.330: INFO: 	Container kube-lego ready: true, restart count 0
Feb 20 18:53:27.330: INFO: vpn-shoot-8655cb5f7b-9pd79 from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.330: INFO: 	Container vpn-shoot ready: true, restart count 0
Feb 20 18:53:27.330: INFO: addons-nginx-ingress-controller-7778b8d74b-jkkjz from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.330: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 20 18:53:27.330: INFO: metrics-server-56d7786d8c-vpvx4 from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.330: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 18:53:27.331: INFO: kube-proxy-hjfzl from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.331: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 18:53:27.331: INFO: node-exporter-sk9v2 from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.331: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 18:53:27.331: INFO: coredns-67df79bbdd-78l6g from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.331: INFO: 	Container coredns ready: true, restart count 0
Feb 20 18:53:27.331: INFO: addons-kubernetes-dashboard-6579b646c5-9vwqw from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.331: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 20 18:53:27.331: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-whcxr from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.331: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Feb 20 18:53:27.331: INFO: blackbox-exporter-d6c46f9fc-f22mj from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:53:27.331: INFO: 	Container blackbox-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1585274126d325eb], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:53:28.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-64fx2" for this suite.
Feb 20 18:53:34.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:53:36.109: INFO: namespace: e2e-tests-sched-pred-64fx2, resource: bindings, ignored listing per whitelist
Feb 20 18:53:36.360: INFO: namespace e2e-tests-sched-pred-64fx2 deletion completed in 7.77087484s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.094 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:53:36.361: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-tk8nk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 20 18:53:42.448: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 18:53:42.490: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 18:53:44.491: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 18:53:44.534: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 18:53:46.492: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 18:53:46.534: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:53:46.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-tk8nk" for this suite.
Feb 20 18:54:08.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:54:10.236: INFO: namespace: e2e-tests-container-lifecycle-hook-tk8nk, resource: bindings, ignored listing per whitelist
Feb 20 18:54:10.363: INFO: namespace e2e-tests-container-lifecycle-hook-tk8nk deletion completed in 23.72946841s

• [SLOW TEST:34.002 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:54:10.363: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-rwbvk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rwbvk
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 18:54:12.158: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 18:54:32.938: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.24:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rwbvk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:54:32.938: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:54:33.705: INFO: Found all expected endpoints: [netserver-0]
Feb 20 18:54:33.748: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.117:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rwbvk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:54:33.749: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:54:34.373: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:54:34.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rwbvk" for this suite.
Feb 20 18:54:56.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:54:57.433: INFO: namespace: e2e-tests-pod-network-test-rwbvk, resource: bindings, ignored listing per whitelist
Feb 20 18:54:58.146: INFO: namespace e2e-tests-pod-network-test-rwbvk deletion completed in 23.726786115s

• [SLOW TEST:47.783 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:54:58.147: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fccwv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 20 18:54:59.980: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml proxy --unix-socket=/tmp/kubectl-proxy-unix482845328/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:55:00.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fccwv" for this suite.
Feb 20 18:55:06.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:55:07.891: INFO: namespace: e2e-tests-kubectl-fccwv, resource: bindings, ignored listing per whitelist
Feb 20 18:55:07.975: INFO: namespace e2e-tests-kubectl-fccwv deletion completed in 7.881796842s

• [SLOW TEST:9.829 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:55:07.976: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-tbpvp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 20 18:55:09.803: INFO: Waiting up to 5m0s for pod "client-containers-0bbcdae3-3541-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-containers-tbpvp" to be "success or failure"
Feb 20 18:55:09.845: INFO: Pod "client-containers-0bbcdae3-3541-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.408649ms
Feb 20 18:55:11.889: INFO: Pod "client-containers-0bbcdae3-3541-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086396846s
STEP: Saw pod success
Feb 20 18:55:11.890: INFO: Pod "client-containers-0bbcdae3-3541-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:55:11.932: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod client-containers-0bbcdae3-3541-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 18:55:12.025: INFO: Waiting for pod client-containers-0bbcdae3-3541-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:55:12.067: INFO: Pod client-containers-0bbcdae3-3541-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:55:12.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-tbpvp" for this suite.
Feb 20 18:55:18.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:55:19.396: INFO: namespace: e2e-tests-containers-tbpvp, resource: bindings, ignored listing per whitelist
Feb 20 18:55:19.901: INFO: namespace e2e-tests-containers-tbpvp deletion completed in 7.791314966s

• [SLOW TEST:11.925 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:55:19.901: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-zfwjs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:55:23.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zfwjs" for this suite.
Feb 20 18:56:15.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:56:17.043: INFO: namespace: e2e-tests-kubelet-test-zfwjs, resource: bindings, ignored listing per whitelist
Feb 20 18:56:17.593: INFO: namespace e2e-tests-kubelet-test-zfwjs deletion completed in 53.747566102s

• [SLOW TEST:57.691 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:56:17.593: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-vsqc4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 20 18:56:19.363: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 18:56:19.449: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 18:56:19.490: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-0-144.eu-west-1.compute.internal before test
Feb 20 18:56:19.537: INFO: kube-proxy-ckxln from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.537: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 18:56:19.537: INFO: node-exporter-v62ww from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.537: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 18:56:19.537: INFO: calico-node-gwqtg from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.537: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 18:56:19.537: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-10-87.eu-west-1.compute.internal before test
Feb 20 18:56:19.598: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-whcxr from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.598: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Feb 20 18:56:19.598: INFO: blackbox-exporter-d6c46f9fc-f22mj from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.598: INFO: 	Container blackbox-exporter ready: true, restart count 0
Feb 20 18:56:19.598: INFO: calico-node-hbf5r from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.598: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 18:56:19.598: INFO: addons-kube-lego-69bbdc96b6-tg58h from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.598: INFO: 	Container kube-lego ready: true, restart count 0
Feb 20 18:56:19.599: INFO: vpn-shoot-8655cb5f7b-9pd79 from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.599: INFO: 	Container vpn-shoot ready: true, restart count 0
Feb 20 18:56:19.599: INFO: addons-nginx-ingress-controller-7778b8d74b-jkkjz from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.599: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 20 18:56:19.599: INFO: metrics-server-56d7786d8c-vpvx4 from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.599: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 18:56:19.599: INFO: kube-proxy-hjfzl from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.599: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 18:56:19.599: INFO: node-exporter-sk9v2 from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.599: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 18:56:19.599: INFO: coredns-67df79bbdd-78l6g from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.599: INFO: 	Container coredns ready: true, restart count 0
Feb 20 18:56:19.599: INFO: addons-kubernetes-dashboard-6579b646c5-9vwqw from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 18:56:19.599: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-10-250-0-144.eu-west-1.compute.internal
STEP: verifying the node has the label node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod addons-kube-lego-69bbdc96b6-tg58h requesting resource cpu=20m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod addons-kubernetes-dashboard-6579b646c5-9vwqw requesting resource cpu=50m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod addons-nginx-ingress-controller-7778b8d74b-jkkjz requesting resource cpu=100m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-whcxr requesting resource cpu=0m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod blackbox-exporter-d6c46f9fc-f22mj requesting resource cpu=5m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod calico-node-gwqtg requesting resource cpu=100m on Node ip-10-250-0-144.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod calico-node-hbf5r requesting resource cpu=100m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod coredns-67df79bbdd-78l6g requesting resource cpu=50m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod kube-proxy-ckxln requesting resource cpu=20m on Node ip-10-250-0-144.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod kube-proxy-hjfzl requesting resource cpu=20m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod metrics-server-56d7786d8c-vpvx4 requesting resource cpu=20m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod node-exporter-sk9v2 requesting resource cpu=5m on Node ip-10-250-10-87.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod node-exporter-v62ww requesting resource cpu=5m on Node ip-10-250-0-144.eu-west-1.compute.internal
Feb 20 18:56:19.860: INFO: Pod vpn-shoot-8655cb5f7b-9pd79 requesting resource cpu=50m on Node ip-10-250-10-87.eu-west-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3585a964-3541-11e9-96fe-8e2b2e6369d7.158527694ad6a262], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-vsqc4/filler-pod-3585a964-3541-11e9-96fe-8e2b2e6369d7 to ip-10-250-10-87.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3585a964-3541-11e9-96fe-8e2b2e6369d7.1585276977c280fe], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3585a964-3541-11e9-96fe-8e2b2e6369d7.15852769a4424557], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3585a964-3541-11e9-96fe-8e2b2e6369d7.15852769a70b4319], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3585a964-3541-11e9-96fe-8e2b2e6369d7.15852769b018f60d], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-358c73bd-3541-11e9-96fe-8e2b2e6369d7.158527694d6db03e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-vsqc4/filler-pod-358c73bd-3541-11e9-96fe-8e2b2e6369d7 to ip-10-250-0-144.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-358c73bd-3541-11e9-96fe-8e2b2e6369d7.158527697618f219], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-358c73bd-3541-11e9-96fe-8e2b2e6369d7.1585276978a78246], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-358c73bd-3541-11e9-96fe-8e2b2e6369d7.158527698002b9a2], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1585276a4b06cc2c], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-250-0-144.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-250-10-87.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:56:25.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-vsqc4" for this suite.
Feb 20 18:56:31.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:56:31.801: INFO: namespace: e2e-tests-sched-pred-vsqc4, resource: bindings, ignored listing per whitelist
Feb 20 18:56:33.275: INFO: namespace e2e-tests-sched-pred-vsqc4 deletion completed in 7.727438909s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:15.682 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:56:33.275: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-qgfcv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-qgfcv
I0220 18:56:35.026390   30217 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-qgfcv, replica count: 1
I0220 18:56:36.076894   30217 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 18:56:37.077137   30217 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 18:56:37.223: INFO: Created: latency-svc-swwmp
Feb 20 18:56:37.228: INFO: Got endpoints: latency-svc-swwmp [51.509756ms]
Feb 20 18:56:37.275: INFO: Created: latency-svc-vnzq5
Feb 20 18:56:37.276: INFO: Got endpoints: latency-svc-vnzq5 [47.325851ms]
Feb 20 18:56:37.279: INFO: Created: latency-svc-hs6qc
Feb 20 18:56:37.282: INFO: Got endpoints: latency-svc-hs6qc [53.872483ms]
Feb 20 18:56:37.283: INFO: Created: latency-svc-fbcl2
Feb 20 18:56:37.286: INFO: Got endpoints: latency-svc-fbcl2 [57.684592ms]
Feb 20 18:56:37.286: INFO: Created: latency-svc-qwtvw
Feb 20 18:56:37.290: INFO: Got endpoints: latency-svc-qwtvw [61.63546ms]
Feb 20 18:56:37.290: INFO: Created: latency-svc-j8f6p
Feb 20 18:56:37.292: INFO: Got endpoints: latency-svc-j8f6p [63.001502ms]
Feb 20 18:56:37.295: INFO: Created: latency-svc-5ztq5
Feb 20 18:56:37.296: INFO: Got endpoints: latency-svc-5ztq5 [67.287251ms]
Feb 20 18:56:37.300: INFO: Created: latency-svc-rdq4s
Feb 20 18:56:37.301: INFO: Got endpoints: latency-svc-rdq4s [72.210636ms]
Feb 20 18:56:37.305: INFO: Created: latency-svc-hth5j
Feb 20 18:56:37.306: INFO: Got endpoints: latency-svc-hth5j [77.210769ms]
Feb 20 18:56:37.310: INFO: Created: latency-svc-qsfnm
Feb 20 18:56:37.313: INFO: Got endpoints: latency-svc-qsfnm [84.243638ms]
Feb 20 18:56:37.313: INFO: Created: latency-svc-jxv7c
Feb 20 18:56:37.314: INFO: Got endpoints: latency-svc-jxv7c [85.093228ms]
Feb 20 18:56:37.322: INFO: Created: latency-svc-57pk7
Feb 20 18:56:37.322: INFO: Got endpoints: latency-svc-57pk7 [92.949246ms]
Feb 20 18:56:37.322: INFO: Created: latency-svc-sfk8x
Feb 20 18:56:37.323: INFO: Got endpoints: latency-svc-sfk8x [94.127435ms]
Feb 20 18:56:37.327: INFO: Created: latency-svc-4g7pz
Feb 20 18:56:37.334: INFO: Created: latency-svc-dtjth
Feb 20 18:56:37.334: INFO: Got endpoints: latency-svc-4g7pz [105.537139ms]
Feb 20 18:56:37.336: INFO: Got endpoints: latency-svc-dtjth [107.659605ms]
Feb 20 18:56:37.339: INFO: Created: latency-svc-fr7lj
Feb 20 18:56:37.343: INFO: Created: latency-svc-wdsqg
Feb 20 18:56:37.343: INFO: Got endpoints: latency-svc-fr7lj [114.190236ms]
Feb 20 18:56:37.344: INFO: Got endpoints: latency-svc-wdsqg [68.34849ms]
Feb 20 18:56:37.347: INFO: Created: latency-svc-rdzn7
Feb 20 18:56:37.348: INFO: Got endpoints: latency-svc-rdzn7 [65.886542ms]
Feb 20 18:56:37.352: INFO: Created: latency-svc-wmbvr
Feb 20 18:56:37.354: INFO: Got endpoints: latency-svc-wmbvr [67.41335ms]
Feb 20 18:56:37.356: INFO: Created: latency-svc-6ld57
Feb 20 18:56:37.360: INFO: Created: latency-svc-ssfw7
Feb 20 18:56:37.360: INFO: Got endpoints: latency-svc-6ld57 [69.843982ms]
Feb 20 18:56:37.363: INFO: Created: latency-svc-8dwm2
Feb 20 18:56:37.364: INFO: Got endpoints: latency-svc-ssfw7 [72.056086ms]
Feb 20 18:56:37.367: INFO: Created: latency-svc-q7rbb
Feb 20 18:56:37.368: INFO: Got endpoints: latency-svc-8dwm2 [71.666129ms]
Feb 20 18:56:37.371: INFO: Created: latency-svc-pbjkw
Feb 20 18:56:37.376: INFO: Created: latency-svc-h95m5
Feb 20 18:56:37.380: INFO: Created: latency-svc-4cxzf
Feb 20 18:56:37.383: INFO: Created: latency-svc-974lm
Feb 20 18:56:37.387: INFO: Created: latency-svc-97z86
Feb 20 18:56:37.390: INFO: Created: latency-svc-fnnjw
Feb 20 18:56:37.394: INFO: Created: latency-svc-7shzp
Feb 20 18:56:37.399: INFO: Created: latency-svc-lsgd8
Feb 20 18:56:37.402: INFO: Created: latency-svc-6qljv
Feb 20 18:56:37.407: INFO: Created: latency-svc-snq6k
Feb 20 18:56:37.411: INFO: Created: latency-svc-hx4hm
Feb 20 18:56:37.415: INFO: Created: latency-svc-jdgsc
Feb 20 18:56:37.418: INFO: Created: latency-svc-r5kgn
Feb 20 18:56:37.422: INFO: Created: latency-svc-mpfrk
Feb 20 18:56:37.432: INFO: Got endpoints: latency-svc-q7rbb [131.318545ms]
Feb 20 18:56:37.443: INFO: Got endpoints: latency-svc-h95m5 [129.910213ms]
Feb 20 18:56:37.443: INFO: Got endpoints: latency-svc-pbjkw [137.006082ms]
Feb 20 18:56:37.478: INFO: Created: latency-svc-n8mtx
Feb 20 18:56:37.490: INFO: Created: latency-svc-g8xn7
Feb 20 18:56:37.494: INFO: Created: latency-svc-5g46q
Feb 20 18:56:37.532: INFO: Got endpoints: latency-svc-97z86 [209.167095ms]
Feb 20 18:56:37.532: INFO: Got endpoints: latency-svc-974lm [210.753146ms]
Feb 20 18:56:37.532: INFO: Got endpoints: latency-svc-4cxzf [218.681049ms]
Feb 20 18:56:37.533: INFO: Got endpoints: latency-svc-7shzp [196.161457ms]
Feb 20 18:56:37.533: INFO: Got endpoints: latency-svc-fnnjw [198.338478ms]
Feb 20 18:56:37.534: INFO: Got endpoints: latency-svc-6qljv [190.002251ms]
Feb 20 18:56:37.534: INFO: Got endpoints: latency-svc-lsgd8 [191.36702ms]
Feb 20 18:56:37.535: INFO: Got endpoints: latency-svc-hx4hm [181.177236ms]
Feb 20 18:56:37.535: INFO: Got endpoints: latency-svc-snq6k [186.865581ms]
Feb 20 18:56:37.535: INFO: Got endpoints: latency-svc-jdgsc [175.037043ms]
Feb 20 18:56:37.579: INFO: Created: latency-svc-plg5v
Feb 20 18:56:37.583: INFO: Created: latency-svc-4ngk7
Feb 20 18:56:37.587: INFO: Created: latency-svc-5ns7r
Feb 20 18:56:37.591: INFO: Created: latency-svc-c78bs
Feb 20 18:56:37.594: INFO: Created: latency-svc-phgpz
Feb 20 18:56:37.598: INFO: Created: latency-svc-cz9vj
Feb 20 18:56:37.602: INFO: Created: latency-svc-sbdqk
Feb 20 18:56:37.605: INFO: Created: latency-svc-b5fsk
Feb 20 18:56:37.610: INFO: Created: latency-svc-2qwmp
Feb 20 18:56:37.614: INFO: Created: latency-svc-fghzd
Feb 20 18:56:37.632: INFO: Got endpoints: latency-svc-r5kgn [268.424683ms]
Feb 20 18:56:37.632: INFO: Got endpoints: latency-svc-g8xn7 [189.533691ms]
Feb 20 18:56:37.633: INFO: Got endpoints: latency-svc-mpfrk [264.940935ms]
Feb 20 18:56:37.679: INFO: Created: latency-svc-g5jch
Feb 20 18:56:37.679: INFO: Got endpoints: latency-svc-n8mtx [246.342247ms]
Feb 20 18:56:37.682: INFO: Created: latency-svc-k58sg
Feb 20 18:56:37.686: INFO: Created: latency-svc-slh26
Feb 20 18:56:37.725: INFO: Created: latency-svc-rqsvm
Feb 20 18:56:37.726: INFO: Got endpoints: latency-svc-5g46q [283.301577ms]
Feb 20 18:56:37.772: INFO: Created: latency-svc-d67r7
Feb 20 18:56:37.776: INFO: Got endpoints: latency-svc-plg5v [244.386246ms]
Feb 20 18:56:37.823: INFO: Created: latency-svc-mjhkq
Feb 20 18:56:37.826: INFO: Got endpoints: latency-svc-4ngk7 [291.322335ms]
Feb 20 18:56:37.873: INFO: Created: latency-svc-tjwwk
Feb 20 18:56:37.876: INFO: Got endpoints: latency-svc-5ns7r [343.859128ms]
Feb 20 18:56:37.922: INFO: Created: latency-svc-mszjk
Feb 20 18:56:37.926: INFO: Got endpoints: latency-svc-c78bs [394.025406ms]
Feb 20 18:56:37.973: INFO: Created: latency-svc-jz8m7
Feb 20 18:56:37.977: INFO: Got endpoints: latency-svc-phgpz [444.010085ms]
Feb 20 18:56:38.023: INFO: Created: latency-svc-v5jkc
Feb 20 18:56:38.026: INFO: Got endpoints: latency-svc-cz9vj [493.637856ms]
Feb 20 18:56:38.074: INFO: Created: latency-svc-wpdhx
Feb 20 18:56:38.076: INFO: Got endpoints: latency-svc-sbdqk [541.886064ms]
Feb 20 18:56:38.122: INFO: Created: latency-svc-t7wkg
Feb 20 18:56:38.126: INFO: Got endpoints: latency-svc-b5fsk [592.040096ms]
Feb 20 18:56:38.174: INFO: Created: latency-svc-6x7tr
Feb 20 18:56:38.176: INFO: Got endpoints: latency-svc-2qwmp [641.349988ms]
Feb 20 18:56:38.223: INFO: Created: latency-svc-7fjj6
Feb 20 18:56:38.227: INFO: Got endpoints: latency-svc-fghzd [691.378867ms]
Feb 20 18:56:38.273: INFO: Created: latency-svc-d24rh
Feb 20 18:56:38.278: INFO: Got endpoints: latency-svc-g5jch [645.76815ms]
Feb 20 18:56:38.325: INFO: Created: latency-svc-pflcv
Feb 20 18:56:38.326: INFO: Got endpoints: latency-svc-k58sg [693.858568ms]
Feb 20 18:56:38.372: INFO: Created: latency-svc-qj5xf
Feb 20 18:56:38.376: INFO: Got endpoints: latency-svc-slh26 [743.937729ms]
Feb 20 18:56:38.423: INFO: Created: latency-svc-zjpd6
Feb 20 18:56:38.427: INFO: Got endpoints: latency-svc-rqsvm [747.896932ms]
Feb 20 18:56:38.473: INFO: Created: latency-svc-bbxpj
Feb 20 18:56:38.476: INFO: Got endpoints: latency-svc-d67r7 [750.164884ms]
Feb 20 18:56:38.523: INFO: Created: latency-svc-vq2vf
Feb 20 18:56:38.526: INFO: Got endpoints: latency-svc-mjhkq [750.061703ms]
Feb 20 18:56:38.573: INFO: Created: latency-svc-8pcg7
Feb 20 18:56:38.576: INFO: Got endpoints: latency-svc-tjwwk [749.81867ms]
Feb 20 18:56:38.622: INFO: Created: latency-svc-6hwrq
Feb 20 18:56:38.627: INFO: Got endpoints: latency-svc-mszjk [750.229057ms]
Feb 20 18:56:38.674: INFO: Created: latency-svc-6jbxt
Feb 20 18:56:38.676: INFO: Got endpoints: latency-svc-jz8m7 [749.929098ms]
Feb 20 18:56:38.723: INFO: Created: latency-svc-tf6p2
Feb 20 18:56:38.727: INFO: Got endpoints: latency-svc-v5jkc [750.223994ms]
Feb 20 18:56:38.774: INFO: Created: latency-svc-926d2
Feb 20 18:56:38.777: INFO: Got endpoints: latency-svc-wpdhx [750.597689ms]
Feb 20 18:56:38.823: INFO: Created: latency-svc-fxw2s
Feb 20 18:56:38.826: INFO: Got endpoints: latency-svc-t7wkg [750.12233ms]
Feb 20 18:56:38.873: INFO: Created: latency-svc-kpcjx
Feb 20 18:56:38.876: INFO: Got endpoints: latency-svc-6x7tr [750.093445ms]
Feb 20 18:56:38.923: INFO: Created: latency-svc-5xscc
Feb 20 18:56:38.926: INFO: Got endpoints: latency-svc-7fjj6 [750.054715ms]
Feb 20 18:56:38.973: INFO: Created: latency-svc-j58k7
Feb 20 18:56:38.976: INFO: Got endpoints: latency-svc-d24rh [749.866983ms]
Feb 20 18:56:39.051: INFO: Created: latency-svc-x29nh
Feb 20 18:56:39.053: INFO: Got endpoints: latency-svc-pflcv [775.336652ms]
Feb 20 18:56:39.077: INFO: Got endpoints: latency-svc-qj5xf [751.128382ms]
Feb 20 18:56:39.153: INFO: Got endpoints: latency-svc-zjpd6 [776.005211ms]
Feb 20 18:56:39.157: INFO: Created: latency-svc-sz7ht
Feb 20 18:56:39.161: INFO: Created: latency-svc-z2vz8
Feb 20 18:56:39.176: INFO: Got endpoints: latency-svc-bbxpj [749.660626ms]
Feb 20 18:56:39.199: INFO: Created: latency-svc-2jbt9
Feb 20 18:56:39.222: INFO: Created: latency-svc-bt4dm
Feb 20 18:56:39.226: INFO: Got endpoints: latency-svc-vq2vf [749.914035ms]
Feb 20 18:56:39.273: INFO: Created: latency-svc-qzdz6
Feb 20 18:56:39.276: INFO: Got endpoints: latency-svc-8pcg7 [749.874692ms]
Feb 20 18:56:39.323: INFO: Created: latency-svc-5j57x
Feb 20 18:56:39.326: INFO: Got endpoints: latency-svc-6hwrq [750.049911ms]
Feb 20 18:56:39.376: INFO: Created: latency-svc-zfcqp
Feb 20 18:56:39.376: INFO: Got endpoints: latency-svc-6jbxt [749.89821ms]
Feb 20 18:56:39.426: INFO: Created: latency-svc-b4jfl
Feb 20 18:56:39.426: INFO: Got endpoints: latency-svc-tf6p2 [749.992516ms]
Feb 20 18:56:39.473: INFO: Created: latency-svc-ldt8g
Feb 20 18:56:39.477: INFO: Got endpoints: latency-svc-926d2 [749.609733ms]
Feb 20 18:56:39.525: INFO: Created: latency-svc-msfsv
Feb 20 18:56:39.526: INFO: Got endpoints: latency-svc-fxw2s [749.386515ms]
Feb 20 18:56:39.573: INFO: Created: latency-svc-h46cv
Feb 20 18:56:39.577: INFO: Got endpoints: latency-svc-kpcjx [750.915131ms]
Feb 20 18:56:39.624: INFO: Created: latency-svc-nmz7s
Feb 20 18:56:39.636: INFO: Got endpoints: latency-svc-5xscc [759.788719ms]
Feb 20 18:56:39.677: INFO: Got endpoints: latency-svc-j58k7 [750.510361ms]
Feb 20 18:56:39.683: INFO: Created: latency-svc-k5gjz
Feb 20 18:56:39.725: INFO: Created: latency-svc-r4j67
Feb 20 18:56:39.726: INFO: Got endpoints: latency-svc-x29nh [749.858496ms]
Feb 20 18:56:39.773: INFO: Created: latency-svc-hs6nd
Feb 20 18:56:39.777: INFO: Got endpoints: latency-svc-sz7ht [723.17117ms]
Feb 20 18:56:39.823: INFO: Created: latency-svc-w2rfb
Feb 20 18:56:39.826: INFO: Got endpoints: latency-svc-z2vz8 [748.822475ms]
Feb 20 18:56:39.874: INFO: Created: latency-svc-84g2b
Feb 20 18:56:39.876: INFO: Got endpoints: latency-svc-2jbt9 [723.743979ms]
Feb 20 18:56:39.923: INFO: Created: latency-svc-nxg2l
Feb 20 18:56:39.926: INFO: Got endpoints: latency-svc-bt4dm [750.125444ms]
Feb 20 18:56:39.973: INFO: Created: latency-svc-mqbm7
Feb 20 18:56:39.976: INFO: Got endpoints: latency-svc-qzdz6 [750.062879ms]
Feb 20 18:56:40.024: INFO: Created: latency-svc-zwlmr
Feb 20 18:56:40.027: INFO: Got endpoints: latency-svc-5j57x [750.255085ms]
Feb 20 18:56:40.074: INFO: Created: latency-svc-qsx87
Feb 20 18:56:40.076: INFO: Got endpoints: latency-svc-zfcqp [750.000562ms]
Feb 20 18:56:40.123: INFO: Created: latency-svc-4zr2x
Feb 20 18:56:40.127: INFO: Got endpoints: latency-svc-b4jfl [750.28115ms]
Feb 20 18:56:40.173: INFO: Created: latency-svc-prbtm
Feb 20 18:56:40.176: INFO: Got endpoints: latency-svc-ldt8g [749.90779ms]
Feb 20 18:56:40.223: INFO: Created: latency-svc-69w9v
Feb 20 18:56:40.227: INFO: Got endpoints: latency-svc-msfsv [749.944628ms]
Feb 20 18:56:40.274: INFO: Created: latency-svc-6rhc8
Feb 20 18:56:40.276: INFO: Got endpoints: latency-svc-h46cv [750.074763ms]
Feb 20 18:56:40.323: INFO: Created: latency-svc-t4rtm
Feb 20 18:56:40.326: INFO: Got endpoints: latency-svc-nmz7s [749.112919ms]
Feb 20 18:56:40.372: INFO: Created: latency-svc-6fqsd
Feb 20 18:56:40.377: INFO: Got endpoints: latency-svc-k5gjz [740.526342ms]
Feb 20 18:56:40.423: INFO: Created: latency-svc-jxc7d
Feb 20 18:56:40.426: INFO: Got endpoints: latency-svc-r4j67 [749.279552ms]
Feb 20 18:56:40.473: INFO: Created: latency-svc-xrsw2
Feb 20 18:56:40.476: INFO: Got endpoints: latency-svc-hs6nd [749.78806ms]
Feb 20 18:56:40.523: INFO: Created: latency-svc-g4hlq
Feb 20 18:56:40.526: INFO: Got endpoints: latency-svc-w2rfb [749.785777ms]
Feb 20 18:56:40.576: INFO: Created: latency-svc-nnw5q
Feb 20 18:56:40.577: INFO: Got endpoints: latency-svc-84g2b [750.250704ms]
Feb 20 18:56:40.624: INFO: Created: latency-svc-smlnb
Feb 20 18:56:40.626: INFO: Got endpoints: latency-svc-nxg2l [749.851691ms]
Feb 20 18:56:40.677: INFO: Got endpoints: latency-svc-mqbm7 [750.794197ms]
Feb 20 18:56:40.677: INFO: Created: latency-svc-8h6xt
Feb 20 18:56:40.724: INFO: Created: latency-svc-swd66
Feb 20 18:56:40.727: INFO: Got endpoints: latency-svc-zwlmr [750.046413ms]
Feb 20 18:56:40.774: INFO: Created: latency-svc-m4hkf
Feb 20 18:56:40.777: INFO: Got endpoints: latency-svc-qsx87 [749.891568ms]
Feb 20 18:56:40.823: INFO: Created: latency-svc-kp7jm
Feb 20 18:56:40.826: INFO: Got endpoints: latency-svc-4zr2x [749.856487ms]
Feb 20 18:56:40.873: INFO: Created: latency-svc-snfz8
Feb 20 18:56:40.876: INFO: Got endpoints: latency-svc-prbtm [749.290035ms]
Feb 20 18:56:40.923: INFO: Created: latency-svc-6689n
Feb 20 18:56:40.927: INFO: Got endpoints: latency-svc-69w9v [750.182303ms]
Feb 20 18:56:40.973: INFO: Created: latency-svc-5sbt5
Feb 20 18:56:40.977: INFO: Got endpoints: latency-svc-6rhc8 [750.058616ms]
Feb 20 18:56:41.024: INFO: Created: latency-svc-sp7wr
Feb 20 18:56:41.028: INFO: Got endpoints: latency-svc-t4rtm [751.071267ms]
Feb 20 18:56:41.075: INFO: Created: latency-svc-8kz9s
Feb 20 18:56:41.076: INFO: Got endpoints: latency-svc-6fqsd [749.7164ms]
Feb 20 18:56:41.123: INFO: Created: latency-svc-6rv8f
Feb 20 18:56:41.127: INFO: Got endpoints: latency-svc-jxc7d [750.441563ms]
Feb 20 18:56:41.174: INFO: Created: latency-svc-dfqbj
Feb 20 18:56:41.176: INFO: Got endpoints: latency-svc-xrsw2 [750.171059ms]
Feb 20 18:56:41.223: INFO: Created: latency-svc-rgbvc
Feb 20 18:56:41.226: INFO: Got endpoints: latency-svc-g4hlq [750.175496ms]
Feb 20 18:56:41.273: INFO: Created: latency-svc-75fd4
Feb 20 18:56:41.276: INFO: Got endpoints: latency-svc-nnw5q [750.010867ms]
Feb 20 18:56:41.323: INFO: Created: latency-svc-8pvm7
Feb 20 18:56:41.326: INFO: Got endpoints: latency-svc-smlnb [749.597511ms]
Feb 20 18:56:41.373: INFO: Created: latency-svc-bz8td
Feb 20 18:56:41.376: INFO: Got endpoints: latency-svc-8h6xt [749.896683ms]
Feb 20 18:56:41.423: INFO: Created: latency-svc-zwrdn
Feb 20 18:56:41.426: INFO: Got endpoints: latency-svc-swd66 [748.904305ms]
Feb 20 18:56:41.472: INFO: Created: latency-svc-8lnf8
Feb 20 18:56:41.476: INFO: Got endpoints: latency-svc-m4hkf [749.387282ms]
Feb 20 18:56:41.522: INFO: Created: latency-svc-8vdm5
Feb 20 18:56:41.526: INFO: Got endpoints: latency-svc-kp7jm [749.596265ms]
Feb 20 18:56:41.572: INFO: Created: latency-svc-kwv25
Feb 20 18:56:41.576: INFO: Got endpoints: latency-svc-snfz8 [749.885582ms]
Feb 20 18:56:41.623: INFO: Created: latency-svc-5gnfx
Feb 20 18:56:41.627: INFO: Got endpoints: latency-svc-6689n [750.476173ms]
Feb 20 18:56:41.673: INFO: Created: latency-svc-b4ngc
Feb 20 18:56:41.676: INFO: Got endpoints: latency-svc-5sbt5 [749.628827ms]
Feb 20 18:56:41.723: INFO: Created: latency-svc-7j8f4
Feb 20 18:56:41.727: INFO: Got endpoints: latency-svc-sp7wr [750.07676ms]
Feb 20 18:56:41.773: INFO: Created: latency-svc-sjp76
Feb 20 18:56:41.776: INFO: Got endpoints: latency-svc-8kz9s [748.618342ms]
Feb 20 18:56:41.827: INFO: Got endpoints: latency-svc-6rv8f [750.50371ms]
Feb 20 18:56:41.827: INFO: Created: latency-svc-bz927
Feb 20 18:56:41.873: INFO: Created: latency-svc-xrgck
Feb 20 18:56:41.876: INFO: Got endpoints: latency-svc-dfqbj [749.021852ms]
Feb 20 18:56:41.926: INFO: Created: latency-svc-ctzlx
Feb 20 18:56:41.926: INFO: Got endpoints: latency-svc-rgbvc [749.887545ms]
Feb 20 18:56:41.973: INFO: Created: latency-svc-9cwmp
Feb 20 18:56:41.977: INFO: Got endpoints: latency-svc-75fd4 [750.085867ms]
Feb 20 18:56:42.024: INFO: Created: latency-svc-hj2lj
Feb 20 18:56:42.032: INFO: Got endpoints: latency-svc-8pvm7 [755.376117ms]
Feb 20 18:56:42.079: INFO: Created: latency-svc-dh49z
Feb 20 18:56:42.079: INFO: Got endpoints: latency-svc-bz8td [752.847165ms]
Feb 20 18:56:42.126: INFO: Created: latency-svc-ktdpj
Feb 20 18:56:42.127: INFO: Got endpoints: latency-svc-zwrdn [751.087274ms]
Feb 20 18:56:42.174: INFO: Created: latency-svc-px4c5
Feb 20 18:56:42.176: INFO: Got endpoints: latency-svc-8lnf8 [749.738424ms]
Feb 20 18:56:42.224: INFO: Created: latency-svc-2mmqx
Feb 20 18:56:42.226: INFO: Got endpoints: latency-svc-8vdm5 [750.391318ms]
Feb 20 18:56:42.273: INFO: Created: latency-svc-kztsw
Feb 20 18:56:42.276: INFO: Got endpoints: latency-svc-kwv25 [750.056528ms]
Feb 20 18:56:42.324: INFO: Created: latency-svc-jpv4f
Feb 20 18:56:42.327: INFO: Got endpoints: latency-svc-5gnfx [750.970147ms]
Feb 20 18:56:42.374: INFO: Created: latency-svc-gr9sn
Feb 20 18:56:42.376: INFO: Got endpoints: latency-svc-b4ngc [749.802214ms]
Feb 20 18:56:42.423: INFO: Created: latency-svc-z56w4
Feb 20 18:56:42.427: INFO: Got endpoints: latency-svc-7j8f4 [750.143397ms]
Feb 20 18:56:42.473: INFO: Created: latency-svc-cfd7b
Feb 20 18:56:42.477: INFO: Got endpoints: latency-svc-sjp76 [749.807186ms]
Feb 20 18:56:42.523: INFO: Created: latency-svc-dxghj
Feb 20 18:56:42.527: INFO: Got endpoints: latency-svc-bz927 [750.50357ms]
Feb 20 18:56:42.573: INFO: Created: latency-svc-zr8cz
Feb 20 18:56:42.576: INFO: Got endpoints: latency-svc-xrgck [749.5665ms]
Feb 20 18:56:42.623: INFO: Created: latency-svc-j8lcq
Feb 20 18:56:42.626: INFO: Got endpoints: latency-svc-ctzlx [749.666617ms]
Feb 20 18:56:42.673: INFO: Created: latency-svc-8cvbr
Feb 20 18:56:42.676: INFO: Got endpoints: latency-svc-9cwmp [749.853438ms]
Feb 20 18:56:42.723: INFO: Created: latency-svc-f6nw2
Feb 20 18:56:42.727: INFO: Got endpoints: latency-svc-hj2lj [750.504404ms]
Feb 20 18:56:42.773: INFO: Created: latency-svc-hjt8f
Feb 20 18:56:42.777: INFO: Got endpoints: latency-svc-dh49z [744.656935ms]
Feb 20 18:56:42.824: INFO: Created: latency-svc-dzgqz
Feb 20 18:56:42.826: INFO: Got endpoints: latency-svc-ktdpj [747.015572ms]
Feb 20 18:56:42.873: INFO: Created: latency-svc-rcpr6
Feb 20 18:56:42.876: INFO: Got endpoints: latency-svc-px4c5 [748.998373ms]
Feb 20 18:56:42.923: INFO: Created: latency-svc-2nsfl
Feb 20 18:56:42.926: INFO: Got endpoints: latency-svc-2mmqx [750.334947ms]
Feb 20 18:56:42.973: INFO: Created: latency-svc-48xft
Feb 20 18:56:42.976: INFO: Got endpoints: latency-svc-kztsw [749.900994ms]
Feb 20 18:56:43.026: INFO: Created: latency-svc-9x4sb
Feb 20 18:56:43.026: INFO: Got endpoints: latency-svc-jpv4f [749.950846ms]
Feb 20 18:56:43.076: INFO: Created: latency-svc-sb6r8
Feb 20 18:56:43.076: INFO: Got endpoints: latency-svc-gr9sn [749.017582ms]
Feb 20 18:56:43.122: INFO: Created: latency-svc-sx5db
Feb 20 18:56:43.126: INFO: Got endpoints: latency-svc-z56w4 [749.837721ms]
Feb 20 18:56:43.176: INFO: Created: latency-svc-6qnqx
Feb 20 18:56:43.176: INFO: Got endpoints: latency-svc-cfd7b [749.76716ms]
Feb 20 18:56:43.222: INFO: Created: latency-svc-889t7
Feb 20 18:56:43.226: INFO: Got endpoints: latency-svc-dxghj [749.637327ms]
Feb 20 18:56:43.272: INFO: Created: latency-svc-9j8vs
Feb 20 18:56:43.280: INFO: Got endpoints: latency-svc-zr8cz [752.828427ms]
Feb 20 18:56:43.326: INFO: Created: latency-svc-gdbkd
Feb 20 18:56:43.327: INFO: Got endpoints: latency-svc-j8lcq [750.81739ms]
Feb 20 18:56:43.374: INFO: Created: latency-svc-mbnw4
Feb 20 18:56:43.376: INFO: Got endpoints: latency-svc-8cvbr [750.173926ms]
Feb 20 18:56:43.424: INFO: Created: latency-svc-lxx62
Feb 20 18:56:43.427: INFO: Got endpoints: latency-svc-f6nw2 [750.375337ms]
Feb 20 18:56:43.475: INFO: Created: latency-svc-455tw
Feb 20 18:56:43.477: INFO: Got endpoints: latency-svc-hjt8f [750.299005ms]
Feb 20 18:56:43.524: INFO: Created: latency-svc-bmzn7
Feb 20 18:56:43.528: INFO: Got endpoints: latency-svc-dzgqz [751.441882ms]
Feb 20 18:56:43.576: INFO: Created: latency-svc-l5btj
Feb 20 18:56:43.577: INFO: Got endpoints: latency-svc-rcpr6 [750.190319ms]
Feb 20 18:56:43.623: INFO: Created: latency-svc-7b6m9
Feb 20 18:56:43.626: INFO: Got endpoints: latency-svc-2nsfl [749.843269ms]
Feb 20 18:56:43.673: INFO: Created: latency-svc-tpzsz
Feb 20 18:56:43.676: INFO: Got endpoints: latency-svc-48xft [749.953653ms]
Feb 20 18:56:43.724: INFO: Created: latency-svc-c6r8m
Feb 20 18:56:43.726: INFO: Got endpoints: latency-svc-9x4sb [749.96388ms]
Feb 20 18:56:43.774: INFO: Created: latency-svc-kztwq
Feb 20 18:56:43.777: INFO: Got endpoints: latency-svc-sb6r8 [750.285353ms]
Feb 20 18:56:43.825: INFO: Created: latency-svc-wd7zb
Feb 20 18:56:43.826: INFO: Got endpoints: latency-svc-sx5db [749.920365ms]
Feb 20 18:56:43.873: INFO: Created: latency-svc-vs6zb
Feb 20 18:56:43.876: INFO: Got endpoints: latency-svc-6qnqx [749.962191ms]
Feb 20 18:56:43.923: INFO: Created: latency-svc-gtl4f
Feb 20 18:56:43.926: INFO: Got endpoints: latency-svc-889t7 [749.99745ms]
Feb 20 18:56:43.973: INFO: Created: latency-svc-8t9s5
Feb 20 18:56:43.976: INFO: Got endpoints: latency-svc-9j8vs [749.978185ms]
Feb 20 18:56:44.023: INFO: Created: latency-svc-pnlwq
Feb 20 18:56:44.026: INFO: Got endpoints: latency-svc-gdbkd [746.787658ms]
Feb 20 18:56:44.073: INFO: Created: latency-svc-nh69l
Feb 20 18:56:44.077: INFO: Got endpoints: latency-svc-mbnw4 [749.603468ms]
Feb 20 18:56:44.124: INFO: Created: latency-svc-x5whl
Feb 20 18:56:44.126: INFO: Got endpoints: latency-svc-lxx62 [749.937605ms]
Feb 20 18:56:44.174: INFO: Created: latency-svc-t95pd
Feb 20 18:56:44.176: INFO: Got endpoints: latency-svc-455tw [749.456574ms]
Feb 20 18:56:44.223: INFO: Created: latency-svc-gppr5
Feb 20 18:56:44.226: INFO: Got endpoints: latency-svc-bmzn7 [748.994383ms]
Feb 20 18:56:44.273: INFO: Created: latency-svc-zgnls
Feb 20 18:56:44.277: INFO: Got endpoints: latency-svc-l5btj [748.526289ms]
Feb 20 18:56:44.326: INFO: Created: latency-svc-hgl42
Feb 20 18:56:44.327: INFO: Got endpoints: latency-svc-7b6m9 [750.905571ms]
Feb 20 18:56:44.375: INFO: Created: latency-svc-c25z4
Feb 20 18:56:44.376: INFO: Got endpoints: latency-svc-tpzsz [749.988339ms]
Feb 20 18:56:44.425: INFO: Created: latency-svc-l5bzb
Feb 20 18:56:44.426: INFO: Got endpoints: latency-svc-c6r8m [749.845088ms]
Feb 20 18:56:44.474: INFO: Created: latency-svc-mzqxz
Feb 20 18:56:44.477: INFO: Got endpoints: latency-svc-kztwq [750.693913ms]
Feb 20 18:56:44.524: INFO: Created: latency-svc-kmzmq
Feb 20 18:56:44.530: INFO: Got endpoints: latency-svc-wd7zb [752.659326ms]
Feb 20 18:56:44.577: INFO: Created: latency-svc-kf4ks
Feb 20 18:56:44.577: INFO: Got endpoints: latency-svc-vs6zb [750.786136ms]
Feb 20 18:56:44.623: INFO: Created: latency-svc-8vj6c
Feb 20 18:56:44.626: INFO: Got endpoints: latency-svc-gtl4f [749.997152ms]
Feb 20 18:56:44.673: INFO: Created: latency-svc-k78l2
Feb 20 18:56:44.676: INFO: Got endpoints: latency-svc-8t9s5 [749.790748ms]
Feb 20 18:56:44.722: INFO: Created: latency-svc-lt2sq
Feb 20 18:56:44.727: INFO: Got endpoints: latency-svc-pnlwq [750.068506ms]
Feb 20 18:56:44.773: INFO: Created: latency-svc-qmnqh
Feb 20 18:56:44.777: INFO: Got endpoints: latency-svc-nh69l [750.182746ms]
Feb 20 18:56:44.823: INFO: Created: latency-svc-szvn6
Feb 20 18:56:44.826: INFO: Got endpoints: latency-svc-x5whl [749.175994ms]
Feb 20 18:56:44.874: INFO: Created: latency-svc-ss4fb
Feb 20 18:56:44.876: INFO: Got endpoints: latency-svc-t95pd [749.768526ms]
Feb 20 18:56:44.923: INFO: Created: latency-svc-66gjn
Feb 20 18:56:44.926: INFO: Got endpoints: latency-svc-gppr5 [750.242652ms]
Feb 20 18:56:44.974: INFO: Created: latency-svc-2bgk9
Feb 20 18:56:44.976: INFO: Got endpoints: latency-svc-zgnls [749.845695ms]
Feb 20 18:56:45.023: INFO: Created: latency-svc-bf7qr
Feb 20 18:56:45.026: INFO: Got endpoints: latency-svc-hgl42 [749.732746ms]
Feb 20 18:56:45.073: INFO: Created: latency-svc-rp4nm
Feb 20 18:56:45.076: INFO: Got endpoints: latency-svc-c25z4 [748.755156ms]
Feb 20 18:56:45.127: INFO: Got endpoints: latency-svc-l5bzb [750.710767ms]
Feb 20 18:56:45.177: INFO: Got endpoints: latency-svc-mzqxz [750.6197ms]
Feb 20 18:56:45.227: INFO: Got endpoints: latency-svc-kmzmq [749.880967ms]
Feb 20 18:56:45.277: INFO: Got endpoints: latency-svc-kf4ks [747.182623ms]
Feb 20 18:56:45.327: INFO: Got endpoints: latency-svc-8vj6c [749.927437ms]
Feb 20 18:56:45.378: INFO: Got endpoints: latency-svc-k78l2 [751.07116ms]
Feb 20 18:56:45.427: INFO: Got endpoints: latency-svc-lt2sq [750.378016ms]
Feb 20 18:56:45.477: INFO: Got endpoints: latency-svc-qmnqh [750.305794ms]
Feb 20 18:56:45.527: INFO: Got endpoints: latency-svc-szvn6 [750.164353ms]
Feb 20 18:56:45.578: INFO: Got endpoints: latency-svc-ss4fb [751.527221ms]
Feb 20 18:56:45.631: INFO: Got endpoints: latency-svc-66gjn [754.395515ms]
Feb 20 18:56:45.677: INFO: Got endpoints: latency-svc-2bgk9 [750.611692ms]
Feb 20 18:56:45.728: INFO: Got endpoints: latency-svc-bf7qr [751.953737ms]
Feb 20 18:56:45.777: INFO: Got endpoints: latency-svc-rp4nm [750.558005ms]
Feb 20 18:56:45.777: INFO: Latencies: [47.325851ms 53.872483ms 57.684592ms 61.63546ms 63.001502ms 65.886542ms 67.287251ms 67.41335ms 68.34849ms 69.843982ms 71.666129ms 72.056086ms 72.210636ms 77.210769ms 84.243638ms 85.093228ms 92.949246ms 94.127435ms 105.537139ms 107.659605ms 114.190236ms 129.910213ms 131.318545ms 137.006082ms 175.037043ms 181.177236ms 186.865581ms 189.533691ms 190.002251ms 191.36702ms 196.161457ms 198.338478ms 209.167095ms 210.753146ms 218.681049ms 244.386246ms 246.342247ms 264.940935ms 268.424683ms 283.301577ms 291.322335ms 343.859128ms 394.025406ms 444.010085ms 493.637856ms 541.886064ms 592.040096ms 641.349988ms 645.76815ms 691.378867ms 693.858568ms 723.17117ms 723.743979ms 740.526342ms 743.937729ms 744.656935ms 746.787658ms 747.015572ms 747.182623ms 747.896932ms 748.526289ms 748.618342ms 748.755156ms 748.822475ms 748.904305ms 748.994383ms 748.998373ms 749.017582ms 749.021852ms 749.112919ms 749.175994ms 749.279552ms 749.290035ms 749.386515ms 749.387282ms 749.456574ms 749.5665ms 749.596265ms 749.597511ms 749.603468ms 749.609733ms 749.628827ms 749.637327ms 749.660626ms 749.666617ms 749.7164ms 749.732746ms 749.738424ms 749.76716ms 749.768526ms 749.785777ms 749.78806ms 749.790748ms 749.802214ms 749.807186ms 749.81867ms 749.837721ms 749.843269ms 749.845088ms 749.845695ms 749.851691ms 749.853438ms 749.856487ms 749.858496ms 749.866983ms 749.874692ms 749.880967ms 749.885582ms 749.887545ms 749.891568ms 749.896683ms 749.89821ms 749.900994ms 749.90779ms 749.914035ms 749.920365ms 749.927437ms 749.929098ms 749.937605ms 749.944628ms 749.950846ms 749.953653ms 749.962191ms 749.96388ms 749.978185ms 749.988339ms 749.992516ms 749.997152ms 749.99745ms 750.000562ms 750.010867ms 750.046413ms 750.049911ms 750.054715ms 750.056528ms 750.058616ms 750.061703ms 750.062879ms 750.068506ms 750.074763ms 750.07676ms 750.085867ms 750.093445ms 750.12233ms 750.125444ms 750.143397ms 750.164353ms 750.164884ms 750.171059ms 750.173926ms 750.175496ms 750.182303ms 750.182746ms 750.190319ms 750.223994ms 750.229057ms 750.242652ms 750.250704ms 750.255085ms 750.28115ms 750.285353ms 750.299005ms 750.305794ms 750.334947ms 750.375337ms 750.378016ms 750.391318ms 750.441563ms 750.476173ms 750.50357ms 750.50371ms 750.504404ms 750.510361ms 750.558005ms 750.597689ms 750.611692ms 750.6197ms 750.693913ms 750.710767ms 750.786136ms 750.794197ms 750.81739ms 750.905571ms 750.915131ms 750.970147ms 751.07116ms 751.071267ms 751.087274ms 751.128382ms 751.441882ms 751.527221ms 751.953737ms 752.659326ms 752.828427ms 752.847165ms 754.395515ms 755.376117ms 759.788719ms 775.336652ms 776.005211ms]
Feb 20 18:56:45.777: INFO: 50 %ile: 749.851691ms
Feb 20 18:56:45.777: INFO: 90 %ile: 750.794197ms
Feb 20 18:56:45.777: INFO: 99 %ile: 775.336652ms
Feb 20 18:56:45.777: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:56:45.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-qgfcv" for this suite.
Feb 20 18:57:05.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:57:06.247: INFO: namespace: e2e-tests-svc-latency-qgfcv, resource: bindings, ignored listing per whitelist
Feb 20 18:57:07.663: INFO: namespace e2e-tests-svc-latency-qgfcv deletion completed in 21.843199275s

• [SLOW TEST:34.389 seconds]
[sig-network] Service endpoints latency
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:57:07.664: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-4rq8f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:57:09.369: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:57:11.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4rq8f" for this suite.
Feb 20 18:57:54.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:57:54.674: INFO: namespace: e2e-tests-pods-4rq8f, resource: bindings, ignored listing per whitelist
Feb 20 18:57:55.728: INFO: namespace e2e-tests-pods-4rq8f deletion completed in 43.731416084s

• [SLOW TEST:48.064 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:57:55.728: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-slg8v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 20 18:58:07.763: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:58:07.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-slg8v" for this suite.
Feb 20 18:58:30.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:58:31.170: INFO: namespace: e2e-tests-replicaset-slg8v, resource: bindings, ignored listing per whitelist
Feb 20 18:58:31.851: INFO: namespace e2e-tests-replicaset-slg8v deletion completed in 23.916315385s

• [SLOW TEST:36.122 seconds]
[sig-apps] ReplicaSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:58:31.851: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-v4p8b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 20 18:58:33.569: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:58:33.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v4p8b" for this suite.
Feb 20 18:58:39.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:58:40.616: INFO: namespace: e2e-tests-kubectl-v4p8b, resource: bindings, ignored listing per whitelist
Feb 20 18:58:41.625: INFO: namespace e2e-tests-kubectl-v4p8b deletion completed in 7.768895788s

• [SLOW TEST:9.774 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:58:41.625: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tsc7l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8b0f2aa3-3541-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 18:58:43.455: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b15a92d-3541-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-tsc7l" to be "success or failure"
Feb 20 18:58:43.497: INFO: Pod "pod-projected-configmaps-8b15a92d-3541-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.175762ms
Feb 20 18:58:45.541: INFO: Pod "pod-projected-configmaps-8b15a92d-3541-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085527243s
STEP: Saw pod success
Feb 20 18:58:45.541: INFO: Pod "pod-projected-configmaps-8b15a92d-3541-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 18:58:45.583: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-configmaps-8b15a92d-3541-11e9-96fe-8e2b2e6369d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:58:45.676: INFO: Waiting for pod pod-projected-configmaps-8b15a92d-3541-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 18:58:45.719: INFO: Pod pod-projected-configmaps-8b15a92d-3541-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 18:58:45.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tsc7l" for this suite.
Feb 20 18:58:51.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:58:52.491: INFO: namespace: e2e-tests-projected-tsc7l, resource: bindings, ignored listing per whitelist
Feb 20 18:58:53.570: INFO: namespace e2e-tests-projected-tsc7l deletion completed in 7.807380012s

• [SLOW TEST:11.945 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 18:58:53.570: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-gcf8s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:58:55.481: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 20 18:58:55.566: INFO: Number of nodes with available pods: 0
Feb 20 18:58:55.566: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 20 18:58:55.736: INFO: Number of nodes with available pods: 0
Feb 20 18:58:55.736: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:58:56.778: INFO: Number of nodes with available pods: 1
Feb 20 18:58:56.779: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 20 18:58:56.952: INFO: Number of nodes with available pods: 0
Feb 20 18:58:56.952: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 20 18:58:57.041: INFO: Number of nodes with available pods: 0
Feb 20 18:58:57.041: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:58:58.083: INFO: Number of nodes with available pods: 0
Feb 20 18:58:58.083: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:58:59.083: INFO: Number of nodes with available pods: 0
Feb 20 18:58:59.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:00.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:00.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:01.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:01.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:02.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:02.083: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:03.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:03.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:04.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:04.083: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:05.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:05.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:06.087: INFO: Number of nodes with available pods: 0
Feb 20 18:59:06.087: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:07.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:07.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:08.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:08.083: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:09.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:09.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:10.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:10.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:11.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:11.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:12.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:12.083: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:13.093: INFO: Number of nodes with available pods: 0
Feb 20 18:59:13.093: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:14.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:14.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:15.086: INFO: Number of nodes with available pods: 0
Feb 20 18:59:15.086: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:16.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:16.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:17.085: INFO: Number of nodes with available pods: 0
Feb 20 18:59:17.085: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:18.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:18.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:19.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:19.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:20.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:20.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:21.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:21.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:22.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:22.083: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:23.090: INFO: Number of nodes with available pods: 0
Feb 20 18:59:23.090: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:24.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:24.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:25.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:25.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:26.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:26.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:27.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:27.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:28.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:28.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:29.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:29.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:30.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:30.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:31.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:31.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:32.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:32.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:33.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:33.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:34.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:34.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:35.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:35.083: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:36.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:36.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:37.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:37.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:38.085: INFO: Number of nodes with available pods: 0
Feb 20 18:59:38.085: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:39.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:39.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:40.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:40.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:41.083: INFO: Number of nodes with available pods: 0
Feb 20 18:59:41.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:42.084: INFO: Number of nodes with available pods: 0
Feb 20 18:59:42.084: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:43.083: INFO: Number of nodes with available pods: 1
Feb 20 18:59:43.083: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-gcf8s, will wait for the garbage collector to delete the pods
Feb 20 18:59:43.309: INFO: Deleting DaemonSet.extensions daemon-set took: 43.726048ms
Feb 20 18:59:43.409: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.297368ms
Feb 20 19:00:21.452: INFO: Number of nodes with available pods: 0
Feb 20 19:00:21.453: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 19:00:21.495: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gcf8s/daemonsets","resourceVersion":"12260"},"items":null}

Feb 20 19:00:21.537: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gcf8s/pods","resourceVersion":"12260"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:00:21.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gcf8s" for this suite.
Feb 20 19:00:27.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:00:29.234: INFO: namespace: e2e-tests-daemonsets-gcf8s, resource: bindings, ignored listing per whitelist
Feb 20 19:00:29.488: INFO: namespace e2e-tests-daemonsets-gcf8s deletion completed in 7.735742655s

• [SLOW TEST:95.918 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:00:29.488: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-k9ffq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-k9ffq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 19:00:31.169: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 19:00:55.907: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.130:8080/dial?request=hostName&protocol=http&host=100.96.0.26&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-k9ffq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:00:55.907: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:00:56.718: INFO: Waiting for endpoints: map[]
Feb 20 19:00:56.761: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.130:8080/dial?request=hostName&protocol=http&host=100.96.1.129&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-k9ffq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:00:56.761: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:00:57.373: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:00:57.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-k9ffq" for this suite.
Feb 20 19:01:19.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:01:20.392: INFO: namespace: e2e-tests-pod-network-test-k9ffq, resource: bindings, ignored listing per whitelist
Feb 20 19:01:21.252: INFO: namespace e2e-tests-pod-network-test-k9ffq deletion completed in 23.835506921s

• [SLOW TEST:51.763 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:01:21.252: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-l9t6j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-jnqc
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 19:01:23.200: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jnqc" in namespace "e2e-tests-subpath-l9t6j" to be "success or failure"
Feb 20 19:01:23.242: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Pending", Reason="", readiness=false. Elapsed: 42.213044ms
Feb 20 19:01:25.285: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084905232s
Feb 20 19:01:27.328: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 4.127874828s
Feb 20 19:01:29.374: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 6.174116281s
Feb 20 19:01:31.423: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 8.222719426s
Feb 20 19:01:33.468: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 10.268468021s
Feb 20 19:01:35.511: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 12.311264528s
Feb 20 19:01:37.554: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 14.354175427s
Feb 20 19:01:39.597: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 16.39732973s
Feb 20 19:01:41.640: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 18.440162256s
Feb 20 19:01:43.682: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Running", Reason="", readiness=false. Elapsed: 20.48227685s
Feb 20 19:01:45.726: INFO: Pod "pod-subpath-test-downwardapi-jnqc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.525804191s
STEP: Saw pod success
Feb 20 19:01:45.726: INFO: Pod "pod-subpath-test-downwardapi-jnqc" satisfied condition "success or failure"
Feb 20 19:01:45.769: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-subpath-test-downwardapi-jnqc container test-container-subpath-downwardapi-jnqc: <nil>
STEP: delete the pod
Feb 20 19:01:45.862: INFO: Waiting for pod pod-subpath-test-downwardapi-jnqc to disappear
Feb 20 19:01:45.905: INFO: Pod pod-subpath-test-downwardapi-jnqc no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-jnqc
Feb 20 19:01:45.905: INFO: Deleting pod "pod-subpath-test-downwardapi-jnqc" in namespace "e2e-tests-subpath-l9t6j"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:01:45.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-l9t6j" for this suite.
Feb 20 19:01:52.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:01:52.499: INFO: namespace: e2e-tests-subpath-l9t6j, resource: bindings, ignored listing per whitelist
Feb 20 19:01:53.772: INFO: namespace e2e-tests-subpath-l9t6j deletion completed in 7.781810076s

• [SLOW TEST:32.520 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:01:53.772: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-9qsfr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:02:20.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-9qsfr" for this suite.
Feb 20 19:02:26.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:02:27.661: INFO: namespace: e2e-tests-container-runtime-9qsfr, resource: bindings, ignored listing per whitelist
Feb 20 19:02:28.312: INFO: namespace e2e-tests-container-runtime-9qsfr deletion completed in 7.752258699s

• [SLOW TEST:34.541 seconds]
[k8s.io] Container Runtime
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:02:28.313: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-67njl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-27v2x in namespace e2e-tests-proxy-67njl
I0220 19:02:30.157114   30217 runners.go:184] Created replication controller with name: proxy-service-27v2x, namespace: e2e-tests-proxy-67njl, replica count: 1
I0220 19:02:31.207508   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 19:02:32.207706   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 19:02:33.207890   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:34.208091   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:35.208343   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:36.208534   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:37.208744   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:38.208993   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:39.209180   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:40.209486   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:41.209693   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:42.209896   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 19:02:43.210128   30217 runners.go:184] proxy-service-27v2x Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 19:02:43.289: INFO: setup took 13.221916563s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 20 19:02:43.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 51.629554ms)
Feb 20 19:02:43.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 51.94196ms)
Feb 20 19:02:43.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 51.717392ms)
Feb 20 19:02:43.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 51.877826ms)
Feb 20 19:02:43.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 51.762961ms)
Feb 20 19:02:43.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 52.104048ms)
Feb 20 19:02:43.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 52.027ms)
Feb 20 19:02:43.348: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 58.605984ms)
Feb 20 19:02:43.352: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 62.559658ms)
Feb 20 19:02:43.353: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 63.011519ms)
Feb 20 19:02:43.353: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 63.157759ms)
Feb 20 19:02:43.354: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 64.592688ms)
Feb 20 19:02:43.354: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 64.632035ms)
Feb 20 19:02:43.354: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 64.549728ms)
Feb 20 19:02:43.355: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 65.332964ms)
Feb 20 19:02:43.358: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 68.303255ms)
Feb 20 19:02:43.402: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.529778ms)
Feb 20 19:02:43.402: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 43.850512ms)
Feb 20 19:02:43.402: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.16371ms)
Feb 20 19:02:43.402: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 43.812328ms)
Feb 20 19:02:43.403: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 44.05598ms)
Feb 20 19:02:43.403: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 43.863823ms)
Feb 20 19:02:43.403: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 44.487323ms)
Feb 20 19:02:43.403: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 44.019472ms)
Feb 20 19:02:43.403: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.378416ms)
Feb 20 19:02:43.403: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 44.492267ms)
Feb 20 19:02:43.403: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 44.506835ms)
Feb 20 19:02:43.403: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 44.877546ms)
Feb 20 19:02:43.404: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 44.810542ms)
Feb 20 19:02:43.404: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 46.406116ms)
Feb 20 19:02:43.405: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 45.474782ms)
Feb 20 19:02:43.405: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 45.553669ms)
Feb 20 19:02:43.451: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 46.144118ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 46.356259ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 46.318343ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 46.728558ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 47.204352ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 47.025581ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 46.928838ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.382041ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 47.041853ms)
Feb 20 19:02:43.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.653381ms)
Feb 20 19:02:43.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 92.205843ms)
Feb 20 19:02:43.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 91.79089ms)
Feb 20 19:02:43.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 91.938192ms)
Feb 20 19:02:43.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 91.485738ms)
Feb 20 19:02:43.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 91.925573ms)
Feb 20 19:02:43.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 91.472098ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 46.182687ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.626621ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 46.044317ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 46.651588ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.225377ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 46.419933ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 46.038138ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 46.671201ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 46.01237ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 46.536246ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 46.271831ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 46.171104ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 46.466283ms)
Feb 20 19:02:43.544: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 46.296505ms)
Feb 20 19:02:43.545: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 47.719912ms)
Feb 20 19:02:43.545: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 47.541463ms)
Feb 20 19:02:43.658: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 43.807322ms)
Feb 20 19:02:43.658: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 43.712539ms)
Feb 20 19:02:43.658: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.076295ms)
Feb 20 19:02:43.658: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 43.668276ms)
Feb 20 19:02:43.658: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.480897ms)
Feb 20 19:02:43.658: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 43.886512ms)
Feb 20 19:02:43.659: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.058474ms)
Feb 20 19:02:43.659: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.439367ms)
Feb 20 19:02:43.659: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 44.05442ms)
Feb 20 19:02:43.659: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 44.804423ms)
Feb 20 19:02:43.659: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 44.665083ms)
Feb 20 19:02:43.659: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 44.376056ms)
Feb 20 19:02:43.660: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 45.239573ms)
Feb 20 19:02:43.661: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 46.687301ms)
Feb 20 19:02:43.661: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 46.399037ms)
Feb 20 19:02:43.661: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 46.970261ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.841886ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 43.826856ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.03119ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 43.795198ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.132848ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.634967ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 43.756859ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 43.546711ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 43.783518ms)
Feb 20 19:02:43.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 43.872634ms)
Feb 20 19:02:43.706: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 44.930722ms)
Feb 20 19:02:43.706: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 45.106387ms)
Feb 20 19:02:43.706: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 45.00906ms)
Feb 20 19:02:43.707: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 45.714479ms)
Feb 20 19:02:43.707: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 45.07431ms)
Feb 20 19:02:43.707: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 45.137803ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.559393ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 44.862281ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.877876ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 44.764839ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.504374ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 44.465959ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 44.604518ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.439262ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.336029ms)
Feb 20 19:02:43.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 45.389075ms)
Feb 20 19:02:43.754: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 46.489407ms)
Feb 20 19:02:43.754: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 47.153378ms)
Feb 20 19:02:43.754: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 46.903012ms)
Feb 20 19:02:43.754: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 47.142332ms)
Feb 20 19:02:43.754: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 47.476603ms)
Feb 20 19:02:43.754: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 47.118098ms)
Feb 20 19:02:43.800: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 45.443706ms)
Feb 20 19:02:43.800: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 46.042935ms)
Feb 20 19:02:43.800: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 45.526723ms)
Feb 20 19:02:43.800: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 45.477843ms)
Feb 20 19:02:43.800: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 45.633852ms)
Feb 20 19:02:43.802: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 46.740078ms)
Feb 20 19:02:43.802: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 47.04121ms)
Feb 20 19:02:43.802: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 47.041164ms)
Feb 20 19:02:43.802: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 47.010982ms)
Feb 20 19:02:43.802: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 46.958726ms)
Feb 20 19:02:43.802: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 47.214476ms)
Feb 20 19:02:43.802: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 47.07934ms)
Feb 20 19:02:43.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 51.157729ms)
Feb 20 19:02:43.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 51.352249ms)
Feb 20 19:02:43.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 51.354837ms)
Feb 20 19:02:43.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 51.18111ms)
Feb 20 19:02:43.851: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 45.078311ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 45.24853ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.945612ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 45.178226ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 45.384659ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 45.329523ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 45.527578ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 45.837223ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 45.605806ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 45.747687ms)
Feb 20 19:02:43.852: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 45.588214ms)
Feb 20 19:02:43.853: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 46.235342ms)
Feb 20 19:02:43.853: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 47.051519ms)
Feb 20 19:02:43.854: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 47.183221ms)
Feb 20 19:02:43.854: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 47.52034ms)
Feb 20 19:02:43.854: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 47.073984ms)
Feb 20 19:02:43.898: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 43.430664ms)
Feb 20 19:02:43.898: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.070053ms)
Feb 20 19:02:43.898: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 43.623146ms)
Feb 20 19:02:43.898: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 43.940562ms)
Feb 20 19:02:43.898: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.906534ms)
Feb 20 19:02:43.898: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 44.074737ms)
Feb 20 19:02:43.898: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.154039ms)
Feb 20 19:02:43.899: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 44.330669ms)
Feb 20 19:02:43.899: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.082323ms)
Feb 20 19:02:43.899: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.809093ms)
Feb 20 19:02:43.899: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 44.067521ms)
Feb 20 19:02:43.899: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 44.308425ms)
Feb 20 19:02:43.900: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 45.852954ms)
Feb 20 19:02:43.900: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 45.395519ms)
Feb 20 19:02:43.900: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 44.970685ms)
Feb 20 19:02:43.900: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 45.321445ms)
Feb 20 19:02:43.944: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.013412ms)
Feb 20 19:02:43.944: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.650692ms)
Feb 20 19:02:43.944: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 43.77847ms)
Feb 20 19:02:43.944: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 43.533361ms)
Feb 20 19:02:43.944: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 44.079937ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 44.043861ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 44.845404ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.79133ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.034894ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 44.208286ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 44.84692ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 44.008655ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 44.828004ms)
Feb 20 19:02:43.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.47549ms)
Feb 20 19:02:43.948: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 48.126569ms)
Feb 20 19:02:43.949: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 47.999573ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 47.876495ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 47.849629ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 48.168854ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 47.866487ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 47.560276ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 47.808439ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 48.490742ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 47.588255ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 47.85168ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 47.698876ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 48.069568ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 48.257905ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 47.705536ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 48.140553ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 47.994224ms)
Feb 20 19:02:43.997: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 48.523837ms)
Feb 20 19:02:44.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 43.992852ms)
Feb 20 19:02:44.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 44.542949ms)
Feb 20 19:02:44.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.91752ms)
Feb 20 19:02:44.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 44.691456ms)
Feb 20 19:02:44.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.074051ms)
Feb 20 19:02:44.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 44.96966ms)
Feb 20 19:02:44.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 44.230707ms)
Feb 20 19:02:44.043: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 44.710897ms)
Feb 20 19:02:44.043: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.590391ms)
Feb 20 19:02:44.043: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.833354ms)
Feb 20 19:02:44.043: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 44.92423ms)
Feb 20 19:02:44.043: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 44.615573ms)
Feb 20 19:02:44.043: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 45.527778ms)
Feb 20 19:02:44.044: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 45.948918ms)
Feb 20 19:02:44.044: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.100373ms)
Feb 20 19:02:44.044: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 45.750031ms)
Feb 20 19:02:44.089: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 45.144858ms)
Feb 20 19:02:44.089: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 44.649775ms)
Feb 20 19:02:44.089: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.517299ms)
Feb 20 19:02:44.089: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 45.085764ms)
Feb 20 19:02:44.089: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.689114ms)
Feb 20 19:02:44.089: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.613138ms)
Feb 20 19:02:44.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 45.369368ms)
Feb 20 19:02:44.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 45.45643ms)
Feb 20 19:02:44.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 45.173818ms)
Feb 20 19:02:44.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 45.558201ms)
Feb 20 19:02:44.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 44.986908ms)
Feb 20 19:02:44.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 45.517708ms)
Feb 20 19:02:44.091: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 46.649485ms)
Feb 20 19:02:44.091: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.428342ms)
Feb 20 19:02:44.091: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 46.795206ms)
Feb 20 19:02:44.091: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 46.423724ms)
Feb 20 19:02:44.134: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 42.801251ms)
Feb 20 19:02:44.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 44.519208ms)
Feb 20 19:02:44.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 43.379567ms)
Feb 20 19:02:44.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.336826ms)
Feb 20 19:02:44.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 43.481467ms)
Feb 20 19:02:44.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 44.378099ms)
Feb 20 19:02:44.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 44.41082ms)
Feb 20 19:02:44.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.361623ms)
Feb 20 19:02:44.137: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.19817ms)
Feb 20 19:02:44.137: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 44.770063ms)
Feb 20 19:02:44.137: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 44.674406ms)
Feb 20 19:02:44.137: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.641323ms)
Feb 20 19:02:44.137: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 45.321672ms)
Feb 20 19:02:44.138: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 45.463839ms)
Feb 20 19:02:44.138: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 46.436956ms)
Feb 20 19:02:44.138: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 45.273097ms)
Feb 20 19:02:44.181: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 43.168771ms)
Feb 20 19:02:44.182: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.005442ms)
Feb 20 19:02:44.182: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 43.817637ms)
Feb 20 19:02:44.182: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 43.972479ms)
Feb 20 19:02:44.182: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 43.743737ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 51.866475ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 51.528994ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 51.760879ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 51.635656ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 51.602837ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 51.589782ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 51.606484ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 51.685397ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 51.915862ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 51.67169ms)
Feb 20 19:02:44.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 51.650143ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 46.892923ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 46.824093ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.833158ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 47.200078ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 46.816549ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 47.030536ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 47.020535ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 47.087894ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 47.231552ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 46.89451ms)
Feb 20 19:02:44.237: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 47.211049ms)
Feb 20 19:02:44.238: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 47.321314ms)
Feb 20 19:02:44.238: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 47.736865ms)
Feb 20 19:02:44.238: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 47.6786ms)
Feb 20 19:02:44.238: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 47.996296ms)
Feb 20 19:02:44.238: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 47.697424ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.624809ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.770554ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 44.578491ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 44.795529ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 44.729652ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 44.702163ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 44.979743ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.799663ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 44.775378ms)
Feb 20 19:02:44.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.928217ms)
Feb 20 19:02:44.284: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 45.268644ms)
Feb 20 19:02:44.284: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 45.171053ms)
Feb 20 19:02:44.284: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 45.5662ms)
Feb 20 19:02:44.285: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 46.125897ms)
Feb 20 19:02:44.285: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 46.317053ms)
Feb 20 19:02:44.285: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 46.29339ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 46.224512ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 46.573674ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 45.897751ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 46.129709ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 46.488392ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.854669ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 46.771846ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 46.548464ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 46.116762ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 46.192534ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 46.417808ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 46.482533ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 46.392077ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 46.522029ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 46.887597ms)
Feb 20 19:02:44.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 46.951695ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname2/proxy/: bar (200; 45.194737ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:1080/proxy/rewri... (200; 45.232793ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 45.374213ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 44.912058ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w/proxy/rewriteme"... (200; 45.536952ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:160/proxy/: foo (200; 45.514654ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/proxy-service-27v2x-4sn2w:162/proxy/: bar (200; 44.94303ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:443/proxy/... (200; 45.07537ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-67njl/pods/http:proxy-service-27v2x-4sn2w:1080/proxy/... (200; 45.159253ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:460/proxy/: tls baz (200; 45.405155ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/pods/https:proxy-service-27v2x-4sn2w:462/proxy/: tls qux (200; 45.993874ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname2/proxy/: tls qux (200; 45.300394ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/services/https:proxy-service-27v2x:tlsportname1/proxy/: tls baz (200; 45.833272ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/services/http:proxy-service-27v2x:portname1/proxy/: foo (200; 46.110012ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname2/proxy/: bar (200; 45.603383ms)
Feb 20 19:02:44.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-67njl/services/proxy-service-27v2x:portname1/proxy/: foo (200; 45.693577ms)
STEP: deleting ReplicationController proxy-service-27v2x in namespace e2e-tests-proxy-67njl, will wait for the garbage collector to delete the pods
Feb 20 19:02:44.539: INFO: Deleting ReplicationController proxy-service-27v2x took: 48.320517ms
Feb 20 19:02:44.639: INFO: Terminating ReplicationController proxy-service-27v2x pods took: 100.20895ms
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:02:46.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-67njl" for this suite.
Feb 20 19:02:52.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:02:53.500: INFO: namespace: e2e-tests-proxy-67njl, resource: bindings, ignored listing per whitelist
Feb 20 19:02:53.965: INFO: namespace e2e-tests-proxy-67njl deletion completed in 7.782573155s

• [SLOW TEST:25.652 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:02:53.965: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l66gl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb 20 19:02:55.681: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-l66gl'
Feb 20 19:02:58.128: INFO: stderr: ""
Feb 20 19:02:58.128: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 20 19:02:59.171: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:02:59.171: INFO: Found 0 / 1
Feb 20 19:03:00.172: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:03:00.172: INFO: Found 1 / 1
Feb 20 19:03:00.172: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 20 19:03:00.215: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:03:00.215: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 20 19:03:00.215: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml logs redis-master-bcm4b redis-master --namespace=e2e-tests-kubectl-l66gl'
Feb 20 19:03:00.574: INFO: stderr: ""
Feb 20 19:03:00.574: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Feb 19:02:58.952 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Feb 19:02:58.952 # Server started, Redis version 3.2.12\n1:M 20 Feb 19:02:58.952 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Feb 19:02:58.952 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 20 19:03:00.574: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-bcm4b redis-master --namespace=e2e-tests-kubectl-l66gl --tail=1'
Feb 20 19:03:00.917: INFO: stderr: ""
Feb 20 19:03:00.917: INFO: stdout: "1:M 20 Feb 19:02:58.952 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 20 19:03:00.917: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-bcm4b redis-master --namespace=e2e-tests-kubectl-l66gl --limit-bytes=1'
Feb 20 19:03:01.279: INFO: stderr: ""
Feb 20 19:03:01.279: INFO: stdout: " "
STEP: exposing timestamps
Feb 20 19:03:01.279: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-bcm4b redis-master --namespace=e2e-tests-kubectl-l66gl --tail=1 --timestamps'
Feb 20 19:03:01.625: INFO: stderr: ""
Feb 20 19:03:01.625: INFO: stdout: "2019-02-20T19:02:58.952811806Z 1:M 20 Feb 19:02:58.952 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 20 19:03:04.126: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-bcm4b redis-master --namespace=e2e-tests-kubectl-l66gl --since=1s'
Feb 20 19:03:04.473: INFO: stderr: ""
Feb 20 19:03:04.473: INFO: stdout: ""
Feb 20 19:03:04.473: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-bcm4b redis-master --namespace=e2e-tests-kubectl-l66gl --since=24h'
Feb 20 19:03:04.814: INFO: stderr: ""
Feb 20 19:03:04.814: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Feb 19:02:58.952 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Feb 19:02:58.952 # Server started, Redis version 3.2.12\n1:M 20 Feb 19:02:58.952 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Feb 19:02:58.952 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb 20 19:03:04.814: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l66gl'
Feb 20 19:03:05.137: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:03:05.137: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 20 19:03:05.137: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-l66gl'
Feb 20 19:03:05.508: INFO: stderr: "No resources found.\n"
Feb 20 19:03:05.509: INFO: stdout: ""
Feb 20 19:03:05.509: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -l name=nginx --namespace=e2e-tests-kubectl-l66gl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 19:03:05.842: INFO: stderr: ""
Feb 20 19:03:05.842: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:03:05.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l66gl" for this suite.
Feb 20 19:03:28.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:03:28.611: INFO: namespace: e2e-tests-kubectl-l66gl, resource: bindings, ignored listing per whitelist
Feb 20 19:03:29.660: INFO: namespace e2e-tests-kubectl-l66gl deletion completed in 23.775527575s

• [SLOW TEST:35.695 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:03:29.661: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-82v24
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 20 19:03:31.409: INFO: Waiting up to 5m0s for pod "pod-36b7fb2f-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-82v24" to be "success or failure"
Feb 20 19:03:31.451: INFO: Pod "pod-36b7fb2f-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.051558ms
Feb 20 19:03:33.496: INFO: Pod "pod-36b7fb2f-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086662089s
STEP: Saw pod success
Feb 20 19:03:33.496: INFO: Pod "pod-36b7fb2f-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:03:33.539: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-36b7fb2f-3542-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:03:33.632: INFO: Waiting for pod pod-36b7fb2f-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:03:33.675: INFO: Pod pod-36b7fb2f-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:03:33.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-82v24" for this suite.
Feb 20 19:03:39.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:03:41.250: INFO: namespace: e2e-tests-emptydir-82v24, resource: bindings, ignored listing per whitelist
Feb 20 19:03:41.508: INFO: namespace e2e-tests-emptydir-82v24 deletion completed in 7.789266082s

• [SLOW TEST:11.847 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:03:41.509: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-588s7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3dcfee77-3542-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:03:43.355: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3dd6c5d5-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-588s7" to be "success or failure"
Feb 20 19:03:43.410: INFO: Pod "pod-projected-configmaps-3dd6c5d5-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 54.880146ms
Feb 20 19:03:45.454: INFO: Pod "pod-projected-configmaps-3dd6c5d5-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.099356226s
STEP: Saw pod success
Feb 20 19:03:45.454: INFO: Pod "pod-projected-configmaps-3dd6c5d5-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:03:45.496: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-configmaps-3dd6c5d5-3542-11e9-96fe-8e2b2e6369d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:03:45.600: INFO: Waiting for pod pod-projected-configmaps-3dd6c5d5-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:03:45.647: INFO: Pod pod-projected-configmaps-3dd6c5d5-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:03:45.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-588s7" for this suite.
Feb 20 19:03:51.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:03:53.127: INFO: namespace: e2e-tests-projected-588s7, resource: bindings, ignored listing per whitelist
Feb 20 19:03:53.476: INFO: namespace e2e-tests-projected-588s7 deletion completed in 7.785474835s

• [SLOW TEST:11.967 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:03:53.476: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xxqxf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 20 19:03:57.480: INFO: Pod pod-hostip-44f6c177-3542-11e9-96fe-8e2b2e6369d7 has hostIP: 10.250.0.144
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:03:57.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xxqxf" for this suite.
Feb 20 19:04:19.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:04:21.261: INFO: namespace: e2e-tests-pods-xxqxf, resource: bindings, ignored listing per whitelist
Feb 20 19:04:21.261: INFO: namespace e2e-tests-pods-xxqxf deletion completed in 23.737307158s

• [SLOW TEST:27.785 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:04:21.261: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ds5rr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-557af8ef-3542-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:04:23.061: INFO: Waiting up to 5m0s for pod "pod-configmaps-55816b62-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-ds5rr" to be "success or failure"
Feb 20 19:04:23.103: INFO: Pod "pod-configmaps-55816b62-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.95449ms
Feb 20 19:04:25.146: INFO: Pod "pod-configmaps-55816b62-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084554909s
STEP: Saw pod success
Feb 20 19:04:25.146: INFO: Pod "pod-configmaps-55816b62-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:04:25.189: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-55816b62-3542-11e9-96fe-8e2b2e6369d7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:04:25.281: INFO: Waiting for pod pod-configmaps-55816b62-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:04:25.323: INFO: Pod pod-configmaps-55816b62-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:04:25.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ds5rr" for this suite.
Feb 20 19:04:31.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:04:32.891: INFO: namespace: e2e-tests-configmap-ds5rr, resource: bindings, ignored listing per whitelist
Feb 20 19:04:33.141: INFO: namespace e2e-tests-configmap-ds5rr deletion completed in 7.77568948s

• [SLOW TEST:11.881 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:04:33.142: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hp7mb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-5c92285b-3542-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 19:04:34.957: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5c98ad48-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-hp7mb" to be "success or failure"
Feb 20 19:04:35.001: INFO: Pod "pod-projected-secrets-5c98ad48-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.224978ms
Feb 20 19:04:37.044: INFO: Pod "pod-projected-secrets-5c98ad48-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085140072s
STEP: Saw pod success
Feb 20 19:04:37.044: INFO: Pod "pod-projected-secrets-5c98ad48-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:04:37.087: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-secrets-5c98ad48-3542-11e9-96fe-8e2b2e6369d7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 19:04:37.185: INFO: Waiting for pod pod-projected-secrets-5c98ad48-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:04:37.227: INFO: Pod pod-projected-secrets-5c98ad48-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:04:37.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hp7mb" for this suite.
Feb 20 19:04:43.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:04:44.710: INFO: namespace: e2e-tests-projected-hp7mb, resource: bindings, ignored listing per whitelist
Feb 20 19:04:45.048: INFO: namespace e2e-tests-projected-hp7mb deletion completed in 7.777262754s

• [SLOW TEST:11.906 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:04:45.048: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5gqqz
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 20 19:04:46.911: INFO: Waiting up to 5m0s for pod "pod-63b8d375-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-5gqqz" to be "success or failure"
Feb 20 19:04:46.954: INFO: Pod "pod-63b8d375-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.457354ms
Feb 20 19:04:48.996: INFO: Pod "pod-63b8d375-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085106992s
STEP: Saw pod success
Feb 20 19:04:48.996: INFO: Pod "pod-63b8d375-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:04:49.039: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-63b8d375-3542-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:04:49.132: INFO: Waiting for pod pod-63b8d375-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:04:49.174: INFO: Pod pod-63b8d375-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:04:49.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5gqqz" for this suite.
Feb 20 19:04:55.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:04:56.872: INFO: namespace: e2e-tests-emptydir-5gqqz, resource: bindings, ignored listing per whitelist
Feb 20 19:04:57.000: INFO: namespace e2e-tests-emptydir-5gqqz deletion completed in 7.782928009s

• [SLOW TEST:11.952 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:04:57.000: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-m5l5w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 20 19:05:01.573: INFO: Successfully updated pod "labelsupdate6ad040a6-3542-11e9-96fe-8e2b2e6369d7"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:05:03.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m5l5w" for this suite.
Feb 20 19:05:25.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:05:26.756: INFO: namespace: e2e-tests-downward-api-m5l5w, resource: bindings, ignored listing per whitelist
Feb 20 19:05:27.516: INFO: namespace e2e-tests-downward-api-m5l5w deletion completed in 23.803131482s

• [SLOW TEST:30.516 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:05:27.517: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-dzgdq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-dzgdq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dzgdq to expose endpoints map[]
Feb 20 19:05:29.372: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dzgdq exposes endpoints map[] (42.104921ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-dzgdq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dzgdq to expose endpoints map[pod1:[80]]
Feb 20 19:05:31.700: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dzgdq exposes endpoints map[pod1:[80]] (2.283117949s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-dzgdq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dzgdq to expose endpoints map[pod1:[80] pod2:[80]]
Feb 20 19:05:34.124: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dzgdq exposes endpoints map[pod1:[80] pod2:[80]] (2.380846041s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-dzgdq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dzgdq to expose endpoints map[pod2:[80]]
Feb 20 19:05:34.253: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dzgdq exposes endpoints map[pod2:[80]] (85.410028ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-dzgdq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dzgdq to expose endpoints map[]
Feb 20 19:05:34.337: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dzgdq exposes endpoints map[] (41.924298ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:05:34.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-dzgdq" for this suite.
Feb 20 19:05:56.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:05:58.076: INFO: namespace: e2e-tests-services-dzgdq, resource: bindings, ignored listing per whitelist
Feb 20 19:05:58.285: INFO: namespace e2e-tests-services-dzgdq deletion completed in 23.857159882s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.769 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:05:58.286: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-j5vj4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:06:20.148: INFO: Container started at 2019-02-20 19:06:00 +0000 UTC, pod became ready at 2019-02-20 19:06:18 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:06:20.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-j5vj4" for this suite.
Feb 20 19:06:42.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:06:42.953: INFO: namespace: e2e-tests-container-probe-j5vj4, resource: bindings, ignored listing per whitelist
Feb 20 19:06:43.922: INFO: namespace e2e-tests-container-probe-j5vj4 deletion completed in 23.730332811s

• [SLOW TEST:45.637 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:06:43.922: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-zwtzc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 20 19:06:45.712: INFO: Waiting up to 5m0s for pod "pod-aa885247-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-zwtzc" to be "success or failure"
Feb 20 19:06:45.755: INFO: Pod "pod-aa885247-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.114413ms
Feb 20 19:06:47.797: INFO: Pod "pod-aa885247-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084904919s
STEP: Saw pod success
Feb 20 19:06:47.797: INFO: Pod "pod-aa885247-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:06:47.840: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-aa885247-3542-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:06:47.933: INFO: Waiting for pod pod-aa885247-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:06:47.975: INFO: Pod pod-aa885247-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:06:47.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zwtzc" for this suite.
Feb 20 19:06:54.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:06:54.652: INFO: namespace: e2e-tests-emptydir-zwtzc, resource: bindings, ignored listing per whitelist
Feb 20 19:06:55.754: INFO: namespace e2e-tests-emptydir-zwtzc deletion completed in 7.736392315s

• [SLOW TEST:11.832 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:06:55.754: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-2mc47
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 20 19:06:57.512: INFO: Waiting up to 5m0s for pod "var-expansion-b190b577-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-var-expansion-2mc47" to be "success or failure"
Feb 20 19:06:57.555: INFO: Pod "var-expansion-b190b577-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.273703ms
Feb 20 19:06:59.597: INFO: Pod "var-expansion-b190b577-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085123867s
STEP: Saw pod success
Feb 20 19:06:59.598: INFO: Pod "var-expansion-b190b577-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:06:59.640: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod var-expansion-b190b577-3542-11e9-96fe-8e2b2e6369d7 container dapi-container: <nil>
STEP: delete the pod
Feb 20 19:06:59.733: INFO: Waiting for pod var-expansion-b190b577-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:06:59.775: INFO: Pod var-expansion-b190b577-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:06:59.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-2mc47" for this suite.
Feb 20 19:07:05.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:07:06.624: INFO: namespace: e2e-tests-var-expansion-2mc47, resource: bindings, ignored listing per whitelist
Feb 20 19:07:07.553: INFO: namespace e2e-tests-var-expansion-2mc47 deletion completed in 7.735183977s

• [SLOW TEST:11.799 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:07:07.554: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wfs9q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 20 19:07:09.403: INFO: Waiting up to 5m0s for pod "pod-b8a72ddb-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-wfs9q" to be "success or failure"
Feb 20 19:07:09.445: INFO: Pod "pod-b8a72ddb-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.064251ms
Feb 20 19:07:11.487: INFO: Pod "pod-b8a72ddb-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084744742s
STEP: Saw pod success
Feb 20 19:07:11.487: INFO: Pod "pod-b8a72ddb-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:07:11.530: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-b8a72ddb-3542-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:07:11.623: INFO: Waiting for pod pod-b8a72ddb-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:07:11.665: INFO: Pod pod-b8a72ddb-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:07:11.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wfs9q" for this suite.
Feb 20 19:07:17.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:07:19.186: INFO: namespace: e2e-tests-emptydir-wfs9q, resource: bindings, ignored listing per whitelist
Feb 20 19:07:19.439: INFO: namespace e2e-tests-emptydir-wfs9q deletion completed in 7.729939503s

• [SLOW TEST:11.885 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:07:19.439: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-l9hr4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-bfb13852-3542-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:07:21.256: INFO: Waiting up to 5m0s for pod "pod-configmaps-bfb7a9f6-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-l9hr4" to be "success or failure"
Feb 20 19:07:21.298: INFO: Pod "pod-configmaps-bfb7a9f6-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.895844ms
Feb 20 19:07:23.341: INFO: Pod "pod-configmaps-bfb7a9f6-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08474409s
STEP: Saw pod success
Feb 20 19:07:23.341: INFO: Pod "pod-configmaps-bfb7a9f6-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:07:23.383: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-bfb7a9f6-3542-11e9-96fe-8e2b2e6369d7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:07:23.475: INFO: Waiting for pod pod-configmaps-bfb7a9f6-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:07:23.516: INFO: Pod pod-configmaps-bfb7a9f6-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:07:23.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-l9hr4" for this suite.
Feb 20 19:07:29.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:07:29.898: INFO: namespace: e2e-tests-configmap-l9hr4, resource: bindings, ignored listing per whitelist
Feb 20 19:07:31.289: INFO: namespace e2e-tests-configmap-l9hr4 deletion completed in 7.729563933s

• [SLOW TEST:11.850 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:07:31.289: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-22k7h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-22k7h/configmap-test-c6c78fe4-3542-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:07:33.145: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6ce0a3f-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-22k7h" to be "success or failure"
Feb 20 19:07:33.187: INFO: Pod "pod-configmaps-c6ce0a3f-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.027344ms
Feb 20 19:07:35.230: INFO: Pod "pod-configmaps-c6ce0a3f-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084966997s
STEP: Saw pod success
Feb 20 19:07:35.230: INFO: Pod "pod-configmaps-c6ce0a3f-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:07:35.273: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-c6ce0a3f-3542-11e9-96fe-8e2b2e6369d7 container env-test: <nil>
STEP: delete the pod
Feb 20 19:07:35.368: INFO: Waiting for pod pod-configmaps-c6ce0a3f-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:07:35.410: INFO: Pod pod-configmaps-c6ce0a3f-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:07:35.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-22k7h" for this suite.
Feb 20 19:07:41.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:07:42.002: INFO: namespace: e2e-tests-configmap-22k7h, resource: bindings, ignored listing per whitelist
Feb 20 19:07:43.187: INFO: namespace e2e-tests-configmap-22k7h deletion completed in 7.733984146s

• [SLOW TEST:11.898 seconds]
[sig-node] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:07:43.188: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-q4lbw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 20 19:07:44.910: INFO: Waiting up to 5m0s for pod "pod-cdd14123-3542-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-q4lbw" to be "success or failure"
Feb 20 19:07:44.952: INFO: Pod "pod-cdd14123-3542-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.980737ms
Feb 20 19:07:46.994: INFO: Pod "pod-cdd14123-3542-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084021147s
STEP: Saw pod success
Feb 20 19:07:46.994: INFO: Pod "pod-cdd14123-3542-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:07:47.037: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-cdd14123-3542-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:07:47.131: INFO: Waiting for pod pod-cdd14123-3542-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:07:47.173: INFO: Pod pod-cdd14123-3542-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:07:47.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q4lbw" for this suite.
Feb 20 19:07:53.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:07:53.763: INFO: namespace: e2e-tests-emptydir-q4lbw, resource: bindings, ignored listing per whitelist
Feb 20 19:07:54.941: INFO: namespace e2e-tests-emptydir-q4lbw deletion completed in 7.724364898s

• [SLOW TEST:11.753 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:07:54.941: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kfjbp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 20 19:07:56.766: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-kfjbp'
Feb 20 19:07:57.366: INFO: stderr: ""
Feb 20 19:07:57.366: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 19:07:58.409: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:07:58.409: INFO: Found 0 / 1
Feb 20 19:07:59.409: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:07:59.409: INFO: Found 1 / 1
Feb 20 19:07:59.409: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 20 19:07:59.451: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:07:59.452: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 19:07:59.452: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml patch pod redis-master-4wnjt --namespace=e2e-tests-kubectl-kfjbp -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 20 19:07:59.742: INFO: stderr: ""
Feb 20 19:07:59.742: INFO: stdout: "pod/redis-master-4wnjt patched\n"
STEP: checking annotations
Feb 20 19:07:59.785: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:07:59.785: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:07:59.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kfjbp" for this suite.
Feb 20 19:08:21.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:08:22.166: INFO: namespace: e2e-tests-kubectl-kfjbp, resource: bindings, ignored listing per whitelist
Feb 20 19:08:23.596: INFO: namespace e2e-tests-kubectl-kfjbp deletion completed in 23.768302482s

• [SLOW TEST:28.655 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:08:23.596: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mxb8r
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e5fb13fa-3542-11e9-96fe-8e2b2e6369d7
STEP: Creating secret with name s-test-opt-upd-e5fb143b-3542-11e9-96fe-8e2b2e6369d7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e5fb13fa-3542-11e9-96fe-8e2b2e6369d7
STEP: Updating secret s-test-opt-upd-e5fb143b-3542-11e9-96fe-8e2b2e6369d7
STEP: Creating secret with name s-test-opt-create-e5fb1452-3542-11e9-96fe-8e2b2e6369d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:08:30.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mxb8r" for this suite.
Feb 20 19:08:52.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:08:52.916: INFO: namespace: e2e-tests-projected-mxb8r, resource: bindings, ignored listing per whitelist
Feb 20 19:08:54.000: INFO: namespace e2e-tests-projected-mxb8r deletion completed in 23.820324017s

• [SLOW TEST:30.404 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:08:54.001: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-wkpns
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-xshg
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 19:08:55.813: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xshg" in namespace "e2e-tests-subpath-wkpns" to be "success or failure"
Feb 20 19:08:55.857: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Pending", Reason="", readiness=false. Elapsed: 43.478712ms
Feb 20 19:08:57.899: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086209607s
Feb 20 19:08:59.942: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 4.128977943s
Feb 20 19:09:01.985: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 6.172021102s
Feb 20 19:09:04.031: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 8.217531847s
Feb 20 19:09:06.074: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 10.260530361s
Feb 20 19:09:08.116: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 12.303344608s
Feb 20 19:09:10.160: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 14.346774956s
Feb 20 19:09:12.203: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 16.38954063s
Feb 20 19:09:14.246: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 18.432503088s
Feb 20 19:09:16.289: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Running", Reason="", readiness=false. Elapsed: 20.475943046s
Feb 20 19:09:18.332: INFO: Pod "pod-subpath-test-configmap-xshg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.518636567s
STEP: Saw pod success
Feb 20 19:09:18.332: INFO: Pod "pod-subpath-test-configmap-xshg" satisfied condition "success or failure"
Feb 20 19:09:18.374: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-subpath-test-configmap-xshg container test-container-subpath-configmap-xshg: <nil>
STEP: delete the pod
Feb 20 19:09:18.469: INFO: Waiting for pod pod-subpath-test-configmap-xshg to disappear
Feb 20 19:09:18.512: INFO: Pod pod-subpath-test-configmap-xshg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xshg
Feb 20 19:09:18.512: INFO: Deleting pod "pod-subpath-test-configmap-xshg" in namespace "e2e-tests-subpath-wkpns"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:09:18.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wkpns" for this suite.
Feb 20 19:09:24.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:09:25.699: INFO: namespace: e2e-tests-subpath-wkpns, resource: bindings, ignored listing per whitelist
Feb 20 19:09:26.328: INFO: namespace e2e-tests-subpath-wkpns deletion completed in 7.730943107s

• [SLOW TEST:32.328 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:09:26.329: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-pnbzf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-pnbzf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 19:09:28.066: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 19:09:50.834: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.156:8080/dial?request=hostName&protocol=udp&host=100.96.1.155&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pnbzf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:09:50.834: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:09:51.498: INFO: Waiting for endpoints: map[]
Feb 20 19:09:51.540: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.156:8080/dial?request=hostName&protocol=udp&host=100.96.0.28&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pnbzf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:09:51.540: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:09:51.973: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:09:51.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-pnbzf" for this suite.
Feb 20 19:10:14.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:10:14.695: INFO: namespace: e2e-tests-pod-network-test-pnbzf, resource: bindings, ignored listing per whitelist
Feb 20 19:10:15.757: INFO: namespace e2e-tests-pod-network-test-pnbzf deletion completed in 23.741162805s

• [SLOW TEST:49.428 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:10:15.758: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-6zkvq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:10:19.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6zkvq" for this suite.
Feb 20 19:11:03.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:11:04.195: INFO: namespace: e2e-tests-kubelet-test-6zkvq, resource: bindings, ignored listing per whitelist
Feb 20 19:11:05.506: INFO: namespace e2e-tests-kubelet-test-6zkvq deletion completed in 45.775935837s

• [SLOW TEST:49.748 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:11:05.506: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-5btzx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:11:07.274: INFO: Creating ReplicaSet my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7
Feb 20 19:11:07.359: INFO: Pod name my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7: Found 1 pods out of 1
Feb 20 19:11:07.359: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7" is running
Feb 20 19:11:09.444: INFO: Pod "my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7-x4zs4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 19:11:07 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 19:11:07 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 19:11:07 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 19:11:07 +0000 UTC Reason: Message:}])
Feb 20 19:11:09.444: INFO: Trying to dial the pod
Feb 20 19:11:14.658: INFO: Controller my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7: Got expected result from replica 1 [my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7-x4zs4]: "my-hostname-basic-46763860-3543-11e9-96fe-8e2b2e6369d7-x4zs4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:11:14.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-5btzx" for this suite.
Feb 20 19:11:20.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:11:21.591: INFO: namespace: e2e-tests-replicaset-5btzx, resource: bindings, ignored listing per whitelist
Feb 20 19:11:22.434: INFO: namespace e2e-tests-replicaset-5btzx deletion completed in 7.731661971s

• [SLOW TEST:16.928 seconds]
[sig-apps] ReplicaSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:11:22.435: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-bmjqb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 20 19:11:24.332: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-a,UID:509cbeeb-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14129,Generation:0,CreationTimestamp:2019-02-20 19:11:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 19:11:24.333: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-a,UID:509cbeeb-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14129,Generation:0,CreationTimestamp:2019-02-20 19:11:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 20 19:11:34.418: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-a,UID:509cbeeb-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14149,Generation:0,CreationTimestamp:2019-02-20 19:11:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 20 19:11:34.419: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-a,UID:509cbeeb-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14149,Generation:0,CreationTimestamp:2019-02-20 19:11:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 20 19:11:44.503: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-a,UID:509cbeeb-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14168,Generation:0,CreationTimestamp:2019-02-20 19:11:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 19:11:44.503: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-a,UID:509cbeeb-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14168,Generation:0,CreationTimestamp:2019-02-20 19:11:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 20 19:11:54.547: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-a,UID:509cbeeb-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14187,Generation:0,CreationTimestamp:2019-02-20 19:11:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 19:11:54.547: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-a,UID:509cbeeb-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14187,Generation:0,CreationTimestamp:2019-02-20 19:11:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 20 19:12:04.592: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-b,UID:689b9b5f-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14207,Generation:0,CreationTimestamp:2019-02-20 19:12:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 19:12:04.592: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-b,UID:689b9b5f-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14207,Generation:0,CreationTimestamp:2019-02-20 19:12:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 20 19:12:14.636: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-b,UID:689b9b5f-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14226,Generation:0,CreationTimestamp:2019-02-20 19:12:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 19:12:14.636: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-bmjqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-bmjqb/configmaps/e2e-watch-test-configmap-b,UID:689b9b5f-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14226,Generation:0,CreationTimestamp:2019-02-20 19:12:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:12:24.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bmjqb" for this suite.
Feb 20 19:12:30.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:12:31.477: INFO: namespace: e2e-tests-watch-bmjqb, resource: bindings, ignored listing per whitelist
Feb 20 19:12:32.443: INFO: namespace e2e-tests-watch-bmjqb deletion completed in 7.763895833s

• [SLOW TEST:70.009 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:12:32.444: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-x8f97
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:12:34.211: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a40f295-3543-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-x8f97" to be "success or failure"
Feb 20 19:12:34.253: INFO: Pod "downwardapi-volume-7a40f295-3543-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.320317ms
Feb 20 19:12:36.297: INFO: Pod "downwardapi-volume-7a40f295-3543-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085467753s
STEP: Saw pod success
Feb 20 19:12:36.297: INFO: Pod "downwardapi-volume-7a40f295-3543-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:12:36.339: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-7a40f295-3543-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:12:36.434: INFO: Waiting for pod downwardapi-volume-7a40f295-3543-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:12:36.476: INFO: Pod downwardapi-volume-7a40f295-3543-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:12:36.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x8f97" for this suite.
Feb 20 19:12:42.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:12:42.781: INFO: namespace: e2e-tests-downward-api-x8f97, resource: bindings, ignored listing per whitelist
Feb 20 19:12:44.362: INFO: namespace e2e-tests-downward-api-x8f97 deletion completed in 7.843523954s

• [SLOW TEST:11.919 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:12:44.362: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-hphh4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 20 19:12:46.111: INFO: Waiting up to 5m0s for pod "client-containers-8158ad88-3543-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-containers-hphh4" to be "success or failure"
Feb 20 19:12:46.153: INFO: Pod "client-containers-8158ad88-3543-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.175284ms
Feb 20 19:12:48.195: INFO: Pod "client-containers-8158ad88-3543-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084639349s
STEP: Saw pod success
Feb 20 19:12:48.195: INFO: Pod "client-containers-8158ad88-3543-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:12:48.237: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod client-containers-8158ad88-3543-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:12:48.330: INFO: Waiting for pod client-containers-8158ad88-3543-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:12:48.372: INFO: Pod client-containers-8158ad88-3543-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:12:48.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hphh4" for this suite.
Feb 20 19:12:54.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:12:55.555: INFO: namespace: e2e-tests-containers-hphh4, resource: bindings, ignored listing per whitelist
Feb 20 19:12:56.192: INFO: namespace e2e-tests-containers-hphh4 deletion completed in 7.776184275s

• [SLOW TEST:11.829 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:12:56.192: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-cmx6j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 20 19:13:00.092: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-88629b86-3543-11e9-96fe-8e2b2e6369d7,GenerateName:,Namespace:e2e-tests-events-cmx6j,SelfLink:/api/v1/namespaces/e2e-tests-events-cmx6j/pods/send-events-88629b86-3543-11e9-96fe-8e2b2e6369d7,UID:8864eba8-3543-11e9-a8b6-5a3f4013d0a1,ResourceVersion:14361,Generation:0,CreationTimestamp:2019-02-20 19:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 875550976,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.161/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xlfpz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xlfpz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-xlfpz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002078580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020785a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:12:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:12:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:12:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:12:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.161,StartTime:2019-02-20 19:12:57 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-20 19:12:58 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://3298f125a157d8e5eec3fc0ada2d8f10e660a2afec3760482735b6480346a175}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 20 19:13:02.136: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 20 19:13:04.180: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:13:04.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-cmx6j" for this suite.
Feb 20 19:13:42.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:13:42.608: INFO: namespace: e2e-tests-events-cmx6j, resource: bindings, ignored listing per whitelist
Feb 20 19:13:44.012: INFO: namespace e2e-tests-events-cmx6j deletion completed in 39.745968776s

• [SLOW TEST:47.820 seconds]
[k8s.io] [sig-node] Events
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:13:44.013: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-799xl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-799xl
Feb 20 19:13:49.824: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-799xl
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 19:13:49.866: INFO: Initial restart count of pod liveness-http is 0
Feb 20 19:14:04.211: INFO: Restart count of pod e2e-tests-container-probe-799xl/liveness-http is now 1 (14.344105679s elapsed)
Feb 20 19:14:24.639: INFO: Restart count of pod e2e-tests-container-probe-799xl/liveness-http is now 2 (34.772449647s elapsed)
Feb 20 19:14:45.066: INFO: Restart count of pod e2e-tests-container-probe-799xl/liveness-http is now 3 (55.199956753s elapsed)
Feb 20 19:15:03.453: INFO: Restart count of pod e2e-tests-container-probe-799xl/liveness-http is now 4 (1m13.586623973s elapsed)
Feb 20 19:16:06.780: INFO: Restart count of pod e2e-tests-container-probe-799xl/liveness-http is now 5 (2m16.913620288s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:16:06.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-799xl" for this suite.
Feb 20 19:16:12.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:16:14.285: INFO: namespace: e2e-tests-container-probe-799xl, resource: bindings, ignored listing per whitelist
Feb 20 19:16:14.665: INFO: namespace e2e-tests-container-probe-799xl deletion completed in 7.796422942s

• [SLOW TEST:150.652 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:16:14.665: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-qpblp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0220 19:16:27.072888   30217 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 19:16:27.072: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:16:27.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qpblp" for this suite.
Feb 20 19:16:33.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:16:34.640: INFO: namespace: e2e-tests-gc-qpblp, resource: bindings, ignored listing per whitelist
Feb 20 19:16:35.147: INFO: namespace e2e-tests-gc-qpblp deletion completed in 8.031736502s

• [SLOW TEST:20.481 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:16:35.147: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-s7f9r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 20 19:16:41.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:41.345: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:43.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:43.387: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:45.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:45.389: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:47.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:47.387: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:49.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:49.387: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:51.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:51.388: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:53.346: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:53.396: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:55.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:55.388: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:57.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:57.388: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:16:59.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:16:59.388: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 19:17:01.345: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 19:17:01.388: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:17:01.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-s7f9r" for this suite.
Feb 20 19:17:23.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:17:24.148: INFO: namespace: e2e-tests-container-lifecycle-hook-s7f9r, resource: bindings, ignored listing per whitelist
Feb 20 19:17:25.239: INFO: namespace e2e-tests-container-lifecycle-hook-s7f9r deletion completed in 23.808475447s

• [SLOW TEST:50.092 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:17:25.240: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-t9d7n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 20 19:17:29.814: INFO: Successfully updated pod "annotationupdate28c683f4-3544-11e9-96fe-8e2b2e6369d7"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:17:31.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t9d7n" for this suite.
Feb 20 19:17:48.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:17:48.878: INFO: namespace: e2e-tests-downward-api-t9d7n, resource: bindings, ignored listing per whitelist
Feb 20 19:17:49.718: INFO: namespace e2e-tests-downward-api-t9d7n deletion completed in 17.764263161s

• [SLOW TEST:24.479 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:17:49.718: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-95kd4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-4nxk
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 19:17:51.589: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-4nxk" in namespace "e2e-tests-subpath-95kd4" to be "success or failure"
Feb 20 19:17:51.632: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Pending", Reason="", readiness=false. Elapsed: 42.228116ms
Feb 20 19:17:53.674: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 2.085167428s
Feb 20 19:17:55.717: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 4.128126205s
Feb 20 19:17:57.761: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 6.171231566s
Feb 20 19:17:59.803: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 8.214082994s
Feb 20 19:18:01.846: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 10.257192832s
Feb 20 19:18:03.890: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 12.300598796s
Feb 20 19:18:05.933: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 14.343325086s
Feb 20 19:18:07.976: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 16.386295176s
Feb 20 19:18:10.019: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 18.429232845s
Feb 20 19:18:12.063: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Running", Reason="", readiness=false. Elapsed: 20.473221483s
Feb 20 19:18:14.105: INFO: Pod "pod-subpath-test-projected-4nxk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.516148107s
STEP: Saw pod success
Feb 20 19:18:14.105: INFO: Pod "pod-subpath-test-projected-4nxk" satisfied condition "success or failure"
Feb 20 19:18:14.148: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-subpath-test-projected-4nxk container test-container-subpath-projected-4nxk: <nil>
STEP: delete the pod
Feb 20 19:18:14.243: INFO: Waiting for pod pod-subpath-test-projected-4nxk to disappear
Feb 20 19:18:14.285: INFO: Pod pod-subpath-test-projected-4nxk no longer exists
STEP: Deleting pod pod-subpath-test-projected-4nxk
Feb 20 19:18:14.285: INFO: Deleting pod "pod-subpath-test-projected-4nxk" in namespace "e2e-tests-subpath-95kd4"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:18:14.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-95kd4" for this suite.
Feb 20 19:18:20.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:18:20.753: INFO: namespace: e2e-tests-subpath-95kd4, resource: bindings, ignored listing per whitelist
Feb 20 19:18:22.150: INFO: namespace e2e-tests-subpath-95kd4 deletion completed in 7.778783283s

• [SLOW TEST:32.431 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:18:22.150: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4fh7x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 20 19:18:23.870: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 20 19:18:23.870: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:26.440: INFO: stderr: ""
Feb 20 19:18:26.440: INFO: stdout: "service/redis-slave created\n"
Feb 20 19:18:26.440: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 20 19:18:26.440: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:26.877: INFO: stderr: ""
Feb 20 19:18:26.877: INFO: stdout: "service/redis-master created\n"
Feb 20 19:18:26.877: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 20 19:18:26.877: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:27.352: INFO: stderr: ""
Feb 20 19:18:27.352: INFO: stdout: "service/frontend created\n"
Feb 20 19:18:27.352: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 20 19:18:27.352: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:27.763: INFO: stderr: ""
Feb 20 19:18:27.763: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 20 19:18:27.763: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 20 19:18:27.763: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:28.180: INFO: stderr: ""
Feb 20 19:18:28.180: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 20 19:18:28.180: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 20 19:18:28.180: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:28.648: INFO: stderr: ""
Feb 20 19:18:28.648: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 20 19:18:28.648: INFO: Waiting for all frontend pods to be Running.
Feb 20 19:18:53.700: INFO: Waiting for frontend to serve content.
Feb 20 19:18:53.831: INFO: Trying to add a new entry to the guestbook.
Feb 20 19:18:53.962: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 20 19:18:54.013: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:54.321: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:18:54.321: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:18:54.321: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:54.618: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:18:54.618: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:18:54.618: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:54.892: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:18:54.892: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:18:54.892: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:55.186: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:18:55.186: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:18:55.187: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:55.495: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:18:55.495: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:18:55.495: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4fh7x'
Feb 20 19:18:55.771: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:18:55.771: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:18:55.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4fh7x" for this suite.
Feb 20 19:19:39.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:19:40.280: INFO: namespace: e2e-tests-kubectl-4fh7x, resource: bindings, ignored listing per whitelist
Feb 20 19:19:41.588: INFO: namespace e2e-tests-kubectl-4fh7x deletion completed in 45.774617528s

• [SLOW TEST:79.438 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:19:41.589: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-7fh6d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7fh6d
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-7fh6d
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-7fh6d
Feb 20 19:19:43.406: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 20 19:19:53.449: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 20 19:19:53.493: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:19:54.327: INFO: stderr: ""
Feb 20 19:19:54.327: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:19:54.327: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:19:54.370: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 20 19:20:04.424: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 19:20:04.424: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 19:20:04.594: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999586s
Feb 20 19:20:05.637: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.956923659s
Feb 20 19:20:06.680: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.913566624s
Feb 20 19:20:07.723: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.870857608s
Feb 20 19:20:08.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.827340057s
Feb 20 19:20:09.810: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.783999196s
Feb 20 19:20:10.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.740993062s
Feb 20 19:20:11.896: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.697722092s
Feb 20 19:20:12.940: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.65460447s
Feb 20 19:20:13.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 611.047971ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-7fh6d
Feb 20 19:20:15.026: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:20:15.903: INFO: stderr: ""
Feb 20 19:20:15.903: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:20:15.903: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:20:15.903: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:20:16.835: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 20 19:20:16.835: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:20:16.835: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:20:16.835: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:20:17.698: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 20 19:20:17.698: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:20:17.698: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:20:17.741: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:20:17.741: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:20:17.741: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 20 19:20:17.784: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:20:18.633: INFO: stderr: ""
Feb 20 19:20:18.633: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:20:18.633: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:20:18.633: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:20:19.506: INFO: stderr: ""
Feb 20 19:20:19.506: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:20:19.506: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:20:19.506: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:20:20.350: INFO: stderr: ""
Feb 20 19:20:20.350: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:20:20.350: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:20:20.350: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 19:20:20.392: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 20 19:20:30.478: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 19:20:30.478: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 19:20:30.478: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 19:20:30.605: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:30.605: INFO: ss-0  ip-10-250-0-144.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:19:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:19:43 +0000 UTC  }]
Feb 20 19:20:30.606: INFO: ss-1  ip-10-250-10-87.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:30.606: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:30.606: INFO: 
Feb 20 19:20:30.606: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:20:31.649: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:31.649: INFO: ss-0  ip-10-250-0-144.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:19:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:19:43 +0000 UTC  }]
Feb 20 19:20:31.649: INFO: ss-1  ip-10-250-10-87.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:31.649: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:31.649: INFO: 
Feb 20 19:20:31.649: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:20:32.692: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:32.692: INFO: ss-0  ip-10-250-0-144.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:19:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:19:43 +0000 UTC  }]
Feb 20 19:20:32.692: INFO: ss-1  ip-10-250-10-87.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:32.692: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:32.692: INFO: 
Feb 20 19:20:32.692: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:20:33.735: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:33.735: INFO: ss-0  ip-10-250-0-144.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:19:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:19:43 +0000 UTC  }]
Feb 20 19:20:33.735: INFO: ss-1  ip-10-250-10-87.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:33.735: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:33.735: INFO: 
Feb 20 19:20:33.735: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:20:34.779: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:34.779: INFO: ss-1  ip-10-250-10-87.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:34.779: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:34.779: INFO: 
Feb 20 19:20:34.779: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 20 19:20:35.823: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:35.823: INFO: ss-1  ip-10-250-10-87.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:35.823: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:35.823: INFO: 
Feb 20 19:20:35.823: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 20 19:20:36.866: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:36.866: INFO: ss-1  ip-10-250-10-87.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:36.866: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:36.866: INFO: 
Feb 20 19:20:36.866: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 20 19:20:37.909: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:37.909: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:37.909: INFO: 
Feb 20 19:20:37.909: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 20 19:20:38.952: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:38.952: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:38.953: INFO: 
Feb 20 19:20:38.953: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 20 19:20:39.996: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 20 19:20:39.996: INFO: ss-2  ip-10-250-0-144.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:20:04 +0000 UTC  }]
Feb 20 19:20:39.996: INFO: 
Feb 20 19:20:39.996: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-7fh6d
Feb 20 19:20:41.039: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:20:41.448: INFO: rc: 1
Feb 20 19:20:41.448: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001489f20 exit status 1 <nil> <nil> true [0xc0023e8798 0xc0023e87b0 0xc0023e8818] [0xc0023e8798 0xc0023e87b0 0xc0023e8818] [0xc0023e87a8 0xc0023e87d8] [0x933040 0x933040] 0xc00118bec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:20:51.448: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:20:51.673: INFO: rc: 1
Feb 20 19:20:51.673: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a5a1e0 exit status 1 <nil> <nil> true [0xc0023e8848 0xc0023e88e0 0xc0023e8948] [0xc0023e8848 0xc0023e88e0 0xc0023e8948] [0xc0023e88b8 0xc0023e8900] [0x933040 0x933040] 0xc0009ec720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:21:01.673: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:21:01.930: INFO: rc: 1
Feb 20 19:21:01.930: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a05d0 exit status 1 <nil> <nil> true [0xc001dfa138 0xc001dfa150 0xc001dfa168] [0xc001dfa138 0xc001dfa150 0xc001dfa168] [0xc001dfa148 0xc001dfa160] [0x933040 0x933040] 0xc001808540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:21:11.931: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:21:12.198: INFO: rc: 1
Feb 20 19:21:12.198: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001768b70 exit status 1 <nil> <nil> true [0xc00000f840 0xc00000f8e0 0xc00000f938] [0xc00000f840 0xc00000f8e0 0xc00000f938] [0xc00000f8d8 0xc00000f928] [0x933040 0x933040] 0xc0012585a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:21:22.199: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:21:22.433: INFO: rc: 1
Feb 20 19:21:22.433: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a08d0 exit status 1 <nil> <nil> true [0xc001dfa170 0xc001dfa188 0xc001dfa1a0] [0xc001dfa170 0xc001dfa188 0xc001dfa1a0] [0xc001dfa180 0xc001dfa198] [0x933040 0x933040] 0xc0018091a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:21:32.433: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:21:32.654: INFO: rc: 1
Feb 20 19:21:32.655: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a0b70 exit status 1 <nil> <nil> true [0xc001dfa1a8 0xc001dfa1c0 0xc001dfa1d8] [0xc001dfa1a8 0xc001dfa1c0 0xc001dfa1d8] [0xc001dfa1b8 0xc001dfa1d0] [0x933040 0x933040] 0xc001720360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:21:42.655: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:21:42.904: INFO: rc: 1
Feb 20 19:21:42.904: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011a10b0 exit status 1 <nil> <nil> true [0xc001dfa1e0 0xc001dfa1f8 0xc001dfa210] [0xc001dfa1e0 0xc001dfa1f8 0xc001dfa210] [0xc001dfa1f0 0xc001dfa208] [0x933040 0x933040] 0xc001631ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:21:52.904: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:21:53.132: INFO: rc: 1
Feb 20 19:21:53.132: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a5a450 exit status 1 <nil> <nil> true [0xc0023e8978 0xc0023e8a38 0xc0023e8b18] [0xc0023e8978 0xc0023e8a38 0xc0023e8b18] [0xc0023e8a10 0xc0023e8ac0] [0x933040 0x933040] 0xc0009ecf60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:22:03.132: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:22:03.395: INFO: rc: 1
Feb 20 19:22:03.395: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a5a6c0 exit status 1 <nil> <nil> true [0xc0023e8b28 0xc0023e8ba0 0xc0023e8bf0] [0xc0023e8b28 0xc0023e8ba0 0xc0023e8bf0] [0xc0023e8b98 0xc0023e8bd8] [0x933040 0x933040] 0xc0009ed8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:22:13.395: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:22:13.622: INFO: rc: 1
Feb 20 19:22:13.622: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014882a0 exit status 1 <nil> <nil> true [0xc0023e8008 0xc0023e8030 0xc0023e8068] [0xc0023e8008 0xc0023e8030 0xc0023e8068] [0xc0023e8028 0xc0023e8060] [0x933040 0x933040] 0xc001631ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:22:23.622: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:22:23.859: INFO: rc: 1
Feb 20 19:22:23.859: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6a5a0 exit status 1 <nil> <nil> true [0xc001dfa000 0xc001dfa018 0xc001dfa030] [0xc001dfa000 0xc001dfa018 0xc001dfa030] [0xc001dfa010 0xc001dfa028] [0x933040 0x933040] 0xc001808ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:22:33.859: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:22:34.104: INFO: rc: 1
Feb 20 19:22:34.104: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488540 exit status 1 <nil> <nil> true [0xc0023e8078 0xc0023e80a0 0xc0023e80d8] [0xc0023e8078 0xc0023e80a0 0xc0023e80d8] [0xc0023e8098 0xc0023e80b8] [0x933040 0x933040] 0xc00149e8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:22:44.104: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:22:44.411: INFO: rc: 1
Feb 20 19:22:44.411: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6a900 exit status 1 <nil> <nil> true [0xc001dfa038 0xc001dfa050 0xc001dfa068] [0xc001dfa038 0xc001dfa050 0xc001dfa068] [0xc001dfa048 0xc001dfa060] [0x933040 0x933040] 0xc0018094a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:22:54.412: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:22:54.644: INFO: rc: 1
Feb 20 19:22:54.644: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488840 exit status 1 <nil> <nil> true [0xc0023e80e0 0xc0023e8110 0xc0023e8140] [0xc0023e80e0 0xc0023e8110 0xc0023e8140] [0xc0023e8100 0xc0023e8138] [0x933040 0x933040] 0xc00149fe60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:23:04.644: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:04.936: INFO: rc: 1
Feb 20 19:23:04.936: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6adb0 exit status 1 <nil> <nil> true [0xc001dfa070 0xc001dfa088 0xc001dfa0a0] [0xc001dfa070 0xc001dfa088 0xc001dfa0a0] [0xc001dfa080 0xc001dfa098] [0x933040 0x933040] 0xc0017d4ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:23:14.936: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:15.168: INFO: rc: 1
Feb 20 19:23:15.169: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6b140 exit status 1 <nil> <nil> true [0xc001dfa0a8 0xc001dfa0c0 0xc001dfa0d8] [0xc001dfa0a8 0xc001dfa0c0 0xc001dfa0d8] [0xc001dfa0b8 0xc001dfa0d0] [0x933040 0x933040] 0xc0017d55c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:23:25.169: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:25.396: INFO: rc: 1
Feb 20 19:23:25.396: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000acc5a0 exit status 1 <nil> <nil> true [0xc00018c000 0xc00018c3e8 0xc00018c810] [0xc00018c000 0xc00018c3e8 0xc00018c810] [0xc00018c248 0xc00018c7f0] [0x933040 0x933040] 0xc00118a300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:23:35.397: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:35.629: INFO: rc: 1
Feb 20 19:23:35.629: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6b680 exit status 1 <nil> <nil> true [0xc001dfa0e0 0xc001dfa0f8 0xc001dfa110] [0xc001dfa0e0 0xc001dfa0f8 0xc001dfa110] [0xc001dfa0f0 0xc001dfa108] [0x933040 0x933040] 0xc0017d5920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:23:45.630: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:45.883: INFO: rc: 1
Feb 20 19:23:45.883: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f9e2a0 exit status 1 <nil> <nil> true [0xc00000e058 0xc00000e1b0 0xc00000e440] [0xc00000e058 0xc00000e1b0 0xc00000e440] [0xc00000e170 0xc00000e2d0] [0x933040 0x933040] 0xc00091ef00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:23:55.883: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:56.140: INFO: rc: 1
Feb 20 19:23:56.140: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488e10 exit status 1 <nil> <nil> true [0xc0023e8158 0xc0023e81c8 0xc0023e82b0] [0xc0023e8158 0xc0023e81c8 0xc0023e82b0] [0xc0023e8190 0xc0023e8250] [0x933040 0x933040] 0xc00122d3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:24:06.140: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:24:06.432: INFO: rc: 1
Feb 20 19:24:06.432: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6b920 exit status 1 <nil> <nil> true [0xc001dfa120 0xc001dfa138 0xc001dfa150] [0xc001dfa120 0xc001dfa138 0xc001dfa150] [0xc001dfa130 0xc001dfa148] [0x933040 0x933040] 0xc0017d5c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:24:16.433: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:24:16.695: INFO: rc: 1
Feb 20 19:24:16.695: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014882d0 exit status 1 <nil> <nil> true [0xc00000e058 0xc00000e1b0 0xc00000e440] [0xc00000e058 0xc00000e1b0 0xc00000e440] [0xc00000e170 0xc00000e2d0] [0x933040 0x933040] 0xc00149eae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:24:26.695: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:24:26.926: INFO: rc: 1
Feb 20 19:24:26.926: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000acc5d0 exit status 1 <nil> <nil> true [0xc0023e8000 0xc0023e8028 0xc0023e8060] [0xc0023e8000 0xc0023e8028 0xc0023e8060] [0xc0023e8018 0xc0023e8038] [0x933040 0x933040] 0xc001808ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:24:36.927: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:24:37.161: INFO: rc: 1
Feb 20 19:24:37.161: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f9e330 exit status 1 <nil> <nil> true [0xc00018c000 0xc00018c3e8 0xc00018c810] [0xc00018c000 0xc00018c3e8 0xc00018c810] [0xc00018c248 0xc00018c7f0] [0x933040 0x933040] 0xc0016309c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:24:47.161: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:24:47.482: INFO: rc: 1
Feb 20 19:24:47.482: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f9e8d0 exit status 1 <nil> <nil> true [0xc00018c820 0xc00018ca18 0xc00018cb70] [0xc00018c820 0xc00018ca18 0xc00018cb70] [0xc00018c9f8 0xc00018cb68] [0x933040 0x933040] 0xc00091ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:24:57.482: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:24:57.708: INFO: rc: 1
Feb 20 19:24:57.708: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6a5d0 exit status 1 <nil> <nil> true [0xc001dfa000 0xc001dfa018 0xc001dfa030] [0xc001dfa000 0xc001dfa018 0xc001dfa030] [0xc001dfa010 0xc001dfa028] [0x933040 0x933040] 0xc00122d3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:25:07.708: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:25:07.957: INFO: rc: 1
Feb 20 19:25:07.957: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488570 exit status 1 <nil> <nil> true [0xc00000e4e8 0xc00000e758 0xc00000e998] [0xc00000e4e8 0xc00000e758 0xc00000e998] [0xc00000e6b8 0xc00000e948] [0x933040 0x933040] 0xc00118a000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:25:17.957: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:25:18.182: INFO: rc: 1
Feb 20 19:25:18.182: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001488870 exit status 1 <nil> <nil> true [0xc00000eaa8 0xc00000eb68 0xc00000ec00] [0xc00000eaa8 0xc00000eb68 0xc00000ec00] [0xc00000eb28 0xc00000ebd0] [0x933040 0x933040] 0xc00118a420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:25:28.183: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:25:28.409: INFO: rc: 1
Feb 20 19:25:28.409: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6a930 exit status 1 <nil> <nil> true [0xc001dfa038 0xc001dfa050 0xc001dfa068] [0xc001dfa038 0xc001dfa050 0xc001dfa068] [0xc001dfa048 0xc001dfa060] [0x933040 0x933040] 0xc0017d4ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:25:38.410: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:25:38.664: INFO: rc: 1
Feb 20 19:25:38.665: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c6ae40 exit status 1 <nil> <nil> true [0xc001dfa070 0xc001dfa088 0xc001dfa0a0] [0xc001dfa070 0xc001dfa088 0xc001dfa0a0] [0xc001dfa080 0xc001dfa098] [0x933040 0x933040] 0xc0017d5620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 19:25:48.665: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-7fh6d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:25:48.920: INFO: rc: 1
Feb 20 19:25:48.921: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 20 19:25:48.921: INFO: Scaling statefulset ss to 0
Feb 20 19:25:49.047: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 19:25:49.090: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7fh6d
Feb 20 19:25:49.132: INFO: Scaling statefulset ss to 0
Feb 20 19:25:49.259: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 19:25:49.301: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:25:49.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7fh6d" for this suite.
Feb 20 19:25:55.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:25:56.313: INFO: namespace: e2e-tests-statefulset-7fh6d, resource: bindings, ignored listing per whitelist
Feb 20 19:25:57.199: INFO: namespace e2e-tests-statefulset-7fh6d deletion completed in 7.728089s

• [SLOW TEST:375.610 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:25:57.199: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-jqlst
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-59eccf74-3545-11e9-96fe-8e2b2e6369d7
STEP: Creating configMap with name cm-test-opt-upd-59eccfaf-3545-11e9-96fe-8e2b2e6369d7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-59eccf74-3545-11e9-96fe-8e2b2e6369d7
STEP: Updating configmap cm-test-opt-upd-59eccfaf-3545-11e9-96fe-8e2b2e6369d7
STEP: Creating configMap with name cm-test-opt-create-59eccfc3-3545-11e9-96fe-8e2b2e6369d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:26:05.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jqlst" for this suite.
Feb 20 19:26:27.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:26:29.262: INFO: namespace: e2e-tests-configmap-jqlst, resource: bindings, ignored listing per whitelist
Feb 20 19:26:29.516: INFO: namespace e2e-tests-configmap-jqlst deletion completed in 23.745376371s

• [SLOW TEST:32.316 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:26:29.516: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7wz5g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 20 19:26:31.267: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:31.812: INFO: stderr: ""
Feb 20 19:26:31.812: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 19:26:31.812: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:32.052: INFO: stderr: ""
Feb 20 19:26:32.052: INFO: stdout: "update-demo-nautilus-gknhr update-demo-nautilus-rn5tf "
Feb 20 19:26:32.052: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-gknhr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:32.302: INFO: stderr: ""
Feb 20 19:26:32.302: INFO: stdout: ""
Feb 20 19:26:32.302: INFO: update-demo-nautilus-gknhr is created but not running
Feb 20 19:26:37.302: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:37.561: INFO: stderr: ""
Feb 20 19:26:37.561: INFO: stdout: "update-demo-nautilus-gknhr update-demo-nautilus-rn5tf "
Feb 20 19:26:37.561: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-gknhr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:37.792: INFO: stderr: ""
Feb 20 19:26:37.792: INFO: stdout: "true"
Feb 20 19:26:37.792: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-gknhr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:38.034: INFO: stderr: ""
Feb 20 19:26:38.034: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:26:38.034: INFO: validating pod update-demo-nautilus-gknhr
Feb 20 19:26:38.163: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:26:38.163: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:26:38.163: INFO: update-demo-nautilus-gknhr is verified up and running
Feb 20 19:26:38.163: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-rn5tf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:38.468: INFO: stderr: ""
Feb 20 19:26:38.468: INFO: stdout: "true"
Feb 20 19:26:38.468: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-rn5tf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:38.711: INFO: stderr: ""
Feb 20 19:26:38.712: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:26:38.712: INFO: validating pod update-demo-nautilus-rn5tf
Feb 20 19:26:38.843: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:26:38.843: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:26:38.843: INFO: update-demo-nautilus-rn5tf is verified up and running
STEP: using delete to clean up resources
Feb 20 19:26:38.843: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:39.131: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:26:39.132: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 20 19:26:39.132: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-7wz5g'
Feb 20 19:26:39.425: INFO: stderr: "No resources found.\n"
Feb 20 19:26:39.426: INFO: stdout: ""
Feb 20 19:26:39.426: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -l name=update-demo --namespace=e2e-tests-kubectl-7wz5g -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 19:26:39.661: INFO: stderr: ""
Feb 20 19:26:39.662: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:26:39.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7wz5g" for this suite.
Feb 20 19:27:01.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:27:02.380: INFO: namespace: e2e-tests-kubectl-7wz5g, resource: bindings, ignored listing per whitelist
Feb 20 19:27:03.439: INFO: namespace e2e-tests-kubectl-7wz5g deletion completed in 23.734142473s

• [SLOW TEST:33.923 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:27:03.439: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mdbtc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:27:05.210: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8168e6f4-3545-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-mdbtc" to be "success or failure"
Feb 20 19:27:05.252: INFO: Pod "downwardapi-volume-8168e6f4-3545-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.299096ms
Feb 20 19:27:07.295: INFO: Pod "downwardapi-volume-8168e6f4-3545-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085010019s
STEP: Saw pod success
Feb 20 19:27:07.295: INFO: Pod "downwardapi-volume-8168e6f4-3545-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:27:07.337: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-8168e6f4-3545-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:27:07.441: INFO: Waiting for pod downwardapi-volume-8168e6f4-3545-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:27:07.483: INFO: Pod downwardapi-volume-8168e6f4-3545-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:27:07.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mdbtc" for this suite.
Feb 20 19:27:13.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:27:15.507: INFO: namespace: e2e-tests-projected-mdbtc, resource: bindings, ignored listing per whitelist
Feb 20 19:27:15.550: INFO: namespace e2e-tests-projected-mdbtc deletion completed in 8.023266624s

• [SLOW TEST:12.111 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:27:15.550: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-shqfk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:27:17.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-shqfk" for this suite.
Feb 20 19:27:23.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:27:24.182: INFO: namespace: e2e-tests-services-shqfk, resource: bindings, ignored listing per whitelist
Feb 20 19:27:25.315: INFO: namespace e2e-tests-services-shqfk deletion completed in 7.76656905s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:9.765 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:27:25.315: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4hmjz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb 20 19:27:26.994: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-4hmjz'
Feb 20 19:27:27.596: INFO: stderr: ""
Feb 20 19:27:27.597: INFO: stdout: "pod/pause created\n"
Feb 20 19:27:27.597: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 20 19:27:27.597: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-4hmjz" to be "running and ready"
Feb 20 19:27:27.639: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 42.015302ms
Feb 20 19:27:29.682: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.085008946s
Feb 20 19:27:29.682: INFO: Pod "pause" satisfied condition "running and ready"
Feb 20 19:27:29.682: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 20 19:27:29.682: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-4hmjz'
Feb 20 19:27:29.966: INFO: stderr: ""
Feb 20 19:27:29.967: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 20 19:27:29.967: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pod pause -L testing-label --namespace=e2e-tests-kubectl-4hmjz'
Feb 20 19:27:30.282: INFO: stderr: ""
Feb 20 19:27:30.282: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 20 19:27:30.282: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml label pods pause testing-label- --namespace=e2e-tests-kubectl-4hmjz'
Feb 20 19:27:30.592: INFO: stderr: ""
Feb 20 19:27:30.592: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 20 19:27:30.592: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pod pause -L testing-label --namespace=e2e-tests-kubectl-4hmjz'
Feb 20 19:27:30.841: INFO: stderr: ""
Feb 20 19:27:30.841: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb 20 19:27:30.841: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4hmjz'
Feb 20 19:27:31.119: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:27:31.119: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 20 19:27:31.119: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-4hmjz'
Feb 20 19:27:31.393: INFO: stderr: "No resources found.\n"
Feb 20 19:27:31.393: INFO: stdout: ""
Feb 20 19:27:31.393: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -l name=pause --namespace=e2e-tests-kubectl-4hmjz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 19:27:31.628: INFO: stderr: ""
Feb 20 19:27:31.628: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:27:31.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4hmjz" for this suite.
Feb 20 19:27:37.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:27:39.142: INFO: namespace: e2e-tests-kubectl-4hmjz, resource: bindings, ignored listing per whitelist
Feb 20 19:27:39.453: INFO: namespace e2e-tests-kubectl-4hmjz deletion completed in 7.78117101s

• [SLOW TEST:14.138 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:27:39.453: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-zwznd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-zwznd A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-zwznd;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-zwznd A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-zwznd.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-zwznd.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-zwznd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-zwznd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-zwznd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-zwznd.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zwznd.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 189.203.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.203.189_udp@PTR;check="$$(dig +tcp +noall +answer +search 189.203.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.203.189_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-zwznd A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-zwznd;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-zwznd A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-zwznd;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-zwznd.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-zwznd.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-zwznd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-zwznd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-zwznd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-zwznd.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zwznd.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 189.203.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.203.189_udp@PTR;check="$$(dig +tcp +noall +answer +search 189.203.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.203.189_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 19:27:43.555: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:43.600: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:43.644: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:43.687: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:43.731: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:43.776: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:43.820: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:43.864: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.185: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.230: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.276: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.321: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.364: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.407: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.451: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.495: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:44.761: INFO: Lookups using e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-zwznd wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-zwznd jessie_tcp@dns-test-service.e2e-tests-dns-zwznd jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc]

Feb 20 19:27:49.805: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:49.849: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:49.892: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:49.936: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:49.980: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.023: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.068: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.113: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.425: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.469: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.513: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.558: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.605: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.649: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.693: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:50.737: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:51.005: INFO: Lookups using e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-zwznd wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-zwznd jessie_tcp@dns-test-service.e2e-tests-dns-zwznd jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc]

Feb 20 19:27:54.805: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:54.849: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:54.893: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:54.937: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:54.981: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.025: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.071: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.117: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.428: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.471: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.516: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.559: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.603: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.647: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.691: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:55.735: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:56.003: INFO: Lookups using e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-zwznd wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-zwznd jessie_tcp@dns-test-service.e2e-tests-dns-zwznd jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc]

Feb 20 19:27:59.808: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:59.851: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:59.896: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:59.939: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:27:59.984: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.045: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.095: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.142: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.456: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.499: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.543: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.590: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.635: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.679: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.724: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:00.768: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:01.036: INFO: Lookups using e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-zwznd wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-zwznd jessie_tcp@dns-test-service.e2e-tests-dns-zwznd jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc]

Feb 20 19:28:04.807: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:04.852: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:04.901: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:04.945: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:04.989: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.032: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.076: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.124: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.437: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.481: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.525: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.573: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.617: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.661: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.704: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:05.751: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:06.025: INFO: Lookups using e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-zwznd wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-zwznd jessie_tcp@dns-test-service.e2e-tests-dns-zwznd jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc]

Feb 20 19:28:09.806: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:09.849: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:09.893: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:09.937: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:09.981: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.025: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.069: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.114: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.432: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.475: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.519: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.564: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.607: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.654: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.704: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:10.748: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc from pod e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7: the server could not find the requested resource (get pods dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7)
Feb 20 19:28:11.017: INFO: Lookups using e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-zwznd wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd wheezy_udp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@dns-test-service.e2e-tests-dns-zwznd.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-zwznd jessie_tcp@dns-test-service.e2e-tests-dns-zwznd jessie_udp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@dns-test-service.e2e-tests-dns-zwznd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zwznd.svc]

Feb 20 19:28:16.036: INFO: DNS probes using e2e-tests-dns-zwznd/dns-test-96eb0228-3545-11e9-96fe-8e2b2e6369d7 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:28:16.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-zwznd" for this suite.
Feb 20 19:28:22.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:28:23.110: INFO: namespace: e2e-tests-dns-zwznd, resource: bindings, ignored listing per whitelist
Feb 20 19:28:23.970: INFO: namespace e2e-tests-dns-zwznd deletion completed in 7.75114527s

• [SLOW TEST:44.517 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:28:23.970: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-nf98r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:28:25.667: INFO: Creating deployment "nginx-deployment"
Feb 20 19:28:25.710: INFO: Waiting for observed generation 1
Feb 20 19:28:25.752: INFO: Waiting for all required pods to come up
Feb 20 19:28:25.795: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 20 19:28:29.882: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 20 19:28:29.967: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 20 19:28:30.052: INFO: Updating deployment nginx-deployment
Feb 20 19:28:30.052: INFO: Waiting for observed generation 2
Feb 20 19:28:32.137: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 20 19:28:32.179: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 20 19:28:32.221: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 20 19:28:32.350: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 20 19:28:32.350: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 20 19:28:32.393: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 20 19:28:32.477: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 20 19:28:32.477: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 20 19:28:32.563: INFO: Updating deployment nginx-deployment
Feb 20 19:28:32.563: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 20 19:28:32.655: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 20 19:28:32.754: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 19:28:32.956: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-nf98r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nf98r/deployments/nginx-deployment,UID:b16691d6-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16852,Generation:3,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:32,UpdatedReplicas:12,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-20 19:28:32 +0000 UTC 2019-02-20 19:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-20 19:28:32 +0000 UTC 2019-02-20 19:28:25 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 20 19:28:32.999: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-nf98r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nf98r/replicasets/nginx-deployment-65bbdb5f8,UID:b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16853,Generation:3,CreationTimestamp:2019-02-20 19:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b16691d6-3545-11e9-a8b6-5a3f4013d0a1 0xc001c9da37 0xc001c9da38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:28:32.999: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 20 19:28:32.999: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-nf98r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nf98r/replicasets/nginx-deployment-555b55d965,UID:b1674920-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16845,Generation:3,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b16691d6-3545-11e9-a8b6-5a3f4013d0a1 0xc001c9d977 0xc001c9d978}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 20 19:28:33.092: INFO: Pod "nginx-deployment-555b55d965-29tck" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-29tck,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-29tck,UID:b16828a1-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16714,Generation:0,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.184/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc0013686a7 0xc0013686a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001368720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001368740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.184,StartTime:2019-02-20 19:28:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 19:28:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://cf2ca6e423eb812520e2bb745ce18648a49d7f716a2f571310c3a868b25073a8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.092: INFO: Pod "nginx-deployment-555b55d965-2jrjm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2jrjm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-2jrjm,UID:b168fb5b-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16744,Generation:0,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.187/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc0013688d7 0xc0013688d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001368980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013689a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.187,StartTime:2019-02-20 19:28:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 19:28:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://d30824b8b97a85959b50f02d6503f837bdc533e67e62ccad4a3532584b6c045d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.092: INFO: Pod "nginx-deployment-555b55d965-667nc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-667nc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-667nc,UID:b16891ca-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16723,Generation:0,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.37/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001368b57 0xc001368b58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001368bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001368be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:100.96.0.37,StartTime:2019-02-20 19:28:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 19:28:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://50b01a0f0f749f74c4ab7bc2a24ef8db5c962ef2c9ad7b019dc4cedc2ba7f9b3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.093: INFO: Pod "nginx-deployment-555b55d965-6cx8w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6cx8w,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-6cx8w,UID:b57cfa84-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16819,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001368cd0 0xc001368cd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001368d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001368d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.093: INFO: Pod "nginx-deployment-555b55d965-6r6l4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6r6l4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-6r6l4,UID:b1697ba9-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16717,Generation:0,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.39/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001369247 0xc001369248}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013692b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013692d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:100.96.0.39,StartTime:2019-02-20 19:28:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 19:28:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://5e72cffbda7076c7d93e3ecb559c85ccfe2daf036dd7ec71bb671d84229215c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.093: INFO: Pod "nginx-deployment-555b55d965-7l9s8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7l9s8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-7l9s8,UID:b168fc08-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16732,Generation:0,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.186/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc0013693a0 0xc0013693a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001369400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001369420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.186,StartTime:2019-02-20 19:28:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 19:28:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://66f9ce4a0e48adb99be584745cb6536104e4ac7221dd7a143cb05530d41e9bac}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.093: INFO: Pod "nginx-deployment-555b55d965-7z5s7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7z5s7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-7z5s7,UID:b57e0a9f-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16843,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc0013694e7 0xc0013694e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001369550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001369590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.093: INFO: Pod "nginx-deployment-555b55d965-9b52b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9b52b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-9b52b,UID:b5877846-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16859,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001369647 0xc001369648}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013696b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013696d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.093: INFO: Pod "nginx-deployment-555b55d965-bsstv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bsstv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-bsstv,UID:b57e0903-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16851,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001369867 0xc001369868}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013698d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013698f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.093: INFO: Pod "nginx-deployment-555b55d965-gcg6k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gcg6k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-gcg6k,UID:b5876822-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16860,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc0013699a7 0xc0013699a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001369ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001369af0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.093: INFO: Pod "nginx-deployment-555b55d965-k74zj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k74zj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-k74zj,UID:b16982a6-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16741,Generation:0,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.188/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001369bb7 0xc001369bb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001369c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001369cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.188,StartTime:2019-02-20 19:28:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 19:28:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://5e0cecee574770c7c5296a709c429394fc5e0419ffc592521ac3f6f84c743473}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.094: INFO: Pod "nginx-deployment-555b55d965-l7lz8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l7lz8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-l7lz8,UID:b5878b60-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16839,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001369d97 0xc001369d98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001369e00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001369e20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.094: INFO: Pod "nginx-deployment-555b55d965-lhjm7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lhjm7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-lhjm7,UID:b57e0000-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16857,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001369f00 0xc001369f01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001369f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001369f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.094: INFO: Pod "nginx-deployment-555b55d965-mgs4p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mgs4p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-mgs4p,UID:b168f5aa-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16726,Generation:0,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.38/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001b58047 0xc001b58048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b580e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b58100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:100.96.0.38,StartTime:2019-02-20 19:28:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 19:28:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://076cd1ebc0b5855f73370ebfcad0cb271030e43a20d7befbf2d8661a15b34457}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.094: INFO: Pod "nginx-deployment-555b55d965-mszrw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mszrw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-mszrw,UID:b16a4e4e-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16720,Generation:0,CreationTimestamp:2019-02-20 19:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.40/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001b58340 0xc001b58341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b583a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b583c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:100.96.0.40,StartTime:2019-02-20 19:28:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 19:28:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://1d979761a51b10d3a68d2e5e984d309f813b6ec05f22ed3694ee5c9a680820a8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.094: INFO: Pod "nginx-deployment-555b55d965-rfn52" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rfn52,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-rfn52,UID:b5877f44-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16862,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001b584c0 0xc001b584c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b58630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b58650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.094: INFO: Pod "nginx-deployment-555b55d965-v4qhf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-v4qhf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-v4qhf,UID:b57df888-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16854,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001b58707 0xc001b58708}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b58800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b58820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.094: INFO: Pod "nginx-deployment-555b55d965-vszwd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vszwd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-vszwd,UID:b57d58f4-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16832,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001b588d7 0xc001b588d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b589b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b589d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.095: INFO: Pod "nginx-deployment-555b55d965-xxgfs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xxgfs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-xxgfs,UID:b57d5acb-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16848,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001b58a87 0xc001b58a88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b58af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b58b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.095: INFO: Pod "nginx-deployment-555b55d965-zdl5g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zdl5g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-555b55d965-zdl5g,UID:b58778c4-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16864,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b1674920-3545-11e9-a8b6-5a3f4013d0a1 0xc001b58c27 0xc001b58c28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b58c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b58cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.096: INFO: Pod "nginx-deployment-65bbdb5f8-79lrm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-79lrm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-79lrm,UID:b409975a-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16788,Generation:0,CreationTimestamp:2019-02-20 19:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.192/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b58dc7 0xc001b58dc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b58e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b58e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.096: INFO: Pod "nginx-deployment-65bbdb5f8-7cbvq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7cbvq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-7cbvq,UID:b58a5937-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16863,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b58f10 0xc001b58f11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b58f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b58fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.096: INFO: Pod "nginx-deployment-65bbdb5f8-8dk74" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8dk74,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-8dk74,UID:b57da9db-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16856,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b59060 0xc001b59061}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b590d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b590f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.096: INFO: Pod "nginx-deployment-65bbdb5f8-8rs74" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8rs74,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-8rs74,UID:b5879492-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16858,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b591b0 0xc001b591b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b59220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b59240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.097: INFO: Pod "nginx-deployment-65bbdb5f8-8zbsw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8zbsw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-8zbsw,UID:b5879160-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16861,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b59310 0xc001b59311}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b59380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b593a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.097: INFO: Pod "nginx-deployment-65bbdb5f8-d47v8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-d47v8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-d47v8,UID:b3fdf5e5-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16787,Generation:0,CreationTimestamp:2019-02-20 19:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.191/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b596a0 0xc001b596a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b59710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b59730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.097: INFO: Pod "nginx-deployment-65bbdb5f8-dsbmf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dsbmf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-dsbmf,UID:b57d3d5b-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16820,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b598f0 0xc001b598f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b599e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b59ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.097: INFO: Pod "nginx-deployment-65bbdb5f8-j42ks" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j42ks,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-j42ks,UID:b3fe6111-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16793,Generation:0,CreationTimestamp:2019-02-20 19:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.190/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b59ba0 0xc001b59ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b59c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b59ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.190,StartTime:2019-02-20 19:28:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.097: INFO: Pod "nginx-deployment-65bbdb5f8-lvh2l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lvh2l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-lvh2l,UID:b3fe628e-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16865,Generation:0,CreationTimestamp:2019-02-20 19:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.43/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001b59e30 0xc001b59e31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b59ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b59ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:100.96.0.43,StartTime:2019-02-20 19:28:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.097: INFO: Pod "nginx-deployment-65bbdb5f8-p9clj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-p9clj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-p9clj,UID:b57da621-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16829,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001cd60b0 0xc001cd60b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd6180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd61a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.097: INFO: Pod "nginx-deployment-65bbdb5f8-v7ktz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-v7ktz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-v7ktz,UID:b40af592-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16785,Generation:0,CreationTimestamp:2019-02-20 19:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.42/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001cd62e0 0xc001cd62e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-87.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd6380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd63a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.10.87,PodIP:,StartTime:2019-02-20 19:28:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.098: INFO: Pod "nginx-deployment-65bbdb5f8-vmbrt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vmbrt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-vmbrt,UID:b58790ad-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16840,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001cd6510 0xc001cd6511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd6680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd66b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 19:28:33.098: INFO: Pod "nginx-deployment-65bbdb5f8-vrbjs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vrbjs,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nf98r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nf98r/pods/nginx-deployment-65bbdb5f8-vrbjs,UID:b58797cf-3545-11e9-a8b6-5a3f4013d0a1,ResourceVersion:16836,Generation:0,CreationTimestamp:2019-02-20 19:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b3fd7d1f-3545-11e9-a8b6-5a3f4013d0a1 0xc001cd6780 0xc001cd6781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ngq6s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ngq6s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ngq6s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd6b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd6b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:28:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:28:33.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-nf98r" for this suite.
Feb 20 19:28:39.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:28:40.418: INFO: namespace: e2e-tests-deployment-nf98r, resource: bindings, ignored listing per whitelist
Feb 20 19:28:40.879: INFO: namespace e2e-tests-deployment-nf98r deletion completed in 7.736263205s

• [SLOW TEST:16.909 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:28:40.879: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-qgmn4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 20 19:28:42.751: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:28:42.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-qgmn4" for this suite.
Feb 20 19:28:49.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:28:49.178: INFO: namespace: e2e-tests-replication-controller-qgmn4, resource: bindings, ignored listing per whitelist
Feb 20 19:28:50.674: INFO: namespace e2e-tests-replication-controller-qgmn4 deletion completed in 7.750041808s

• [SLOW TEST:9.795 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:28:50.674: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bbdlj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c14e447a-3545-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:28:52.453: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c154d439-3545-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-bbdlj" to be "success or failure"
Feb 20 19:28:52.495: INFO: Pod "pod-projected-configmaps-c154d439-3545-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.362564ms
Feb 20 19:28:54.539: INFO: Pod "pod-projected-configmaps-c154d439-3545-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085643738s
STEP: Saw pod success
Feb 20 19:28:54.539: INFO: Pod "pod-projected-configmaps-c154d439-3545-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:28:54.581: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-configmaps-c154d439-3545-11e9-96fe-8e2b2e6369d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:28:54.673: INFO: Waiting for pod pod-projected-configmaps-c154d439-3545-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:28:54.715: INFO: Pod pod-projected-configmaps-c154d439-3545-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:28:54.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bbdlj" for this suite.
Feb 20 19:29:00.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:29:01.265: INFO: namespace: e2e-tests-projected-bbdlj, resource: bindings, ignored listing per whitelist
Feb 20 19:29:02.490: INFO: namespace e2e-tests-projected-bbdlj deletion completed in 7.731828347s

• [SLOW TEST:11.816 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:29:02.490: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-2lxnb
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:29:04.216: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:29:04.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-2lxnb" for this suite.
Feb 20 19:29:11.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:29:11.707: INFO: namespace: e2e-tests-custom-resource-definition-2lxnb, resource: bindings, ignored listing per whitelist
Feb 20 19:29:12.854: INFO: namespace e2e-tests-custom-resource-definition-2lxnb deletion completed in 7.907185869s

• [SLOW TEST:10.364 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:29:12.855: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-fst8z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 20 19:29:14.612: INFO: Waiting up to 5m0s for pod "client-containers-ce89f906-3545-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-containers-fst8z" to be "success or failure"
Feb 20 19:29:14.654: INFO: Pod "client-containers-ce89f906-3545-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.49367ms
Feb 20 19:29:16.696: INFO: Pod "client-containers-ce89f906-3545-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084836236s
STEP: Saw pod success
Feb 20 19:29:16.696: INFO: Pod "client-containers-ce89f906-3545-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:29:16.739: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod client-containers-ce89f906-3545-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:29:16.831: INFO: Waiting for pod client-containers-ce89f906-3545-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:29:16.879: INFO: Pod client-containers-ce89f906-3545-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:29:16.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fst8z" for this suite.
Feb 20 19:29:23.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:29:23.640: INFO: namespace: e2e-tests-containers-fst8z, resource: bindings, ignored listing per whitelist
Feb 20 19:29:24.657: INFO: namespace e2e-tests-containers-fst8z deletion completed in 7.73484749s

• [SLOW TEST:11.802 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:29:24.657: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z4bl5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d59390d9-3545-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 19:29:26.464: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d59a35ab-3545-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-z4bl5" to be "success or failure"
Feb 20 19:29:26.506: INFO: Pod "pod-projected-secrets-d59a35ab-3545-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.562428ms
Feb 20 19:29:28.549: INFO: Pod "pod-projected-secrets-d59a35ab-3545-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085589386s
STEP: Saw pod success
Feb 20 19:29:28.549: INFO: Pod "pod-projected-secrets-d59a35ab-3545-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:29:28.592: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-secrets-d59a35ab-3545-11e9-96fe-8e2b2e6369d7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 19:29:28.684: INFO: Waiting for pod pod-projected-secrets-d59a35ab-3545-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:29:28.726: INFO: Pod pod-projected-secrets-d59a35ab-3545-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:29:28.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z4bl5" for this suite.
Feb 20 19:29:34.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:29:36.456: INFO: namespace: e2e-tests-projected-z4bl5, resource: bindings, ignored listing per whitelist
Feb 20 19:29:36.541: INFO: namespace e2e-tests-projected-z4bl5 deletion completed in 7.771866694s

• [SLOW TEST:11.884 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:29:36.541: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-76794
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-dcaa3217-3545-11e9-96fe-8e2b2e6369d7
STEP: Creating secret with name secret-projected-all-test-volume-dcaa3205-3545-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 20 19:29:38.395: INFO: Waiting up to 5m0s for pod "projected-volume-dcaa3138-3545-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-76794" to be "success or failure"
Feb 20 19:29:38.437: INFO: Pod "projected-volume-dcaa3138-3545-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.083062ms
Feb 20 19:29:40.480: INFO: Pod "projected-volume-dcaa3138-3545-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085036122s
STEP: Saw pod success
Feb 20 19:29:40.480: INFO: Pod "projected-volume-dcaa3138-3545-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:29:40.523: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod projected-volume-dcaa3138-3545-11e9-96fe-8e2b2e6369d7 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 20 19:29:40.616: INFO: Waiting for pod projected-volume-dcaa3138-3545-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:29:40.659: INFO: Pod projected-volume-dcaa3138-3545-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected combined
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:29:40.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-76794" for this suite.
Feb 20 19:29:46.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:29:47.125: INFO: namespace: e2e-tests-projected-76794, resource: bindings, ignored listing per whitelist
Feb 20 19:29:48.459: INFO: namespace e2e-tests-projected-76794 deletion completed in 7.757089983s

• [SLOW TEST:11.918 seconds]
[sig-storage] Projected combined
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:29:48.459: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-b7c7m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:29:50.224: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e3c40aee-3545-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-b7c7m" to be "success or failure"
Feb 20 19:29:50.273: INFO: Pod "downwardapi-volume-e3c40aee-3545-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 49.032272ms
Feb 20 19:29:52.316: INFO: Pod "downwardapi-volume-e3c40aee-3545-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.091966196s
STEP: Saw pod success
Feb 20 19:29:52.316: INFO: Pod "downwardapi-volume-e3c40aee-3545-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:29:52.360: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-e3c40aee-3545-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:29:52.454: INFO: Waiting for pod downwardapi-volume-e3c40aee-3545-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:29:52.497: INFO: Pod downwardapi-volume-e3c40aee-3545-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:29:52.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b7c7m" for this suite.
Feb 20 19:29:58.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:29:59.182: INFO: namespace: e2e-tests-downward-api-b7c7m, resource: bindings, ignored listing per whitelist
Feb 20 19:30:00.417: INFO: namespace e2e-tests-downward-api-b7c7m deletion completed in 7.875361947s

• [SLOW TEST:11.958 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:30:00.418: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-kjqn2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:30:02.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kjqn2" for this suite.
Feb 20 19:30:24.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:30:25.343: INFO: namespace: e2e-tests-pods-kjqn2, resource: bindings, ignored listing per whitelist
Feb 20 19:30:26.190: INFO: namespace e2e-tests-pods-kjqn2 deletion completed in 23.778591594s

• [SLOW TEST:25.772 seconds]
[k8s.io] [sig-node] Pods Extended
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:30:26.190: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xp976
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:30:27.916: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa3b4a35-3545-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-xp976" to be "success or failure"
Feb 20 19:30:27.958: INFO: Pod "downwardapi-volume-fa3b4a35-3545-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.202266ms
Feb 20 19:30:30.001: INFO: Pod "downwardapi-volume-fa3b4a35-3545-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085434947s
STEP: Saw pod success
Feb 20 19:30:30.001: INFO: Pod "downwardapi-volume-fa3b4a35-3545-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:30:30.044: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-fa3b4a35-3545-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:30:30.139: INFO: Waiting for pod downwardapi-volume-fa3b4a35-3545-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:30:30.181: INFO: Pod downwardapi-volume-fa3b4a35-3545-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:30:30.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xp976" for this suite.
Feb 20 19:30:36.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:30:37.747: INFO: namespace: e2e-tests-projected-xp976, resource: bindings, ignored listing per whitelist
Feb 20 19:30:37.997: INFO: namespace e2e-tests-projected-xp976 deletion completed in 7.773341362s

• [SLOW TEST:11.807 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:30:37.998: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-mdqkm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:31:39.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mdqkm" for this suite.
Feb 20 19:32:02.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:32:03.036: INFO: namespace: e2e-tests-container-probe-mdqkm, resource: bindings, ignored listing per whitelist
Feb 20 19:32:03.628: INFO: namespace e2e-tests-container-probe-mdqkm deletion completed in 23.733419825s

• [SLOW TEST:85.631 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:32:03.629: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-djfmq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-34580bf5-3546-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 19:32:05.454: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-345e7c7d-3546-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-djfmq" to be "success or failure"
Feb 20 19:32:05.496: INFO: Pod "pod-projected-secrets-345e7c7d-3546-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.919801ms
Feb 20 19:32:07.539: INFO: Pod "pod-projected-secrets-345e7c7d-3546-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084698695s
STEP: Saw pod success
Feb 20 19:32:07.539: INFO: Pod "pod-projected-secrets-345e7c7d-3546-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:32:07.581: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-secrets-345e7c7d-3546-11e9-96fe-8e2b2e6369d7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 19:32:07.713: INFO: Waiting for pod pod-projected-secrets-345e7c7d-3546-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:32:07.755: INFO: Pod pod-projected-secrets-345e7c7d-3546-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:32:07.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-djfmq" for this suite.
Feb 20 19:32:13.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:32:15.152: INFO: namespace: e2e-tests-projected-djfmq, resource: bindings, ignored listing per whitelist
Feb 20 19:32:15.532: INFO: namespace e2e-tests-projected-djfmq deletion completed in 7.733376171s

• [SLOW TEST:11.903 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:32:15.532: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-q8mdr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:32:17.310: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b6f89f5-3546-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-q8mdr" to be "success or failure"
Feb 20 19:32:17.352: INFO: Pod "downwardapi-volume-3b6f89f5-3546-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.209741ms
Feb 20 19:32:19.395: INFO: Pod "downwardapi-volume-3b6f89f5-3546-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085027486s
STEP: Saw pod success
Feb 20 19:32:19.395: INFO: Pod "downwardapi-volume-3b6f89f5-3546-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:32:19.438: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-3b6f89f5-3546-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:32:19.530: INFO: Waiting for pod downwardapi-volume-3b6f89f5-3546-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:32:19.572: INFO: Pod downwardapi-volume-3b6f89f5-3546-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:32:19.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q8mdr" for this suite.
Feb 20 19:32:25.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:32:26.456: INFO: namespace: e2e-tests-downward-api-q8mdr, resource: bindings, ignored listing per whitelist
Feb 20 19:32:27.383: INFO: namespace e2e-tests-downward-api-q8mdr deletion completed in 7.768343906s

• [SLOW TEST:11.850 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:32:27.383: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-9zb6x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:32:29.152: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 19:32:31.237: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 20 19:32:33.280: INFO: Creating deployment "test-rollover-deployment"
Feb 20 19:32:33.365: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 20 19:32:33.407: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 20 19:32:33.493: INFO: Ensure that both replica sets have 1 created replica
Feb 20 19:32:33.577: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 20 19:32:33.662: INFO: Updating deployment test-rollover-deployment
Feb 20 19:32:33.663: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 20 19:32:33.705: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 20 19:32:33.790: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 20 19:32:33.874: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:32:33.877: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:32:35.963: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:32:35.963: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287954, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:32:37.962: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:32:37.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287954, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:32:39.962: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:32:39.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287954, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:32:41.963: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:32:41.963: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287954, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:32:43.962: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:32:43.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287954, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686287953, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:32:45.965: INFO: 
Feb 20 19:32:45.965: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 19:32:46.092: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-9zb6x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9zb6x/deployments/test-rollover-deployment,UID:44fd44a2-3546-11e9-a8b6-5a3f4013d0a1,ResourceVersion:17795,Generation:2,CreationTimestamp:2019-02-20 19:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-20 19:32:33 +0000 UTC 2019-02-20 19:32:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-20 19:32:45 +0000 UTC 2019-02-20 19:32:33 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 19:32:46.135: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-9zb6x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9zb6x/replicasets/test-rollover-deployment-6b7f9d6597,UID:45317794-3546-11e9-a8b6-5a3f4013d0a1,ResourceVersion:17788,Generation:2,CreationTimestamp:2019-02-20 19:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 44fd44a2-3546-11e9-a8b6-5a3f4013d0a1 0xc0019a12c7 0xc0019a12c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 20 19:32:46.135: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 20 19:32:46.135: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-9zb6x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9zb6x/replicasets/test-rollover-controller,UID:427a64a8-3546-11e9-a8b6-5a3f4013d0a1,ResourceVersion:17794,Generation:2,CreationTimestamp:2019-02-20 19:32:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 44fd44a2-3546-11e9-a8b6-5a3f4013d0a1 0xc0019a1137 0xc0019a1138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:32:46.135: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-9zb6x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9zb6x/replicasets/test-rollover-deployment-6586df867b,UID:44fe82ee-3546-11e9-a8b6-5a3f4013d0a1,ResourceVersion:17758,Generation:2,CreationTimestamp:2019-02-20 19:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 44fd44a2-3546-11e9-a8b6-5a3f4013d0a1 0xc0019a11f7 0xc0019a11f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:32:46.178: INFO: Pod "test-rollover-deployment-6b7f9d6597-tf4hd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-tf4hd,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-9zb6x,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9zb6x/pods/test-rollover-deployment-6b7f9d6597-tf4hd,UID:4533128e-3546-11e9-a8b6-5a3f4013d0a1,ResourceVersion:17767,Generation:0,CreationTimestamp:2019-02-20 19:32:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.217/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 45317794-3546-11e9-a8b6-5a3f4013d0a1 0xc001b76057 0xc001b76058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hmk2k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hmk2k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hmk2k true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b76140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b76160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:32:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:32:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:32:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:32:33 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.217,StartTime:2019-02-20 19:32:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-20 19:32:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://503784ae5e84ae1573b86402e743ae6f45bf3d1d6bb4711848c8d70774145d48}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:32:46.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9zb6x" for this suite.
Feb 20 19:32:52.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:32:53.951: INFO: namespace: e2e-tests-deployment-9zb6x, resource: bindings, ignored listing per whitelist
Feb 20 19:32:53.993: INFO: namespace e2e-tests-deployment-9zb6x deletion completed in 7.771881863s

• [SLOW TEST:26.610 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:32:53.993: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wl9ns
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:32:55.712: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52534c01-3546-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-wl9ns" to be "success or failure"
Feb 20 19:32:55.755: INFO: Pod "downwardapi-volume-52534c01-3546-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.184085ms
Feb 20 19:32:57.797: INFO: Pod "downwardapi-volume-52534c01-3546-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08496814s
STEP: Saw pod success
Feb 20 19:32:57.797: INFO: Pod "downwardapi-volume-52534c01-3546-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:32:57.840: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-52534c01-3546-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:32:57.932: INFO: Waiting for pod downwardapi-volume-52534c01-3546-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:32:57.975: INFO: Pod downwardapi-volume-52534c01-3546-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:32:57.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wl9ns" for this suite.
Feb 20 19:33:04.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:33:05.328: INFO: namespace: e2e-tests-projected-wl9ns, resource: bindings, ignored listing per whitelist
Feb 20 19:33:05.749: INFO: namespace e2e-tests-projected-wl9ns deletion completed in 7.731196044s

• [SLOW TEST:11.756 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:33:05.749: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qzstq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:33:07.610: INFO: Waiting up to 5m0s for pod "downwardapi-volume-596aad69-3546-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-qzstq" to be "success or failure"
Feb 20 19:33:07.652: INFO: Pod "downwardapi-volume-596aad69-3546-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.155773ms
Feb 20 19:33:09.695: INFO: Pod "downwardapi-volume-596aad69-3546-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085373274s
STEP: Saw pod success
Feb 20 19:33:09.695: INFO: Pod "downwardapi-volume-596aad69-3546-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:33:09.738: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-596aad69-3546-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:33:09.831: INFO: Waiting for pod downwardapi-volume-596aad69-3546-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:33:09.873: INFO: Pod downwardapi-volume-596aad69-3546-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:33:09.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qzstq" for this suite.
Feb 20 19:33:16.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:33:16.800: INFO: namespace: e2e-tests-downward-api-qzstq, resource: bindings, ignored listing per whitelist
Feb 20 19:33:17.686: INFO: namespace e2e-tests-downward-api-qzstq deletion completed in 7.770651479s

• [SLOW TEST:11.937 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:33:17.687: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-5bv7m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:33:21.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-5bv7m" for this suite.
Feb 20 19:33:27.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:33:29.446: INFO: namespace: e2e-tests-emptydir-wrapper-5bv7m, resource: bindings, ignored listing per whitelist
Feb 20 19:33:29.573: INFO: namespace e2e-tests-emptydir-wrapper-5bv7m deletion completed in 7.77088799s

• [SLOW TEST:11.886 seconds]
[sig-storage] EmptyDir wrapper volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:33:29.573: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-nx8zr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 19:33:31.612: INFO: Number of nodes with available pods: 0
Feb 20 19:33:31.612: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:32.697: INFO: Number of nodes with available pods: 2
Feb 20 19:33:32.697: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 20 19:33:32.911: INFO: Number of nodes with available pods: 1
Feb 20 19:33:32.911: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:33.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:33.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:34.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:34.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:35.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:35.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:36.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:36.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:37.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:37.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:38.997: INFO: Number of nodes with available pods: 1
Feb 20 19:33:38.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:39.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:39.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:40.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:40.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:41.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:41.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:42.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:42.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:43.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:43.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:44.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:44.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:45.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:45.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:46.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:46.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:47.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:47.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:48.995: INFO: Number of nodes with available pods: 1
Feb 20 19:33:48.995: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:49.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:49.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:50.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:50.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:51.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:51.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:52.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:52.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:53.997: INFO: Number of nodes with available pods: 1
Feb 20 19:33:53.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:54.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:54.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:55.997: INFO: Number of nodes with available pods: 1
Feb 20 19:33:55.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:56.997: INFO: Number of nodes with available pods: 1
Feb 20 19:33:56.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:57.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:57.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:58.998: INFO: Number of nodes with available pods: 1
Feb 20 19:33:58.998: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:59.996: INFO: Number of nodes with available pods: 1
Feb 20 19:33:59.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:00.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:00.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:01.997: INFO: Number of nodes with available pods: 1
Feb 20 19:34:01.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:02.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:02.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:03.999: INFO: Number of nodes with available pods: 1
Feb 20 19:34:03.999: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:04.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:04.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:05.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:05.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:06.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:06.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:07.997: INFO: Number of nodes with available pods: 1
Feb 20 19:34:07.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:08.997: INFO: Number of nodes with available pods: 1
Feb 20 19:34:08.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:09.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:09.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:10.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:10.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:11.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:11.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:12.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:12.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:13.997: INFO: Number of nodes with available pods: 1
Feb 20 19:34:13.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:14.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:14.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:15.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:15.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:16.998: INFO: Number of nodes with available pods: 1
Feb 20 19:34:16.998: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:17.997: INFO: Number of nodes with available pods: 1
Feb 20 19:34:17.997: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:18.996: INFO: Number of nodes with available pods: 1
Feb 20 19:34:18.996: INFO: Node ip-10-250-10-87.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:34:19.996: INFO: Number of nodes with available pods: 2
Feb 20 19:34:19.996: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-nx8zr, will wait for the garbage collector to delete the pods
Feb 20 19:34:20.175: INFO: Deleting DaemonSet.extensions daemon-set took: 43.501914ms
Feb 20 19:34:20.275: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.303087ms
Feb 20 19:34:53.817: INFO: Number of nodes with available pods: 0
Feb 20 19:34:53.817: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 19:34:53.860: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nx8zr/daemonsets","resourceVersion":"18146"},"items":null}

Feb 20 19:34:53.902: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nx8zr/pods","resourceVersion":"18146"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:34:54.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nx8zr" for this suite.
Feb 20 19:35:00.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:35:01.556: INFO: namespace: e2e-tests-daemonsets-nx8zr, resource: bindings, ignored listing per whitelist
Feb 20 19:35:01.874: INFO: namespace e2e-tests-daemonsets-nx8zr deletion completed in 7.762182797s

• [SLOW TEST:92.301 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:35:01.875: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-mgbh6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0220 19:35:13.823299   30217 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 19:35:13.823: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:35:13.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mgbh6" for this suite.
Feb 20 19:35:19.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:35:21.182: INFO: namespace: e2e-tests-gc-mgbh6, resource: bindings, ignored listing per whitelist
Feb 20 19:35:21.604: INFO: namespace e2e-tests-gc-mgbh6 deletion completed in 7.738631832s

• [SLOW TEST:19.730 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:35:21.604: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-5977w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-mrm4
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 19:35:23.495: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mrm4" in namespace "e2e-tests-subpath-5977w" to be "success or failure"
Feb 20 19:35:23.538: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Pending", Reason="", readiness=false. Elapsed: 42.153791ms
Feb 20 19:35:25.580: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084957449s
Feb 20 19:35:27.623: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 4.127821725s
Feb 20 19:35:29.666: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 6.170824141s
Feb 20 19:35:31.709: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 8.213617553s
Feb 20 19:35:33.752: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 10.256003678s
Feb 20 19:35:35.794: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 12.298539434s
Feb 20 19:35:37.837: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 14.341091435s
Feb 20 19:35:39.879: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 16.383657923s
Feb 20 19:35:41.922: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 18.426883774s
Feb 20 19:35:43.965: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 20.469859085s
Feb 20 19:35:46.009: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Running", Reason="", readiness=false. Elapsed: 22.513066876s
Feb 20 19:35:48.052: INFO: Pod "pod-subpath-test-secret-mrm4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.556251236s
STEP: Saw pod success
Feb 20 19:35:48.052: INFO: Pod "pod-subpath-test-secret-mrm4" satisfied condition "success or failure"
Feb 20 19:35:48.094: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-subpath-test-secret-mrm4 container test-container-subpath-secret-mrm4: <nil>
STEP: delete the pod
Feb 20 19:35:48.194: INFO: Waiting for pod pod-subpath-test-secret-mrm4 to disappear
Feb 20 19:35:48.252: INFO: Pod pod-subpath-test-secret-mrm4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-mrm4
Feb 20 19:35:48.252: INFO: Deleting pod "pod-subpath-test-secret-mrm4" in namespace "e2e-tests-subpath-5977w"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:35:48.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5977w" for this suite.
Feb 20 19:35:54.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:35:54.945: INFO: namespace: e2e-tests-subpath-5977w, resource: bindings, ignored listing per whitelist
Feb 20 19:35:56.128: INFO: namespace e2e-tests-subpath-5977w deletion completed in 7.732318309s

• [SLOW TEST:34.524 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:35:56.129: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-h2w65
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0220 19:36:38.177280   30217 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 19:36:38.177: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:36:38.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-h2w65" for this suite.
Feb 20 19:36:44.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:36:45.112: INFO: namespace: e2e-tests-gc-h2w65, resource: bindings, ignored listing per whitelist
Feb 20 19:36:45.972: INFO: namespace e2e-tests-gc-h2w65 deletion completed in 7.750516455s

• [SLOW TEST:49.843 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:36:45.972: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-fdrbr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-fdrbr
Feb 20 19:36:49.894: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-fdrbr
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 19:36:49.936: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:40:51.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fdrbr" for this suite.
Feb 20 19:40:57.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:40:57.806: INFO: namespace: e2e-tests-container-probe-fdrbr, resource: bindings, ignored listing per whitelist
Feb 20 19:40:58.863: INFO: namespace e2e-tests-container-probe-fdrbr deletion completed in 7.77192245s

• [SLOW TEST:252.891 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:40:58.863: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-s54bs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 20 19:41:00.574: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:41:04.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-s54bs" for this suite.
Feb 20 19:41:26.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:41:27.703: INFO: namespace: e2e-tests-init-container-s54bs, resource: bindings, ignored listing per whitelist
Feb 20 19:41:28.587: INFO: namespace e2e-tests-init-container-s54bs deletion completed in 23.773846047s

• [SLOW TEST:29.725 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:41:28.588: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-s2xjw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 20 19:41:30.310: INFO: Waiting up to 5m0s for pod "var-expansion-850c9966-3547-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-var-expansion-s2xjw" to be "success or failure"
Feb 20 19:41:30.353: INFO: Pod "var-expansion-850c9966-3547-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.344691ms
Feb 20 19:41:32.395: INFO: Pod "var-expansion-850c9966-3547-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084929995s
STEP: Saw pod success
Feb 20 19:41:32.395: INFO: Pod "var-expansion-850c9966-3547-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:41:32.437: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod var-expansion-850c9966-3547-11e9-96fe-8e2b2e6369d7 container dapi-container: <nil>
STEP: delete the pod
Feb 20 19:41:32.533: INFO: Waiting for pod var-expansion-850c9966-3547-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:41:32.575: INFO: Pod var-expansion-850c9966-3547-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:41:32.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-s2xjw" for this suite.
Feb 20 19:41:38.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:41:39.081: INFO: namespace: e2e-tests-var-expansion-s2xjw, resource: bindings, ignored listing per whitelist
Feb 20 19:41:40.352: INFO: namespace e2e-tests-var-expansion-s2xjw deletion completed in 7.733914093s

• [SLOW TEST:11.765 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:41:40.353: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-7gc4f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 20 19:41:44.869: INFO: Successfully updated pod "pod-update-8c155d51-3547-11e9-96fe-8e2b2e6369d7"
STEP: verifying the updated pod is in kubernetes
Feb 20 19:41:44.953: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:41:44.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7gc4f" for this suite.
Feb 20 19:42:07.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:42:07.749: INFO: namespace: e2e-tests-pods-7gc4f, resource: bindings, ignored listing per whitelist
Feb 20 19:42:08.887: INFO: namespace e2e-tests-pods-7gc4f deletion completed in 23.890679782s

• [SLOW TEST:28.534 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:42:08.887: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-5g7c5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 20 19:42:12.866: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-9d1258c3-3547-11e9-96fe-8e2b2e6369d7", GenerateName:"", Namespace:"e2e-tests-pods-5g7c5", SelfLink:"/api/v1/namespaces/e2e-tests-pods-5g7c5/pods/pod-submit-remove-9d1258c3-3547-11e9-96fe-8e2b2e6369d7", UID:"9d218055-3547-11e9-a8b6-5a3f4013d0a1", ResourceVersion:"19213", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686288530, loc:(*time.Location)(0x791ea40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"568626071"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.234/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5xfhs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0026c5f00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5xfhs", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0027717c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-250-0-144.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0017f0480), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002771800)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002771820)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002771828), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00277182c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686288530, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686288532, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686288532, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686288530, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.144", PodIP:"100.96.1.234", StartTime:(*v1.Time)(0xc000b12be0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000b12c00), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://de52d3eb7c234130bf4896e8ae0ad77ffad829112c4e7e034f17141c46411145"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:42:21.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5g7c5" for this suite.
Feb 20 19:42:27.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:42:27.749: INFO: namespace: e2e-tests-pods-5g7c5, resource: bindings, ignored listing per whitelist
Feb 20 19:42:29.387: INFO: namespace e2e-tests-pods-5g7c5 deletion completed in 7.97683908s

• [SLOW TEST:20.499 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:42:29.387: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gx28h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 20 19:42:31.067: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:33.867: INFO: stderr: ""
Feb 20 19:42:33.867: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 19:42:33.867: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:34.125: INFO: stderr: ""
Feb 20 19:42:34.125: INFO: stdout: "update-demo-nautilus-jl64m update-demo-nautilus-zc5th "
Feb 20 19:42:34.125: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-jl64m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:34.372: INFO: stderr: ""
Feb 20 19:42:34.372: INFO: stdout: ""
Feb 20 19:42:34.372: INFO: update-demo-nautilus-jl64m is created but not running
Feb 20 19:42:39.373: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:39.625: INFO: stderr: ""
Feb 20 19:42:39.625: INFO: stdout: "update-demo-nautilus-jl64m update-demo-nautilus-zc5th "
Feb 20 19:42:39.625: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-jl64m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:39.865: INFO: stderr: ""
Feb 20 19:42:39.865: INFO: stdout: "true"
Feb 20 19:42:39.865: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-jl64m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:40.098: INFO: stderr: ""
Feb 20 19:42:40.098: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:42:40.098: INFO: validating pod update-demo-nautilus-jl64m
Feb 20 19:42:40.229: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:42:40.229: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:42:40.229: INFO: update-demo-nautilus-jl64m is verified up and running
Feb 20 19:42:40.229: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-zc5th -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:40.472: INFO: stderr: ""
Feb 20 19:42:40.472: INFO: stdout: "true"
Feb 20 19:42:40.472: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-zc5th -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:40.723: INFO: stderr: ""
Feb 20 19:42:40.723: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:42:40.723: INFO: validating pod update-demo-nautilus-zc5th
Feb 20 19:42:40.853: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:42:40.853: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:42:40.853: INFO: update-demo-nautilus-zc5th is verified up and running
STEP: scaling down the replication controller
Feb 20 19:42:40.858: INFO: scanned /root for discovery docs: <nil>
Feb 20 19:42:40.858: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:41.241: INFO: stderr: ""
Feb 20 19:42:41.241: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 19:42:41.242: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:41.502: INFO: stderr: ""
Feb 20 19:42:41.502: INFO: stdout: "update-demo-nautilus-jl64m update-demo-nautilus-zc5th "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 20 19:42:46.502: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:46.739: INFO: stderr: ""
Feb 20 19:42:46.739: INFO: stdout: "update-demo-nautilus-jl64m "
Feb 20 19:42:46.739: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-jl64m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:46.967: INFO: stderr: ""
Feb 20 19:42:46.967: INFO: stdout: "true"
Feb 20 19:42:46.967: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-jl64m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:47.193: INFO: stderr: ""
Feb 20 19:42:47.193: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:42:47.193: INFO: validating pod update-demo-nautilus-jl64m
Feb 20 19:42:47.237: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:42:47.237: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:42:47.237: INFO: update-demo-nautilus-jl64m is verified up and running
STEP: scaling up the replication controller
Feb 20 19:42:47.245: INFO: scanned /root for discovery docs: <nil>
Feb 20 19:42:47.246: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:47.624: INFO: stderr: ""
Feb 20 19:42:47.624: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 19:42:47.624: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:47.876: INFO: stderr: ""
Feb 20 19:42:47.876: INFO: stdout: "update-demo-nautilus-jl64m update-demo-nautilus-l4dxn "
Feb 20 19:42:47.876: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-jl64m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:48.128: INFO: stderr: ""
Feb 20 19:42:48.128: INFO: stdout: "true"
Feb 20 19:42:48.128: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-jl64m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:48.427: INFO: stderr: ""
Feb 20 19:42:48.427: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:42:48.427: INFO: validating pod update-demo-nautilus-jl64m
Feb 20 19:42:48.471: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:42:48.471: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:42:48.471: INFO: update-demo-nautilus-jl64m is verified up and running
Feb 20 19:42:48.471: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-l4dxn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:48.705: INFO: stderr: ""
Feb 20 19:42:48.705: INFO: stdout: "true"
Feb 20 19:42:48.706: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-l4dxn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:48.936: INFO: stderr: ""
Feb 20 19:42:48.936: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:42:48.936: INFO: validating pod update-demo-nautilus-l4dxn
Feb 20 19:42:49.064: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:42:49.064: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:42:49.065: INFO: update-demo-nautilus-l4dxn is verified up and running
STEP: using delete to clean up resources
Feb 20 19:42:49.065: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:49.354: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:42:49.354: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 20 19:42:49.354: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-gx28h'
Feb 20 19:42:49.639: INFO: stderr: "No resources found.\n"
Feb 20 19:42:49.639: INFO: stdout: ""
Feb 20 19:42:49.639: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -l name=update-demo --namespace=e2e-tests-kubectl-gx28h -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 19:42:49.886: INFO: stderr: ""
Feb 20 19:42:49.886: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:42:49.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gx28h" for this suite.
Feb 20 19:43:12.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:43:13.238: INFO: namespace: e2e-tests-kubectl-gx28h, resource: bindings, ignored listing per whitelist
Feb 20 19:43:13.708: INFO: namespace e2e-tests-kubectl-gx28h deletion completed in 23.778148813s

• [SLOW TEST:44.321 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:43:13.708: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zvl2k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c3b4d97c-3547-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:43:15.474: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3bb6bc0-3547-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-zvl2k" to be "success or failure"
Feb 20 19:43:15.517: INFO: Pod "pod-projected-configmaps-c3bb6bc0-3547-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.418823ms
Feb 20 19:43:17.559: INFO: Pod "pod-projected-configmaps-c3bb6bc0-3547-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085105127s
STEP: Saw pod success
Feb 20 19:43:17.560: INFO: Pod "pod-projected-configmaps-c3bb6bc0-3547-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:43:17.602: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-configmaps-c3bb6bc0-3547-11e9-96fe-8e2b2e6369d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:43:17.693: INFO: Waiting for pod pod-projected-configmaps-c3bb6bc0-3547-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:43:17.735: INFO: Pod pod-projected-configmaps-c3bb6bc0-3547-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:43:17.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zvl2k" for this suite.
Feb 20 19:43:23.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:43:25.077: INFO: namespace: e2e-tests-projected-zvl2k, resource: bindings, ignored listing per whitelist
Feb 20 19:43:25.579: INFO: namespace e2e-tests-projected-zvl2k deletion completed in 7.802011738s

• [SLOW TEST:11.872 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:43:25.580: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ftg4s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cac9c0a5-3547-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:43:27.354: INFO: Waiting up to 5m0s for pod "pod-configmaps-cad03a46-3547-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-ftg4s" to be "success or failure"
Feb 20 19:43:27.397: INFO: Pod "pod-configmaps-cad03a46-3547-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.075495ms
Feb 20 19:43:29.439: INFO: Pod "pod-configmaps-cad03a46-3547-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084790802s
STEP: Saw pod success
Feb 20 19:43:29.439: INFO: Pod "pod-configmaps-cad03a46-3547-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:43:29.481: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-cad03a46-3547-11e9-96fe-8e2b2e6369d7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:43:29.577: INFO: Waiting for pod pod-configmaps-cad03a46-3547-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:43:29.619: INFO: Pod pod-configmaps-cad03a46-3547-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:43:29.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ftg4s" for this suite.
Feb 20 19:43:35.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:43:36.419: INFO: namespace: e2e-tests-configmap-ftg4s, resource: bindings, ignored listing per whitelist
Feb 20 19:43:37.436: INFO: namespace e2e-tests-configmap-ftg4s deletion completed in 7.774023032s

• [SLOW TEST:11.856 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:43:37.436: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-fxtvj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 19:43:39.509: INFO: Number of nodes with available pods: 0
Feb 20 19:43:39.509: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:43:40.596: INFO: Number of nodes with available pods: 1
Feb 20 19:43:40.596: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:43:41.595: INFO: Number of nodes with available pods: 2
Feb 20 19:43:41.595: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 20 19:43:41.808: INFO: Number of nodes with available pods: 1
Feb 20 19:43:41.808: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:43:42.894: INFO: Number of nodes with available pods: 1
Feb 20 19:43:42.894: INFO: Node ip-10-250-0-144.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:43:43.895: INFO: Number of nodes with available pods: 2
Feb 20 19:43:43.895: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-fxtvj, will wait for the garbage collector to delete the pods
Feb 20 19:43:44.117: INFO: Deleting DaemonSet.extensions daemon-set took: 43.618931ms
Feb 20 19:43:44.217: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.373712ms
Feb 20 19:44:17.560: INFO: Number of nodes with available pods: 0
Feb 20 19:44:17.560: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 19:44:17.602: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fxtvj/daemonsets","resourceVersion":"19587"},"items":null}

Feb 20 19:44:17.644: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fxtvj/pods","resourceVersion":"19587"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:44:17.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fxtvj" for this suite.
Feb 20 19:44:23.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:44:24.480: INFO: namespace: e2e-tests-daemonsets-fxtvj, resource: bindings, ignored listing per whitelist
Feb 20 19:44:25.574: INFO: namespace e2e-tests-daemonsets-fxtvj deletion completed in 7.760592939s

• [SLOW TEST:48.138 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:44:25.575: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-hm6mt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:44:29.625: INFO: Waiting up to 5m0s for pod "client-envvars-efee30c6-3547-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-pods-hm6mt" to be "success or failure"
Feb 20 19:44:29.668: INFO: Pod "client-envvars-efee30c6-3547-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.153882ms
Feb 20 19:44:31.710: INFO: Pod "client-envvars-efee30c6-3547-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084689865s
STEP: Saw pod success
Feb 20 19:44:31.710: INFO: Pod "client-envvars-efee30c6-3547-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:44:31.754: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod client-envvars-efee30c6-3547-11e9-96fe-8e2b2e6369d7 container env3cont: <nil>
STEP: delete the pod
Feb 20 19:44:31.847: INFO: Waiting for pod client-envvars-efee30c6-3547-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:44:31.889: INFO: Pod client-envvars-efee30c6-3547-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:44:31.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hm6mt" for this suite.
Feb 20 19:45:10.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:45:10.567: INFO: namespace: e2e-tests-pods-hm6mt, resource: bindings, ignored listing per whitelist
Feb 20 19:45:11.664: INFO: namespace e2e-tests-pods-hm6mt deletion completed in 39.731934186s

• [SLOW TEST:46.090 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:45:11.664: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bq7st
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 20 19:45:13.429: INFO: Waiting up to 5m0s for pod "pod-0a09fbcf-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-bq7st" to be "success or failure"
Feb 20 19:45:13.472: INFO: Pod "pod-0a09fbcf-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.440138ms
Feb 20 19:45:15.522: INFO: Pod "pod-0a09fbcf-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093085411s
STEP: Saw pod success
Feb 20 19:45:15.523: INFO: Pod "pod-0a09fbcf-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:45:15.565: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-0a09fbcf-3548-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:45:15.659: INFO: Waiting for pod pod-0a09fbcf-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:45:15.701: INFO: Pod pod-0a09fbcf-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:45:15.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bq7st" for this suite.
Feb 20 19:45:21.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:45:22.505: INFO: namespace: e2e-tests-emptydir-bq7st, resource: bindings, ignored listing per whitelist
Feb 20 19:45:23.484: INFO: namespace e2e-tests-emptydir-bq7st deletion completed in 7.740327313s

• [SLOW TEST:11.820 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:45:23.484: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-c8r2q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 20 19:45:25.267: INFO: namespace e2e-tests-kubectl-c8r2q
Feb 20 19:45:25.267: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-c8r2q'
Feb 20 19:45:25.781: INFO: stderr: ""
Feb 20 19:45:25.781: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 19:45:26.824: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:45:26.824: INFO: Found 0 / 1
Feb 20 19:45:27.824: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:45:27.824: INFO: Found 1 / 1
Feb 20 19:45:27.824: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 20 19:45:27.867: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:45:27.867: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 19:45:27.867: INFO: wait on redis-master startup in e2e-tests-kubectl-c8r2q 
Feb 20 19:45:27.867: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml logs redis-master-tt7vt redis-master --namespace=e2e-tests-kubectl-c8r2q'
Feb 20 19:45:28.163: INFO: stderr: ""
Feb 20 19:45:28.163: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Feb 19:45:26.594 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Feb 19:45:26.594 # Server started, Redis version 3.2.12\n1:M 20 Feb 19:45:26.594 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Feb 19:45:26.594 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 20 19:45:28.163: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-c8r2q'
Feb 20 19:45:28.523: INFO: stderr: ""
Feb 20 19:45:28.523: INFO: stdout: "service/rm2 exposed\n"
Feb 20 19:45:28.565: INFO: Service rm2 in namespace e2e-tests-kubectl-c8r2q found.
STEP: exposing service
Feb 20 19:45:30.650: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-c8r2q'
Feb 20 19:45:30.938: INFO: stderr: ""
Feb 20 19:45:30.938: INFO: stdout: "service/rm3 exposed\n"
Feb 20 19:45:30.980: INFO: Service rm3 in namespace e2e-tests-kubectl-c8r2q found.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:45:33.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c8r2q" for this suite.
Feb 20 19:45:55.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:45:55.783: INFO: namespace: e2e-tests-kubectl-c8r2q, resource: bindings, ignored listing per whitelist
Feb 20 19:45:56.838: INFO: namespace e2e-tests-kubectl-c8r2q deletion completed in 23.729578493s

• [SLOW TEST:33.354 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:45:56.839: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-c82hb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:45:58.751: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"2506ddce-3548-11e9-a8b6-5a3f4013d0a1", Controller:(*bool)(0xc0027714a2), BlockOwnerDeletion:(*bool)(0xc0027714a3)}}
Feb 20 19:45:58.795: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"24f9c66b-3548-11e9-a8b6-5a3f4013d0a1", Controller:(*bool)(0xc00173e332), BlockOwnerDeletion:(*bool)(0xc00173e333)}}
Feb 20 19:45:58.838: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"250056a1-3548-11e9-a8b6-5a3f4013d0a1", Controller:(*bool)(0xc00255e526), BlockOwnerDeletion:(*bool)(0xc00255e527)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:46:03.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-c82hb" for this suite.
Feb 20 19:46:10.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:46:10.389: INFO: namespace: e2e-tests-gc-c82hb, resource: bindings, ignored listing per whitelist
Feb 20 19:46:11.869: INFO: namespace e2e-tests-gc-c82hb deletion completed in 7.902814395s

• [SLOW TEST:15.031 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:46:11.869: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-7lr9j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0220 19:46:43.924735   30217 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 19:46:43.924: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:46:43.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7lr9j" for this suite.
Feb 20 19:46:50.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:46:51.235: INFO: namespace: e2e-tests-gc-7lr9j, resource: bindings, ignored listing per whitelist
Feb 20 19:46:51.739: INFO: namespace e2e-tests-gc-7lr9j deletion completed in 7.771641131s

• [SLOW TEST:39.869 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:46:51.739: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-dm8r2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-dm8r2/secret-test-45b29830-3548-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 19:46:53.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-45b90a28-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-dm8r2" to be "success or failure"
Feb 20 19:46:53.604: INFO: Pod "pod-configmaps-45b90a28-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.291167ms
Feb 20 19:46:55.647: INFO: Pod "pod-configmaps-45b90a28-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08486381s
STEP: Saw pod success
Feb 20 19:46:55.647: INFO: Pod "pod-configmaps-45b90a28-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:46:55.689: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-45b90a28-3548-11e9-96fe-8e2b2e6369d7 container env-test: <nil>
STEP: delete the pod
Feb 20 19:46:55.784: INFO: Waiting for pod pod-configmaps-45b90a28-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:46:55.827: INFO: Pod pod-configmaps-45b90a28-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:46:55.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dm8r2" for this suite.
Feb 20 19:47:01.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:47:02.253: INFO: namespace: e2e-tests-secrets-dm8r2, resource: bindings, ignored listing per whitelist
Feb 20 19:47:03.657: INFO: namespace e2e-tests-secrets-dm8r2 deletion completed in 7.787360426s

• [SLOW TEST:11.918 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:47:03.658: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-cdl5w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4cc823b1-3548-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:47:05.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-4cce90e1-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-configmap-cdl5w" to be "success or failure"
Feb 20 19:47:05.490: INFO: Pod "pod-configmaps-4cce90e1-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.616639ms
Feb 20 19:47:07.534: INFO: Pod "pod-configmaps-4cce90e1-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086015938s
STEP: Saw pod success
Feb 20 19:47:07.534: INFO: Pod "pod-configmaps-4cce90e1-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:47:07.576: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-configmaps-4cce90e1-3548-11e9-96fe-8e2b2e6369d7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:47:07.705: INFO: Waiting for pod pod-configmaps-4cce90e1-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:47:07.748: INFO: Pod pod-configmaps-4cce90e1-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:47:07.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cdl5w" for this suite.
Feb 20 19:47:13.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:47:15.324: INFO: namespace: e2e-tests-configmap-cdl5w, resource: bindings, ignored listing per whitelist
Feb 20 19:47:15.534: INFO: namespace e2e-tests-configmap-cdl5w deletion completed in 7.74260416s

• [SLOW TEST:11.877 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:47:15.534: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-g2szj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-53e25a11-3548-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 19:47:17.364: INFO: Waiting up to 5m0s for pod "pod-secrets-53e8d709-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-g2szj" to be "success or failure"
Feb 20 19:47:17.406: INFO: Pod "pod-secrets-53e8d709-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.307864ms
Feb 20 19:47:19.449: INFO: Pod "pod-secrets-53e8d709-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085194212s
STEP: Saw pod success
Feb 20 19:47:19.449: INFO: Pod "pod-secrets-53e8d709-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:47:19.491: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-secrets-53e8d709-3548-11e9-96fe-8e2b2e6369d7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 19:47:19.583: INFO: Waiting for pod pod-secrets-53e8d709-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:47:19.625: INFO: Pod pod-secrets-53e8d709-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:47:19.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g2szj" for this suite.
Feb 20 19:47:25.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:47:26.428: INFO: namespace: e2e-tests-secrets-g2szj, resource: bindings, ignored listing per whitelist
Feb 20 19:47:27.396: INFO: namespace e2e-tests-secrets-g2szj deletion completed in 7.727670261s

• [SLOW TEST:11.862 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:47:27.397: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6pm8q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 19:47:29.074: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-6pm8q'
Feb 20 19:47:29.390: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 19:47:29.390: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Feb 20 19:47:29.477: INFO: scanned /root for discovery docs: <nil>
Feb 20 19:47:29.478: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-6pm8q'
Feb 20 19:47:41.098: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 20 19:47:41.098: INFO: stdout: "Created e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a\nScaling up e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 20 19:47:41.098: INFO: stdout: "Created e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a\nScaling up e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 20 19:47:41.099: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6pm8q'
Feb 20 19:47:41.334: INFO: stderr: ""
Feb 20 19:47:41.334: INFO: stdout: "e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a-zjbsz "
Feb 20 19:47:41.334: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a-zjbsz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pm8q'
Feb 20 19:47:41.566: INFO: stderr: ""
Feb 20 19:47:41.566: INFO: stdout: "true"
Feb 20 19:47:41.566: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a-zjbsz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pm8q'
Feb 20 19:47:41.866: INFO: stderr: ""
Feb 20 19:47:41.866: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 20 19:47:41.866: INFO: e2e-test-nginx-rc-2b176aa70af8f639fedce0fd5dd2923a-zjbsz is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb 20 19:47:41.866: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6pm8q'
Feb 20 19:47:42.152: INFO: stderr: ""
Feb 20 19:47:42.152: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:47:42.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6pm8q" for this suite.
Feb 20 19:48:04.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:48:04.666: INFO: namespace: e2e-tests-kubectl-6pm8q, resource: bindings, ignored listing per whitelist
Feb 20 19:48:05.937: INFO: namespace e2e-tests-kubectl-6pm8q deletion completed in 23.742041706s

• [SLOW TEST:38.540 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:48:05.937: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ft927
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 19:48:07.707: INFO: Waiting up to 5m0s for pod "downward-api-71eaa5d1-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-ft927" to be "success or failure"
Feb 20 19:48:07.749: INFO: Pod "downward-api-71eaa5d1-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.869359ms
Feb 20 19:48:09.792: INFO: Pod "downward-api-71eaa5d1-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085175549s
STEP: Saw pod success
Feb 20 19:48:09.792: INFO: Pod "downward-api-71eaa5d1-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:48:09.835: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downward-api-71eaa5d1-3548-11e9-96fe-8e2b2e6369d7 container dapi-container: <nil>
STEP: delete the pod
Feb 20 19:48:09.927: INFO: Waiting for pod downward-api-71eaa5d1-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:48:09.969: INFO: Pod downward-api-71eaa5d1-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:48:09.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ft927" for this suite.
Feb 20 19:48:16.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:48:16.941: INFO: namespace: e2e-tests-downward-api-ft927, resource: bindings, ignored listing per whitelist
Feb 20 19:48:17.740: INFO: namespace e2e-tests-downward-api-ft927 deletion completed in 7.727212751s

• [SLOW TEST:11.803 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:48:17.740: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nfglg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:48:19.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78f2e8f1-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-nfglg" to be "success or failure"
Feb 20 19:48:19.547: INFO: Pod "downwardapi-volume-78f2e8f1-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.01319ms
Feb 20 19:48:21.590: INFO: Pod "downwardapi-volume-78f2e8f1-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084783014s
STEP: Saw pod success
Feb 20 19:48:21.590: INFO: Pod "downwardapi-volume-78f2e8f1-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:48:21.633: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-78f2e8f1-3548-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:48:21.725: INFO: Waiting for pod downwardapi-volume-78f2e8f1-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:48:21.767: INFO: Pod downwardapi-volume-78f2e8f1-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:48:21.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nfglg" for this suite.
Feb 20 19:48:27.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:48:29.122: INFO: namespace: e2e-tests-downward-api-nfglg, resource: bindings, ignored listing per whitelist
Feb 20 19:48:29.604: INFO: namespace e2e-tests-downward-api-nfglg deletion completed in 7.794327338s

• [SLOW TEST:11.864 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:48:29.604: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xskhn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 20 19:48:31.326: INFO: Waiting up to 5m0s for pod "pod-7ffeab4c-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-xskhn" to be "success or failure"
Feb 20 19:48:31.369: INFO: Pod "pod-7ffeab4c-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.150235ms
Feb 20 19:48:33.412: INFO: Pod "pod-7ffeab4c-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085272819s
STEP: Saw pod success
Feb 20 19:48:33.412: INFO: Pod "pod-7ffeab4c-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:48:33.454: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-7ffeab4c-3548-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:48:33.548: INFO: Waiting for pod pod-7ffeab4c-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:48:33.590: INFO: Pod pod-7ffeab4c-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:48:33.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xskhn" for this suite.
Feb 20 19:48:39.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:48:40.020: INFO: namespace: e2e-tests-emptydir-xskhn, resource: bindings, ignored listing per whitelist
Feb 20 19:48:41.366: INFO: namespace e2e-tests-emptydir-xskhn deletion completed in 7.731705784s

• [SLOW TEST:11.761 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:48:41.366: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kp2z6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 20 19:48:43.069: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml cluster-info'
Feb 20 19:48:43.363: INFO: stderr: ""
Feb 20 19:48:43.364: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:48:43.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kp2z6" for this suite.
Feb 20 19:48:49.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:48:49.786: INFO: namespace: e2e-tests-kubectl-kp2z6, resource: bindings, ignored listing per whitelist
Feb 20 19:48:51.173: INFO: namespace e2e-tests-kubectl-kp2z6 deletion completed in 7.766962731s

• [SLOW TEST:9.807 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:48:51.174: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fggzf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:48:52.909: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8cdbd441-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-fggzf" to be "success or failure"
Feb 20 19:48:52.951: INFO: Pod "downwardapi-volume-8cdbd441-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.254833ms
Feb 20 19:48:54.994: INFO: Pod "downwardapi-volume-8cdbd441-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08511439s
STEP: Saw pod success
Feb 20 19:48:54.994: INFO: Pod "downwardapi-volume-8cdbd441-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:48:55.037: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-8cdbd441-3548-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:48:55.129: INFO: Waiting for pod downwardapi-volume-8cdbd441-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:48:55.171: INFO: Pod downwardapi-volume-8cdbd441-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:48:55.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fggzf" for this suite.
Feb 20 19:49:01.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:49:02.530: INFO: namespace: e2e-tests-projected-fggzf, resource: bindings, ignored listing per whitelist
Feb 20 19:49:02.996: INFO: namespace e2e-tests-projected-fggzf deletion completed in 7.780968944s

• [SLOW TEST:11.822 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:49:02.996: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6qq96
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:49:04.722: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93e66111-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-6qq96" to be "success or failure"
Feb 20 19:49:04.764: INFO: Pod "downwardapi-volume-93e66111-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.263515ms
Feb 20 19:49:06.807: INFO: Pod "downwardapi-volume-93e66111-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085235444s
STEP: Saw pod success
Feb 20 19:49:06.807: INFO: Pod "downwardapi-volume-93e66111-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:49:06.849: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-93e66111-3548-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:49:06.942: INFO: Waiting for pod downwardapi-volume-93e66111-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:49:06.984: INFO: Pod downwardapi-volume-93e66111-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:49:06.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6qq96" for this suite.
Feb 20 19:49:13.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:49:13.579: INFO: namespace: e2e-tests-projected-6qq96, resource: bindings, ignored listing per whitelist
Feb 20 19:49:14.814: INFO: namespace e2e-tests-projected-6qq96 deletion completed in 7.786557946s

• [SLOW TEST:11.818 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:49:14.814: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fbthk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
W0220 19:49:16.863545   30217 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 19:49:16.863: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:49:16.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fbthk" for this suite.
Feb 20 19:49:23.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:49:23.204: INFO: namespace: e2e-tests-gc-fbthk, resource: bindings, ignored listing per whitelist
Feb 20 19:49:24.682: INFO: namespace e2e-tests-gc-fbthk deletion completed in 7.776574535s

• [SLOW TEST:9.868 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:49:24.683: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-v5xdn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:49:26.362: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml version --client'
Feb 20 19:49:26.428: INFO: stderr: ""
Feb 20 19:49:26.428: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"archive\", BuildDate:\"2019-02-20T18:08:14Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 20 19:49:26.470: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-v5xdn'
Feb 20 19:49:26.963: INFO: stderr: ""
Feb 20 19:49:26.963: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 20 19:49:26.963: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-v5xdn'
Feb 20 19:49:27.336: INFO: stderr: ""
Feb 20 19:49:27.336: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 19:49:28.379: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:49:28.379: INFO: Found 1 / 1
Feb 20 19:49:28.379: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 20 19:49:28.421: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:49:28.422: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 19:49:28.422: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe pod redis-master-f48tm --namespace=e2e-tests-kubectl-v5xdn'
Feb 20 19:49:28.752: INFO: stderr: ""
Feb 20 19:49:28.752: INFO: stdout: "Name:               redis-master-f48tm\nNamespace:          e2e-tests-kubectl-v5xdn\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-250-0-144.eu-west-1.compute.internal/10.250.0.144\nStart Time:         Wed, 20 Feb 2019 19:49:26 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 100.96.1.3/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 100.96.1.3\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6fd4e98c19a21cba0dfb5c3561c8f5c4be9e7d558b31776e1883d35ca0cd8875\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 20 Feb 2019 19:49:27 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-84mrl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-84mrl:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-84mrl\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                 Message\n  ----    ------     ----  ----                                                 -------\n  Normal  Scheduled  2s    default-scheduler                                    Successfully assigned e2e-tests-kubectl-v5xdn/redis-master-f48tm to ip-10-250-0-144.eu-west-1.compute.internal\n  Normal  Pulled     1s    kubelet, ip-10-250-0-144.eu-west-1.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-10-250-0-144.eu-west-1.compute.internal  Created container\n  Normal  Started    1s    kubelet, ip-10-250-0-144.eu-west-1.compute.internal  Started container\n"
Feb 20 19:49:28.752: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe rc redis-master --namespace=e2e-tests-kubectl-v5xdn'
Feb 20 19:49:29.120: INFO: stderr: ""
Feb 20 19:49:29.120: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-v5xdn\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-f48tm\n"
Feb 20 19:49:29.120: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe service redis-master --namespace=e2e-tests-kubectl-v5xdn'
Feb 20 19:49:29.489: INFO: stderr: ""
Feb 20 19:49:29.489: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-v5xdn\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.67.145.208\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.3:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 20 19:49:29.535: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe node ip-10-250-0-144.eu-west-1.compute.internal'
Feb 20 19:49:29.910: INFO: stderr: ""
Feb 20 19:49:29.910: INFO: stdout: "Name:               ip-10-250-0-144.eu-west-1.compute.internal\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=m4.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-west-1\n                    failure-domain.beta.kubernetes.io/zone=eu-west-1a\n                    kubernetes.io/hostname=ip-10-250-0-144.eu-west-1.compute.internal\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\n                    worker.garden.sapcloud.io/group=cpu-worker\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.144/19\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 20 Feb 2019 17:54:01 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 20 Feb 2019 19:49:27 +0000   Wed, 20 Feb 2019 17:54:01 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 20 Feb 2019 19:49:27 +0000   Wed, 20 Feb 2019 17:54:01 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 20 Feb 2019 19:49:27 +0000   Wed, 20 Feb 2019 17:54:01 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 20 Feb 2019 19:49:27 +0000   Wed, 20 Feb 2019 17:54:21 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.250.0.144\n  InternalDNS:  ip-10-250-0-144.eu-west-1.compute.internal\n  Hostname:     ip-10-250-0-144.eu-west-1.compute.internal\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           17897500Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      8169012Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         1920m\n ephemeral-storage:           17410687987\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      6873073044\n pods:                        110\nSystem Info:\n Machine ID:                 9c7c62100eca4791b80b37136e7896e2\n System UUID:                EC2BDA8E-653A-15D1-EF71-99C849EEDEF1\n Boot ID:                    e3e5ef73-ac0f-4141-8f5b-e8b9d4c4c486\n Kernel Version:             4.14.96-coreos\n OS Image:                   Container Linux by CoreOS 1967.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.3\n Kube-Proxy Version:         v1.13.3\nPodCIDR:                     100.96.1.0/24\nProviderID:                  aws:///eu-west-1a/i-0dd3f0ccdc2e7ba80\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                   CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                   ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-v5xdn    redis-master-f48tm     0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  kube-system                calico-node-gwqtg      100m (5%)     500m (26%)  100Mi (1%)       700Mi (10%)    115m\n  kube-system                kube-proxy-ckxln       20m (1%)      900m (46%)  64Mi (0%)        200Mi (3%)     115m\n  kube-system                node-exporter-v62ww    5m (0%)       15m (0%)    10Mi (0%)        50Mi (0%)      115m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         125m (6%)   1415m (73%)\n  memory                      174Mi (2%)  950Mi (14%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Feb 20 19:49:29.911: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe namespace e2e-tests-kubectl-v5xdn'
Feb 20 19:49:30.281: INFO: stderr: ""
Feb 20 19:49:30.281: INFO: stdout: "Name:         e2e-tests-kubectl-v5xdn\nLabels:       e2e-framework=kubectl\n              e2e-run=c7c4244a-353a-11e9-96fe-8e2b2e6369d7\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:49:30.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v5xdn" for this suite.
Feb 20 19:49:52.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:49:53.426: INFO: namespace: e2e-tests-kubectl-v5xdn, resource: bindings, ignored listing per whitelist
Feb 20 19:49:54.061: INFO: namespace e2e-tests-kubectl-v5xdn deletion completed in 23.736975102s

• [SLOW TEST:29.378 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:49:54.061: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5lljf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b2598264-3548-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 19:49:55.851: INFO: Waiting up to 5m0s for pod "pod-secrets-b2600922-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-secrets-5lljf" to be "success or failure"
Feb 20 19:49:55.894: INFO: Pod "pod-secrets-b2600922-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.13412ms
Feb 20 19:49:57.937: INFO: Pod "pod-secrets-b2600922-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085119145s
STEP: Saw pod success
Feb 20 19:49:57.937: INFO: Pod "pod-secrets-b2600922-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:49:57.979: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-secrets-b2600922-3548-11e9-96fe-8e2b2e6369d7 container secret-env-test: <nil>
STEP: delete the pod
Feb 20 19:49:58.072: INFO: Waiting for pod pod-secrets-b2600922-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:49:58.114: INFO: Pod pod-secrets-b2600922-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:49:58.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5lljf" for this suite.
Feb 20 19:50:04.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:50:05.466: INFO: namespace: e2e-tests-secrets-5lljf, resource: bindings, ignored listing per whitelist
Feb 20 19:50:05.888: INFO: namespace e2e-tests-secrets-5lljf deletion completed in 7.731015651s

• [SLOW TEST:11.827 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:50:05.888: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-64mqr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:50:07.652: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 19:50:09.737: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 19:50:12.076: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-64mqr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-64mqr/deployments/test-cleanup-deployment,UID:babcc153-3548-11e9-a8b6-5a3f4013d0a1,ResourceVersion:20762,Generation:1,CreationTimestamp:2019-02-20 19:50:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-20 19:50:09 +0000 UTC 2019-02-20 19:50:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-20 19:50:11 +0000 UTC 2019-02-20 19:50:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 19:50:12.119: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-64mqr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-64mqr/replicasets/test-cleanup-deployment-7dbbfcf846,UID:babe0ebf-3548-11e9-a8b6-5a3f4013d0a1,ResourceVersion:20755,Generation:1,CreationTimestamp:2019-02-20 19:50:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment babcc153-3548-11e9-a8b6-5a3f4013d0a1 0xc0022e4de7 0xc0022e4de8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 20 19:50:12.162: INFO: Pod "test-cleanup-deployment-7dbbfcf846-74cx2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-74cx2,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-64mqr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-64mqr/pods/test-cleanup-deployment-7dbbfcf846-74cx2,UID:babe5a64-3548-11e9-a8b6-5a3f4013d0a1,ResourceVersion:20754,Generation:0,CreationTimestamp:2019-02-20 19:50:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.6/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 babe0ebf-3548-11e9-a8b6-5a3f4013d0a1 0xc001e9d057 0xc001e9d058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tnb45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tnb45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tnb45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e9d0c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e9d0e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:50:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:50:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:50:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:50:09 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:100.96.1.6,StartTime:2019-02-20 19:50:09 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-20 19:50:10 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9668be9d22098eeea31b04a52d69a071d3890390cf01e727933997be9a987d3b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:50:12.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-64mqr" for this suite.
Feb 20 19:50:18.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:50:18.967: INFO: namespace: e2e-tests-deployment-64mqr, resource: bindings, ignored listing per whitelist
Feb 20 19:50:19.977: INFO: namespace e2e-tests-deployment-64mqr deletion completed in 7.772135799s

• [SLOW TEST:14.089 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:50:19.977: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-grbqt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 20 19:50:21.833: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-grbqt,SelfLink:/api/v1/namespaces/e2e-tests-watch-grbqt/configmaps/e2e-watch-test-watch-closed,UID:c1d2560c-3548-11e9-a8b6-5a3f4013d0a1,ResourceVersion:20799,Generation:0,CreationTimestamp:2019-02-20 19:50:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 19:50:21.834: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-grbqt,SelfLink:/api/v1/namespaces/e2e-tests-watch-grbqt/configmaps/e2e-watch-test-watch-closed,UID:c1d2560c-3548-11e9-a8b6-5a3f4013d0a1,ResourceVersion:20800,Generation:0,CreationTimestamp:2019-02-20 19:50:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 20 19:50:22.003: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-grbqt,SelfLink:/api/v1/namespaces/e2e-tests-watch-grbqt/configmaps/e2e-watch-test-watch-closed,UID:c1d2560c-3548-11e9-a8b6-5a3f4013d0a1,ResourceVersion:20801,Generation:0,CreationTimestamp:2019-02-20 19:50:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 19:50:22.003: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-grbqt,SelfLink:/api/v1/namespaces/e2e-tests-watch-grbqt/configmaps/e2e-watch-test-watch-closed,UID:c1d2560c-3548-11e9-a8b6-5a3f4013d0a1,ResourceVersion:20802,Generation:0,CreationTimestamp:2019-02-20 19:50:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:50:22.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-grbqt" for this suite.
Feb 20 19:50:28.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:50:29.359: INFO: namespace: e2e-tests-watch-grbqt, resource: bindings, ignored listing per whitelist
Feb 20 19:50:29.787: INFO: namespace e2e-tests-watch-grbqt deletion completed in 7.740742365s

• [SLOW TEST:9.809 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:50:29.787: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9jdjz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 19:50:31.464: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-9jdjz'
Feb 20 19:50:31.812: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 19:50:31.812: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb 20 19:50:33.897: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-9jdjz'
Feb 20 19:50:34.169: INFO: stderr: ""
Feb 20 19:50:34.169: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:50:34.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9jdjz" for this suite.
Feb 20 19:50:56.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:50:57.738: INFO: namespace: e2e-tests-kubectl-9jdjz, resource: bindings, ignored listing per whitelist
Feb 20 19:50:57.951: INFO: namespace e2e-tests-kubectl-9jdjz deletion completed in 23.739360453s

• [SLOW TEST:28.164 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:50:57.952: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d7l7q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d86ff4e9-3548-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume configMaps
Feb 20 19:50:59.751: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d8765c55-3548-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-d7l7q" to be "success or failure"
Feb 20 19:50:59.793: INFO: Pod "pod-projected-configmaps-d8765c55-3548-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.601954ms
Feb 20 19:51:01.836: INFO: Pod "pod-projected-configmaps-d8765c55-3548-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085308245s
STEP: Saw pod success
Feb 20 19:51:01.836: INFO: Pod "pod-projected-configmaps-d8765c55-3548-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:51:01.878: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-configmaps-d8765c55-3548-11e9-96fe-8e2b2e6369d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:51:01.972: INFO: Waiting for pod pod-projected-configmaps-d8765c55-3548-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:51:02.014: INFO: Pod pod-projected-configmaps-d8765c55-3548-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:51:02.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d7l7q" for this suite.
Feb 20 19:51:08.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:51:08.885: INFO: namespace: e2e-tests-projected-d7l7q, resource: bindings, ignored listing per whitelist
Feb 20 19:51:09.961: INFO: namespace e2e-tests-projected-d7l7q deletion completed in 7.903612108s

• [SLOW TEST:12.010 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:51:09.962: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-bjx4h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-bjx4h
Feb 20 19:51:13.921: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-bjx4h
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 19:51:13.963: INFO: Initial restart count of pod liveness-http is 0
Feb 20 19:51:32.636: INFO: Restart count of pod e2e-tests-container-probe-bjx4h/liveness-http is now 1 (18.673117904s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:51:32.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bjx4h" for this suite.
Feb 20 19:51:38.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:51:39.402: INFO: namespace: e2e-tests-container-probe-bjx4h, resource: bindings, ignored listing per whitelist
Feb 20 19:51:40.502: INFO: namespace e2e-tests-container-probe-bjx4h deletion completed in 7.737128315s

• [SLOW TEST:30.541 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:51:40.504: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-wnrj8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-wnrj8
Feb 20 19:51:44.396: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-wnrj8
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 19:51:44.441: INFO: Initial restart count of pod liveness-exec is 0
Feb 20 19:52:31.506: INFO: Restart count of pod e2e-tests-container-probe-wnrj8/liveness-exec is now 1 (47.065095213s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:52:31.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wnrj8" for this suite.
Feb 20 19:52:37.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:52:38.274: INFO: namespace: e2e-tests-container-probe-wnrj8, resource: bindings, ignored listing per whitelist
Feb 20 19:52:39.373: INFO: namespace e2e-tests-container-probe-wnrj8 deletion completed in 7.78000243s

• [SLOW TEST:58.870 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:52:39.374: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-l5xv2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 20 19:52:41.459: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-l5xv2,SelfLink:/api/v1/namespaces/e2e-tests-watch-l5xv2/configmaps/e2e-watch-test-resource-version,UID:14f15d15-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:21170,Generation:0,CreationTimestamp:2019-02-20 19:52:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 19:52:41.459: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-l5xv2,SelfLink:/api/v1/namespaces/e2e-tests-watch-l5xv2/configmaps/e2e-watch-test-resource-version,UID:14f15d15-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:21171,Generation:0,CreationTimestamp:2019-02-20 19:52:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:52:41.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-l5xv2" for this suite.
Feb 20 19:52:47.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:52:48.123: INFO: namespace: e2e-tests-watch-l5xv2, resource: bindings, ignored listing per whitelist
Feb 20 19:52:49.318: INFO: namespace e2e-tests-watch-l5xv2 deletion completed in 7.813592466s

• [SLOW TEST:9.944 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:52:49.318: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-49p9w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-49p9w
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 20 19:52:51.203: INFO: Found 1 stateful pods, waiting for 3
Feb 20 19:53:01.246: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:53:01.246: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:53:01.246: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:53:01.380: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-49p9w ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:53:02.429: INFO: stderr: ""
Feb 20 19:53:02.430: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:53:02.430: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 20 19:53:12.696: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 20 19:53:12.831: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-49p9w ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:53:13.942: INFO: stderr: ""
Feb 20 19:53:13.942: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:53:13.942: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:53:24.202: INFO: Waiting for StatefulSet e2e-tests-statefulset-49p9w/ss2 to complete update
Feb 20 19:53:24.202: INFO: Waiting for Pod e2e-tests-statefulset-49p9w/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 20 19:53:24.202: INFO: Waiting for Pod e2e-tests-statefulset-49p9w/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 20 19:53:34.287: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-49p9w ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:53:35.173: INFO: stderr: ""
Feb 20 19:53:35.173: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:53:35.173: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:53:45.445: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 20 19:53:45.577: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-c7m4n.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-49p9w ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:53:46.524: INFO: stderr: ""
Feb 20 19:53:46.524: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:53:46.524: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:53:56.785: INFO: Waiting for StatefulSet e2e-tests-statefulset-49p9w/ss2 to complete update
Feb 20 19:53:56.785: INFO: Waiting for Pod e2e-tests-statefulset-49p9w/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 19:54:06.873: INFO: Deleting all statefulset in ns e2e-tests-statefulset-49p9w
Feb 20 19:54:06.916: INFO: Scaling statefulset ss2 to 0
Feb 20 19:54:27.086: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 19:54:27.128: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:54:27.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-49p9w" for this suite.
Feb 20 19:54:33.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:54:34.058: INFO: namespace: e2e-tests-statefulset-49p9w, resource: bindings, ignored listing per whitelist
Feb 20 19:54:35.029: INFO: namespace e2e-tests-statefulset-49p9w deletion completed in 7.728940038s

• [SLOW TEST:105.711 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:54:35.029: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8zqcm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:54:36.809: INFO: Waiting up to 5m0s for pod "downwardapi-volume-59d6d633-3549-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-downward-api-8zqcm" to be "success or failure"
Feb 20 19:54:36.851: INFO: Pod "downwardapi-volume-59d6d633-3549-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.743007ms
Feb 20 19:54:38.894: INFO: Pod "downwardapi-volume-59d6d633-3549-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085225921s
STEP: Saw pod success
Feb 20 19:54:38.894: INFO: Pod "downwardapi-volume-59d6d633-3549-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:54:38.936: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod downwardapi-volume-59d6d633-3549-11e9-96fe-8e2b2e6369d7 container client-container: <nil>
STEP: delete the pod
Feb 20 19:54:39.029: INFO: Waiting for pod downwardapi-volume-59d6d633-3549-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:54:39.071: INFO: Pod downwardapi-volume-59d6d633-3549-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:54:39.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8zqcm" for this suite.
Feb 20 19:54:45.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:54:46.245: INFO: namespace: e2e-tests-downward-api-8zqcm, resource: bindings, ignored listing per whitelist
Feb 20 19:54:46.948: INFO: namespace e2e-tests-downward-api-8zqcm deletion completed in 7.834130949s

• [SLOW TEST:11.919 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:54:46.949: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nv2jw
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-60f76a32-3549-11e9-96fe-8e2b2e6369d7
STEP: Creating configMap with name cm-test-opt-upd-60f76a71-3549-11e9-96fe-8e2b2e6369d7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-60f76a32-3549-11e9-96fe-8e2b2e6369d7
STEP: Updating configmap cm-test-opt-upd-60f76a71-3549-11e9-96fe-8e2b2e6369d7
STEP: Creating configMap with name cm-test-opt-create-60f76a89-3549-11e9-96fe-8e2b2e6369d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:54:55.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nv2jw" for this suite.
Feb 20 19:55:17.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:55:18.989: INFO: namespace: e2e-tests-projected-nv2jw, resource: bindings, ignored listing per whitelist
Feb 20 19:55:19.373: INFO: namespace e2e-tests-projected-nv2jw deletion completed in 23.814343591s

• [SLOW TEST:32.424 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:55:19.373: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lxpzb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-744c9aa6-3549-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 19:55:21.243: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-74530943-3549-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-lxpzb" to be "success or failure"
Feb 20 19:55:21.285: INFO: Pod "pod-projected-secrets-74530943-3549-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.240773ms
Feb 20 19:55:23.329: INFO: Pod "pod-projected-secrets-74530943-3549-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085373634s
STEP: Saw pod success
Feb 20 19:55:23.329: INFO: Pod "pod-projected-secrets-74530943-3549-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:55:23.371: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-secrets-74530943-3549-11e9-96fe-8e2b2e6369d7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 19:55:23.470: INFO: Waiting for pod pod-projected-secrets-74530943-3549-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:55:23.511: INFO: Pod pod-projected-secrets-74530943-3549-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:55:23.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lxpzb" for this suite.
Feb 20 19:55:29.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:55:31.005: INFO: namespace: e2e-tests-projected-lxpzb, resource: bindings, ignored listing per whitelist
Feb 20 19:55:31.342: INFO: namespace e2e-tests-projected-lxpzb deletion completed in 7.787220729s

• [SLOW TEST:11.969 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:55:31.342: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7ctvd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7b65dc3f-3549-11e9-96fe-8e2b2e6369d7
STEP: Creating a pod to test consume secrets
Feb 20 19:55:33.159: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b6cf796-3549-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-projected-7ctvd" to be "success or failure"
Feb 20 19:55:33.202: INFO: Pod "pod-projected-secrets-7b6cf796-3549-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.645235ms
Feb 20 19:55:35.245: INFO: Pod "pod-projected-secrets-7b6cf796-3549-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085340002s
STEP: Saw pod success
Feb 20 19:55:35.245: INFO: Pod "pod-projected-secrets-7b6cf796-3549-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:55:35.287: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-projected-secrets-7b6cf796-3549-11e9-96fe-8e2b2e6369d7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 19:55:35.381: INFO: Waiting for pod pod-projected-secrets-7b6cf796-3549-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:55:35.423: INFO: Pod pod-projected-secrets-7b6cf796-3549-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:55:35.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7ctvd" for this suite.
Feb 20 19:55:41.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:55:42.184: INFO: namespace: e2e-tests-projected-7ctvd, resource: bindings, ignored listing per whitelist
Feb 20 19:55:43.250: INFO: namespace e2e-tests-projected-7ctvd deletion completed in 7.783011145s

• [SLOW TEST:11.908 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:55:43.251: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-xvvnp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 20 19:55:44.987: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 19:55:45.073: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 19:55:45.115: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-0-144.eu-west-1.compute.internal before test
Feb 20 19:55:45.163: INFO: node-exporter-v62ww from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.163: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 19:55:45.163: INFO: kube-proxy-ckxln from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.163: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 19:55:45.163: INFO: calico-node-gwqtg from kube-system started at 2019-02-20 17:54:01 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.163: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 19:55:45.163: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-10-87.eu-west-1.compute.internal before test
Feb 20 19:55:45.310: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-whcxr from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Feb 20 19:55:45.311: INFO: blackbox-exporter-d6c46f9fc-f22mj from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container blackbox-exporter ready: true, restart count 0
Feb 20 19:55:45.311: INFO: calico-node-hbf5r from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 19:55:45.311: INFO: addons-kube-lego-69bbdc96b6-tg58h from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container kube-lego ready: true, restart count 0
Feb 20 19:55:45.311: INFO: vpn-shoot-8655cb5f7b-9pd79 from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container vpn-shoot ready: true, restart count 0
Feb 20 19:55:45.311: INFO: addons-nginx-ingress-controller-7778b8d74b-jkkjz from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 20 19:55:45.311: INFO: metrics-server-56d7786d8c-vpvx4 from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 19:55:45.311: INFO: kube-proxy-hjfzl from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 19:55:45.311: INFO: node-exporter-sk9v2 from kube-system started at 2019-02-20 17:53:58 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 19:55:45.311: INFO: coredns-67df79bbdd-78l6g from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container coredns ready: true, restart count 0
Feb 20 19:55:45.311: INFO: addons-kubernetes-dashboard-6579b646c5-9vwqw from kube-system started at 2019-02-20 17:54:08 +0000 UTC (1 container statuses recorded)
Feb 20 19:55:45.311: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8404f4b9-3549-11e9-96fe-8e2b2e6369d7 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-8404f4b9-3549-11e9-96fe-8e2b2e6369d7 off the node ip-10-250-0-144.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8404f4b9-3549-11e9-96fe-8e2b2e6369d7
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:55:49.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xvvnp" for this suite.
Feb 20 19:55:58.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:55:58.751: INFO: namespace: e2e-tests-sched-pred-xvvnp, resource: bindings, ignored listing per whitelist
Feb 20 19:55:59.810: INFO: namespace e2e-tests-sched-pred-xvvnp deletion completed in 9.77208412s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.559 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:55:59.810: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-r9fpl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 20 19:56:01.818: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-r9fpl,SelfLink:/api/v1/namespaces/e2e-tests-watch-r9fpl/configmaps/e2e-watch-test-label-changed,UID:8c6a7a59-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:21860,Generation:0,CreationTimestamp:2019-02-20 19:56:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 19:56:01.819: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-r9fpl,SelfLink:/api/v1/namespaces/e2e-tests-watch-r9fpl/configmaps/e2e-watch-test-label-changed,UID:8c6a7a59-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:21861,Generation:0,CreationTimestamp:2019-02-20 19:56:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 20 19:56:01.819: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-r9fpl,SelfLink:/api/v1/namespaces/e2e-tests-watch-r9fpl/configmaps/e2e-watch-test-label-changed,UID:8c6a7a59-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:21862,Generation:0,CreationTimestamp:2019-02-20 19:56:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 20 19:56:12.123: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-r9fpl,SelfLink:/api/v1/namespaces/e2e-tests-watch-r9fpl/configmaps/e2e-watch-test-label-changed,UID:8c6a7a59-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:21882,Generation:0,CreationTimestamp:2019-02-20 19:56:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 19:56:12.123: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-r9fpl,SelfLink:/api/v1/namespaces/e2e-tests-watch-r9fpl/configmaps/e2e-watch-test-label-changed,UID:8c6a7a59-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:21883,Generation:0,CreationTimestamp:2019-02-20 19:56:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 20 19:56:12.123: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-r9fpl,SelfLink:/api/v1/namespaces/e2e-tests-watch-r9fpl/configmaps/e2e-watch-test-label-changed,UID:8c6a7a59-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:21884,Generation:0,CreationTimestamp:2019-02-20 19:56:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:56:12.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-r9fpl" for this suite.
Feb 20 19:56:18.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:56:19.318: INFO: namespace: e2e-tests-watch-r9fpl, resource: bindings, ignored listing per whitelist
Feb 20 19:56:19.908: INFO: namespace e2e-tests-watch-r9fpl deletion completed in 7.741351916s

• [SLOW TEST:20.098 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:56:19.908: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vkhgn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 20 19:56:21.629: INFO: Waiting up to 5m0s for pod "pod-98512ad2-3549-11e9-96fe-8e2b2e6369d7" in namespace "e2e-tests-emptydir-vkhgn" to be "success or failure"
Feb 20 19:56:21.671: INFO: Pod "pod-98512ad2-3549-11e9-96fe-8e2b2e6369d7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.210089ms
Feb 20 19:56:23.716: INFO: Pod "pod-98512ad2-3549-11e9-96fe-8e2b2e6369d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086703792s
STEP: Saw pod success
Feb 20 19:56:23.716: INFO: Pod "pod-98512ad2-3549-11e9-96fe-8e2b2e6369d7" satisfied condition "success or failure"
Feb 20 19:56:23.758: INFO: Trying to get logs from node ip-10-250-0-144.eu-west-1.compute.internal pod pod-98512ad2-3549-11e9-96fe-8e2b2e6369d7 container test-container: <nil>
STEP: delete the pod
Feb 20 19:56:23.853: INFO: Waiting for pod pod-98512ad2-3549-11e9-96fe-8e2b2e6369d7 to disappear
Feb 20 19:56:23.895: INFO: Pod pod-98512ad2-3549-11e9-96fe-8e2b2e6369d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:56:23.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vkhgn" for this suite.
Feb 20 19:56:30.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:56:30.868: INFO: namespace: e2e-tests-emptydir-vkhgn, resource: bindings, ignored listing per whitelist
Feb 20 19:56:31.753: INFO: namespace e2e-tests-emptydir-vkhgn deletion completed in 7.814221615s

• [SLOW TEST:11.845 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:56:31.753: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-ffnkv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:56:37.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-ffnkv" for this suite.
Feb 20 19:56:59.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:57:01.401: INFO: namespace: e2e-tests-replication-controller-ffnkv, resource: bindings, ignored listing per whitelist
Feb 20 19:57:01.528: INFO: namespace e2e-tests-replication-controller-ffnkv deletion completed in 23.758215789s

• [SLOW TEST:29.775 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:57:01.528: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-ks6gt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:57:03.278: INFO: Creating deployment "test-recreate-deployment"
Feb 20 19:57:03.320: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 20 19:57:03.408: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 20 19:57:03.451: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686289423, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686289423, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686289423, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686289423, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:57:05.494: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 20 19:57:05.578: INFO: Updating deployment test-recreate-deployment
Feb 20 19:57:05.578: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 19:57:05.674: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-ks6gt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ks6gt/deployments/test-recreate-deployment,UID:b12d5524-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:22069,Generation:2,CreationTimestamp:2019-02-20 19:57:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-20 19:57:05 +0000 UTC 2019-02-20 19:57:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-20 19:57:05 +0000 UTC 2019-02-20 19:57:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 20 19:57:05.716: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-ks6gt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ks6gt/replicasets/test-recreate-deployment-697fbf54bf,UID:b287d4d0-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:22067,Generation:1,CreationTimestamp:2019-02-20 19:57:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b12d5524-3549-11e9-a8b6-5a3f4013d0a1 0xc0015c3787 0xc0015c3788}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:57:05.717: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 20 19:57:05.717: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-ks6gt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ks6gt/replicasets/test-recreate-deployment-5dfdcc846d,UID:b12e1420-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:22060,Generation:2,CreationTimestamp:2019-02-20 19:57:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b12d5524-3549-11e9-a8b6-5a3f4013d0a1 0xc0015c36c7 0xc0015c36c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:57:05.760: INFO: Pod "test-recreate-deployment-697fbf54bf-8mcpk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-8mcpk,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-ks6gt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ks6gt/pods/test-recreate-deployment-697fbf54bf-8mcpk,UID:b2881fe2-3549-11e9-a8b6-5a3f4013d0a1,ResourceVersion:22068,Generation:0,CreationTimestamp:2019-02-20 19:57:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf b287d4d0-3549-11e9-a8b6-5a3f4013d0a1 0xc000b29897 0xc000b29898}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wlb2f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wlb2f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wlb2f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-0-144.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b29a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001670010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:57:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:57:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:57:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:57:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.144,PodIP:,StartTime:2019-02-20 19:57:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:57:05.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ks6gt" for this suite.
Feb 20 19:57:11.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:57:12.145: INFO: namespace: e2e-tests-deployment-ks6gt, resource: bindings, ignored listing per whitelist
Feb 20 19:57:13.579: INFO: namespace e2e-tests-deployment-ks6gt deletion completed in 7.77579456s

• [SLOW TEST:12.051 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 20 19:57:13.579: INFO: >>> kubeConfig: /tmp/build/0b081913/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-wck5h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-wck5h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wck5h to expose endpoints map[]
Feb 20 19:57:15.453: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wck5h exposes endpoints map[] (42.086864ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-wck5h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wck5h to expose endpoints map[pod1:[100]]
Feb 20 19:57:16.668: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wck5h exposes endpoints map[pod1:[100]] (1.170506226s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-wck5h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wck5h to expose endpoints map[pod1:[100] pod2:[101]]
Feb 20 19:57:19.092: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wck5h exposes endpoints map[pod1:[100] pod2:[101]] (2.380066036s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-wck5h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wck5h to expose endpoints map[pod2:[101]]
Feb 20 19:57:19.219: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wck5h exposes endpoints map[pod2:[101]] (84.030311ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-wck5h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wck5h to expose endpoints map[]
Feb 20 19:57:19.304: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wck5h exposes endpoints map[] (41.856465ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 20 19:57:19.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-wck5h" for this suite.
Feb 20 19:57:25.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:57:26.873: INFO: namespace: e2e-tests-services-wck5h, resource: bindings, ignored listing per whitelist
Feb 20 19:57:27.126: INFO: namespace e2e-tests-services-wck5h deletion completed in 7.730405673s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.546 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSFeb 20 19:57:27.126: INFO: Running AfterSuite actions on all nodes
Feb 20 19:57:27.126: INFO: Running AfterSuite actions on node 1
Feb 20 19:57:27.126: INFO: Skipping dumping logs from cluster

Ran 200 of 2161 Specs in 6427.675 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Flaked | 0 Pending | 1961 Skipped PASS

Ginkgo ran 1 suite in 1h47m8.458817867s
Test Suite Passed

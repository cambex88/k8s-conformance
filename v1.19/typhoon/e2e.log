I0827 08:10:38.519727      19 test_context.go:416] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-356341267
I0827 08:10:38.519912      19 test_context.go:429] Tolerating taints "node-role.kubernetes.io/controller" when considering if nodes are ready
I0827 08:10:38.520080      19 e2e.go:129] Starting e2e run "bdc88c35-17bb-41ca-958b-48ca3c0772e5" on Ginkgo node 1
{"msg":"Test Suite starting","total":303,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1598515835 - Will randomize all specs
Will run 303 of 5232 specs

Aug 27 08:10:38.634: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:10:38.637: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 27 08:10:38.658: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 27 08:10:38.691: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 27 08:10:38.691: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Aug 27 08:10:38.691: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 27 08:10:38.702: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug 27 08:10:38.702: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Aug 27 08:10:38.702: INFO: e2e test version: v1.19.0
Aug 27 08:10:38.704: INFO: kube-apiserver version: v1.19.0
Aug 27 08:10:38.704: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:10:38.709: INFO: Cluster IP family: ipv4
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:10:38.710: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename gc
Aug 27 08:10:38.749: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:10:38.786: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6b1d841f-4401-4440-8132-4b979ed14de7", Controller:(*bool)(0xc00265b1fa), BlockOwnerDeletion:(*bool)(0xc00265b1fb)}}
Aug 27 08:10:38.796: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"1aa5dcd1-2e35-438b-b0cc-854a865b070e", Controller:(*bool)(0xc00265b406), BlockOwnerDeletion:(*bool)(0xc00265b407)}}
Aug 27 08:10:38.808: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"2234dd6b-7677-4fc7-b87e-c5eb74edc8b6", Controller:(*bool)(0xc00265b606), BlockOwnerDeletion:(*bool)(0xc00265b607)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:10:43.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4723" for this suite.

• [SLOW TEST:5.125 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":303,"completed":1,"skipped":11,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:10:43.836: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:10:57.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3356" for this suite.

• [SLOW TEST:13.283 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":303,"completed":2,"skipped":18,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:10:57.120: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 27 08:10:57.371: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 27 08:11:02.402: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:11:03.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3054" for this suite.

• [SLOW TEST:6.654 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":303,"completed":3,"skipped":46,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:11:03.777: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Aug 27 08:11:03.813: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:11:07.320: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:11:20.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2652" for this suite.

• [SLOW TEST:17.013 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":303,"completed":4,"skipped":49,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:11:20.792: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:11:20.826: INFO: Creating ReplicaSet my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f
Aug 27 08:11:20.834: INFO: Pod name my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f: Found 0 pods out of 1
Aug 27 08:11:25.839: INFO: Pod name my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f: Found 1 pods out of 1
Aug 27 08:11:25.839: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f" is running
Aug 27 08:11:27.845: INFO: Pod "my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f-kf7mw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-27 08:11:20 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-27 08:11:20 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-27 08:11:20 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-27 08:11:20 +0000 UTC Reason: Message:}])
Aug 27 08:11:27.846: INFO: Trying to dial the pod
Aug 27 08:11:32.862: INFO: Controller my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f: Got expected result from replica 1 [my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f-kf7mw]: "my-hostname-basic-7fadb9d4-c8ab-45df-a43f-71d853be002f-kf7mw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:11:32.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-596" for this suite.

• [SLOW TEST:12.078 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":303,"completed":5,"skipped":59,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:11:32.873: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:181
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:11:32.914: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:11:36.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5750" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":303,"completed":6,"skipped":73,"failed":0}

------------------------------
[k8s.io] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:11:36.996: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod with failed condition
STEP: updating the pod
Aug 27 08:13:37.587: INFO: Successfully updated pod "var-expansion-6b435cee-49af-48c7-acdc-af9eba0d4432"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Aug 27 08:13:39.604: INFO: Deleting pod "var-expansion-6b435cee-49af-48c7-acdc-af9eba0d4432" in namespace "var-expansion-7997"
Aug 27 08:13:39.608: INFO: Wait up to 5m0s for pod "var-expansion-6b435cee-49af-48c7-acdc-af9eba0d4432" to be fully deleted
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:14:23.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7997" for this suite.

• [SLOW TEST:166.635 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [sig-storage][Slow] [Conformance]","total":303,"completed":7,"skipped":73,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:14:23.635: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 27 08:14:23.688: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-717 /api/v1/namespaces/watch-717/configmaps/e2e-watch-test-watch-closed 6d45d73d-3a39-40d4-ac46-5d051e7d3357 1894 0 2020-08-27 08:14:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-08-27 08:14:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:14:23.689: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-717 /api/v1/namespaces/watch-717/configmaps/e2e-watch-test-watch-closed 6d45d73d-3a39-40d4-ac46-5d051e7d3357 1895 0 2020-08-27 08:14:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-08-27 08:14:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 27 08:14:23.700: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-717 /api/v1/namespaces/watch-717/configmaps/e2e-watch-test-watch-closed 6d45d73d-3a39-40d4-ac46-5d051e7d3357 1896 0 2020-08-27 08:14:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-08-27 08:14:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:14:23.700: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-717 /api/v1/namespaces/watch-717/configmaps/e2e-watch-test-watch-closed 6d45d73d-3a39-40d4-ac46-5d051e7d3357 1897 0 2020-08-27 08:14:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-08-27 08:14:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:14:23.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-717" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":303,"completed":8,"skipped":85,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:14:23.710: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name secret-test-6a4a0fbb-4d68-44dd-b416-763b4d82e032
STEP: Creating a pod to test consume secrets
Aug 27 08:14:23.754: INFO: Waiting up to 5m0s for pod "pod-secrets-ff0ff5b4-e2d1-4c8b-ad49-bbe61c556cc1" in namespace "secrets-1250" to be "Succeeded or Failed"
Aug 27 08:14:23.762: INFO: Pod "pod-secrets-ff0ff5b4-e2d1-4c8b-ad49-bbe61c556cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.899754ms
Aug 27 08:14:25.765: INFO: Pod "pod-secrets-ff0ff5b4-e2d1-4c8b-ad49-bbe61c556cc1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009585233s
STEP: Saw pod success
Aug 27 08:14:25.766: INFO: Pod "pod-secrets-ff0ff5b4-e2d1-4c8b-ad49-bbe61c556cc1" satisfied condition "Succeeded or Failed"
Aug 27 08:14:25.771: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-secrets-ff0ff5b4-e2d1-4c8b-ad49-bbe61c556cc1 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 08:14:25.827: INFO: Waiting for pod pod-secrets-ff0ff5b4-e2d1-4c8b-ad49-bbe61c556cc1 to disappear
Aug 27 08:14:25.838: INFO: Pod pod-secrets-ff0ff5b4-e2d1-4c8b-ad49-bbe61c556cc1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:14:25.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1250" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":9,"skipped":87,"failed":0}

------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:14:25.858: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:14:36.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4665" for this suite.

• [SLOW TEST:11.102 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":303,"completed":10,"skipped":87,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:14:36.962: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 27 08:14:39.102: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:14:39.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8555" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":303,"completed":11,"skipped":106,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:14:39.125: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service in namespace services-2161
STEP: creating service affinity-clusterip-transition in namespace services-2161
STEP: creating replication controller affinity-clusterip-transition in namespace services-2161
I0827 08:14:39.224294      19 runners.go:190] Created replication controller with name: affinity-clusterip-transition, namespace: services-2161, replica count: 3
I0827 08:14:42.285111      19 runners.go:190] affinity-clusterip-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:14:45.285236      19 runners.go:190] affinity-clusterip-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:14:48.285570      19 runners.go:190] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:14:51.285788      19 runners.go:190] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 08:14:51.292: INFO: Creating new exec pod
Aug 27 08:14:54.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2161 execpod-affinitykzn52 -- /bin/sh -x -c nc -zv -t -w 2 affinity-clusterip-transition 80'
Aug 27 08:14:55.236: INFO: stderr: "+ nc -zv -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Aug 27 08:14:55.236: INFO: stdout: ""
Aug 27 08:14:55.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2161 execpod-affinitykzn52 -- /bin/sh -x -c nc -zv -t -w 2 10.3.65.44 80'
Aug 27 08:14:55.434: INFO: stderr: "+ nc -zv -t -w 2 10.3.65.44 80\nConnection to 10.3.65.44 80 port [tcp/http] succeeded!\n"
Aug 27 08:14:55.434: INFO: stdout: ""
Aug 27 08:14:55.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2161 execpod-affinitykzn52 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.65.44:80/ ; done'
Aug 27 08:14:55.917: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n"
Aug 27 08:14:55.917: INFO: stdout: "\naffinity-clusterip-transition-qp5wm\naffinity-clusterip-transition-bjt85\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-qp5wm\naffinity-clusterip-transition-bjt85\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-qp5wm\naffinity-clusterip-transition-bjt85\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-qp5wm\naffinity-clusterip-transition-bjt85\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-qp5wm\naffinity-clusterip-transition-bjt85\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-qp5wm"
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-qp5wm
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-bjt85
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-qp5wm
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-bjt85
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-qp5wm
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-bjt85
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-qp5wm
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-bjt85
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-qp5wm
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-bjt85
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:55.917: INFO: Received response from host: affinity-clusterip-transition-qp5wm
Aug 27 08:14:55.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2161 execpod-affinitykzn52 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.65.44:80/ ; done'
Aug 27 08:14:56.347: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.65.44:80/\n"
Aug 27 08:14:56.348: INFO: stdout: "\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7\naffinity-clusterip-transition-6qkb7"
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Received response from host: affinity-clusterip-transition-6qkb7
Aug 27 08:14:56.348: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2161, will wait for the garbage collector to delete the pods
Aug 27 08:14:56.419: INFO: Deleting ReplicationController affinity-clusterip-transition took: 4.836054ms
Aug 27 08:14:56.920: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 501.12711ms
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:15:05.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2161" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:26.314 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":303,"completed":12,"skipped":130,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] IngressClass API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:15:05.448: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/ingressclass.go:148
[It]  should support creating IngressClass API operations [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug 27 08:15:05.935: INFO: starting watch
STEP: patching
STEP: updating
Aug 27 08:15:05.944: INFO: waiting for watch events with expected annotations
Aug 27 08:15:05.944: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:15:05.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-9411" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":303,"completed":13,"skipped":150,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:15:06.021: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service in namespace services-1503
Aug 27 08:15:08.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-1503 kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug 27 08:15:08.343: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug 27 08:15:08.343: INFO: stdout: "ipvs"
Aug 27 08:15:08.343: INFO: proxyMode: ipvs
Aug 27 08:15:08.348: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:15:08.352: INFO: Pod kube-proxy-mode-detector still exists
Aug 27 08:15:10.352: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:15:10.355: INFO: Pod kube-proxy-mode-detector still exists
Aug 27 08:15:12.352: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:15:12.355: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-1503
STEP: creating replication controller affinity-clusterip-timeout in namespace services-1503
I0827 08:15:12.370678      19 runners.go:190] Created replication controller with name: affinity-clusterip-timeout, namespace: services-1503, replica count: 3
I0827 08:15:15.424688      19 runners.go:190] affinity-clusterip-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:15:18.424845      19 runners.go:190] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 08:15:18.430: INFO: Creating new exec pod
Aug 27 08:15:21.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-1503 execpod-affinitygwdhc -- /bin/sh -x -c nc -zv -t -w 2 affinity-clusterip-timeout 80'
Aug 27 08:15:21.764: INFO: stderr: "+ nc -zv -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Aug 27 08:15:21.764: INFO: stdout: ""
Aug 27 08:15:21.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-1503 execpod-affinitygwdhc -- /bin/sh -x -c nc -zv -t -w 2 10.3.98.55 80'
Aug 27 08:15:21.993: INFO: stderr: "+ nc -zv -t -w 2 10.3.98.55 80\nConnection to 10.3.98.55 80 port [tcp/http] succeeded!\n"
Aug 27 08:15:21.993: INFO: stdout: ""
Aug 27 08:15:21.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-1503 execpod-affinitygwdhc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.98.55:80/ ; done'
Aug 27 08:15:22.320: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n"
Aug 27 08:15:22.320: INFO: stdout: "\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr\naffinity-clusterip-timeout-x8fxr"
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Received response from host: affinity-clusterip-timeout-x8fxr
Aug 27 08:15:22.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-1503 execpod-affinitygwdhc -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.3.98.55:80/'
Aug 27 08:15:22.500: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n"
Aug 27 08:15:22.500: INFO: stdout: "affinity-clusterip-timeout-x8fxr"
Aug 27 08:17:27.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-1503 execpod-affinitygwdhc -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.3.98.55:80/'
Aug 27 08:17:27.920: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.3.98.55:80/\n"
Aug 27 08:17:27.920: INFO: stdout: "affinity-clusterip-timeout-8fmcr"
Aug 27 08:17:27.920: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-1503, will wait for the garbage collector to delete the pods
Aug 27 08:17:27.992: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 6.103512ms
Aug 27 08:17:28.493: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 500.241418ms
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:17:44.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1503" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:158.214 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":303,"completed":14,"skipped":158,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:17:44.241: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward api env vars
Aug 27 08:17:44.288: INFO: Waiting up to 5m0s for pod "downward-api-33c3710e-0a1b-4da2-afd8-737e2186e4d6" in namespace "downward-api-2816" to be "Succeeded or Failed"
Aug 27 08:17:44.295: INFO: Pod "downward-api-33c3710e-0a1b-4da2-afd8-737e2186e4d6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.430018ms
Aug 27 08:17:46.299: INFO: Pod "downward-api-33c3710e-0a1b-4da2-afd8-737e2186e4d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010144723s
Aug 27 08:17:48.303: INFO: Pod "downward-api-33c3710e-0a1b-4da2-afd8-737e2186e4d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01431874s
STEP: Saw pod success
Aug 27 08:17:48.303: INFO: Pod "downward-api-33c3710e-0a1b-4da2-afd8-737e2186e4d6" satisfied condition "Succeeded or Failed"
Aug 27 08:17:48.305: INFO: Trying to get logs from node ip-10-0-45-43 pod downward-api-33c3710e-0a1b-4da2-afd8-737e2186e4d6 container dapi-container: <nil>
STEP: delete the pod
Aug 27 08:17:48.338: INFO: Waiting for pod downward-api-33c3710e-0a1b-4da2-afd8-737e2186e4d6 to disappear
Aug 27 08:17:48.342: INFO: Pod downward-api-33c3710e-0a1b-4da2-afd8-737e2186e4d6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:17:48.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2816" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":303,"completed":15,"skipped":211,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:17:48.355: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:17:48.400: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 27 08:17:51.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-4913 create -f -'
Aug 27 08:17:51.761: INFO: stderr: ""
Aug 27 08:17:51.761: INFO: stdout: "e2e-test-crd-publish-openapi-3416-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 27 08:17:51.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-4913 delete e2e-test-crd-publish-openapi-3416-crds test-cr'
Aug 27 08:17:51.846: INFO: stderr: ""
Aug 27 08:17:51.846: INFO: stdout: "e2e-test-crd-publish-openapi-3416-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Aug 27 08:17:51.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-4913 apply -f -'
Aug 27 08:17:52.049: INFO: stderr: ""
Aug 27 08:17:52.049: INFO: stdout: "e2e-test-crd-publish-openapi-3416-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 27 08:17:52.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-4913 delete e2e-test-crd-publish-openapi-3416-crds test-cr'
Aug 27 08:17:52.143: INFO: stderr: ""
Aug 27 08:17:52.143: INFO: stdout: "e2e-test-crd-publish-openapi-3416-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Aug 27 08:17:52.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 explain e2e-test-crd-publish-openapi-3416-crds'
Aug 27 08:17:52.343: INFO: stderr: ""
Aug 27 08:17:52.343: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3416-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:17:55.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4913" for this suite.

• [SLOW TEST:6.927 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":303,"completed":16,"skipped":234,"failed":0}
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:17:55.292: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating server pod server in namespace prestop-7812
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7812
STEP: Deleting pre-stop pod
Aug 27 08:18:04.366: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:18:04.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7812" for this suite.

• [SLOW TEST:9.102 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":303,"completed":17,"skipped":235,"failed":0}
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:18:04.395: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating Agnhost RC
Aug 27 08:18:04.441: INFO: namespace kubectl-9926
Aug 27 08:18:04.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-9926'
Aug 27 08:18:04.728: INFO: stderr: ""
Aug 27 08:18:04.728: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug 27 08:18:05.731: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 08:18:05.731: INFO: Found 0 / 1
Aug 27 08:18:06.731: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 08:18:06.731: INFO: Found 1 / 1
Aug 27 08:18:06.731: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 27 08:18:06.734: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 08:18:06.734: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 08:18:06.734: INFO: wait on agnhost-primary startup in kubectl-9926 
Aug 27 08:18:06.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 logs agnhost-primary-j9h7n agnhost-primary --namespace=kubectl-9926'
Aug 27 08:18:06.840: INFO: stderr: ""
Aug 27 08:18:06.840: INFO: stdout: "Paused\n"
STEP: exposing RC
Aug 27 08:18:06.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9926'
Aug 27 08:18:06.963: INFO: stderr: ""
Aug 27 08:18:06.963: INFO: stdout: "service/rm2 exposed\n"
Aug 27 08:18:06.968: INFO: Service rm2 in namespace kubectl-9926 found.
STEP: exposing service
Aug 27 08:18:08.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9926'
Aug 27 08:18:09.122: INFO: stderr: ""
Aug 27 08:18:09.122: INFO: stdout: "service/rm3 exposed\n"
Aug 27 08:18:09.138: INFO: Service rm3 in namespace kubectl-9926 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:18:11.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9926" for this suite.

• [SLOW TEST:6.761 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
    should create services for rc  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":303,"completed":18,"skipped":235,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:18:11.159: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:181
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 27 08:18:11.247: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:18:23.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3275" for this suite.

• [SLOW TEST:12.186 seconds]
[k8s.io] Pods
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":303,"completed":19,"skipped":271,"failed":0}
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:18:23.347: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod pod-subpath-test-projected-sdgj
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 08:18:23.431: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-sdgj" in namespace "subpath-1089" to be "Succeeded or Failed"
Aug 27 08:18:23.435: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111502ms
Aug 27 08:18:25.439: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 2.008019391s
Aug 27 08:18:27.442: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 4.011083308s
Aug 27 08:18:29.446: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 6.014645192s
Aug 27 08:18:31.449: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 8.017758091s
Aug 27 08:18:33.452: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 10.021058556s
Aug 27 08:18:35.456: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 12.024498306s
Aug 27 08:18:37.462: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 14.030881766s
Aug 27 08:18:39.465: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 16.034050854s
Aug 27 08:18:41.468: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 18.037376893s
Aug 27 08:18:43.473: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Running", Reason="", readiness=true. Elapsed: 20.041529053s
Aug 27 08:18:45.477: INFO: Pod "pod-subpath-test-projected-sdgj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.046287302s
STEP: Saw pod success
Aug 27 08:18:45.477: INFO: Pod "pod-subpath-test-projected-sdgj" satisfied condition "Succeeded or Failed"
Aug 27 08:18:45.480: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-subpath-test-projected-sdgj container test-container-subpath-projected-sdgj: <nil>
STEP: delete the pod
Aug 27 08:18:45.503: INFO: Waiting for pod pod-subpath-test-projected-sdgj to disappear
Aug 27 08:18:45.509: INFO: Pod pod-subpath-test-projected-sdgj no longer exists
STEP: Deleting pod pod-subpath-test-projected-sdgj
Aug 27 08:18:45.509: INFO: Deleting pod "pod-subpath-test-projected-sdgj" in namespace "subpath-1089"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:18:45.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1089" for this suite.

• [SLOW TEST:22.175 seconds]
[sig-storage] Subpath
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":303,"completed":20,"skipped":271,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:18:45.526: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should check if kubectl can dry-run update Pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 27 08:18:45.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-1016'
Aug 27 08:18:45.691: INFO: stderr: ""
Aug 27 08:18:45.691: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Aug 27 08:18:45.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pod e2e-test-httpd-pod -o json --namespace=kubectl-1016'
Aug 27 08:18:45.797: INFO: stderr: ""
Aug 27 08:18:45.797: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-08-27T08:18:45Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl-run\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-08-27T08:18:45Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:message\": {},\n                                \"f:reason\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:message\": {},\n                                \"f:reason\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-08-27T08:18:45Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1016\",\n        \"resourceVersion\": \"3209\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1016/pods/e2e-test-httpd-pod\",\n        \"uid\": \"f34a48b4-a6a3-488c-a078-48c5ff90506a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-bxhhl\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-2-216\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-bxhhl\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-bxhhl\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-27T08:18:45Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-27T08:18:45Z\",\n                \"message\": \"containers with unready status: [e2e-test-httpd-pod]\",\n                \"reason\": \"ContainersNotReady\",\n                \"status\": \"False\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-27T08:18:45Z\",\n                \"message\": \"containers with unready status: [e2e-test-httpd-pod]\",\n                \"reason\": \"ContainersNotReady\",\n                \"status\": \"False\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-27T08:18:45Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": false,\n                \"restartCount\": 0,\n                \"started\": false,\n                \"state\": {\n                    \"waiting\": {\n                        \"reason\": \"ContainerCreating\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.2.216\",\n        \"phase\": \"Pending\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-08-27T08:18:45Z\"\n    }\n}\n"
Aug 27 08:18:45.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 replace -f - --dry-run server --namespace=kubectl-1016'
Aug 27 08:18:46.060: INFO: stderr: "W0827 08:18:45.877485     111 helpers.go:553] --dry-run is deprecated and can be replaced with --dry-run=client.\n"
Aug 27 08:18:46.060: INFO: stdout: "pod/e2e-test-httpd-pod replaced (dry run)\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/httpd:2.4.38-alpine
Aug 27 08:18:46.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete pods e2e-test-httpd-pod --namespace=kubectl-1016'
Aug 27 08:18:53.303: INFO: stderr: ""
Aug 27 08:18:53.303: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:18:53.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1016" for this suite.

• [SLOW TEST:7.784 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:919
    should check if kubectl can dry-run update Pods [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":303,"completed":21,"skipped":276,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:18:53.309: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 27 08:18:53.367: INFO: Waiting up to 5m0s for pod "pod-150388c5-0c86-431b-a514-eac445a5224f" in namespace "emptydir-1011" to be "Succeeded or Failed"
Aug 27 08:18:53.371: INFO: Pod "pod-150388c5-0c86-431b-a514-eac445a5224f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.425714ms
Aug 27 08:18:55.375: INFO: Pod "pod-150388c5-0c86-431b-a514-eac445a5224f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007003273s
STEP: Saw pod success
Aug 27 08:18:55.375: INFO: Pod "pod-150388c5-0c86-431b-a514-eac445a5224f" satisfied condition "Succeeded or Failed"
Aug 27 08:18:55.377: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-150388c5-0c86-431b-a514-eac445a5224f container test-container: <nil>
STEP: delete the pod
Aug 27 08:18:55.396: INFO: Waiting for pod pod-150388c5-0c86-431b-a514-eac445a5224f to disappear
Aug 27 08:18:55.401: INFO: Pod pod-150388c5-0c86-431b-a514-eac445a5224f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:18:55.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1011" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":22,"skipped":292,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:18:55.411: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name projected-secret-test-b98a980e-0728-48be-a4bb-60d565413e9f
STEP: Creating a pod to test consume secrets
Aug 27 08:18:55.464: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-391207b3-cced-431b-ba5a-5e836c4e3211" in namespace "projected-601" to be "Succeeded or Failed"
Aug 27 08:18:55.468: INFO: Pod "pod-projected-secrets-391207b3-cced-431b-ba5a-5e836c4e3211": Phase="Pending", Reason="", readiness=false. Elapsed: 4.141213ms
Aug 27 08:18:57.471: INFO: Pod "pod-projected-secrets-391207b3-cced-431b-ba5a-5e836c4e3211": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007635344s
STEP: Saw pod success
Aug 27 08:18:57.471: INFO: Pod "pod-projected-secrets-391207b3-cced-431b-ba5a-5e836c4e3211" satisfied condition "Succeeded or Failed"
Aug 27 08:18:57.474: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-secrets-391207b3-cced-431b-ba5a-5e836c4e3211 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 08:18:57.494: INFO: Waiting for pod pod-projected-secrets-391207b3-cced-431b-ba5a-5e836c4e3211 to disappear
Aug 27 08:18:57.498: INFO: Pod pod-projected-secrets-391207b3-cced-431b-ba5a-5e836c4e3211 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:18:57.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-601" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":303,"completed":23,"skipped":294,"failed":0}

------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:18:57.506: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug 27 08:18:57.542: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Registering the sample API server.
Aug 27 08:18:58.192: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 27 08:19:00.471: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-67c46cd746\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 08:19:02.478: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-67c46cd746\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 08:19:04.486: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-67c46cd746\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 08:19:06.475: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-67c46cd746\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 08:19:08.475: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-67c46cd746\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 08:19:10.478: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734113138, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-67c46cd746\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 08:19:13.801: INFO: Waited 1.319371982s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:19:14.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1143" for this suite.

• [SLOW TEST:17.372 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":303,"completed":24,"skipped":294,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:19:14.885: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:89
Aug 27 08:19:14.928: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 08:20:14.966: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:20:14.970: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:487
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Aug 27 08:20:17.187: INFO: found a healthy node: ip-10-0-2-216
[It] runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:20:33.311: INFO: pods created so far: [1 1 1]
Aug 27 08:20:33.312: INFO: length of pods created so far: 3
Aug 27 08:20:43.323: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:20:50.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-3773" for this suite.
[AfterEach] PreemptionExecutionPath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:461
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:20:50.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4611" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:77

• [SLOW TEST:95.808 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:450
    runs ReplicaSets to verify preemption running path [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":303,"completed":25,"skipped":314,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:20:50.693: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: set up a multi version CRD
Aug 27 08:20:50.725: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:21:09.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5421" for this suite.

• [SLOW TEST:18.971 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":303,"completed":26,"skipped":317,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] version v1
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:21:09.672: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-mkfqw in namespace proxy-3153
I0827 08:21:09.759000      19 runners.go:190] Created replication controller with name: proxy-service-mkfqw, namespace: proxy-3153, replica count: 1
I0827 08:21:10.817646      19 runners.go:190] proxy-service-mkfqw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:21:11.817866      19 runners.go:190] proxy-service-mkfqw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:21:12.818097      19 runners.go:190] proxy-service-mkfqw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0827 08:21:13.818234      19 runners.go:190] proxy-service-mkfqw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0827 08:21:14.819798      19 runners.go:190] proxy-service-mkfqw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 08:21:14.822: INFO: setup took 5.096824948s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 27 08:21:14.845: INFO: (0) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 21.299308ms)
Aug 27 08:21:14.845: INFO: (0) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 22.658747ms)
Aug 27 08:21:14.851: INFO: (0) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 28.123041ms)
Aug 27 08:21:14.852: INFO: (0) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 28.715319ms)
Aug 27 08:21:14.852: INFO: (0) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 28.375285ms)
Aug 27 08:21:14.852: INFO: (0) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 28.419744ms)
Aug 27 08:21:14.852: INFO: (0) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 28.744281ms)
Aug 27 08:21:14.853: INFO: (0) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 29.69073ms)
Aug 27 08:21:14.853: INFO: (0) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 29.73207ms)
Aug 27 08:21:14.860: INFO: (0) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 36.247971ms)
Aug 27 08:21:14.861: INFO: (0) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 37.117148ms)
Aug 27 08:21:14.861: INFO: (0) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 37.261619ms)
Aug 27 08:21:14.861: INFO: (0) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 37.587503ms)
Aug 27 08:21:14.861: INFO: (0) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 38.328084ms)
Aug 27 08:21:14.862: INFO: (0) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 39.163824ms)
Aug 27 08:21:14.862: INFO: (0) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 38.247608ms)
Aug 27 08:21:14.879: INFO: (1) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 17.091671ms)
Aug 27 08:21:14.880: INFO: (1) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 17.306166ms)
Aug 27 08:21:14.880: INFO: (1) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 17.498436ms)
Aug 27 08:21:14.880: INFO: (1) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 17.525948ms)
Aug 27 08:21:14.880: INFO: (1) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 18.085652ms)
Aug 27 08:21:14.880: INFO: (1) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 18.191205ms)
Aug 27 08:21:14.881: INFO: (1) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 18.10703ms)
Aug 27 08:21:14.881: INFO: (1) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 18.511403ms)
Aug 27 08:21:14.881: INFO: (1) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 18.810475ms)
Aug 27 08:21:14.881: INFO: (1) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 18.860137ms)
Aug 27 08:21:14.881: INFO: (1) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 19.046447ms)
Aug 27 08:21:14.882: INFO: (1) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 19.458076ms)
Aug 27 08:21:14.882: INFO: (1) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 19.556739ms)
Aug 27 08:21:14.882: INFO: (1) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 20.020018ms)
Aug 27 08:21:14.882: INFO: (1) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 20.162153ms)
Aug 27 08:21:14.882: INFO: (1) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 19.686959ms)
Aug 27 08:21:14.900: INFO: (2) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 16.207383ms)
Aug 27 08:21:14.900: INFO: (2) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 17.51667ms)
Aug 27 08:21:14.901: INFO: (2) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 17.374812ms)
Aug 27 08:21:14.901: INFO: (2) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 18.800574ms)
Aug 27 08:21:14.901: INFO: (2) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 17.257837ms)
Aug 27 08:21:14.901: INFO: (2) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 17.486103ms)
Aug 27 08:21:14.901: INFO: (2) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 18.468538ms)
Aug 27 08:21:14.902: INFO: (2) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 18.35826ms)
Aug 27 08:21:14.902: INFO: (2) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 18.200526ms)
Aug 27 08:21:14.902: INFO: (2) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 18.423594ms)
Aug 27 08:21:14.904: INFO: (2) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 20.764634ms)
Aug 27 08:21:14.904: INFO: (2) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 21.049737ms)
Aug 27 08:21:14.904: INFO: (2) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 20.554607ms)
Aug 27 08:21:14.904: INFO: (2) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 21.371435ms)
Aug 27 08:21:14.904: INFO: (2) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 21.290643ms)
Aug 27 08:21:14.904: INFO: (2) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 20.952272ms)
Aug 27 08:21:14.914: INFO: (3) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 9.835693ms)
Aug 27 08:21:14.918: INFO: (3) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 12.74149ms)
Aug 27 08:21:14.918: INFO: (3) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 12.237329ms)
Aug 27 08:21:14.919: INFO: (3) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 13.274199ms)
Aug 27 08:21:14.919: INFO: (3) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 13.629773ms)
Aug 27 08:21:14.919: INFO: (3) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 13.943887ms)
Aug 27 08:21:14.920: INFO: (3) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 14.076302ms)
Aug 27 08:21:14.920: INFO: (3) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 14.223153ms)
Aug 27 08:21:14.920: INFO: (3) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 14.746841ms)
Aug 27 08:21:14.920: INFO: (3) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 14.876768ms)
Aug 27 08:21:14.922: INFO: (3) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 17.067587ms)
Aug 27 08:21:14.922: INFO: (3) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 16.867282ms)
Aug 27 08:21:14.923: INFO: (3) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 17.784707ms)
Aug 27 08:21:14.923: INFO: (3) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 17.029235ms)
Aug 27 08:21:14.923: INFO: (3) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 17.85636ms)
Aug 27 08:21:14.924: INFO: (3) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 18.28015ms)
Aug 27 08:21:14.937: INFO: (4) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 12.980268ms)
Aug 27 08:21:14.940: INFO: (4) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 15.381017ms)
Aug 27 08:21:14.941: INFO: (4) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 15.965237ms)
Aug 27 08:21:14.941: INFO: (4) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 16.065954ms)
Aug 27 08:21:14.941: INFO: (4) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 16.39487ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 16.661133ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 17.30189ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 17.368802ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 17.447138ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 16.675239ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 16.997872ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 17.346217ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 17.651658ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 16.969185ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 17.423773ms)
Aug 27 08:21:14.942: INFO: (4) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 17.330563ms)
Aug 27 08:21:14.974: INFO: (5) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 29.300203ms)
Aug 27 08:21:14.974: INFO: (5) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 28.783913ms)
Aug 27 08:21:14.975: INFO: (5) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 30.469631ms)
Aug 27 08:21:14.976: INFO: (5) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 30.614148ms)
Aug 27 08:21:14.976: INFO: (5) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 31.239657ms)
Aug 27 08:21:14.977: INFO: (5) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 31.602296ms)
Aug 27 08:21:14.985: INFO: (5) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 39.837142ms)
Aug 27 08:21:14.986: INFO: (5) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 41.570004ms)
Aug 27 08:21:14.987: INFO: (5) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 42.111476ms)
Aug 27 08:21:14.987: INFO: (5) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 42.037036ms)
Aug 27 08:21:14.987: INFO: (5) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 42.014591ms)
Aug 27 08:21:14.987: INFO: (5) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 41.979195ms)
Aug 27 08:21:14.987: INFO: (5) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 42.586155ms)
Aug 27 08:21:14.988: INFO: (5) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 43.012778ms)
Aug 27 08:21:14.988: INFO: (5) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 43.449571ms)
Aug 27 08:21:14.988: INFO: (5) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 43.535681ms)
Aug 27 08:21:15.005: INFO: (6) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 16.220485ms)
Aug 27 08:21:15.005: INFO: (6) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 16.979981ms)
Aug 27 08:21:15.005: INFO: (6) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 16.967724ms)
Aug 27 08:21:15.005: INFO: (6) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 17.233879ms)
Aug 27 08:21:15.005: INFO: (6) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 17.276828ms)
Aug 27 08:21:15.005: INFO: (6) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 17.525011ms)
Aug 27 08:21:15.006: INFO: (6) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 16.995151ms)
Aug 27 08:21:15.006: INFO: (6) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 17.157786ms)
Aug 27 08:21:15.013: INFO: (6) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 24.944588ms)
Aug 27 08:21:15.014: INFO: (6) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 25.671864ms)
Aug 27 08:21:15.015: INFO: (6) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 26.282133ms)
Aug 27 08:21:15.015: INFO: (6) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 26.799488ms)
Aug 27 08:21:15.015: INFO: (6) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 26.960286ms)
Aug 27 08:21:15.016: INFO: (6) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 27.16595ms)
Aug 27 08:21:15.016: INFO: (6) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 27.317077ms)
Aug 27 08:21:15.016: INFO: (6) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 28.172157ms)
Aug 27 08:21:15.034: INFO: (7) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 16.619011ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 18.02412ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 17.910041ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 17.877711ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 18.075329ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 17.809976ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 18.93097ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 17.828234ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 17.585814ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 18.028009ms)
Aug 27 08:21:15.035: INFO: (7) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 17.696714ms)
Aug 27 08:21:15.039: INFO: (7) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 21.62734ms)
Aug 27 08:21:15.039: INFO: (7) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 20.921199ms)
Aug 27 08:21:15.039: INFO: (7) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 21.234287ms)
Aug 27 08:21:15.039: INFO: (7) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 21.168166ms)
Aug 27 08:21:15.039: INFO: (7) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 21.450932ms)
Aug 27 08:21:15.052: INFO: (8) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 13.053706ms)
Aug 27 08:21:15.052: INFO: (8) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 13.039116ms)
Aug 27 08:21:15.053: INFO: (8) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 13.09764ms)
Aug 27 08:21:15.053: INFO: (8) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 13.652356ms)
Aug 27 08:21:15.056: INFO: (8) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 16.502814ms)
Aug 27 08:21:15.056: INFO: (8) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 16.794883ms)
Aug 27 08:21:15.056: INFO: (8) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 16.351533ms)
Aug 27 08:21:15.056: INFO: (8) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 16.567515ms)
Aug 27 08:21:15.056: INFO: (8) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 16.656644ms)
Aug 27 08:21:15.057: INFO: (8) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 16.941711ms)
Aug 27 08:21:15.058: INFO: (8) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 18.843289ms)
Aug 27 08:21:15.059: INFO: (8) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 19.16321ms)
Aug 27 08:21:15.059: INFO: (8) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 19.435343ms)
Aug 27 08:21:15.059: INFO: (8) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 19.520898ms)
Aug 27 08:21:15.059: INFO: (8) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 19.373015ms)
Aug 27 08:21:15.060: INFO: (8) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 20.689637ms)
Aug 27 08:21:15.074: INFO: (9) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 14.238368ms)
Aug 27 08:21:15.075: INFO: (9) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 14.46059ms)
Aug 27 08:21:15.075: INFO: (9) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 14.987946ms)
Aug 27 08:21:15.075: INFO: (9) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 14.8487ms)
Aug 27 08:21:15.075: INFO: (9) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 14.822062ms)
Aug 27 08:21:15.075: INFO: (9) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 14.683321ms)
Aug 27 08:21:15.076: INFO: (9) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 15.25814ms)
Aug 27 08:21:15.076: INFO: (9) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 15.348348ms)
Aug 27 08:21:15.076: INFO: (9) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 15.475302ms)
Aug 27 08:21:15.077: INFO: (9) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 16.181055ms)
Aug 27 08:21:15.083: INFO: (9) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 22.609858ms)
Aug 27 08:21:15.084: INFO: (9) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 23.049445ms)
Aug 27 08:21:15.084: INFO: (9) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 22.863797ms)
Aug 27 08:21:15.084: INFO: (9) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 23.419194ms)
Aug 27 08:21:15.085: INFO: (9) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 23.988577ms)
Aug 27 08:21:15.085: INFO: (9) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 24.016307ms)
Aug 27 08:21:15.104: INFO: (10) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 19.615373ms)
Aug 27 08:21:15.104: INFO: (10) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 19.211629ms)
Aug 27 08:21:15.104: INFO: (10) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 18.99146ms)
Aug 27 08:21:15.104: INFO: (10) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 19.386694ms)
Aug 27 08:21:15.104: INFO: (10) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 19.544879ms)
Aug 27 08:21:15.104: INFO: (10) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 18.919966ms)
Aug 27 08:21:15.106: INFO: (10) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 21.041907ms)
Aug 27 08:21:15.106: INFO: (10) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 21.427947ms)
Aug 27 08:21:15.106: INFO: (10) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 21.557853ms)
Aug 27 08:21:15.106: INFO: (10) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 21.010469ms)
Aug 27 08:21:15.107: INFO: (10) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 21.957055ms)
Aug 27 08:21:15.107: INFO: (10) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 21.793109ms)
Aug 27 08:21:15.107: INFO: (10) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 22.097925ms)
Aug 27 08:21:15.107: INFO: (10) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 22.051541ms)
Aug 27 08:21:15.107: INFO: (10) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 22.480349ms)
Aug 27 08:21:15.107: INFO: (10) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 22.050158ms)
Aug 27 08:21:15.124: INFO: (11) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 16.250543ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 16.471179ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 17.161ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 17.051327ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 17.119708ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 17.383787ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 17.384731ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 17.315683ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 17.097007ms)
Aug 27 08:21:15.125: INFO: (11) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 17.189259ms)
Aug 27 08:21:15.131: INFO: (11) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 22.912238ms)
Aug 27 08:21:15.131: INFO: (11) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 22.825827ms)
Aug 27 08:21:15.131: INFO: (11) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 22.885602ms)
Aug 27 08:21:15.131: INFO: (11) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 23.572548ms)
Aug 27 08:21:15.131: INFO: (11) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 22.973576ms)
Aug 27 08:21:15.133: INFO: (11) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 25.455336ms)
Aug 27 08:21:15.147: INFO: (12) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 14.072436ms)
Aug 27 08:21:15.154: INFO: (12) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 19.78008ms)
Aug 27 08:21:15.173: INFO: (12) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 38.77273ms)
Aug 27 08:21:15.173: INFO: (12) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 38.866295ms)
Aug 27 08:21:15.174: INFO: (12) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 39.75902ms)
Aug 27 08:21:15.175: INFO: (12) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 41.022949ms)
Aug 27 08:21:15.177: INFO: (12) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 42.346682ms)
Aug 27 08:21:15.177: INFO: (12) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 42.33999ms)
Aug 27 08:21:15.177: INFO: (12) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 42.419914ms)
Aug 27 08:21:15.177: INFO: (12) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 43.004557ms)
Aug 27 08:21:15.177: INFO: (12) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 42.82405ms)
Aug 27 08:21:15.178: INFO: (12) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 43.446241ms)
Aug 27 08:21:15.178: INFO: (12) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 43.22582ms)
Aug 27 08:21:15.178: INFO: (12) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 43.326147ms)
Aug 27 08:21:15.179: INFO: (12) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 44.958907ms)
Aug 27 08:21:15.180: INFO: (12) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 45.644252ms)
Aug 27 08:21:15.198: INFO: (13) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 17.384281ms)
Aug 27 08:21:15.198: INFO: (13) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 17.969057ms)
Aug 27 08:21:15.198: INFO: (13) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 18.020821ms)
Aug 27 08:21:15.198: INFO: (13) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 18.297111ms)
Aug 27 08:21:15.199: INFO: (13) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 17.989427ms)
Aug 27 08:21:15.199: INFO: (13) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 18.140324ms)
Aug 27 08:21:15.199: INFO: (13) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 18.113276ms)
Aug 27 08:21:15.209: INFO: (13) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 27.066742ms)
Aug 27 08:21:15.210: INFO: (13) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 29.839849ms)
Aug 27 08:21:15.212: INFO: (13) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 30.724979ms)
Aug 27 08:21:15.212: INFO: (13) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 30.944409ms)
Aug 27 08:21:15.213: INFO: (13) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 30.895648ms)
Aug 27 08:21:15.213: INFO: (13) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 32.533858ms)
Aug 27 08:21:15.214: INFO: (13) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 33.285082ms)
Aug 27 08:21:15.216: INFO: (13) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 34.374749ms)
Aug 27 08:21:15.216: INFO: (13) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 33.897502ms)
Aug 27 08:21:15.230: INFO: (14) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 13.643769ms)
Aug 27 08:21:15.230: INFO: (14) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 13.810476ms)
Aug 27 08:21:15.246: INFO: (14) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 30.124228ms)
Aug 27 08:21:15.247: INFO: (14) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 30.473852ms)
Aug 27 08:21:15.247: INFO: (14) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 30.751999ms)
Aug 27 08:21:15.248: INFO: (14) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 30.279198ms)
Aug 27 08:21:15.248: INFO: (14) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 31.501361ms)
Aug 27 08:21:15.248: INFO: (14) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 31.155162ms)
Aug 27 08:21:15.248: INFO: (14) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 31.07555ms)
Aug 27 08:21:15.250: INFO: (14) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 32.913428ms)
Aug 27 08:21:15.251: INFO: (14) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 33.573099ms)
Aug 27 08:21:15.251: INFO: (14) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 33.435807ms)
Aug 27 08:21:15.251: INFO: (14) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 33.992429ms)
Aug 27 08:21:15.262: INFO: (14) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 45.115866ms)
Aug 27 08:21:15.262: INFO: (14) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 45.696754ms)
Aug 27 08:21:15.262: INFO: (14) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 45.549472ms)
Aug 27 08:21:15.283: INFO: (15) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 18.502528ms)
Aug 27 08:21:15.284: INFO: (15) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 21.548455ms)
Aug 27 08:21:15.292: INFO: (15) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 28.498894ms)
Aug 27 08:21:15.295: INFO: (15) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 32.352393ms)
Aug 27 08:21:15.295: INFO: (15) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 31.623403ms)
Aug 27 08:21:15.296: INFO: (15) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 31.71582ms)
Aug 27 08:21:15.296: INFO: (15) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 32.272382ms)
Aug 27 08:21:15.296: INFO: (15) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 32.317696ms)
Aug 27 08:21:15.296: INFO: (15) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 32.187023ms)
Aug 27 08:21:15.296: INFO: (15) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 32.51175ms)
Aug 27 08:21:15.300: INFO: (15) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 36.273772ms)
Aug 27 08:21:15.300: INFO: (15) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 37.028529ms)
Aug 27 08:21:15.301: INFO: (15) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 38.194811ms)
Aug 27 08:21:15.301: INFO: (15) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 37.199546ms)
Aug 27 08:21:15.301: INFO: (15) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 36.603507ms)
Aug 27 08:21:15.301: INFO: (15) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 36.712354ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 22.07264ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 21.931481ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 21.981233ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 21.808946ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 21.939412ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 22.413612ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 22.747901ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 22.808995ms)
Aug 27 08:21:15.324: INFO: (16) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 22.694149ms)
Aug 27 08:21:15.325: INFO: (16) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 22.613685ms)
Aug 27 08:21:15.325: INFO: (16) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 22.821544ms)
Aug 27 08:21:15.325: INFO: (16) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 22.413621ms)
Aug 27 08:21:15.325: INFO: (16) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 22.459392ms)
Aug 27 08:21:15.325: INFO: (16) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 23.317016ms)
Aug 27 08:21:15.325: INFO: (16) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 22.607688ms)
Aug 27 08:21:15.325: INFO: (16) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 22.665467ms)
Aug 27 08:21:15.337: INFO: (17) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 11.587666ms)
Aug 27 08:21:15.337: INFO: (17) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 12.233ms)
Aug 27 08:21:15.337: INFO: (17) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 12.558437ms)
Aug 27 08:21:15.338: INFO: (17) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 12.54638ms)
Aug 27 08:21:15.340: INFO: (17) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 15.242625ms)
Aug 27 08:21:15.341: INFO: (17) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 15.327254ms)
Aug 27 08:21:15.341: INFO: (17) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 15.762513ms)
Aug 27 08:21:15.341: INFO: (17) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 16.213603ms)
Aug 27 08:21:15.342: INFO: (17) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 16.459818ms)
Aug 27 08:21:15.342: INFO: (17) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 16.399446ms)
Aug 27 08:21:15.342: INFO: (17) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 16.735681ms)
Aug 27 08:21:15.342: INFO: (17) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 17.074142ms)
Aug 27 08:21:15.342: INFO: (17) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 17.027746ms)
Aug 27 08:21:15.343: INFO: (17) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 17.717479ms)
Aug 27 08:21:15.343: INFO: (17) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 17.774509ms)
Aug 27 08:21:15.343: INFO: (17) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 17.7068ms)
Aug 27 08:21:15.354: INFO: (18) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 10.607203ms)
Aug 27 08:21:15.354: INFO: (18) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 10.942804ms)
Aug 27 08:21:15.358: INFO: (18) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 13.582489ms)
Aug 27 08:21:15.358: INFO: (18) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 14.260551ms)
Aug 27 08:21:15.358: INFO: (18) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 14.496668ms)
Aug 27 08:21:15.359: INFO: (18) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 15.011995ms)
Aug 27 08:21:15.359: INFO: (18) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 15.476748ms)
Aug 27 08:21:15.359: INFO: (18) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 15.542946ms)
Aug 27 08:21:15.359: INFO: (18) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 15.873263ms)
Aug 27 08:21:15.360: INFO: (18) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 15.405823ms)
Aug 27 08:21:15.360: INFO: (18) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 16.13781ms)
Aug 27 08:21:15.360: INFO: (18) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 16.432262ms)
Aug 27 08:21:15.360: INFO: (18) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 16.336523ms)
Aug 27 08:21:15.361: INFO: (18) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 16.970106ms)
Aug 27 08:21:15.361: INFO: (18) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 16.923296ms)
Aug 27 08:21:15.361: INFO: (18) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 16.950993ms)
Aug 27 08:21:15.373: INFO: (19) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 11.921885ms)
Aug 27 08:21:15.374: INFO: (19) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">test<... (200; 12.597992ms)
Aug 27 08:21:15.375: INFO: (19) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:1080/proxy/rewriteme">... (200; 12.18107ms)
Aug 27 08:21:15.375: INFO: (19) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:460/proxy/: tls baz (200; 13.309921ms)
Aug 27 08:21:15.375: INFO: (19) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq/proxy/rewriteme">test</a> (200; 13.246406ms)
Aug 27 08:21:15.375: INFO: (19) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/: <a href="/api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:443/proxy/tlsrewritem... (200; 13.376089ms)
Aug 27 08:21:15.375: INFO: (19) /api/v1/namespaces/proxy-3153/pods/http:proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 12.47237ms)
Aug 27 08:21:15.377: INFO: (19) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:160/proxy/: foo (200; 15.259678ms)
Aug 27 08:21:15.377: INFO: (19) /api/v1/namespaces/proxy-3153/pods/proxy-service-mkfqw-cfqdq:162/proxy/: bar (200; 15.467875ms)
Aug 27 08:21:15.377: INFO: (19) /api/v1/namespaces/proxy-3153/pods/https:proxy-service-mkfqw-cfqdq:462/proxy/: tls qux (200; 15.411247ms)
Aug 27 08:21:15.378: INFO: (19) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname1/proxy/: tls baz (200; 16.287338ms)
Aug 27 08:21:15.378: INFO: (19) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname1/proxy/: foo (200; 16.104279ms)
Aug 27 08:21:15.378: INFO: (19) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname1/proxy/: foo (200; 16.167404ms)
Aug 27 08:21:15.378: INFO: (19) /api/v1/namespaces/proxy-3153/services/proxy-service-mkfqw:portname2/proxy/: bar (200; 16.428123ms)
Aug 27 08:21:15.378: INFO: (19) /api/v1/namespaces/proxy-3153/services/https:proxy-service-mkfqw:tlsportname2/proxy/: tls qux (200; 16.754405ms)
Aug 27 08:21:15.378: INFO: (19) /api/v1/namespaces/proxy-3153/services/http:proxy-service-mkfqw:portname2/proxy/: bar (200; 16.410685ms)
STEP: deleting ReplicationController proxy-service-mkfqw in namespace proxy-3153, will wait for the garbage collector to delete the pods
Aug 27 08:21:15.448: INFO: Deleting ReplicationController proxy-service-mkfqw took: 17.897943ms
Aug 27 08:21:15.954: INFO: Terminating ReplicationController proxy-service-mkfqw pods took: 506.001421ms
[AfterEach] version v1
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:21:18.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3153" for this suite.

• [SLOW TEST:8.400 seconds]
[sig-network] Proxy
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":303,"completed":27,"skipped":365,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:21:18.073: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name secret-test-428d208d-5b8d-4d5c-942e-0be09295449d
STEP: Creating a pod to test consume secrets
Aug 27 08:21:18.155: INFO: Waiting up to 5m0s for pod "pod-secrets-2e8e0c75-683f-4d5e-beda-0136e22e59ae" in namespace "secrets-1721" to be "Succeeded or Failed"
Aug 27 08:21:18.160: INFO: Pod "pod-secrets-2e8e0c75-683f-4d5e-beda-0136e22e59ae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.486704ms
Aug 27 08:21:20.166: INFO: Pod "pod-secrets-2e8e0c75-683f-4d5e-beda-0136e22e59ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010527567s
Aug 27 08:21:22.170: INFO: Pod "pod-secrets-2e8e0c75-683f-4d5e-beda-0136e22e59ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014783403s
STEP: Saw pod success
Aug 27 08:21:22.170: INFO: Pod "pod-secrets-2e8e0c75-683f-4d5e-beda-0136e22e59ae" satisfied condition "Succeeded or Failed"
Aug 27 08:21:22.172: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-secrets-2e8e0c75-683f-4d5e-beda-0136e22e59ae container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 08:21:22.206: INFO: Waiting for pod pod-secrets-2e8e0c75-683f-4d5e-beda-0136e22e59ae to disappear
Aug 27 08:21:22.210: INFO: Pod pod-secrets-2e8e0c75-683f-4d5e-beda-0136e22e59ae no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:21:22.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1721" for this suite.
STEP: Destroying namespace "secret-namespace-9439" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":303,"completed":28,"skipped":367,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:21:22.228: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 08:21:22.272: INFO: Waiting up to 5m0s for pod "downwardapi-volume-124bd941-a18e-462c-a28c-1c970712f070" in namespace "projected-472" to be "Succeeded or Failed"
Aug 27 08:21:22.275: INFO: Pod "downwardapi-volume-124bd941-a18e-462c-a28c-1c970712f070": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258769ms
Aug 27 08:21:24.278: INFO: Pod "downwardapi-volume-124bd941-a18e-462c-a28c-1c970712f070": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004934014s
STEP: Saw pod success
Aug 27 08:21:24.278: INFO: Pod "downwardapi-volume-124bd941-a18e-462c-a28c-1c970712f070" satisfied condition "Succeeded or Failed"
Aug 27 08:21:24.282: INFO: Trying to get logs from node ip-10-0-2-216 pod downwardapi-volume-124bd941-a18e-462c-a28c-1c970712f070 container client-container: <nil>
STEP: delete the pod
Aug 27 08:21:24.303: INFO: Waiting for pod downwardapi-volume-124bd941-a18e-462c-a28c-1c970712f070 to disappear
Aug 27 08:21:24.307: INFO: Pod downwardapi-volume-124bd941-a18e-462c-a28c-1c970712f070 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:21:24.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-472" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":303,"completed":29,"skipped":382,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:21:24.324: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should test the lifecycle of an Endpoint [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:21:24.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2821" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":303,"completed":30,"skipped":387,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:21:24.426: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:181
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 27 08:21:26.984: INFO: Successfully updated pod "pod-update-e385bd8e-2f9d-4f85-b2f3-3459528c4c34"
STEP: verifying the updated pod is in kubernetes
Aug 27 08:21:26.990: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:21:26.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5979" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":303,"completed":31,"skipped":393,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:21:27.016: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service in namespace services-5129
STEP: creating service affinity-clusterip in namespace services-5129
STEP: creating replication controller affinity-clusterip in namespace services-5129
I0827 08:21:27.088277      19 runners.go:190] Created replication controller with name: affinity-clusterip, namespace: services-5129, replica count: 3
I0827 08:21:30.140159      19 runners.go:190] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:21:33.140331      19 runners.go:190] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 08:21:33.145: INFO: Creating new exec pod
Aug 27 08:21:36.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-5129 execpod-affinity282j6 -- /bin/sh -x -c nc -zv -t -w 2 affinity-clusterip 80'
Aug 27 08:21:36.419: INFO: stderr: "+ nc -zv -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Aug 27 08:21:36.419: INFO: stdout: ""
Aug 27 08:21:36.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-5129 execpod-affinity282j6 -- /bin/sh -x -c nc -zv -t -w 2 10.3.137.224 80'
Aug 27 08:21:36.666: INFO: stderr: "+ nc -zv -t -w 2 10.3.137.224 80\nConnection to 10.3.137.224 80 port [tcp/http] succeeded!\n"
Aug 27 08:21:36.666: INFO: stdout: ""
Aug 27 08:21:36.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-5129 execpod-affinity282j6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.137.224:80/ ; done'
Aug 27 08:21:37.082: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.137.224:80/\n"
Aug 27 08:21:37.082: INFO: stdout: "\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27\naffinity-clusterip-zjq27"
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Received response from host: affinity-clusterip-zjq27
Aug 27 08:21:37.082: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-5129, will wait for the garbage collector to delete the pods
Aug 27 08:21:37.160: INFO: Deleting ReplicationController affinity-clusterip took: 8.148154ms
Aug 27 08:21:37.263: INFO: Terminating ReplicationController affinity-clusterip pods took: 102.605591ms
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:21:45.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5129" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:18.347 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":303,"completed":32,"skipped":426,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:21:45.362: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:103
STEP: Creating service test in namespace statefulset-8390
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating stateful set ss in namespace statefulset-8390
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8390
Aug 27 08:21:45.457: INFO: Found 0 stateful pods, waiting for 1
Aug 27 08:21:55.462: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 27 08:21:55.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-8390 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 08:21:55.718: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 08:21:55.718: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 08:21:55.718: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 08:21:55.733: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 27 08:22:05.773: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 08:22:05.773: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 08:22:05.846: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 27 08:22:05.846: INFO: ss-0  ip-10-0-2-216  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:45 +0000 UTC  }]
Aug 27 08:22:05.847: INFO: 
Aug 27 08:22:05.847: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 27 08:22:06.850: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.972468474s
Aug 27 08:22:07.855: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.968886194s
Aug 27 08:22:08.870: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962591267s
Aug 27 08:22:09.882: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.948772207s
Aug 27 08:22:10.894: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.937365789s
Aug 27 08:22:11.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.925158847s
Aug 27 08:22:12.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.919911215s
Aug 27 08:22:13.907: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.916516444s
Aug 27 08:22:14.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 907.909965ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8390
Aug 27 08:22:15.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-8390 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 08:22:16.137: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 08:22:16.137: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 08:22:16.137: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 08:22:16.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-8390 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 08:22:16.349: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 27 08:22:16.350: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 08:22:16.350: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 08:22:16.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-8390 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 08:22:16.565: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 27 08:22:16.565: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 08:22:16.565: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 08:22:16.569: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 27 08:22:26.580: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 08:22:26.580: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 08:22:26.580: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 27 08:22:26.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-8390 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 08:22:26.824: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 08:22:26.824: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 08:22:26.824: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 08:22:26.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-8390 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 08:22:27.301: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 08:22:27.301: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 08:22:27.301: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 08:22:27.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-8390 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 08:22:27.643: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 08:22:27.643: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 08:22:27.643: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 08:22:27.643: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 08:22:27.676: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 27 08:22:37.687: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 08:22:37.687: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 08:22:37.687: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 08:22:37.701: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 08:22:37.701: INFO: ss-0  ip-10-0-2-216   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:45 +0000 UTC  }]
Aug 27 08:22:37.702: INFO: ss-1  ip-10-0-45-43   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:05 +0000 UTC  }]
Aug 27 08:22:37.702: INFO: ss-2  ip-10-0-27-251  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  }]
Aug 27 08:22:37.702: INFO: 
Aug 27 08:22:37.702: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 27 08:22:38.706: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 08:22:38.706: INFO: ss-0  ip-10-0-2-216   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:45 +0000 UTC  }]
Aug 27 08:22:38.706: INFO: ss-1  ip-10-0-45-43   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:05 +0000 UTC  }]
Aug 27 08:22:38.706: INFO: ss-2  ip-10-0-27-251  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  }]
Aug 27 08:22:38.706: INFO: 
Aug 27 08:22:38.706: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 27 08:22:39.711: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 08:22:39.711: INFO: ss-0  ip-10-0-2-216   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:21:45 +0000 UTC  }]
Aug 27 08:22:39.711: INFO: ss-1  ip-10-0-45-43   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:05 +0000 UTC  }]
Aug 27 08:22:39.711: INFO: ss-2  ip-10-0-27-251  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  }]
Aug 27 08:22:39.711: INFO: 
Aug 27 08:22:39.711: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 27 08:22:40.716: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 08:22:40.716: INFO: ss-2  ip-10-0-27-251  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  }]
Aug 27 08:22:40.716: INFO: 
Aug 27 08:22:40.716: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 08:22:41.720: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 08:22:41.720: INFO: ss-2  ip-10-0-27-251  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  }]
Aug 27 08:22:41.720: INFO: 
Aug 27 08:22:41.720: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 08:22:42.725: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 08:22:42.725: INFO: ss-2  ip-10-0-27-251  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  }]
Aug 27 08:22:42.725: INFO: 
Aug 27 08:22:42.725: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 08:22:43.729: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 08:22:43.729: INFO: ss-2  ip-10-0-27-251  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  }]
Aug 27 08:22:43.729: INFO: 
Aug 27 08:22:43.729: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 08:22:44.733: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 08:22:44.733: INFO: ss-2  ip-10-0-27-251  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-27 08:22:06 +0000 UTC  }]
Aug 27 08:22:44.733: INFO: 
Aug 27 08:22:44.733: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 27 08:22:45.737: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.961486466s
Aug 27 08:22:46.740: INFO: Verifying statefulset ss doesn't scale past 0 for another 957.848871ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8390
Aug 27 08:22:47.743: INFO: Scaling statefulset ss to 0
Aug 27 08:22:47.751: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:114
Aug 27 08:22:47.753: INFO: Deleting all statefulset in ns statefulset-8390
Aug 27 08:22:47.755: INFO: Scaling statefulset ss to 0
Aug 27 08:22:47.766: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 08:22:47.774: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:22:47.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8390" for this suite.

• [SLOW TEST:62.458 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":303,"completed":33,"skipped":444,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:22:47.823: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating all guestbook components
Aug 27 08:22:47.864: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Aug 27 08:22:47.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-3693'
Aug 27 08:22:48.141: INFO: stderr: ""
Aug 27 08:22:48.141: INFO: stdout: "service/agnhost-replica created\n"
Aug 27 08:22:48.141: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Aug 27 08:22:48.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-3693'
Aug 27 08:22:48.626: INFO: stderr: ""
Aug 27 08:22:48.626: INFO: stdout: "service/agnhost-primary created\n"
Aug 27 08:22:48.626: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 27 08:22:48.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-3693'
Aug 27 08:22:48.957: INFO: stderr: ""
Aug 27 08:22:48.957: INFO: stdout: "service/frontend created\n"
Aug 27 08:22:48.957: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.20
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Aug 27 08:22:48.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-3693'
Aug 27 08:22:49.289: INFO: stderr: ""
Aug 27 08:22:49.289: INFO: stdout: "deployment.apps/frontend created\n"
Aug 27 08:22:49.289: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.20
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 27 08:22:49.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-3693'
Aug 27 08:22:49.501: INFO: stderr: ""
Aug 27 08:22:49.501: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Aug 27 08:22:49.501: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.20
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 27 08:22:49.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-3693'
Aug 27 08:22:49.690: INFO: stderr: ""
Aug 27 08:22:49.690: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Aug 27 08:22:49.690: INFO: Waiting for all frontend pods to be Running.
Aug 27 08:22:54.740: INFO: Waiting for frontend to serve content.
Aug 27 08:22:54.755: INFO: Trying to add a new entry to the guestbook.
Aug 27 08:22:54.778: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 27 08:22:54.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-3693'
Aug 27 08:22:54.938: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 08:22:54.938: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 08:22:54.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-3693'
Aug 27 08:22:55.227: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 08:22:55.227: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 08:22:55.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-3693'
Aug 27 08:22:55.449: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 08:22:55.449: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 08:22:55.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-3693'
Aug 27 08:22:55.633: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 08:22:55.633: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 08:22:55.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-3693'
Aug 27 08:22:55.806: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 08:22:55.806: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Aug 27 08:22:55.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-3693'
Aug 27 08:22:55.986: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 08:22:55.986: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:22:55.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3693" for this suite.

• [SLOW TEST:8.178 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:351
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":303,"completed":34,"skipped":448,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:22:56.001: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-upd-ef708003-2ab6-497e-b9c9-ef4732c5e399
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:22:58.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7955" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":303,"completed":35,"skipped":458,"failed":0}

------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:22:58.190: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 27 08:22:58.224: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 08:22:58.229: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 08:22:58.232: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-2-216 before test
Aug 27 08:22:58.237: INFO: calico-node-87ksr from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.237: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 08:22:58.237: INFO: coredns-69c75f5c45-9jz8t from kube-system started at 2020-08-27 08:09:33 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.237: INFO: 	Container coredns ready: true, restart count 0
Aug 27 08:22:58.237: INFO: kube-proxy-zlwf6 from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.237: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 08:22:58.237: INFO: frontend-58d458fdbd-8rmph from kubectl-3693 started at 2020-08-27 08:22:49 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.237: INFO: 	Container guestbook-frontend ready: false, restart count 0
Aug 27 08:22:58.237: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-mjhxq from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 08:22:58.237: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 08:22:58.237: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 08:22:58.237: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-27-251 before test
Aug 27 08:22:58.245: INFO: calico-node-8g49c from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.246: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 08:22:58.246: INFO: kube-proxy-zq947 from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.246: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 08:22:58.246: INFO: agnhost-replica-7d6489798-r64pb from kubectl-3693 started at 2020-08-27 08:22:49 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.246: INFO: 	Container replica ready: false, restart count 0
Aug 27 08:22:58.247: INFO: sonobuoy-e2e-job-3e3f44f310e74605 from sonobuoy started at 2020-08-27 08:10:16 +0000 UTC (2 container statuses recorded)
Aug 27 08:22:58.247: INFO: 	Container e2e ready: true, restart count 0
Aug 27 08:22:58.247: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 08:22:58.247: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-96j2z from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 08:22:58.247: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 08:22:58.247: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 08:22:58.247: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-45-43 before test
Aug 27 08:22:58.253: INFO: pod-configmaps-15756c56-f029-4ccb-b8bc-f1369a2fc62f from configmap-7955 started at 2020-08-27 08:22:56 +0000 UTC (2 container statuses recorded)
Aug 27 08:22:58.253: INFO: 	Container configmap-volume-binary-test ready: true, restart count 0
Aug 27 08:22:58.253: INFO: 	Container configmap-volume-data-test ready: true, restart count 0
Aug 27 08:22:58.254: INFO: calico-node-fj4mf from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.254: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 08:22:58.254: INFO: kube-proxy-9v45m from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.254: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 08:22:58.254: INFO: agnhost-primary-76f75c9b74-k2dj6 from kubectl-3693 started at 2020-08-27 08:22:49 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.254: INFO: 	Container primary ready: false, restart count 0
Aug 27 08:22:58.254: INFO: frontend-58d458fdbd-mhbjl from kubectl-3693 started at 2020-08-27 08:22:49 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.255: INFO: 	Container guestbook-frontend ready: false, restart count 0
Aug 27 08:22:58.255: INFO: sonobuoy from sonobuoy started at 2020-08-27 08:10:12 +0000 UTC (1 container statuses recorded)
Aug 27 08:22:58.255: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 08:22:58.255: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-6xtvp from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 08:22:58.255: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 08:22:58.255: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-12f4ba3f-11af-44d2-9f0f-9c860f45b16a 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-12f4ba3f-11af-44d2-9f0f-9c860f45b16a off the node ip-10-0-2-216
STEP: verifying the node doesn't have the label kubernetes.io/e2e-12f4ba3f-11af-44d2-9f0f-9c860f45b16a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:28:04.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5045" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:306.230 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":303,"completed":36,"skipped":458,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:28:04.422: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod busybox-eb17b63f-0488-4ad1-8fbd-3fc29129c270 in namespace container-probe-1782
Aug 27 08:28:06.625: INFO: Started pod busybox-eb17b63f-0488-4ad1-8fbd-3fc29129c270 in namespace container-probe-1782
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 08:28:06.628: INFO: Initial restart count of pod busybox-eb17b63f-0488-4ad1-8fbd-3fc29129c270 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:32:07.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1782" for this suite.

• [SLOW TEST:243.043 seconds]
[k8s.io] Probing container
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":303,"completed":37,"skipped":473,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:32:07.468: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-volume-map-81371d1e-55fe-44db-a989-9c1ef16f7641
STEP: Creating a pod to test consume configMaps
Aug 27 08:32:07.521: INFO: Waiting up to 5m0s for pod "pod-configmaps-a1ebdfe0-2fb7-45db-a441-e64f7a4c347c" in namespace "configmap-6761" to be "Succeeded or Failed"
Aug 27 08:32:07.524: INFO: Pod "pod-configmaps-a1ebdfe0-2fb7-45db-a441-e64f7a4c347c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.551451ms
Aug 27 08:32:09.527: INFO: Pod "pod-configmaps-a1ebdfe0-2fb7-45db-a441-e64f7a4c347c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006138298s
STEP: Saw pod success
Aug 27 08:32:09.528: INFO: Pod "pod-configmaps-a1ebdfe0-2fb7-45db-a441-e64f7a4c347c" satisfied condition "Succeeded or Failed"
Aug 27 08:32:09.530: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-a1ebdfe0-2fb7-45db-a441-e64f7a4c347c container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 08:32:09.557: INFO: Waiting for pod pod-configmaps-a1ebdfe0-2fb7-45db-a441-e64f7a4c347c to disappear
Aug 27 08:32:09.568: INFO: Pod pod-configmaps-a1ebdfe0-2fb7-45db-a441-e64f7a4c347c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:32:09.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6761" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":303,"completed":38,"skipped":479,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:32:09.579: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name projected-configmap-test-volume-93ac79bc-f92b-47d4-a7fb-a50ad995e4b0
STEP: Creating a pod to test consume configMaps
Aug 27 08:32:09.631: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-41ba070f-7af1-497e-aa11-51e626503f70" in namespace "projected-5573" to be "Succeeded or Failed"
Aug 27 08:32:09.636: INFO: Pod "pod-projected-configmaps-41ba070f-7af1-497e-aa11-51e626503f70": Phase="Pending", Reason="", readiness=false. Elapsed: 4.349717ms
Aug 27 08:32:11.640: INFO: Pod "pod-projected-configmaps-41ba070f-7af1-497e-aa11-51e626503f70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00826609s
Aug 27 08:32:13.643: INFO: Pod "pod-projected-configmaps-41ba070f-7af1-497e-aa11-51e626503f70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01132993s
STEP: Saw pod success
Aug 27 08:32:13.644: INFO: Pod "pod-projected-configmaps-41ba070f-7af1-497e-aa11-51e626503f70" satisfied condition "Succeeded or Failed"
Aug 27 08:32:13.647: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-configmaps-41ba070f-7af1-497e-aa11-51e626503f70 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 08:32:13.668: INFO: Waiting for pod pod-projected-configmaps-41ba070f-7af1-497e-aa11-51e626503f70 to disappear
Aug 27 08:32:13.675: INFO: Pod pod-projected-configmaps-41ba070f-7af1-497e-aa11-51e626503f70 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:32:13.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5573" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":303,"completed":39,"skipped":488,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:32:13.704: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:32:24.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5425" for this suite.

• [SLOW TEST:11.174 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":303,"completed":40,"skipped":501,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:32:24.878: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:32:24.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8972" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":303,"completed":41,"skipped":506,"failed":0}
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:32:24.923: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Performing setup for networking test in namespace pod-network-test-6178
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 27 08:32:24.962: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 27 08:32:25.112: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 08:32:27.130: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:32:29.120: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:32:31.117: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:32:33.117: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:32:35.118: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:32:37.118: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:32:39.118: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:32:41.121: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug 27 08:32:41.129: INFO: The status of Pod netserver-1 is Running (Ready = true)
Aug 27 08:32:41.135: INFO: The status of Pod netserver-2 is Running (Ready = false)
Aug 27 08:32:43.138: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Aug 27 08:32:47.168: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.173.37:8080/dial?request=hostname&protocol=udp&host=10.2.173.36&port=8081&tries=1'] Namespace:pod-network-test-6178 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:32:47.168: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:32:47.329: INFO: Waiting for responses: map[]
Aug 27 08:32:47.333: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.173.37:8080/dial?request=hostname&protocol=udp&host=10.2.148.8&port=8081&tries=1'] Namespace:pod-network-test-6178 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:32:47.334: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:32:47.464: INFO: Waiting for responses: map[]
Aug 27 08:32:47.467: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.173.37:8080/dial?request=hostname&protocol=udp&host=10.2.193.15&port=8081&tries=1'] Namespace:pod-network-test-6178 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:32:47.468: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:32:47.578: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:32:47.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6178" for this suite.

• [SLOW TEST:22.666 seconds]
[sig-network] Networking
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":303,"completed":42,"skipped":507,"failed":0}
SSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:32:47.593: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:32:55.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8481" for this suite.

• [SLOW TEST:8.056 seconds]
[sig-apps] Job
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":303,"completed":43,"skipped":512,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:32:55.650: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug 27 08:32:56.858: INFO: starting watch
STEP: patching
STEP: updating
Aug 27 08:32:56.868: INFO: waiting for watch events with expected annotations
Aug 27 08:32:56.868: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:32:56.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-8981" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":303,"completed":44,"skipped":530,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:32:56.964: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 27 08:33:01.585: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-585 pod-service-account-acc6516b-94b4-4587-9ceb-366de7f12d37 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 27 08:33:02.222: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-585 pod-service-account-acc6516b-94b4-4587-9ceb-366de7f12d37 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 27 08:33:02.432: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-585 pod-service-account-acc6516b-94b4-4587-9ceb-366de7f12d37 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:02.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-585" for this suite.

• [SLOW TEST:5.881 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":303,"completed":45,"skipped":558,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:02.847: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:181
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:33:02.900: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:07.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3338" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":303,"completed":46,"skipped":582,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:07.040: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0827 08:33:17.388899      19 metrics_grabber.go:105] Did not receive an external client interface. Grabbing metrics from ClusterAutoscaler is disabled.
Aug 27 08:33:19.477: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 27 08:33:19.481: INFO: Deleting pod "simpletest-rc-to-be-deleted-4k7q5" in namespace "gc-676"
Aug 27 08:33:19.507: INFO: Deleting pod "simpletest-rc-to-be-deleted-59h24" in namespace "gc-676"
Aug 27 08:33:19.535: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rvkm" in namespace "gc-676"
Aug 27 08:33:19.686: INFO: Deleting pod "simpletest-rc-to-be-deleted-hj6zz" in namespace "gc-676"
Aug 27 08:33:19.729: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjg8c" in namespace "gc-676"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:19.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-676" for this suite.

• [SLOW TEST:12.782 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":303,"completed":47,"skipped":640,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:19.825: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:162
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
Aug 27 08:33:19.910: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:23.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7848" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":303,"completed":48,"skipped":699,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:23.318: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: validating cluster-info
Aug 27 08:33:23.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 cluster-info'
Aug 27 08:33:23.468: INFO: stderr: ""
Aug 27 08:33:23.468: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:23.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6814" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":303,"completed":49,"skipped":719,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:23.475: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug 27 08:33:25.530: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-4348 PodName:pod-sharedvolume-d4392c50-eef1-4f82-9f38-0d3290b3d4e1 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:33:25.530: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:33:25.647: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:25.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4348" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":303,"completed":50,"skipped":737,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:25.661: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 27 08:33:25.709: INFO: Waiting up to 5m0s for pod "pod-cd5482cf-b69d-4e01-a237-0fc7fd926db1" in namespace "emptydir-6325" to be "Succeeded or Failed"
Aug 27 08:33:25.713: INFO: Pod "pod-cd5482cf-b69d-4e01-a237-0fc7fd926db1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.52172ms
Aug 27 08:33:27.717: INFO: Pod "pod-cd5482cf-b69d-4e01-a237-0fc7fd926db1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007749725s
STEP: Saw pod success
Aug 27 08:33:27.717: INFO: Pod "pod-cd5482cf-b69d-4e01-a237-0fc7fd926db1" satisfied condition "Succeeded or Failed"
Aug 27 08:33:27.720: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-cd5482cf-b69d-4e01-a237-0fc7fd926db1 container test-container: <nil>
STEP: delete the pod
Aug 27 08:33:27.755: INFO: Waiting for pod pod-cd5482cf-b69d-4e01-a237-0fc7fd926db1 to disappear
Aug 27 08:33:27.764: INFO: Pod pod-cd5482cf-b69d-4e01-a237-0fc7fd926db1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:27.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6325" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":51,"skipped":746,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] server version
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:27.776: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
[It] should find the server version [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Request ServerVersion
STEP: Confirm major version
Aug 27 08:33:27.820: INFO: Major version: 1
STEP: Confirm minor version
Aug 27 08:33:27.820: INFO: cleanMinorVersion: 19
Aug 27 08:33:27.820: INFO: Minor version: 19
[AfterEach] [sig-api-machinery] server version
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:27.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-5384" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":303,"completed":52,"skipped":784,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:27.838: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:27.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3329" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":303,"completed":53,"skipped":864,"failed":0}
SS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:27.917: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:27.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7276" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":303,"completed":54,"skipped":866,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:27.983: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:33:28.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 version'
Aug 27 08:33:28.165: INFO: stderr: ""
Aug 27 08:33:28.165: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"19\", GitVersion:\"v1.19.0\", GitCommit:\"e19964183377d0ec2052d1f1fa930c4d7575bd50\", GitTreeState:\"clean\", BuildDate:\"2020-08-26T14:30:33Z\", GoVersion:\"go1.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"19\", GitVersion:\"v1.19.0\", GitCommit:\"e19964183377d0ec2052d1f1fa930c4d7575bd50\", GitTreeState:\"clean\", BuildDate:\"2020-08-26T14:23:04Z\", GoVersion:\"go1.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:28.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3870" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":303,"completed":55,"skipped":867,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:28.172: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 08:33:28.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99974df9-a2c9-4a91-b93e-d8b0cc3b09cc" in namespace "projected-2921" to be "Succeeded or Failed"
Aug 27 08:33:28.213: INFO: Pod "downwardapi-volume-99974df9-a2c9-4a91-b93e-d8b0cc3b09cc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.828255ms
Aug 27 08:33:30.263: INFO: Pod "downwardapi-volume-99974df9-a2c9-4a91-b93e-d8b0cc3b09cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053571158s
STEP: Saw pod success
Aug 27 08:33:30.263: INFO: Pod "downwardapi-volume-99974df9-a2c9-4a91-b93e-d8b0cc3b09cc" satisfied condition "Succeeded or Failed"
Aug 27 08:33:30.289: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-99974df9-a2c9-4a91-b93e-d8b0cc3b09cc container client-container: <nil>
STEP: delete the pod
Aug 27 08:33:30.611: INFO: Waiting for pod downwardapi-volume-99974df9-a2c9-4a91-b93e-d8b0cc3b09cc to disappear
Aug 27 08:33:30.675: INFO: Pod downwardapi-volume-99974df9-a2c9-4a91-b93e-d8b0cc3b09cc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:30.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2921" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":56,"skipped":879,"failed":0}
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:30.849: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:162
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
Aug 27 08:33:31.139: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:35.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8876" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":303,"completed":57,"skipped":880,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:35.486: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating projection with secret that has name projected-secret-test-map-e9f7ea45-9e9d-4e37-8984-071eaf6bbe8c
STEP: Creating a pod to test consume secrets
Aug 27 08:33:35.662: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ee8ec704-5242-4c30-b8b8-d481baffe9e5" in namespace "projected-9478" to be "Succeeded or Failed"
Aug 27 08:33:35.668: INFO: Pod "pod-projected-secrets-ee8ec704-5242-4c30-b8b8-d481baffe9e5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.98487ms
Aug 27 08:33:37.671: INFO: Pod "pod-projected-secrets-ee8ec704-5242-4c30-b8b8-d481baffe9e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009054308s
Aug 27 08:33:39.675: INFO: Pod "pod-projected-secrets-ee8ec704-5242-4c30-b8b8-d481baffe9e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012488312s
STEP: Saw pod success
Aug 27 08:33:39.675: INFO: Pod "pod-projected-secrets-ee8ec704-5242-4c30-b8b8-d481baffe9e5" satisfied condition "Succeeded or Failed"
Aug 27 08:33:39.678: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-secrets-ee8ec704-5242-4c30-b8b8-d481baffe9e5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 08:33:39.714: INFO: Waiting for pod pod-projected-secrets-ee8ec704-5242-4c30-b8b8-d481baffe9e5 to disappear
Aug 27 08:33:39.719: INFO: Pod pod-projected-secrets-ee8ec704-5242-4c30-b8b8-d481baffe9e5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:39.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9478" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":58,"skipped":882,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:39.732: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name s-test-opt-del-570606bf-781d-4c7f-9ce1-6dd2bf595ee9
STEP: Creating secret with name s-test-opt-upd-fadf095c-95e4-4331-a959-23924207d4fb
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-570606bf-781d-4c7f-9ce1-6dd2bf595ee9
STEP: Updating secret s-test-opt-upd-fadf095c-95e4-4331-a959-23924207d4fb
STEP: Creating secret with name s-test-opt-create-27df72f2-f0e0-4e9a-9222-2e9126be7758
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:43.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2906" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":303,"completed":59,"skipped":895,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:43.862: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 27 08:33:43.904: INFO: Waiting up to 5m0s for pod "pod-5bb2ff4c-f067-46f1-bd7d-b7384659266c" in namespace "emptydir-3233" to be "Succeeded or Failed"
Aug 27 08:33:43.911: INFO: Pod "pod-5bb2ff4c-f067-46f1-bd7d-b7384659266c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.347184ms
Aug 27 08:33:45.920: INFO: Pod "pod-5bb2ff4c-f067-46f1-bd7d-b7384659266c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015841818s
STEP: Saw pod success
Aug 27 08:33:45.925: INFO: Pod "pod-5bb2ff4c-f067-46f1-bd7d-b7384659266c" satisfied condition "Succeeded or Failed"
Aug 27 08:33:45.933: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-5bb2ff4c-f067-46f1-bd7d-b7384659266c container test-container: <nil>
STEP: delete the pod
Aug 27 08:33:45.966: INFO: Waiting for pod pod-5bb2ff4c-f067-46f1-bd7d-b7384659266c to disappear
Aug 27 08:33:45.975: INFO: Pod pod-5bb2ff4c-f067-46f1-bd7d-b7384659266c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:33:45.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3233" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":60,"skipped":897,"failed":0}

------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:33:46.022: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod liveness-a7128b75-3125-4214-8ea7-4785bccb7469 in namespace container-probe-9249
Aug 27 08:33:50.085: INFO: Started pod liveness-a7128b75-3125-4214-8ea7-4785bccb7469 in namespace container-probe-9249
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 08:33:50.087: INFO: Initial restart count of pod liveness-a7128b75-3125-4214-8ea7-4785bccb7469 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:37:50.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9249" for this suite.

• [SLOW TEST:244.922 seconds]
[k8s.io] Probing container
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":303,"completed":61,"skipped":897,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:37:50.945: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name cm-test-opt-del-308e2122-58b3-4f89-a6c0-84a54e540d12
STEP: Creating configMap with name cm-test-opt-upd-30111f10-180c-4403-b4cc-e281c5804719
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-308e2122-58b3-4f89-a6c0-84a54e540d12
STEP: Updating configmap cm-test-opt-upd-30111f10-180c-4403-b4cc-e281c5804719
STEP: Creating configMap with name cm-test-opt-create-9a9d0f2c-58f4-461c-aed8-66f17a2f6d98
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:39:23.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2845" for this suite.

• [SLOW TEST:92.694 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":303,"completed":62,"skipped":921,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:39:23.639: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:39:54.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3638" for this suite.
STEP: Destroying namespace "nsdeletetest-5693" for this suite.
Aug 27 08:39:54.772: INFO: Namespace nsdeletetest-5693 was already deleted
STEP: Destroying namespace "nsdeletetest-7013" for this suite.

• [SLOW TEST:31.136 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":303,"completed":63,"skipped":926,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:39:54.783: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 27 08:39:58.862: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 08:39:58.865: INFO: Pod pod-with-prestop-http-hook still exists
Aug 27 08:40:00.865: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 08:40:00.871: INFO: Pod pod-with-prestop-http-hook still exists
Aug 27 08:40:02.865: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 08:40:02.896: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:40:02.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5159" for this suite.

• [SLOW TEST:8.237 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  when create a pod with lifecycle hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":303,"completed":64,"skipped":954,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:40:03.022: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:40:03.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8700" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":303,"completed":65,"skipped":968,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:40:03.619: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name secret-test-364397cd-1b6b-44e0-a73c-d329ff4f1f35
STEP: Creating a pod to test consume secrets
Aug 27 08:40:03.688: INFO: Waiting up to 5m0s for pod "pod-secrets-f31c339e-9c3e-4dcb-abd4-3d9a3d66e604" in namespace "secrets-6949" to be "Succeeded or Failed"
Aug 27 08:40:03.693: INFO: Pod "pod-secrets-f31c339e-9c3e-4dcb-abd4-3d9a3d66e604": Phase="Pending", Reason="", readiness=false. Elapsed: 3.541756ms
Aug 27 08:40:05.697: INFO: Pod "pod-secrets-f31c339e-9c3e-4dcb-abd4-3d9a3d66e604": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008137777s
STEP: Saw pod success
Aug 27 08:40:05.697: INFO: Pod "pod-secrets-f31c339e-9c3e-4dcb-abd4-3d9a3d66e604" satisfied condition "Succeeded or Failed"
Aug 27 08:40:05.700: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-secrets-f31c339e-9c3e-4dcb-abd4-3d9a3d66e604 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 08:40:05.757: INFO: Waiting for pod pod-secrets-f31c339e-9c3e-4dcb-abd4-3d9a3d66e604 to disappear
Aug 27 08:40:05.765: INFO: Pod pod-secrets-f31c339e-9c3e-4dcb-abd4-3d9a3d66e604 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:40:05.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6949" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":303,"completed":66,"skipped":973,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:40:05.783: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:40:05.853: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Creating first CR 
Aug 27 08:40:06.431: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-27T08:40:06Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-08-27T08:40:06Z]] name:name1 resourceVersion:9032 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:08861efc-dbec-425e-a4b2-ceda6bfd65be] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Aug 27 08:40:16.438: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-27T08:40:16Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-08-27T08:40:16Z]] name:name2 resourceVersion:9094 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:974f2685-344d-4f87-aeb1-31b6326947e4] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Aug 27 08:40:26.446: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-27T08:40:06Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-08-27T08:40:26Z]] name:name1 resourceVersion:9120 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:08861efc-dbec-425e-a4b2-ceda6bfd65be] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Aug 27 08:40:36.452: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-27T08:40:16Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-08-27T08:40:36Z]] name:name2 resourceVersion:9147 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:974f2685-344d-4f87-aeb1-31b6326947e4] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Aug 27 08:40:46.459: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-27T08:40:06Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-08-27T08:40:26Z]] name:name1 resourceVersion:9173 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:08861efc-dbec-425e-a4b2-ceda6bfd65be] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Aug 27 08:40:56.472: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-27T08:40:16Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-08-27T08:40:36Z]] name:name2 resourceVersion:9200 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:974f2685-344d-4f87-aeb1-31b6326947e4] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:41:07.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4299" for this suite.

• [SLOW TEST:61.515 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":303,"completed":67,"skipped":983,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:41:07.302: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name projected-configmap-test-volume-03d6279b-97a4-4175-b084-abe850b0a308
STEP: Creating a pod to test consume configMaps
Aug 27 08:41:07.924: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d19655d0-f048-4a7f-9736-f7db4eb936d7" in namespace "projected-2066" to be "Succeeded or Failed"
Aug 27 08:41:07.928: INFO: Pod "pod-projected-configmaps-d19655d0-f048-4a7f-9736-f7db4eb936d7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.415236ms
Aug 27 08:41:09.931: INFO: Pod "pod-projected-configmaps-d19655d0-f048-4a7f-9736-f7db4eb936d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006590737s
STEP: Saw pod success
Aug 27 08:41:09.932: INFO: Pod "pod-projected-configmaps-d19655d0-f048-4a7f-9736-f7db4eb936d7" satisfied condition "Succeeded or Failed"
Aug 27 08:41:09.935: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-configmaps-d19655d0-f048-4a7f-9736-f7db4eb936d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 08:41:10.041: INFO: Waiting for pod pod-projected-configmaps-d19655d0-f048-4a7f-9736-f7db4eb936d7 to disappear
Aug 27 08:41:10.047: INFO: Pod pod-projected-configmaps-d19655d0-f048-4a7f-9736-f7db4eb936d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:41:10.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2066" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":303,"completed":68,"skipped":984,"failed":0}
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:41:10.064: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:41:32.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5578" for this suite.

• [SLOW TEST:22.366 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  blackbox test
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
    when starting a container that exits
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:42
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":303,"completed":69,"skipped":988,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:41:32.437: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 08:41:32.909: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 08:41:35.927: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:41:35.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9278" for this suite.
STEP: Destroying namespace "webhook-9278-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":303,"completed":70,"skipped":1008,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:41:36.121: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Performing setup for networking test in namespace pod-network-test-5457
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 27 08:41:36.192: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 27 08:41:36.250: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 08:41:38.267: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 08:41:40.256: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:41:42.254: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:41:44.255: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:41:46.253: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:41:48.260: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:41:50.255: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:41:52.253: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:41:54.264: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 08:41:56.254: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug 27 08:41:56.259: INFO: The status of Pod netserver-1 is Running (Ready = true)
Aug 27 08:41:56.263: INFO: The status of Pod netserver-2 is Running (Ready = false)
Aug 27 08:41:58.266: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Aug 27 08:42:00.288: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.173.58:8080/dial?request=hostname&protocol=http&host=10.2.173.57&port=8080&tries=1'] Namespace:pod-network-test-5457 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:42:00.289: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:42:00.426: INFO: Waiting for responses: map[]
Aug 27 08:42:00.430: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.173.58:8080/dial?request=hostname&protocol=http&host=10.2.148.14&port=8080&tries=1'] Namespace:pod-network-test-5457 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:42:00.431: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:42:00.555: INFO: Waiting for responses: map[]
Aug 27 08:42:00.568: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.173.58:8080/dial?request=hostname&protocol=http&host=10.2.193.29&port=8080&tries=1'] Namespace:pod-network-test-5457 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:42:00.568: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:42:00.721: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:42:00.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5457" for this suite.

• [SLOW TEST:24.608 seconds]
[sig-network] Networking
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":303,"completed":71,"skipped":1023,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:42:00.731: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:42:00.787: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-1ed3c8c1-16ae-4479-96c2-fdc53789cbf4" in namespace "security-context-test-8098" to be "Succeeded or Failed"
Aug 27 08:42:00.791: INFO: Pod "alpine-nnp-false-1ed3c8c1-16ae-4479-96c2-fdc53789cbf4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.58076ms
Aug 27 08:42:02.795: INFO: Pod "alpine-nnp-false-1ed3c8c1-16ae-4479-96c2-fdc53789cbf4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007871333s
Aug 27 08:42:04.799: INFO: Pod "alpine-nnp-false-1ed3c8c1-16ae-4479-96c2-fdc53789cbf4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012211743s
Aug 27 08:42:06.847: INFO: Pod "alpine-nnp-false-1ed3c8c1-16ae-4479-96c2-fdc53789cbf4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.06033667s
Aug 27 08:42:06.847: INFO: Pod "alpine-nnp-false-1ed3c8c1-16ae-4479-96c2-fdc53789cbf4" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:42:06.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8098" for this suite.

• [SLOW TEST:6.275 seconds]
[k8s.io] Security Context
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:291
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":72,"skipped":1032,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:42:07.008: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 08:42:07.740: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 08:42:09.760: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114527, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114527, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114527, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114527, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 08:42:12.782: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:42:14.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9947" for this suite.
STEP: Destroying namespace "webhook-9947-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.189 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":303,"completed":73,"skipped":1064,"failed":0}
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:42:14.203: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 27 08:42:16.267: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:42:16.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9473" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":303,"completed":74,"skipped":1064,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:42:16.316: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 27 08:42:16.364: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-a 81bf5b38-9f0b-46b6-9e5f-bbb36fbc31cd 9834 0 2020-08-27 08:42:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:42:16.365: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-a 81bf5b38-9f0b-46b6-9e5f-bbb36fbc31cd 9834 0 2020-08-27 08:42:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 27 08:42:26.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-a 81bf5b38-9f0b-46b6-9e5f-bbb36fbc31cd 9886 0 2020-08-27 08:42:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:42:26.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-a 81bf5b38-9f0b-46b6-9e5f-bbb36fbc31cd 9886 0 2020-08-27 08:42:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 27 08:42:36.380: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-a 81bf5b38-9f0b-46b6-9e5f-bbb36fbc31cd 9912 0 2020-08-27 08:42:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:42:36.380: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-a 81bf5b38-9f0b-46b6-9e5f-bbb36fbc31cd 9912 0 2020-08-27 08:42:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 27 08:42:46.386: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-a 81bf5b38-9f0b-46b6-9e5f-bbb36fbc31cd 9939 0 2020-08-27 08:42:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:42:46.386: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-a 81bf5b38-9f0b-46b6-9e5f-bbb36fbc31cd 9939 0 2020-08-27 08:42:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 27 08:42:56.393: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-b 09088ffd-311b-42dc-a41c-179091c873fa 9965 0 2020-08-27 08:42:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:42:56.394: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-b 09088ffd-311b-42dc-a41c-179091c873fa 9965 0 2020-08-27 08:42:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 27 08:43:06.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-b 09088ffd-311b-42dc-a41c-179091c873fa 9991 0 2020-08-27 08:42:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:43:06.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5819 /api/v1/namespaces/watch-5819/configmaps/e2e-watch-test-configmap-b 09088ffd-311b-42dc-a41c-179091c873fa 9991 0 2020-08-27 08:42:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-08-27 08:42:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:43:16.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5819" for this suite.

• [SLOW TEST:60.094 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":303,"completed":75,"skipped":1072,"failed":0}
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:43:16.410: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:43:16.453: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: creating replication controller svc-latency-rc in namespace svc-latency-57
I0827 08:43:16.466333      19 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-57, replica count: 1
I0827 08:43:17.517036      19 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:43:18.517421      19 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:43:19.517563      19 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:43:20.517709      19 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 08:43:20.628: INFO: Created: latency-svc-tf69x
Aug 27 08:43:20.636: INFO: Got endpoints: latency-svc-tf69x [18.38048ms]
Aug 27 08:43:20.660: INFO: Created: latency-svc-5d7rl
Aug 27 08:43:20.660: INFO: Created: latency-svc-x5lgt
Aug 27 08:43:20.664: INFO: Got endpoints: latency-svc-5d7rl [27.901393ms]
Aug 27 08:43:20.665: INFO: Created: latency-svc-jvd9f
Aug 27 08:43:20.675: INFO: Created: latency-svc-6fg96
Aug 27 08:43:20.675: INFO: Got endpoints: latency-svc-x5lgt [39.007964ms]
Aug 27 08:43:20.738: INFO: Created: latency-svc-57j7b
Aug 27 08:43:20.740: INFO: Created: latency-svc-8kl4z
Aug 27 08:43:20.740: INFO: Created: latency-svc-wjr24
Aug 27 08:43:20.741: INFO: Created: latency-svc-brgk6
Aug 27 08:43:20.741: INFO: Got endpoints: latency-svc-brgk6 [103.878596ms]
Aug 27 08:43:20.744: INFO: Got endpoints: latency-svc-jvd9f [106.863438ms]
Aug 27 08:43:20.744: INFO: Got endpoints: latency-svc-6fg96 [107.845196ms]
Aug 27 08:43:20.744: INFO: Got endpoints: latency-svc-8kl4z [107.89051ms]
Aug 27 08:43:20.747: INFO: Got endpoints: latency-svc-wjr24 [71.317903ms]
Aug 27 08:43:20.747: INFO: Got endpoints: latency-svc-57j7b [110.182039ms]
Aug 27 08:43:20.747: INFO: Created: latency-svc-cwp98
Aug 27 08:43:20.763: INFO: Created: latency-svc-xjdcv
Aug 27 08:43:20.763: INFO: Created: latency-svc-fdsvh
Aug 27 08:43:20.769: INFO: Got endpoints: latency-svc-cwp98 [131.815927ms]
Aug 27 08:43:20.777: INFO: Got endpoints: latency-svc-xjdcv [126.48625ms]
Aug 27 08:43:20.777: INFO: Got endpoints: latency-svc-fdsvh [139.797061ms]
Aug 27 08:43:20.784: INFO: Created: latency-svc-jbwhr
Aug 27 08:43:20.789: INFO: Created: latency-svc-g87px
Aug 27 08:43:20.801: INFO: Got endpoints: latency-svc-jbwhr [150.682591ms]
Aug 27 08:43:20.805: INFO: Created: latency-svc-mz8cq
Aug 27 08:43:20.809: INFO: Got endpoints: latency-svc-g87px [158.837164ms]
Aug 27 08:43:20.815: INFO: Created: latency-svc-2dm9p
Aug 27 08:43:20.819: INFO: Created: latency-svc-m77l5
Aug 27 08:43:20.822: INFO: Got endpoints: latency-svc-mz8cq [171.701301ms]
Aug 27 08:43:20.831: INFO: Created: latency-svc-vkjr2
Aug 27 08:43:20.835: INFO: Got endpoints: latency-svc-m77l5 [183.942286ms]
Aug 27 08:43:20.835: INFO: Got endpoints: latency-svc-2dm9p [184.697318ms]
Aug 27 08:43:20.844: INFO: Created: latency-svc-7hbqz
Aug 27 08:43:20.847: INFO: Got endpoints: latency-svc-vkjr2 [182.537708ms]
Aug 27 08:43:20.848: INFO: Created: latency-svc-jtpm9
Aug 27 08:43:20.862: INFO: Created: latency-svc-gmk2s
Aug 27 08:43:20.862: INFO: Got endpoints: latency-svc-jtpm9 [118.162031ms]
Aug 27 08:43:20.862: INFO: Got endpoints: latency-svc-7hbqz [121.750943ms]
Aug 27 08:43:20.886: INFO: Created: latency-svc-knlv5
Aug 27 08:43:20.941: INFO: Created: latency-svc-6khlb
Aug 27 08:43:20.943: INFO: Created: latency-svc-rbx6v
Aug 27 08:43:20.943: INFO: Created: latency-svc-psnpf
Aug 27 08:43:20.943: INFO: Created: latency-svc-48742
Aug 27 08:43:20.943: INFO: Got endpoints: latency-svc-psnpf [196.270072ms]
Aug 27 08:43:20.943: INFO: Got endpoints: latency-svc-gmk2s [199.125124ms]
Aug 27 08:43:20.943: INFO: Got endpoints: latency-svc-knlv5 [198.877523ms]
Aug 27 08:43:20.943: INFO: Got endpoints: latency-svc-rbx6v [196.231295ms]
Aug 27 08:43:20.948: INFO: Got endpoints: latency-svc-48742 [179.136616ms]
Aug 27 08:43:20.948: INFO: Created: latency-svc-s8mbn
Aug 27 08:43:20.984: INFO: Created: latency-svc-m9xjj
Aug 27 08:43:20.990: INFO: Created: latency-svc-49frq
Aug 27 08:43:20.991: INFO: Created: latency-svc-9k9xl
Aug 27 08:43:20.995: INFO: Got endpoints: latency-svc-9k9xl [185.873794ms]
Aug 27 08:43:20.996: INFO: Got endpoints: latency-svc-6khlb [219.249751ms]
Aug 27 08:43:20.997: INFO: Got endpoints: latency-svc-s8mbn [219.405386ms]
Aug 27 08:43:20.997: INFO: Got endpoints: latency-svc-49frq [195.58833ms]
Aug 27 08:43:20.997: INFO: Got endpoints: latency-svc-m9xjj [174.719769ms]
Aug 27 08:43:20.997: INFO: Created: latency-svc-26lpc
Aug 27 08:43:20.997: INFO: Created: latency-svc-dnpm4
Aug 27 08:43:21.017: INFO: Created: latency-svc-tkbt6
Aug 27 08:43:21.019: INFO: Got endpoints: latency-svc-dnpm4 [183.279537ms]
Aug 27 08:43:21.020: INFO: Got endpoints: latency-svc-26lpc [184.958096ms]
Aug 27 08:43:21.027: INFO: Created: latency-svc-djnd7
Aug 27 08:43:21.027: INFO: Got endpoints: latency-svc-tkbt6 [180.012305ms]
Aug 27 08:43:21.044: INFO: Got endpoints: latency-svc-djnd7 [179.678289ms]
Aug 27 08:43:21.045: INFO: Created: latency-svc-vr8k9
Aug 27 08:43:21.062: INFO: Got endpoints: latency-svc-vr8k9 [197.289784ms]
Aug 27 08:43:21.062: INFO: Created: latency-svc-6d9bs
Aug 27 08:43:21.070: INFO: Created: latency-svc-gjmsc
Aug 27 08:43:21.080: INFO: Created: latency-svc-xt4tk
Aug 27 08:43:21.081: INFO: Got endpoints: latency-svc-6d9bs [137.904051ms]
Aug 27 08:43:21.087: INFO: Created: latency-svc-jhbxr
Aug 27 08:43:21.088: INFO: Got endpoints: latency-svc-gjmsc [139.806555ms]
Aug 27 08:43:21.135: INFO: Created: latency-svc-4xc88
Aug 27 08:43:21.136: INFO: Created: latency-svc-cq9b2
Aug 27 08:43:21.138: INFO: Got endpoints: latency-svc-cq9b2 [194.432141ms]
Aug 27 08:43:21.136: INFO: Created: latency-svc-nccs9
Aug 27 08:43:21.136: INFO: Created: latency-svc-jmldd
Aug 27 08:43:21.136: INFO: Created: latency-svc-8t8rm
Aug 27 08:43:21.136: INFO: Created: latency-svc-8fj9w
Aug 27 08:43:21.136: INFO: Created: latency-svc-bj7f6
Aug 27 08:43:21.136: INFO: Got endpoints: latency-svc-jhbxr [193.058238ms]
Aug 27 08:43:21.136: INFO: Got endpoints: latency-svc-xt4tk [193.184429ms]
Aug 27 08:43:21.136: INFO: Created: latency-svc-k6pg4
Aug 27 08:43:21.145: INFO: Created: latency-svc-whjpl
Aug 27 08:43:21.172: INFO: Created: latency-svc-gxtwv
Aug 27 08:43:21.173: INFO: Created: latency-svc-2n27d
Aug 27 08:43:21.173: INFO: Created: latency-svc-bpvsg
Aug 27 08:43:21.173: INFO: Created: latency-svc-84rdq
Aug 27 08:43:21.174: INFO: Created: latency-svc-tkzlq
Aug 27 08:43:21.174: INFO: Created: latency-svc-kb67b
Aug 27 08:43:21.175: INFO: Created: latency-svc-b9b29
Aug 27 08:43:21.185: INFO: Got endpoints: latency-svc-nccs9 [188.839877ms]
Aug 27 08:43:21.210: INFO: Created: latency-svc-d7dkf
Aug 27 08:43:21.233: INFO: Got endpoints: latency-svc-jmldd [236.046984ms]
Aug 27 08:43:21.243: INFO: Created: latency-svc-6xqch
Aug 27 08:43:21.290: INFO: Got endpoints: latency-svc-8t8rm [293.782071ms]
Aug 27 08:43:21.345: INFO: Created: latency-svc-kb8kr
Aug 27 08:43:21.346: INFO: Got endpoints: latency-svc-8fj9w [339.793658ms]
Aug 27 08:43:21.381: INFO: Created: latency-svc-mzdxb
Aug 27 08:43:21.402: INFO: Got endpoints: latency-svc-bj7f6 [399.720229ms]
Aug 27 08:43:21.441: INFO: Got endpoints: latency-svc-4xc88 [422.093996ms]
Aug 27 08:43:21.443: INFO: Created: latency-svc-txpb8
Aug 27 08:43:21.453: INFO: Created: latency-svc-qlp89
Aug 27 08:43:21.514: INFO: Got endpoints: latency-svc-k6pg4 [493.235864ms]
Aug 27 08:43:21.545: INFO: Got endpoints: latency-svc-whjpl [517.363318ms]
Aug 27 08:43:21.552: INFO: Created: latency-svc-dpwmk
Aug 27 08:43:21.556: INFO: Created: latency-svc-xfvzw
Aug 27 08:43:21.585: INFO: Got endpoints: latency-svc-2n27d [540.978072ms]
Aug 27 08:43:21.595: INFO: Created: latency-svc-z8cv5
Aug 27 08:43:21.636: INFO: Got endpoints: latency-svc-bpvsg [573.903873ms]
Aug 27 08:43:21.647: INFO: Created: latency-svc-ss7vr
Aug 27 08:43:21.684: INFO: Got endpoints: latency-svc-84rdq [602.88402ms]
Aug 27 08:43:21.693: INFO: Created: latency-svc-sbtx7
Aug 27 08:43:21.733: INFO: Got endpoints: latency-svc-tkzlq [644.301624ms]
Aug 27 08:43:21.741: INFO: Created: latency-svc-6nd7v
Aug 27 08:43:21.787: INFO: Got endpoints: latency-svc-kb67b [649.374533ms]
Aug 27 08:43:21.797: INFO: Created: latency-svc-5bqg9
Aug 27 08:43:21.835: INFO: Got endpoints: latency-svc-b9b29 [694.141968ms]
Aug 27 08:43:21.841: INFO: Created: latency-svc-qh9lv
Aug 27 08:43:21.883: INFO: Got endpoints: latency-svc-gxtwv [741.154511ms]
Aug 27 08:43:21.889: INFO: Created: latency-svc-8fzbx
Aug 27 08:43:21.936: INFO: Got endpoints: latency-svc-d7dkf [749.888224ms]
Aug 27 08:43:21.945: INFO: Created: latency-svc-4wpxb
Aug 27 08:43:21.983: INFO: Got endpoints: latency-svc-6xqch [747.761128ms]
Aug 27 08:43:21.990: INFO: Created: latency-svc-sbn7z
Aug 27 08:43:22.059: INFO: Got endpoints: latency-svc-kb8kr [763.272675ms]
Aug 27 08:43:22.066: INFO: Created: latency-svc-6gbxc
Aug 27 08:43:22.102: INFO: Got endpoints: latency-svc-mzdxb [755.916339ms]
Aug 27 08:43:22.109: INFO: Created: latency-svc-g6mj6
Aug 27 08:43:22.134: INFO: Got endpoints: latency-svc-txpb8 [731.69276ms]
Aug 27 08:43:22.142: INFO: Created: latency-svc-wn2hc
Aug 27 08:43:22.185: INFO: Got endpoints: latency-svc-qlp89 [743.247345ms]
Aug 27 08:43:22.193: INFO: Created: latency-svc-kgfxr
Aug 27 08:43:22.234: INFO: Got endpoints: latency-svc-dpwmk [720.219055ms]
Aug 27 08:43:22.242: INFO: Created: latency-svc-pr7hr
Aug 27 08:43:22.284: INFO: Got endpoints: latency-svc-xfvzw [738.175448ms]
Aug 27 08:43:22.292: INFO: Created: latency-svc-7vqfk
Aug 27 08:43:22.336: INFO: Got endpoints: latency-svc-z8cv5 [749.998066ms]
Aug 27 08:43:22.343: INFO: Created: latency-svc-k7c7j
Aug 27 08:43:22.383: INFO: Got endpoints: latency-svc-ss7vr [745.781402ms]
Aug 27 08:43:22.391: INFO: Created: latency-svc-xkgh8
Aug 27 08:43:22.433: INFO: Got endpoints: latency-svc-sbtx7 [748.284521ms]
Aug 27 08:43:22.441: INFO: Created: latency-svc-524lk
Aug 27 08:43:22.492: INFO: Got endpoints: latency-svc-6nd7v [759.131361ms]
Aug 27 08:43:22.509: INFO: Created: latency-svc-dwz87
Aug 27 08:43:22.537: INFO: Got endpoints: latency-svc-5bqg9 [748.035952ms]
Aug 27 08:43:22.577: INFO: Created: latency-svc-fs67m
Aug 27 08:43:22.585: INFO: Got endpoints: latency-svc-qh9lv [749.783364ms]
Aug 27 08:43:22.594: INFO: Created: latency-svc-gp2wf
Aug 27 08:43:22.636: INFO: Got endpoints: latency-svc-8fzbx [752.675258ms]
Aug 27 08:43:22.646: INFO: Created: latency-svc-6qf7r
Aug 27 08:43:22.684: INFO: Got endpoints: latency-svc-4wpxb [747.824333ms]
Aug 27 08:43:22.699: INFO: Created: latency-svc-b8hkf
Aug 27 08:43:22.744: INFO: Got endpoints: latency-svc-sbn7z [760.860353ms]
Aug 27 08:43:22.756: INFO: Created: latency-svc-tdqpg
Aug 27 08:43:22.784: INFO: Got endpoints: latency-svc-6gbxc [725.215102ms]
Aug 27 08:43:22.794: INFO: Created: latency-svc-hnk6b
Aug 27 08:43:22.838: INFO: Got endpoints: latency-svc-g6mj6 [735.622026ms]
Aug 27 08:43:22.847: INFO: Created: latency-svc-qj9dg
Aug 27 08:43:22.883: INFO: Got endpoints: latency-svc-wn2hc [747.980871ms]
Aug 27 08:43:22.890: INFO: Created: latency-svc-czrgc
Aug 27 08:43:22.934: INFO: Got endpoints: latency-svc-kgfxr [748.009509ms]
Aug 27 08:43:22.941: INFO: Created: latency-svc-2j9nx
Aug 27 08:43:22.983: INFO: Got endpoints: latency-svc-pr7hr [748.123672ms]
Aug 27 08:43:22.990: INFO: Created: latency-svc-5mpg8
Aug 27 08:43:23.037: INFO: Got endpoints: latency-svc-7vqfk [752.560711ms]
Aug 27 08:43:23.044: INFO: Created: latency-svc-5s9rk
Aug 27 08:43:23.084: INFO: Got endpoints: latency-svc-k7c7j [747.646486ms]
Aug 27 08:43:23.091: INFO: Created: latency-svc-m72gf
Aug 27 08:43:23.134: INFO: Got endpoints: latency-svc-xkgh8 [750.584723ms]
Aug 27 08:43:23.141: INFO: Created: latency-svc-v76vl
Aug 27 08:43:23.184: INFO: Got endpoints: latency-svc-524lk [750.69109ms]
Aug 27 08:43:23.201: INFO: Created: latency-svc-k75nd
Aug 27 08:43:23.234: INFO: Got endpoints: latency-svc-dwz87 [739.785195ms]
Aug 27 08:43:23.242: INFO: Created: latency-svc-c9w6j
Aug 27 08:43:23.285: INFO: Got endpoints: latency-svc-fs67m [747.363581ms]
Aug 27 08:43:23.292: INFO: Created: latency-svc-4zzd8
Aug 27 08:43:23.334: INFO: Got endpoints: latency-svc-gp2wf [749.105443ms]
Aug 27 08:43:23.349: INFO: Created: latency-svc-kqk7z
Aug 27 08:43:23.384: INFO: Got endpoints: latency-svc-6qf7r [747.743685ms]
Aug 27 08:43:23.390: INFO: Created: latency-svc-n2q4l
Aug 27 08:43:23.433: INFO: Got endpoints: latency-svc-b8hkf [748.790875ms]
Aug 27 08:43:23.445: INFO: Created: latency-svc-xnfq4
Aug 27 08:43:23.484: INFO: Got endpoints: latency-svc-tdqpg [739.657829ms]
Aug 27 08:43:23.491: INFO: Created: latency-svc-gmgzt
Aug 27 08:43:23.533: INFO: Got endpoints: latency-svc-hnk6b [748.595818ms]
Aug 27 08:43:23.542: INFO: Created: latency-svc-r668h
Aug 27 08:43:23.584: INFO: Got endpoints: latency-svc-qj9dg [745.82192ms]
Aug 27 08:43:23.593: INFO: Created: latency-svc-6qhl6
Aug 27 08:43:23.633: INFO: Got endpoints: latency-svc-czrgc [750.441339ms]
Aug 27 08:43:23.641: INFO: Created: latency-svc-9jzcw
Aug 27 08:43:23.684: INFO: Got endpoints: latency-svc-2j9nx [749.745934ms]
Aug 27 08:43:23.692: INFO: Created: latency-svc-m7nkd
Aug 27 08:43:23.735: INFO: Got endpoints: latency-svc-5mpg8 [751.8445ms]
Aug 27 08:43:23.742: INFO: Created: latency-svc-kxhbw
Aug 27 08:43:23.785: INFO: Got endpoints: latency-svc-5s9rk [748.158513ms]
Aug 27 08:43:23.794: INFO: Created: latency-svc-gh7sk
Aug 27 08:43:23.833: INFO: Got endpoints: latency-svc-m72gf [748.743197ms]
Aug 27 08:43:23.841: INFO: Created: latency-svc-76gm7
Aug 27 08:43:23.882: INFO: Got endpoints: latency-svc-v76vl [748.411599ms]
Aug 27 08:43:23.892: INFO: Created: latency-svc-rq7cq
Aug 27 08:43:23.933: INFO: Got endpoints: latency-svc-k75nd [748.568088ms]
Aug 27 08:43:23.940: INFO: Created: latency-svc-wlgrw
Aug 27 08:43:23.991: INFO: Got endpoints: latency-svc-c9w6j [756.605271ms]
Aug 27 08:43:24.029: INFO: Created: latency-svc-pgj9n
Aug 27 08:43:24.033: INFO: Got endpoints: latency-svc-4zzd8 [748.044192ms]
Aug 27 08:43:24.042: INFO: Created: latency-svc-q2gdm
Aug 27 08:43:24.085: INFO: Got endpoints: latency-svc-kqk7z [742.589593ms]
Aug 27 08:43:24.093: INFO: Created: latency-svc-mvz7d
Aug 27 08:43:24.133: INFO: Got endpoints: latency-svc-n2q4l [748.882353ms]
Aug 27 08:43:24.172: INFO: Created: latency-svc-g8ht6
Aug 27 08:43:24.184: INFO: Got endpoints: latency-svc-xnfq4 [750.235218ms]
Aug 27 08:43:24.192: INFO: Created: latency-svc-5dktx
Aug 27 08:43:24.234: INFO: Got endpoints: latency-svc-gmgzt [749.848871ms]
Aug 27 08:43:24.241: INFO: Created: latency-svc-bmm46
Aug 27 08:43:24.282: INFO: Got endpoints: latency-svc-r668h [747.963922ms]
Aug 27 08:43:24.287: INFO: Created: latency-svc-2kh4j
Aug 27 08:43:24.332: INFO: Got endpoints: latency-svc-6qhl6 [747.330114ms]
Aug 27 08:43:24.340: INFO: Created: latency-svc-vf2kh
Aug 27 08:43:24.384: INFO: Got endpoints: latency-svc-9jzcw [750.095543ms]
Aug 27 08:43:24.391: INFO: Created: latency-svc-wwln6
Aug 27 08:43:24.435: INFO: Got endpoints: latency-svc-m7nkd [750.437768ms]
Aug 27 08:43:24.442: INFO: Created: latency-svc-5pm2t
Aug 27 08:43:24.484: INFO: Got endpoints: latency-svc-kxhbw [748.324487ms]
Aug 27 08:43:24.491: INFO: Created: latency-svc-snp7j
Aug 27 08:43:24.534: INFO: Got endpoints: latency-svc-gh7sk [748.482765ms]
Aug 27 08:43:24.541: INFO: Created: latency-svc-24m75
Aug 27 08:43:24.585: INFO: Got endpoints: latency-svc-76gm7 [751.623371ms]
Aug 27 08:43:24.593: INFO: Created: latency-svc-55k9h
Aug 27 08:43:24.634: INFO: Got endpoints: latency-svc-rq7cq [751.028789ms]
Aug 27 08:43:24.641: INFO: Created: latency-svc-rbbk2
Aug 27 08:43:24.683: INFO: Got endpoints: latency-svc-wlgrw [749.696618ms]
Aug 27 08:43:24.690: INFO: Created: latency-svc-j5kdt
Aug 27 08:43:24.734: INFO: Got endpoints: latency-svc-pgj9n [743.689162ms]
Aug 27 08:43:24.742: INFO: Created: latency-svc-t8vzv
Aug 27 08:43:24.784: INFO: Got endpoints: latency-svc-q2gdm [750.65875ms]
Aug 27 08:43:24.791: INFO: Created: latency-svc-bj22l
Aug 27 08:43:24.833: INFO: Got endpoints: latency-svc-mvz7d [747.337206ms]
Aug 27 08:43:24.840: INFO: Created: latency-svc-94t9d
Aug 27 08:43:24.884: INFO: Got endpoints: latency-svc-g8ht6 [750.782617ms]
Aug 27 08:43:24.890: INFO: Created: latency-svc-pn28x
Aug 27 08:43:24.933: INFO: Got endpoints: latency-svc-5dktx [748.178139ms]
Aug 27 08:43:24.940: INFO: Created: latency-svc-zrv6j
Aug 27 08:43:24.982: INFO: Got endpoints: latency-svc-bmm46 [748.107382ms]
Aug 27 08:43:24.989: INFO: Created: latency-svc-sqtw5
Aug 27 08:43:25.043: INFO: Got endpoints: latency-svc-2kh4j [761.004103ms]
Aug 27 08:43:25.092: INFO: Got endpoints: latency-svc-vf2kh [758.43481ms]
Aug 27 08:43:25.093: INFO: Created: latency-svc-jlj95
Aug 27 08:43:25.144: INFO: Created: latency-svc-7vdcs
Aug 27 08:43:25.153: INFO: Got endpoints: latency-svc-wwln6 [768.68023ms]
Aug 27 08:43:25.205: INFO: Got endpoints: latency-svc-5pm2t [769.429713ms]
Aug 27 08:43:25.219: INFO: Created: latency-svc-n7lwc
Aug 27 08:43:25.223: INFO: Created: latency-svc-6dgg5
Aug 27 08:43:25.232: INFO: Got endpoints: latency-svc-snp7j [747.490927ms]
Aug 27 08:43:25.240: INFO: Created: latency-svc-g989l
Aug 27 08:43:25.297: INFO: Got endpoints: latency-svc-24m75 [762.090873ms]
Aug 27 08:43:25.358: INFO: Got endpoints: latency-svc-55k9h [772.778795ms]
Aug 27 08:43:25.362: INFO: Created: latency-svc-nfhl2
Aug 27 08:43:25.376: INFO: Created: latency-svc-bfghm
Aug 27 08:43:25.383: INFO: Got endpoints: latency-svc-rbbk2 [748.611835ms]
Aug 27 08:43:25.390: INFO: Created: latency-svc-nb2js
Aug 27 08:43:25.458: INFO: Got endpoints: latency-svc-j5kdt [774.478814ms]
Aug 27 08:43:25.504: INFO: Got endpoints: latency-svc-t8vzv [768.677735ms]
Aug 27 08:43:25.505: INFO: Created: latency-svc-phzmj
Aug 27 08:43:25.511: INFO: Created: latency-svc-8zjd5
Aug 27 08:43:25.550: INFO: Got endpoints: latency-svc-bj22l [765.360745ms]
Aug 27 08:43:25.596: INFO: Created: latency-svc-qdlbk
Aug 27 08:43:25.597: INFO: Got endpoints: latency-svc-94t9d [763.633825ms]
Aug 27 08:43:25.616: INFO: Created: latency-svc-v86wb
Aug 27 08:43:25.634: INFO: Got endpoints: latency-svc-pn28x [749.93273ms]
Aug 27 08:43:25.642: INFO: Created: latency-svc-64jt9
Aug 27 08:43:25.687: INFO: Got endpoints: latency-svc-zrv6j [754.388854ms]
Aug 27 08:43:25.698: INFO: Created: latency-svc-jrsm6
Aug 27 08:43:25.740: INFO: Got endpoints: latency-svc-sqtw5 [756.904848ms]
Aug 27 08:43:25.771: INFO: Created: latency-svc-89l96
Aug 27 08:43:25.782: INFO: Got endpoints: latency-svc-jlj95 [739.245196ms]
Aug 27 08:43:25.790: INFO: Created: latency-svc-chhmg
Aug 27 08:43:25.832: INFO: Got endpoints: latency-svc-7vdcs [739.354351ms]
Aug 27 08:43:25.839: INFO: Created: latency-svc-wttrc
Aug 27 08:43:25.885: INFO: Got endpoints: latency-svc-n7lwc [731.454659ms]
Aug 27 08:43:25.892: INFO: Created: latency-svc-jk49x
Aug 27 08:43:25.934: INFO: Got endpoints: latency-svc-6dgg5 [728.774932ms]
Aug 27 08:43:25.963: INFO: Created: latency-svc-qhdgc
Aug 27 08:43:26.011: INFO: Got endpoints: latency-svc-g989l [779.169495ms]
Aug 27 08:43:26.036: INFO: Got endpoints: latency-svc-nfhl2 [739.487735ms]
Aug 27 08:43:26.038: INFO: Created: latency-svc-kkgfz
Aug 27 08:43:26.045: INFO: Created: latency-svc-crvbf
Aug 27 08:43:26.103: INFO: Got endpoints: latency-svc-bfghm [744.141418ms]
Aug 27 08:43:26.111: INFO: Created: latency-svc-mdrzq
Aug 27 08:43:26.136: INFO: Got endpoints: latency-svc-nb2js [752.472258ms]
Aug 27 08:43:26.143: INFO: Created: latency-svc-548pc
Aug 27 08:43:26.187: INFO: Got endpoints: latency-svc-phzmj [728.967964ms]
Aug 27 08:43:26.209: INFO: Created: latency-svc-bd7dw
Aug 27 08:43:26.250: INFO: Got endpoints: latency-svc-8zjd5 [746.112034ms]
Aug 27 08:43:26.275: INFO: Created: latency-svc-xfjtg
Aug 27 08:43:26.293: INFO: Got endpoints: latency-svc-qdlbk [743.177336ms]
Aug 27 08:43:26.311: INFO: Created: latency-svc-cs4c4
Aug 27 08:43:26.337: INFO: Got endpoints: latency-svc-v86wb [740.348976ms]
Aug 27 08:43:26.345: INFO: Created: latency-svc-db72l
Aug 27 08:43:26.381: INFO: Got endpoints: latency-svc-64jt9 [747.11405ms]
Aug 27 08:43:26.388: INFO: Created: latency-svc-5hj2z
Aug 27 08:43:26.432: INFO: Got endpoints: latency-svc-jrsm6 [744.184509ms]
Aug 27 08:43:26.439: INFO: Created: latency-svc-67txq
Aug 27 08:43:26.485: INFO: Got endpoints: latency-svc-89l96 [744.48691ms]
Aug 27 08:43:26.493: INFO: Created: latency-svc-5mh4g
Aug 27 08:43:26.536: INFO: Got endpoints: latency-svc-chhmg [752.964447ms]
Aug 27 08:43:26.545: INFO: Created: latency-svc-qtlc7
Aug 27 08:43:26.583: INFO: Got endpoints: latency-svc-wttrc [751.291734ms]
Aug 27 08:43:26.591: INFO: Created: latency-svc-rqbtv
Aug 27 08:43:26.633: INFO: Got endpoints: latency-svc-jk49x [748.065241ms]
Aug 27 08:43:26.641: INFO: Created: latency-svc-zj2gb
Aug 27 08:43:26.693: INFO: Got endpoints: latency-svc-qhdgc [758.426063ms]
Aug 27 08:43:26.703: INFO: Created: latency-svc-t4nfc
Aug 27 08:43:26.734: INFO: Got endpoints: latency-svc-kkgfz [722.409873ms]
Aug 27 08:43:26.741: INFO: Created: latency-svc-h6lkw
Aug 27 08:43:26.784: INFO: Got endpoints: latency-svc-crvbf [745.881011ms]
Aug 27 08:43:26.794: INFO: Created: latency-svc-qbwzk
Aug 27 08:43:26.833: INFO: Got endpoints: latency-svc-mdrzq [729.435898ms]
Aug 27 08:43:26.840: INFO: Created: latency-svc-rjxsb
Aug 27 08:43:26.883: INFO: Got endpoints: latency-svc-548pc [746.683827ms]
Aug 27 08:43:26.891: INFO: Created: latency-svc-g9zlz
Aug 27 08:43:26.935: INFO: Got endpoints: latency-svc-bd7dw [747.291733ms]
Aug 27 08:43:26.942: INFO: Created: latency-svc-sq47w
Aug 27 08:43:26.983: INFO: Got endpoints: latency-svc-xfjtg [732.508383ms]
Aug 27 08:43:26.991: INFO: Created: latency-svc-6wp89
Aug 27 08:43:27.037: INFO: Got endpoints: latency-svc-cs4c4 [743.141205ms]
Aug 27 08:43:27.043: INFO: Created: latency-svc-8fjfj
Aug 27 08:43:27.083: INFO: Got endpoints: latency-svc-db72l [745.551466ms]
Aug 27 08:43:27.090: INFO: Created: latency-svc-6vnbk
Aug 27 08:43:27.134: INFO: Got endpoints: latency-svc-5hj2z [751.96249ms]
Aug 27 08:43:27.141: INFO: Created: latency-svc-9w8mr
Aug 27 08:43:27.184: INFO: Got endpoints: latency-svc-67txq [751.790209ms]
Aug 27 08:43:27.205: INFO: Created: latency-svc-5hjzn
Aug 27 08:43:27.233: INFO: Got endpoints: latency-svc-5mh4g [748.329715ms]
Aug 27 08:43:27.242: INFO: Created: latency-svc-g6qw6
Aug 27 08:43:27.285: INFO: Got endpoints: latency-svc-qtlc7 [748.800064ms]
Aug 27 08:43:27.343: INFO: Created: latency-svc-xxrqc
Aug 27 08:43:27.347: INFO: Got endpoints: latency-svc-rqbtv [763.279561ms]
Aug 27 08:43:27.360: INFO: Created: latency-svc-mlqkm
Aug 27 08:43:27.383: INFO: Got endpoints: latency-svc-zj2gb [749.720474ms]
Aug 27 08:43:27.391: INFO: Created: latency-svc-cbf2m
Aug 27 08:43:27.434: INFO: Got endpoints: latency-svc-t4nfc [740.58475ms]
Aug 27 08:43:27.442: INFO: Created: latency-svc-9m2tg
Aug 27 08:43:27.486: INFO: Got endpoints: latency-svc-h6lkw [751.466695ms]
Aug 27 08:43:27.493: INFO: Created: latency-svc-999js
Aug 27 08:43:27.532: INFO: Got endpoints: latency-svc-qbwzk [748.116363ms]
Aug 27 08:43:27.539: INFO: Created: latency-svc-rvcxj
Aug 27 08:43:27.584: INFO: Got endpoints: latency-svc-rjxsb [750.482373ms]
Aug 27 08:43:27.593: INFO: Created: latency-svc-vg2fb
Aug 27 08:43:27.633: INFO: Got endpoints: latency-svc-g9zlz [749.149511ms]
Aug 27 08:43:27.639: INFO: Created: latency-svc-k422f
Aug 27 08:43:27.683: INFO: Got endpoints: latency-svc-sq47w [747.285812ms]
Aug 27 08:43:27.690: INFO: Created: latency-svc-rbdp5
Aug 27 08:43:27.732: INFO: Got endpoints: latency-svc-6wp89 [748.555185ms]
Aug 27 08:43:27.738: INFO: Created: latency-svc-299h2
Aug 27 08:43:27.786: INFO: Got endpoints: latency-svc-8fjfj [749.625833ms]
Aug 27 08:43:27.797: INFO: Created: latency-svc-v4dq8
Aug 27 08:43:27.833: INFO: Got endpoints: latency-svc-6vnbk [750.419879ms]
Aug 27 08:43:27.841: INFO: Created: latency-svc-zmdpx
Aug 27 08:43:27.886: INFO: Got endpoints: latency-svc-9w8mr [751.687469ms]
Aug 27 08:43:27.897: INFO: Created: latency-svc-h4zpc
Aug 27 08:43:27.934: INFO: Got endpoints: latency-svc-5hjzn [749.578046ms]
Aug 27 08:43:27.941: INFO: Created: latency-svc-7pczk
Aug 27 08:43:27.984: INFO: Got endpoints: latency-svc-g6qw6 [750.177647ms]
Aug 27 08:43:27.992: INFO: Created: latency-svc-zm98w
Aug 27 08:43:28.038: INFO: Got endpoints: latency-svc-xxrqc [752.093969ms]
Aug 27 08:43:28.045: INFO: Created: latency-svc-tvrfz
Aug 27 08:43:28.084: INFO: Got endpoints: latency-svc-mlqkm [736.820716ms]
Aug 27 08:43:28.096: INFO: Created: latency-svc-xmz9c
Aug 27 08:43:28.134: INFO: Got endpoints: latency-svc-cbf2m [750.157511ms]
Aug 27 08:43:28.142: INFO: Created: latency-svc-w2rzd
Aug 27 08:43:28.185: INFO: Got endpoints: latency-svc-9m2tg [750.978179ms]
Aug 27 08:43:28.193: INFO: Created: latency-svc-tgqgj
Aug 27 08:43:28.233: INFO: Got endpoints: latency-svc-999js [746.482802ms]
Aug 27 08:43:28.241: INFO: Created: latency-svc-j8fb8
Aug 27 08:43:28.283: INFO: Got endpoints: latency-svc-rvcxj [750.517594ms]
Aug 27 08:43:28.291: INFO: Created: latency-svc-n4fvg
Aug 27 08:43:28.334: INFO: Got endpoints: latency-svc-vg2fb [750.082522ms]
Aug 27 08:43:28.348: INFO: Created: latency-svc-x5m6s
Aug 27 08:43:28.384: INFO: Got endpoints: latency-svc-k422f [750.644088ms]
Aug 27 08:43:28.391: INFO: Created: latency-svc-2z26p
Aug 27 08:43:28.431: INFO: Got endpoints: latency-svc-rbdp5 [747.806146ms]
Aug 27 08:43:28.437: INFO: Created: latency-svc-gqlgw
Aug 27 08:43:28.482: INFO: Got endpoints: latency-svc-299h2 [749.94341ms]
Aug 27 08:43:28.534: INFO: Got endpoints: latency-svc-v4dq8 [745.833163ms]
Aug 27 08:43:28.584: INFO: Got endpoints: latency-svc-zmdpx [749.71248ms]
Aug 27 08:43:28.634: INFO: Got endpoints: latency-svc-h4zpc [747.49089ms]
Aug 27 08:43:28.684: INFO: Got endpoints: latency-svc-7pczk [749.669389ms]
Aug 27 08:43:28.734: INFO: Got endpoints: latency-svc-zm98w [750.056728ms]
Aug 27 08:43:28.786: INFO: Got endpoints: latency-svc-tvrfz [747.934072ms]
Aug 27 08:43:28.833: INFO: Got endpoints: latency-svc-xmz9c [748.313145ms]
Aug 27 08:43:28.883: INFO: Got endpoints: latency-svc-w2rzd [748.4789ms]
Aug 27 08:43:28.934: INFO: Got endpoints: latency-svc-tgqgj [748.390363ms]
Aug 27 08:43:28.984: INFO: Got endpoints: latency-svc-j8fb8 [750.663445ms]
Aug 27 08:43:29.038: INFO: Got endpoints: latency-svc-n4fvg [753.857094ms]
Aug 27 08:43:29.083: INFO: Got endpoints: latency-svc-x5m6s [747.936212ms]
Aug 27 08:43:29.134: INFO: Got endpoints: latency-svc-2z26p [749.797047ms]
Aug 27 08:43:29.183: INFO: Got endpoints: latency-svc-gqlgw [752.495337ms]
Aug 27 08:43:29.184: INFO: Latencies: [27.901393ms 39.007964ms 71.317903ms 103.878596ms 106.863438ms 107.845196ms 107.89051ms 110.182039ms 118.162031ms 121.750943ms 126.48625ms 131.815927ms 137.904051ms 139.797061ms 139.806555ms 150.682591ms 158.837164ms 171.701301ms 174.719769ms 179.136616ms 179.678289ms 180.012305ms 182.537708ms 183.279537ms 183.942286ms 184.697318ms 184.958096ms 185.873794ms 188.839877ms 193.058238ms 193.184429ms 194.432141ms 195.58833ms 196.231295ms 196.270072ms 197.289784ms 198.877523ms 199.125124ms 219.249751ms 219.405386ms 236.046984ms 293.782071ms 339.793658ms 399.720229ms 422.093996ms 493.235864ms 517.363318ms 540.978072ms 573.903873ms 602.88402ms 644.301624ms 649.374533ms 694.141968ms 720.219055ms 722.409873ms 725.215102ms 728.774932ms 728.967964ms 729.435898ms 731.454659ms 731.69276ms 732.508383ms 735.622026ms 736.820716ms 738.175448ms 739.245196ms 739.354351ms 739.487735ms 739.657829ms 739.785195ms 740.348976ms 740.58475ms 741.154511ms 742.589593ms 743.141205ms 743.177336ms 743.247345ms 743.689162ms 744.141418ms 744.184509ms 744.48691ms 745.551466ms 745.781402ms 745.82192ms 745.833163ms 745.881011ms 746.112034ms 746.482802ms 746.683827ms 747.11405ms 747.285812ms 747.291733ms 747.330114ms 747.337206ms 747.363581ms 747.49089ms 747.490927ms 747.646486ms 747.743685ms 747.761128ms 747.806146ms 747.824333ms 747.934072ms 747.936212ms 747.963922ms 747.980871ms 748.009509ms 748.035952ms 748.044192ms 748.065241ms 748.107382ms 748.116363ms 748.123672ms 748.158513ms 748.178139ms 748.284521ms 748.313145ms 748.324487ms 748.329715ms 748.390363ms 748.411599ms 748.4789ms 748.482765ms 748.555185ms 748.568088ms 748.595818ms 748.611835ms 748.743197ms 748.790875ms 748.800064ms 748.882353ms 749.105443ms 749.149511ms 749.578046ms 749.625833ms 749.669389ms 749.696618ms 749.71248ms 749.720474ms 749.745934ms 749.783364ms 749.797047ms 749.848871ms 749.888224ms 749.93273ms 749.94341ms 749.998066ms 750.056728ms 750.082522ms 750.095543ms 750.157511ms 750.177647ms 750.235218ms 750.419879ms 750.437768ms 750.441339ms 750.482373ms 750.517594ms 750.584723ms 750.644088ms 750.65875ms 750.663445ms 750.69109ms 750.782617ms 750.978179ms 751.028789ms 751.291734ms 751.466695ms 751.623371ms 751.687469ms 751.790209ms 751.8445ms 751.96249ms 752.093969ms 752.472258ms 752.495337ms 752.560711ms 752.675258ms 752.964447ms 753.857094ms 754.388854ms 755.916339ms 756.605271ms 756.904848ms 758.426063ms 758.43481ms 759.131361ms 760.860353ms 761.004103ms 762.090873ms 763.272675ms 763.279561ms 763.633825ms 765.360745ms 768.677735ms 768.68023ms 769.429713ms 772.778795ms 774.478814ms 779.169495ms]
Aug 27 08:43:29.184: INFO: 50 %ile: 747.806146ms
Aug 27 08:43:29.184: INFO: 90 %ile: 754.388854ms
Aug 27 08:43:29.185: INFO: 99 %ile: 774.478814ms
Aug 27 08:43:29.185: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:43:29.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-57" for this suite.

• [SLOW TEST:12.806 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":303,"completed":76,"skipped":1076,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:43:29.224: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:43:29.305: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 27 08:43:29.313: INFO: Number of nodes with available pods: 0
Aug 27 08:43:29.313: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 27 08:43:29.335: INFO: Number of nodes with available pods: 0
Aug 27 08:43:29.335: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:30.338: INFO: Number of nodes with available pods: 0
Aug 27 08:43:30.339: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:31.339: INFO: Number of nodes with available pods: 1
Aug 27 08:43:31.340: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 27 08:43:31.366: INFO: Number of nodes with available pods: 1
Aug 27 08:43:31.366: INFO: Number of running nodes: 0, number of available pods: 1
Aug 27 08:43:32.369: INFO: Number of nodes with available pods: 0
Aug 27 08:43:32.369: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 27 08:43:32.377: INFO: Number of nodes with available pods: 0
Aug 27 08:43:32.377: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:33.381: INFO: Number of nodes with available pods: 0
Aug 27 08:43:33.381: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:34.403: INFO: Number of nodes with available pods: 0
Aug 27 08:43:34.403: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:35.382: INFO: Number of nodes with available pods: 0
Aug 27 08:43:35.382: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:36.442: INFO: Number of nodes with available pods: 0
Aug 27 08:43:36.442: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:37.391: INFO: Number of nodes with available pods: 0
Aug 27 08:43:37.391: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:38.384: INFO: Number of nodes with available pods: 0
Aug 27 08:43:38.385: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:39.383: INFO: Number of nodes with available pods: 0
Aug 27 08:43:39.383: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:40.401: INFO: Number of nodes with available pods: 0
Aug 27 08:43:40.401: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:41.380: INFO: Number of nodes with available pods: 0
Aug 27 08:43:41.380: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:42.380: INFO: Number of nodes with available pods: 0
Aug 27 08:43:42.380: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:43.380: INFO: Number of nodes with available pods: 0
Aug 27 08:43:43.380: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:44.380: INFO: Number of nodes with available pods: 0
Aug 27 08:43:44.380: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 08:43:45.380: INFO: Number of nodes with available pods: 1
Aug 27 08:43:45.381: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4656, will wait for the garbage collector to delete the pods
Aug 27 08:43:45.445: INFO: Deleting DaemonSet.extensions daemon-set took: 4.434202ms
Aug 27 08:43:47.645: INFO: Terminating DaemonSet.extensions daemon-set pods took: 2.200526648s
Aug 27 08:43:49.748: INFO: Number of nodes with available pods: 0
Aug 27 08:43:49.748: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 08:43:49.750: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4656/daemonsets","resourceVersion":"11917"},"items":null}

Aug 27 08:43:49.753: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4656/pods","resourceVersion":"11917"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:43:49.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4656" for this suite.

• [SLOW TEST:20.553 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":303,"completed":77,"skipped":1102,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:43:49.776: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name secret-test-510972a1-a085-402f-90ab-2f36c2719e80
STEP: Creating a pod to test consume secrets
Aug 27 08:43:49.828: INFO: Waiting up to 5m0s for pod "pod-secrets-c172d89f-9ead-4a77-b434-202a14b19ac4" in namespace "secrets-3898" to be "Succeeded or Failed"
Aug 27 08:43:49.832: INFO: Pod "pod-secrets-c172d89f-9ead-4a77-b434-202a14b19ac4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.133516ms
Aug 27 08:43:51.836: INFO: Pod "pod-secrets-c172d89f-9ead-4a77-b434-202a14b19ac4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00780216s
STEP: Saw pod success
Aug 27 08:43:51.836: INFO: Pod "pod-secrets-c172d89f-9ead-4a77-b434-202a14b19ac4" satisfied condition "Succeeded or Failed"
Aug 27 08:43:51.839: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-secrets-c172d89f-9ead-4a77-b434-202a14b19ac4 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 08:43:51.904: INFO: Waiting for pod pod-secrets-c172d89f-9ead-4a77-b434-202a14b19ac4 to disappear
Aug 27 08:43:51.910: INFO: Pod pod-secrets-c172d89f-9ead-4a77-b434-202a14b19ac4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:43:51.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3898" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":78,"skipped":1114,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:43:51.928: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 27 08:43:51.998: INFO: Waiting up to 5m0s for pod "pod-7b4c562d-e955-4871-b482-3b7cfcd32d5f" in namespace "emptydir-8252" to be "Succeeded or Failed"
Aug 27 08:43:52.048: INFO: Pod "pod-7b4c562d-e955-4871-b482-3b7cfcd32d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 49.095587ms
Aug 27 08:43:54.052: INFO: Pod "pod-7b4c562d-e955-4871-b482-3b7cfcd32d5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052575805s
STEP: Saw pod success
Aug 27 08:43:54.052: INFO: Pod "pod-7b4c562d-e955-4871-b482-3b7cfcd32d5f" satisfied condition "Succeeded or Failed"
Aug 27 08:43:54.054: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-7b4c562d-e955-4871-b482-3b7cfcd32d5f container test-container: <nil>
STEP: delete the pod
Aug 27 08:43:54.069: INFO: Waiting for pod pod-7b4c562d-e955-4871-b482-3b7cfcd32d5f to disappear
Aug 27 08:43:54.074: INFO: Pod pod-7b4c562d-e955-4871-b482-3b7cfcd32d5f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:43:54.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8252" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":79,"skipped":1135,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should delete a collection of pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:43:54.082: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:181
[It] should delete a collection of pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Create set of pods
Aug 27 08:43:54.122: INFO: created test-pod-1
Aug 27 08:43:54.127: INFO: created test-pod-2
Aug 27 08:43:54.136: INFO: created test-pod-3
STEP: waiting for all 3 pods to be located
STEP: waiting for all pods to be deleted
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:43:54.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8924" for this suite.
•{"msg":"PASSED [k8s.io] Pods should delete a collection of pods [Conformance]","total":303,"completed":80,"skipped":1137,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:43:54.225: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:44:10.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6473" for this suite.

• [SLOW TEST:16.162 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":303,"completed":81,"skipped":1146,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:44:10.390: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service in namespace services-3342
STEP: creating service affinity-nodeport in namespace services-3342
STEP: creating replication controller affinity-nodeport in namespace services-3342
I0827 08:44:10.449722      19 runners.go:190] Created replication controller with name: affinity-nodeport, namespace: services-3342, replica count: 3
I0827 08:44:13.501969      19 runners.go:190] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:44:16.503143      19 runners.go:190] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 08:44:16.510: INFO: Creating new exec pod
Aug 27 08:44:19.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-3342 execpod-affinityklw7b -- /bin/sh -x -c nc -zv -t -w 2 affinity-nodeport 80'
Aug 27 08:44:19.878: INFO: stderr: "+ nc -zv -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Aug 27 08:44:19.878: INFO: stdout: ""
Aug 27 08:44:19.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-3342 execpod-affinityklw7b -- /bin/sh -x -c nc -zv -t -w 2 10.3.230.208 80'
Aug 27 08:44:20.093: INFO: stderr: "+ nc -zv -t -w 2 10.3.230.208 80\nConnection to 10.3.230.208 80 port [tcp/http] succeeded!\n"
Aug 27 08:44:20.093: INFO: stdout: ""
Aug 27 08:44:20.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-3342 execpod-affinityklw7b -- /bin/sh -x -c nc -zv -t -w 2 10.0.27.251 32078'
Aug 27 08:44:20.291: INFO: stderr: "+ nc -zv -t -w 2 10.0.27.251 32078\nConnection to 10.0.27.251 32078 port [tcp/32078] succeeded!\n"
Aug 27 08:44:20.291: INFO: stdout: ""
Aug 27 08:44:20.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-3342 execpod-affinityklw7b -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.216 32078'
Aug 27 08:44:20.499: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.216 32078\nConnection to 10.0.2.216 32078 port [tcp/32078] succeeded!\n"
Aug 27 08:44:20.499: INFO: stdout: ""
Aug 27 08:44:20.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-3342 execpod-affinityklw7b -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.2.216:32078/ ; done'
Aug 27 08:44:20.845: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:32078/\n"
Aug 27 08:44:20.845: INFO: stdout: "\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf\naffinity-nodeport-6mdxf"
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Received response from host: affinity-nodeport-6mdxf
Aug 27 08:44:20.845: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-3342, will wait for the garbage collector to delete the pods
Aug 27 08:44:20.923: INFO: Deleting ReplicationController affinity-nodeport took: 4.927029ms
Aug 27 08:44:21.439: INFO: Terminating ReplicationController affinity-nodeport pods took: 515.804244ms
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:44:35.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3342" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:24.904 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":303,"completed":82,"skipped":1157,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:44:35.302: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:44:35.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3763" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":303,"completed":83,"skipped":1180,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:44:35.575: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 08:44:36.547: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 08:44:38.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114676, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114676, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114676, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114676, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 08:44:41.570: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:44:41.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1209" for this suite.
STEP: Destroying namespace "webhook-1209-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.095 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":303,"completed":84,"skipped":1256,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:44:41.684: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 27 08:44:41.728: INFO: Waiting up to 5m0s for pod "pod-a09bf147-3198-4d60-901a-4382db5189a9" in namespace "emptydir-2133" to be "Succeeded or Failed"
Aug 27 08:44:41.733: INFO: Pod "pod-a09bf147-3198-4d60-901a-4382db5189a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.650383ms
Aug 27 08:44:43.737: INFO: Pod "pod-a09bf147-3198-4d60-901a-4382db5189a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008661072s
Aug 27 08:44:45.740: INFO: Pod "pod-a09bf147-3198-4d60-901a-4382db5189a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012146816s
STEP: Saw pod success
Aug 27 08:44:45.741: INFO: Pod "pod-a09bf147-3198-4d60-901a-4382db5189a9" satisfied condition "Succeeded or Failed"
Aug 27 08:44:45.744: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-a09bf147-3198-4d60-901a-4382db5189a9 container test-container: <nil>
STEP: delete the pod
Aug 27 08:44:45.760: INFO: Waiting for pod pod-a09bf147-3198-4d60-901a-4382db5189a9 to disappear
Aug 27 08:44:45.765: INFO: Pod pod-a09bf147-3198-4d60-901a-4382db5189a9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:44:45.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2133" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":85,"skipped":1267,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:44:45.777: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod pod-subpath-test-configmap-f7pj
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 08:44:45.823: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-f7pj" in namespace "subpath-6290" to be "Succeeded or Failed"
Aug 27 08:44:45.828: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Pending", Reason="", readiness=false. Elapsed: 3.96006ms
Aug 27 08:44:47.865: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040374522s
Aug 27 08:44:49.868: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 4.044294184s
Aug 27 08:44:51.872: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 6.047607887s
Aug 27 08:44:53.875: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 8.050830781s
Aug 27 08:44:55.879: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 10.054557524s
Aug 27 08:44:57.883: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 12.058616856s
Aug 27 08:44:59.887: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 14.062358361s
Aug 27 08:45:01.901: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 16.077270553s
Aug 27 08:45:03.909: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 18.085183526s
Aug 27 08:45:05.916: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Running", Reason="", readiness=true. Elapsed: 20.092054219s
Aug 27 08:45:07.920: INFO: Pod "pod-subpath-test-configmap-f7pj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.095504329s
STEP: Saw pod success
Aug 27 08:45:07.920: INFO: Pod "pod-subpath-test-configmap-f7pj" satisfied condition "Succeeded or Failed"
Aug 27 08:45:07.924: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-subpath-test-configmap-f7pj container test-container-subpath-configmap-f7pj: <nil>
STEP: delete the pod
Aug 27 08:45:08.018: INFO: Waiting for pod pod-subpath-test-configmap-f7pj to disappear
Aug 27 08:45:08.024: INFO: Pod pod-subpath-test-configmap-f7pj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-f7pj
Aug 27 08:45:08.024: INFO: Deleting pod "pod-subpath-test-configmap-f7pj" in namespace "subpath-6290"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:45:08.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6290" for this suite.

• [SLOW TEST:22.268 seconds]
[sig-storage] Subpath
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":303,"completed":86,"skipped":1278,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:45:08.057: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:181
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating pod
Aug 27 08:45:10.125: INFO: Pod pod-hostip-813579ab-fc25-4356-af35-c517c4ce7124 has hostIP: 10.0.2.216
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:45:10.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-260" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":303,"completed":87,"skipped":1310,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:45:10.133: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating Agnhost RC
Aug 27 08:45:10.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-6409'
Aug 27 08:45:10.446: INFO: stderr: ""
Aug 27 08:45:10.446: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug 27 08:45:11.452: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 08:45:11.452: INFO: Found 0 / 1
Aug 27 08:45:12.460: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 08:45:12.460: INFO: Found 0 / 1
Aug 27 08:45:13.449: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 08:45:13.449: INFO: Found 1 / 1
Aug 27 08:45:13.449: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 27 08:45:13.451: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 08:45:13.451: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 08:45:13.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 patch pod agnhost-primary-m7vqd --namespace=kubectl-6409 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 27 08:45:13.557: INFO: stderr: ""
Aug 27 08:45:13.557: INFO: stdout: "pod/agnhost-primary-m7vqd patched\n"
STEP: checking annotations
Aug 27 08:45:13.561: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 08:45:13.561: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:45:13.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6409" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":303,"completed":88,"skipped":1328,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:45:13.567: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service endpoint-test2 in namespace services-5233
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5233 to expose endpoints map[]
Aug 27 08:45:13.638: INFO: successfully validated that service endpoint-test2 in namespace services-5233 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5233
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5233 to expose endpoints map[pod1:[80]]
Aug 27 08:45:15.721: INFO: successfully validated that service endpoint-test2 in namespace services-5233 exposes endpoints map[pod1:[80]]
STEP: Creating pod pod2 in namespace services-5233
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5233 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 27 08:45:17.806: INFO: successfully validated that service endpoint-test2 in namespace services-5233 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Deleting pod pod1 in namespace services-5233
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5233 to expose endpoints map[pod2:[80]]
Aug 27 08:45:17.832: INFO: successfully validated that service endpoint-test2 in namespace services-5233 exposes endpoints map[pod2:[80]]
STEP: Deleting pod pod2 in namespace services-5233
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5233 to expose endpoints map[]
Aug 27 08:45:17.861: INFO: successfully validated that service endpoint-test2 in namespace services-5233 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:45:17.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5233" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786
•{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":303,"completed":89,"skipped":1368,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:45:17.901: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name secret-test-map-4cc4e5da-a98f-4bc0-85e8-ec70256b7534
STEP: Creating a pod to test consume secrets
Aug 27 08:45:17.965: INFO: Waiting up to 5m0s for pod "pod-secrets-76846efd-fdc5-4c5a-ad4f-1e41ce59ee03" in namespace "secrets-7128" to be "Succeeded or Failed"
Aug 27 08:45:17.974: INFO: Pod "pod-secrets-76846efd-fdc5-4c5a-ad4f-1e41ce59ee03": Phase="Pending", Reason="", readiness=false. Elapsed: 8.726572ms
Aug 27 08:45:19.991: INFO: Pod "pod-secrets-76846efd-fdc5-4c5a-ad4f-1e41ce59ee03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026126467s
STEP: Saw pod success
Aug 27 08:45:19.992: INFO: Pod "pod-secrets-76846efd-fdc5-4c5a-ad4f-1e41ce59ee03" satisfied condition "Succeeded or Failed"
Aug 27 08:45:19.994: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-secrets-76846efd-fdc5-4c5a-ad4f-1e41ce59ee03 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 08:45:20.053: INFO: Waiting for pod pod-secrets-76846efd-fdc5-4c5a-ad4f-1e41ce59ee03 to disappear
Aug 27 08:45:20.082: INFO: Pod pod-secrets-76846efd-fdc5-4c5a-ad4f-1e41ce59ee03 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:45:20.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7128" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":303,"completed":90,"skipped":1380,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:45:20.091: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 27 08:45:20.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4358'
Aug 27 08:45:20.332: INFO: stderr: ""
Aug 27 08:45:20.332: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1550
Aug 27 08:45:20.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete pods e2e-test-httpd-pod --namespace=kubectl-4358'
Aug 27 08:45:33.305: INFO: stderr: ""
Aug 27 08:45:33.305: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:45:33.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4358" for this suite.

• [SLOW TEST:13.220 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1541
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":303,"completed":91,"skipped":1380,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:45:33.312: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 08:45:33.361: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22a323cd-fd53-4f56-955e-0a09ed325d4a" in namespace "projected-5954" to be "Succeeded or Failed"
Aug 27 08:45:33.369: INFO: Pod "downwardapi-volume-22a323cd-fd53-4f56-955e-0a09ed325d4a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.736223ms
Aug 27 08:45:35.381: INFO: Pod "downwardapi-volume-22a323cd-fd53-4f56-955e-0a09ed325d4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020327396s
STEP: Saw pod success
Aug 27 08:45:35.382: INFO: Pod "downwardapi-volume-22a323cd-fd53-4f56-955e-0a09ed325d4a" satisfied condition "Succeeded or Failed"
Aug 27 08:45:35.387: INFO: Trying to get logs from node ip-10-0-2-216 pod downwardapi-volume-22a323cd-fd53-4f56-955e-0a09ed325d4a container client-container: <nil>
STEP: delete the pod
Aug 27 08:45:35.409: INFO: Waiting for pod downwardapi-volume-22a323cd-fd53-4f56-955e-0a09ed325d4a to disappear
Aug 27 08:45:35.412: INFO: Pod downwardapi-volume-22a323cd-fd53-4f56-955e-0a09ed325d4a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:45:35.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5954" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":92,"skipped":1386,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:45:35.434: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 08:45:36.172: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Aug 27 08:45:38.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114736, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114736, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114736, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114736, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 08:45:41.223: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Aug 27 08:45:44.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 attach --namespace=webhook-5818 to-be-attached-pod -i -c=container1'
Aug 27 08:45:44.495: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:45:44.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5818" for this suite.
STEP: Destroying namespace "webhook-5818-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.120 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":303,"completed":93,"skipped":1401,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:45:44.556: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Aug 27 08:45:44.615: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Aug 27 08:45:57.414: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:46:00.412: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:46:14.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4800" for this suite.

• [SLOW TEST:29.992 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":303,"completed":94,"skipped":1410,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:46:14.552: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Aug 27 08:46:14.597: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Aug 27 08:46:14.602: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 27 08:46:14.603: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Aug 27 08:46:14.611: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 27 08:46:14.612: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Aug 27 08:46:14.628: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Aug 27 08:46:14.629: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Aug 27 08:46:21.697: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:46:21.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-5323" for this suite.

• [SLOW TEST:7.161 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":303,"completed":95,"skipped":1421,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:46:21.714: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:89
Aug 27 08:46:21.777: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 08:47:21.799: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Create pods that use 2/3 of node resources.
Aug 27 08:47:21.824: INFO: Created pod: pod0-sched-preemption-low-priority
Aug 27 08:47:21.848: INFO: Created pod: pod1-sched-preemption-medium-priority
Aug 27 08:47:21.885: INFO: Created pod: pod2-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:47:55.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8197" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:77

• [SLOW TEST:94.263 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":303,"completed":96,"skipped":1432,"failed":0}
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:47:55.980: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0827 08:48:02.071844      19 metrics_grabber.go:105] Did not receive an external client interface. Grabbing metrics from ClusterAutoscaler is disabled.
Aug 27 08:48:04.113: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:04.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5104" for this suite.

• [SLOW TEST:8.145 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":303,"completed":97,"skipped":1432,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:04.130: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap that has name configmap-test-emptyKey-96f19bd5-e192-47d0-83c9-5e11ec6674ee
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:04.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8526" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":303,"completed":98,"skipped":1443,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:04.216: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 08:48:04.663: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 08:48:06.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114884, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114884, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114884, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734114884, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 08:48:09.686: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:09.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7230" for this suite.
STEP: Destroying namespace "webhook-7230-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.572 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":303,"completed":99,"skipped":1462,"failed":0}
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:09.790: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 08:48:09.852: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75dfd79a-2b20-4131-91dc-d7fec802c152" in namespace "downward-api-8012" to be "Succeeded or Failed"
Aug 27 08:48:09.860: INFO: Pod "downwardapi-volume-75dfd79a-2b20-4131-91dc-d7fec802c152": Phase="Pending", Reason="", readiness=false. Elapsed: 7.266854ms
Aug 27 08:48:11.863: INFO: Pod "downwardapi-volume-75dfd79a-2b20-4131-91dc-d7fec802c152": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010924353s
STEP: Saw pod success
Aug 27 08:48:11.863: INFO: Pod "downwardapi-volume-75dfd79a-2b20-4131-91dc-d7fec802c152" satisfied condition "Succeeded or Failed"
Aug 27 08:48:11.869: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-75dfd79a-2b20-4131-91dc-d7fec802c152 container client-container: <nil>
STEP: delete the pod
Aug 27 08:48:11.913: INFO: Waiting for pod downwardapi-volume-75dfd79a-2b20-4131-91dc-d7fec802c152 to disappear
Aug 27 08:48:11.916: INFO: Pod downwardapi-volume-75dfd79a-2b20-4131-91dc-d7fec802c152 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:11.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8012" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":303,"completed":100,"skipped":1462,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:11.929: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:15.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2680" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":303,"completed":101,"skipped":1476,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:15.984: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating secret secrets-125/secret-test-31e2b548-5bc2-4eb8-b6d1-0eb157ef4c0a
STEP: Creating a pod to test consume secrets
Aug 27 08:48:16.031: INFO: Waiting up to 5m0s for pod "pod-configmaps-d54f9aa9-ff45-4776-8915-04ca2424c609" in namespace "secrets-125" to be "Succeeded or Failed"
Aug 27 08:48:16.034: INFO: Pod "pod-configmaps-d54f9aa9-ff45-4776-8915-04ca2424c609": Phase="Pending", Reason="", readiness=false. Elapsed: 2.855105ms
Aug 27 08:48:18.037: INFO: Pod "pod-configmaps-d54f9aa9-ff45-4776-8915-04ca2424c609": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005928084s
STEP: Saw pod success
Aug 27 08:48:18.037: INFO: Pod "pod-configmaps-d54f9aa9-ff45-4776-8915-04ca2424c609" satisfied condition "Succeeded or Failed"
Aug 27 08:48:18.039: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-d54f9aa9-ff45-4776-8915-04ca2424c609 container env-test: <nil>
STEP: delete the pod
Aug 27 08:48:18.067: INFO: Waiting for pod pod-configmaps-d54f9aa9-ff45-4776-8915-04ca2424c609 to disappear
Aug 27 08:48:18.072: INFO: Pod pod-configmaps-d54f9aa9-ff45-4776-8915-04ca2424c609 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:18.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-125" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":303,"completed":102,"skipped":1482,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:18.080: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 27 08:48:18.128: INFO: Waiting up to 5m0s for pod "pod-d8b995c5-cfa3-4ef1-94b5-68c78ab1bbce" in namespace "emptydir-1783" to be "Succeeded or Failed"
Aug 27 08:48:18.132: INFO: Pod "pod-d8b995c5-cfa3-4ef1-94b5-68c78ab1bbce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.969286ms
Aug 27 08:48:20.136: INFO: Pod "pod-d8b995c5-cfa3-4ef1-94b5-68c78ab1bbce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007321152s
Aug 27 08:48:22.141: INFO: Pod "pod-d8b995c5-cfa3-4ef1-94b5-68c78ab1bbce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011995389s
STEP: Saw pod success
Aug 27 08:48:22.141: INFO: Pod "pod-d8b995c5-cfa3-4ef1-94b5-68c78ab1bbce" satisfied condition "Succeeded or Failed"
Aug 27 08:48:22.144: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-d8b995c5-cfa3-4ef1-94b5-68c78ab1bbce container test-container: <nil>
STEP: delete the pod
Aug 27 08:48:22.161: INFO: Waiting for pod pod-d8b995c5-cfa3-4ef1-94b5-68c78ab1bbce to disappear
Aug 27 08:48:22.166: INFO: Pod pod-d8b995c5-cfa3-4ef1-94b5-68c78ab1bbce no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:22.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1783" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":103,"skipped":1497,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:22.184: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:29.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7580" for this suite.

• [SLOW TEST:7.094 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":303,"completed":104,"skipped":1508,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:29.279: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 27 08:48:29.333: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3610 /api/v1/namespaces/watch-3610/configmaps/e2e-watch-test-label-changed 6a058f5b-698a-41cf-8129-469cc3176898 14116 0 2020-08-27 08:48:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-08-27 08:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:48:29.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3610 /api/v1/namespaces/watch-3610/configmaps/e2e-watch-test-label-changed 6a058f5b-698a-41cf-8129-469cc3176898 14117 0 2020-08-27 08:48:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-08-27 08:48:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:48:29.334: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3610 /api/v1/namespaces/watch-3610/configmaps/e2e-watch-test-label-changed 6a058f5b-698a-41cf-8129-469cc3176898 14118 0 2020-08-27 08:48:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-08-27 08:48:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 27 08:48:39.359: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3610 /api/v1/namespaces/watch-3610/configmaps/e2e-watch-test-label-changed 6a058f5b-698a-41cf-8129-469cc3176898 14151 0 2020-08-27 08:48:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-08-27 08:48:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:48:39.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3610 /api/v1/namespaces/watch-3610/configmaps/e2e-watch-test-label-changed 6a058f5b-698a-41cf-8129-469cc3176898 14152 0 2020-08-27 08:48:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-08-27 08:48:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 08:48:39.361: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3610 /api/v1/namespaces/watch-3610/configmaps/e2e-watch-test-label-changed 6a058f5b-698a-41cf-8129-469cc3176898 14153 0 2020-08-27 08:48:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-08-27 08:48:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:39.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3610" for this suite.

• [SLOW TEST:10.091 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":303,"completed":105,"skipped":1526,"failed":0}
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:39.371: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 08:48:39.421: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6dc3cec0-3aac-401c-bc5d-32ec152be049" in namespace "projected-8502" to be "Succeeded or Failed"
Aug 27 08:48:39.425: INFO: Pod "downwardapi-volume-6dc3cec0-3aac-401c-bc5d-32ec152be049": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012708ms
Aug 27 08:48:41.428: INFO: Pod "downwardapi-volume-6dc3cec0-3aac-401c-bc5d-32ec152be049": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007542172s
Aug 27 08:48:43.432: INFO: Pod "downwardapi-volume-6dc3cec0-3aac-401c-bc5d-32ec152be049": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011350305s
STEP: Saw pod success
Aug 27 08:48:43.433: INFO: Pod "downwardapi-volume-6dc3cec0-3aac-401c-bc5d-32ec152be049" satisfied condition "Succeeded or Failed"
Aug 27 08:48:43.435: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-6dc3cec0-3aac-401c-bc5d-32ec152be049 container client-container: <nil>
STEP: delete the pod
Aug 27 08:48:43.458: INFO: Waiting for pod downwardapi-volume-6dc3cec0-3aac-401c-bc5d-32ec152be049 to disappear
Aug 27 08:48:43.463: INFO: Pod downwardapi-volume-6dc3cec0-3aac-401c-bc5d-32ec152be049 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:43.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8502" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":303,"completed":106,"skipped":1526,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:43.474: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:49.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2958" for this suite.

• [SLOW TEST:5.658 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":303,"completed":107,"skipped":1540,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:49.133: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:39
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:48:49.830: INFO: Checking APIGroup: apiregistration.k8s.io
Aug 27 08:48:49.832: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Aug 27 08:48:49.832: INFO: Versions found [{apiregistration.k8s.io/v1 v1} {apiregistration.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.832: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Aug 27 08:48:49.833: INFO: Checking APIGroup: extensions
Aug 27 08:48:49.834: INFO: PreferredVersion.GroupVersion: extensions/v1beta1
Aug 27 08:48:49.834: INFO: Versions found [{extensions/v1beta1 v1beta1}]
Aug 27 08:48:49.834: INFO: extensions/v1beta1 matches extensions/v1beta1
Aug 27 08:48:49.835: INFO: Checking APIGroup: apps
Aug 27 08:48:49.836: INFO: PreferredVersion.GroupVersion: apps/v1
Aug 27 08:48:49.836: INFO: Versions found [{apps/v1 v1}]
Aug 27 08:48:49.837: INFO: apps/v1 matches apps/v1
Aug 27 08:48:49.837: INFO: Checking APIGroup: events.k8s.io
Aug 27 08:48:49.838: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Aug 27 08:48:49.838: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.839: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Aug 27 08:48:49.839: INFO: Checking APIGroup: authentication.k8s.io
Aug 27 08:48:49.840: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Aug 27 08:48:49.840: INFO: Versions found [{authentication.k8s.io/v1 v1} {authentication.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.841: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Aug 27 08:48:49.841: INFO: Checking APIGroup: authorization.k8s.io
Aug 27 08:48:49.842: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Aug 27 08:48:49.842: INFO: Versions found [{authorization.k8s.io/v1 v1} {authorization.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.842: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Aug 27 08:48:49.842: INFO: Checking APIGroup: autoscaling
Aug 27 08:48:49.844: INFO: PreferredVersion.GroupVersion: autoscaling/v1
Aug 27 08:48:49.844: INFO: Versions found [{autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Aug 27 08:48:49.844: INFO: autoscaling/v1 matches autoscaling/v1
Aug 27 08:48:49.844: INFO: Checking APIGroup: batch
Aug 27 08:48:49.846: INFO: PreferredVersion.GroupVersion: batch/v1
Aug 27 08:48:49.846: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Aug 27 08:48:49.846: INFO: batch/v1 matches batch/v1
Aug 27 08:48:49.846: INFO: Checking APIGroup: certificates.k8s.io
Aug 27 08:48:49.847: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Aug 27 08:48:49.847: INFO: Versions found [{certificates.k8s.io/v1 v1} {certificates.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.847: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Aug 27 08:48:49.847: INFO: Checking APIGroup: networking.k8s.io
Aug 27 08:48:49.848: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Aug 27 08:48:49.848: INFO: Versions found [{networking.k8s.io/v1 v1} {networking.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.848: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Aug 27 08:48:49.848: INFO: Checking APIGroup: policy
Aug 27 08:48:49.850: INFO: PreferredVersion.GroupVersion: policy/v1beta1
Aug 27 08:48:49.850: INFO: Versions found [{policy/v1beta1 v1beta1}]
Aug 27 08:48:49.850: INFO: policy/v1beta1 matches policy/v1beta1
Aug 27 08:48:49.850: INFO: Checking APIGroup: rbac.authorization.k8s.io
Aug 27 08:48:49.851: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Aug 27 08:48:49.851: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1} {rbac.authorization.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.851: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Aug 27 08:48:49.851: INFO: Checking APIGroup: storage.k8s.io
Aug 27 08:48:49.852: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Aug 27 08:48:49.852: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.852: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Aug 27 08:48:49.852: INFO: Checking APIGroup: admissionregistration.k8s.io
Aug 27 08:48:49.853: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Aug 27 08:48:49.853: INFO: Versions found [{admissionregistration.k8s.io/v1 v1} {admissionregistration.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.853: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Aug 27 08:48:49.853: INFO: Checking APIGroup: apiextensions.k8s.io
Aug 27 08:48:49.854: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Aug 27 08:48:49.854: INFO: Versions found [{apiextensions.k8s.io/v1 v1} {apiextensions.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.854: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Aug 27 08:48:49.854: INFO: Checking APIGroup: scheduling.k8s.io
Aug 27 08:48:49.855: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Aug 27 08:48:49.856: INFO: Versions found [{scheduling.k8s.io/v1 v1} {scheduling.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.856: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Aug 27 08:48:49.856: INFO: Checking APIGroup: coordination.k8s.io
Aug 27 08:48:49.857: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Aug 27 08:48:49.858: INFO: Versions found [{coordination.k8s.io/v1 v1} {coordination.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.858: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Aug 27 08:48:49.858: INFO: Checking APIGroup: node.k8s.io
Aug 27 08:48:49.859: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1beta1
Aug 27 08:48:49.859: INFO: Versions found [{node.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.860: INFO: node.k8s.io/v1beta1 matches node.k8s.io/v1beta1
Aug 27 08:48:49.860: INFO: Checking APIGroup: discovery.k8s.io
Aug 27 08:48:49.861: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1beta1
Aug 27 08:48:49.861: INFO: Versions found [{discovery.k8s.io/v1beta1 v1beta1}]
Aug 27 08:48:49.861: INFO: discovery.k8s.io/v1beta1 matches discovery.k8s.io/v1beta1
Aug 27 08:48:49.861: INFO: Checking APIGroup: crd.projectcalico.org
Aug 27 08:48:49.862: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Aug 27 08:48:49.863: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Aug 27 08:48:49.863: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
[AfterEach] [sig-api-machinery] Discovery
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:48:49.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-1393" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":303,"completed":108,"skipped":1546,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should succeed in writing subpaths in container [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:48:49.875: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should succeed in writing subpaths in container [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Aug 27 08:48:53.922: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5929 PodName:var-expansion-535b181f-f2e1-4bef-b105-76663b14fa29 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:48:53.923: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: test for file in mounted path
Aug 27 08:48:54.082: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5929 PodName:var-expansion-535b181f-f2e1-4bef-b105-76663b14fa29 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:48:54.083: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: updating the annotation value
Aug 27 08:48:54.695: INFO: Successfully updated pod "var-expansion-535b181f-f2e1-4bef-b105-76663b14fa29"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Aug 27 08:48:54.700: INFO: Deleting pod "var-expansion-535b181f-f2e1-4bef-b105-76663b14fa29" in namespace "var-expansion-5929"
Aug 27 08:48:54.705: INFO: Wait up to 5m0s for pod "var-expansion-535b181f-f2e1-4bef-b105-76663b14fa29" to be fully deleted
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:49:28.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5929" for this suite.

• [SLOW TEST:38.847 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should succeed in writing subpaths in container [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should succeed in writing subpaths in container [sig-storage][Slow] [Conformance]","total":303,"completed":109,"skipped":1574,"failed":0}
SS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:49:28.722: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service nodeport-test with type=NodePort in namespace services-2199
STEP: creating replication controller nodeport-test in namespace services-2199
I0827 08:49:28.821761      19 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-2199, replica count: 2
Aug 27 08:49:31.882: INFO: Creating new exec pod
I0827 08:49:31.882634      19 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 08:49:34.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2199 execpodjs5mb -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Aug 27 08:49:35.205: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 27 08:49:35.205: INFO: stdout: ""
Aug 27 08:49:35.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2199 execpodjs5mb -- /bin/sh -x -c nc -zv -t -w 2 10.3.131.97 80'
Aug 27 08:49:35.433: INFO: stderr: "+ nc -zv -t -w 2 10.3.131.97 80\nConnection to 10.3.131.97 80 port [tcp/http] succeeded!\n"
Aug 27 08:49:35.433: INFO: stdout: ""
Aug 27 08:49:35.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2199 execpodjs5mb -- /bin/sh -x -c nc -zv -t -w 2 10.0.45.43 32060'
Aug 27 08:49:35.651: INFO: stderr: "+ nc -zv -t -w 2 10.0.45.43 32060\nConnection to 10.0.45.43 32060 port [tcp/32060] succeeded!\n"
Aug 27 08:49:35.651: INFO: stdout: ""
Aug 27 08:49:35.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2199 execpodjs5mb -- /bin/sh -x -c nc -zv -t -w 2 10.0.27.251 32060'
Aug 27 08:49:35.850: INFO: stderr: "+ nc -zv -t -w 2 10.0.27.251 32060\nConnection to 10.0.27.251 32060 port [tcp/32060] succeeded!\n"
Aug 27 08:49:35.850: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:49:35.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2199" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:7.137 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":303,"completed":110,"skipped":1576,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:49:35.859: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 27 08:49:36.234: INFO: Pod name wrapped-volume-race-63af3664-a436-4c4c-ae29-43f95a36a3ef: Found 1 pods out of 5
Aug 27 08:49:41.247: INFO: Pod name wrapped-volume-race-63af3664-a436-4c4c-ae29-43f95a36a3ef: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-63af3664-a436-4c4c-ae29-43f95a36a3ef in namespace emptydir-wrapper-7525, will wait for the garbage collector to delete the pods
Aug 27 08:49:55.340: INFO: Deleting ReplicationController wrapped-volume-race-63af3664-a436-4c4c-ae29-43f95a36a3ef took: 7.955169ms
Aug 27 08:49:55.941: INFO: Terminating ReplicationController wrapped-volume-race-63af3664-a436-4c4c-ae29-43f95a36a3ef pods took: 600.901215ms
STEP: Creating RC which spawns configmap-volume pods
Aug 27 08:50:04.257: INFO: Pod name wrapped-volume-race-ee8cd7cd-208e-4b44-a425-91647e59cd0e: Found 0 pods out of 5
Aug 27 08:50:09.263: INFO: Pod name wrapped-volume-race-ee8cd7cd-208e-4b44-a425-91647e59cd0e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ee8cd7cd-208e-4b44-a425-91647e59cd0e in namespace emptydir-wrapper-7525, will wait for the garbage collector to delete the pods
Aug 27 08:50:23.446: INFO: Deleting ReplicationController wrapped-volume-race-ee8cd7cd-208e-4b44-a425-91647e59cd0e took: 7.242673ms
Aug 27 08:50:24.146: INFO: Terminating ReplicationController wrapped-volume-race-ee8cd7cd-208e-4b44-a425-91647e59cd0e pods took: 700.639367ms
STEP: Creating RC which spawns configmap-volume pods
Aug 27 08:50:35.720: INFO: Pod name wrapped-volume-race-0bdca1d0-dc6e-4c43-b59c-e043ce550e37: Found 3 pods out of 5
Aug 27 08:50:40.726: INFO: Pod name wrapped-volume-race-0bdca1d0-dc6e-4c43-b59c-e043ce550e37: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0bdca1d0-dc6e-4c43-b59c-e043ce550e37 in namespace emptydir-wrapper-7525, will wait for the garbage collector to delete the pods
Aug 27 08:50:50.850: INFO: Deleting ReplicationController wrapped-volume-race-0bdca1d0-dc6e-4c43-b59c-e043ce550e37 took: 6.618995ms
Aug 27 08:50:51.450: INFO: Terminating ReplicationController wrapped-volume-race-0bdca1d0-dc6e-4c43-b59c-e043ce550e37 pods took: 600.204602ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:04.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7525" for this suite.

• [SLOW TEST:88.956 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":303,"completed":111,"skipped":1583,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:04.823: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:04.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9177" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":303,"completed":112,"skipped":1614,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:04.896: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:06.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7370" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":303,"completed":113,"skipped":1634,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:06.979: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 27 08:51:13.079: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.079: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.176: INFO: Exec stderr: ""
Aug 27 08:51:13.177: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.177: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.280: INFO: Exec stderr: ""
Aug 27 08:51:13.281: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.281: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.373: INFO: Exec stderr: ""
Aug 27 08:51:13.374: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.374: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.482: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 27 08:51:13.483: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.483: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.600: INFO: Exec stderr: ""
Aug 27 08:51:13.601: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.601: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.698: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 27 08:51:13.699: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.699: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.786: INFO: Exec stderr: ""
Aug 27 08:51:13.787: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.787: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.870: INFO: Exec stderr: ""
Aug 27 08:51:13.871: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.871: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:13.967: INFO: Exec stderr: ""
Aug 27 08:51:13.967: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2796 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 08:51:13.967: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 08:51:14.102: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:14.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2796" for this suite.

• [SLOW TEST:7.143 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":114,"skipped":1667,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:14.123: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4975.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4975.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4975.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4975.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4975.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4975.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 08:51:26.232: INFO: DNS probes using dns-4975/dns-test-bed57651-5561-413b-942c-306d51b20502 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:26.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4975" for this suite.

• [SLOW TEST:12.300 seconds]
[sig-network] DNS
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":303,"completed":115,"skipped":1688,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:26.423: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 27 08:51:26.509: INFO: Waiting up to 5m0s for pod "pod-89ae327f-7ef8-4bc8-bbf2-3a474cba32b2" in namespace "emptydir-7682" to be "Succeeded or Failed"
Aug 27 08:51:26.522: INFO: Pod "pod-89ae327f-7ef8-4bc8-bbf2-3a474cba32b2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.615647ms
Aug 27 08:51:28.527: INFO: Pod "pod-89ae327f-7ef8-4bc8-bbf2-3a474cba32b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017124632s
Aug 27 08:51:30.530: INFO: Pod "pod-89ae327f-7ef8-4bc8-bbf2-3a474cba32b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020587519s
STEP: Saw pod success
Aug 27 08:51:30.530: INFO: Pod "pod-89ae327f-7ef8-4bc8-bbf2-3a474cba32b2" satisfied condition "Succeeded or Failed"
Aug 27 08:51:30.533: INFO: Trying to get logs from node ip-10-0-27-251 pod pod-89ae327f-7ef8-4bc8-bbf2-3a474cba32b2 container test-container: <nil>
STEP: delete the pod
Aug 27 08:51:30.566: INFO: Waiting for pod pod-89ae327f-7ef8-4bc8-bbf2-3a474cba32b2 to disappear
Aug 27 08:51:30.570: INFO: Pod pod-89ae327f-7ef8-4bc8-bbf2-3a474cba32b2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:30.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7682" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":116,"skipped":1696,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:30.595: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 08:51:30.708: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6348ed3b-ca95-4b31-8400-24b5609d04bd" in namespace "downward-api-9283" to be "Succeeded or Failed"
Aug 27 08:51:30.711: INFO: Pod "downwardapi-volume-6348ed3b-ca95-4b31-8400-24b5609d04bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.240807ms
Aug 27 08:51:32.714: INFO: Pod "downwardapi-volume-6348ed3b-ca95-4b31-8400-24b5609d04bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005748969s
Aug 27 08:51:34.718: INFO: Pod "downwardapi-volume-6348ed3b-ca95-4b31-8400-24b5609d04bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009170081s
STEP: Saw pod success
Aug 27 08:51:34.718: INFO: Pod "downwardapi-volume-6348ed3b-ca95-4b31-8400-24b5609d04bd" satisfied condition "Succeeded or Failed"
Aug 27 08:51:34.720: INFO: Trying to get logs from node ip-10-0-27-251 pod downwardapi-volume-6348ed3b-ca95-4b31-8400-24b5609d04bd container client-container: <nil>
STEP: delete the pod
Aug 27 08:51:34.739: INFO: Waiting for pod downwardapi-volume-6348ed3b-ca95-4b31-8400-24b5609d04bd to disappear
Aug 27 08:51:34.745: INFO: Pod downwardapi-volume-6348ed3b-ca95-4b31-8400-24b5609d04bd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:34.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9283" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":117,"skipped":1718,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:34.763: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-upd-48a8c759-66a1-4df7-b1f1-86033692dfdd
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-48a8c759-66a1-4df7-b1f1-86033692dfdd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:38.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2702" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":303,"completed":118,"skipped":1730,"failed":0}
SSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:38.865: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 08:51:38.909: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-d0a0c325-cbe8-4f64-9a3f-a803f97cedc0" in namespace "security-context-test-998" to be "Succeeded or Failed"
Aug 27 08:51:38.913: INFO: Pod "busybox-readonly-false-d0a0c325-cbe8-4f64-9a3f-a803f97cedc0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.649179ms
Aug 27 08:51:40.918: INFO: Pod "busybox-readonly-false-d0a0c325-cbe8-4f64-9a3f-a803f97cedc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008622184s
Aug 27 08:51:42.931: INFO: Pod "busybox-readonly-false-d0a0c325-cbe8-4f64-9a3f-a803f97cedc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021684291s
Aug 27 08:51:42.931: INFO: Pod "busybox-readonly-false-d0a0c325-cbe8-4f64-9a3f-a803f97cedc0" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:51:42.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-998" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":303,"completed":119,"skipped":1734,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:51:42.983: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:103
STEP: Creating service test in namespace statefulset-5650
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5650
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5650
Aug 27 08:51:43.082: INFO: Found 0 stateful pods, waiting for 1
Aug 27 08:51:53.092: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 27 08:51:53.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-5650 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 08:51:53.331: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 08:51:53.331: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 08:51:53.331: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 08:51:53.334: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 27 08:52:03.339: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 08:52:03.339: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 08:52:03.353: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999682s
Aug 27 08:52:04.360: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995136287s
Aug 27 08:52:05.364: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988318971s
Aug 27 08:52:06.368: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984552743s
Aug 27 08:52:07.372: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979256778s
Aug 27 08:52:08.377: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975143111s
Aug 27 08:52:09.381: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970267675s
Aug 27 08:52:10.395: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967091684s
Aug 27 08:52:11.445: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.952588311s
Aug 27 08:52:12.453: INFO: Verifying statefulset ss doesn't scale past 1 for another 903.748559ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5650
Aug 27 08:52:13.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-5650 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 08:52:14.165: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 08:52:14.165: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 08:52:14.165: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 08:52:14.169: INFO: Found 2 stateful pods, waiting for 3
Aug 27 08:52:24.173: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 08:52:24.173: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 08:52:24.173: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 27 08:52:24.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-5650 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 08:52:24.580: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 08:52:24.580: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 08:52:24.580: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 08:52:24.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-5650 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 08:52:24.786: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 08:52:24.786: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 08:52:24.786: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 08:52:24.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-5650 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 08:52:25.883: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 08:52:25.883: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 08:52:25.883: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 08:52:25.883: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 08:52:25.886: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 27 08:52:35.896: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 08:52:35.896: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 08:52:35.896: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 08:52:35.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999362s
Aug 27 08:52:36.941: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.983247501s
Aug 27 08:52:37.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97840964s
Aug 27 08:52:38.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.974488716s
Aug 27 08:52:40.015: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.96653586s
Aug 27 08:52:41.020: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.904701278s
Aug 27 08:52:42.025: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.899211775s
Aug 27 08:52:43.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.894788102s
Aug 27 08:52:44.036: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.889459526s
Aug 27 08:52:45.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 883.124271ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5650
Aug 27 08:52:46.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-5650 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 08:52:46.311: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 08:52:46.311: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 08:52:46.311: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 08:52:46.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-5650 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 08:52:46.548: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 08:52:46.548: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 08:52:46.548: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 08:52:46.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-5650 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 08:52:46.801: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 08:52:46.801: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 08:52:46.801: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 08:52:46.801: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:114
Aug 27 08:53:16.835: INFO: Deleting all statefulset in ns statefulset-5650
Aug 27 08:53:16.838: INFO: Scaling statefulset ss to 0
Aug 27 08:53:16.851: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 08:53:16.853: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:53:16.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5650" for this suite.

• [SLOW TEST:93.904 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":303,"completed":120,"skipped":1745,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:53:16.890: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 27 08:53:16.969: INFO: Waiting up to 5m0s for pod "pod-2d2a36c5-a2ca-411c-a1b9-442e24a8ac29" in namespace "emptydir-4500" to be "Succeeded or Failed"
Aug 27 08:53:16.973: INFO: Pod "pod-2d2a36c5-a2ca-411c-a1b9-442e24a8ac29": Phase="Pending", Reason="", readiness=false. Elapsed: 3.968039ms
Aug 27 08:53:18.976: INFO: Pod "pod-2d2a36c5-a2ca-411c-a1b9-442e24a8ac29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007023635s
Aug 27 08:53:20.980: INFO: Pod "pod-2d2a36c5-a2ca-411c-a1b9-442e24a8ac29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010964036s
STEP: Saw pod success
Aug 27 08:53:20.980: INFO: Pod "pod-2d2a36c5-a2ca-411c-a1b9-442e24a8ac29" satisfied condition "Succeeded or Failed"
Aug 27 08:53:20.983: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-2d2a36c5-a2ca-411c-a1b9-442e24a8ac29 container test-container: <nil>
STEP: delete the pod
Aug 27 08:53:21.013: INFO: Waiting for pod pod-2d2a36c5-a2ca-411c-a1b9-442e24a8ac29 to disappear
Aug 27 08:53:21.017: INFO: Pod pod-2d2a36c5-a2ca-411c-a1b9-442e24a8ac29 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:53:21.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4500" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":121,"skipped":1747,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:53:21.043: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 08:53:21.089: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60e64ed4-7259-4c45-b410-f759a43cc34a" in namespace "projected-5487" to be "Succeeded or Failed"
Aug 27 08:53:21.093: INFO: Pod "downwardapi-volume-60e64ed4-7259-4c45-b410-f759a43cc34a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.489182ms
Aug 27 08:53:23.097: INFO: Pod "downwardapi-volume-60e64ed4-7259-4c45-b410-f759a43cc34a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007243964s
Aug 27 08:53:25.100: INFO: Pod "downwardapi-volume-60e64ed4-7259-4c45-b410-f759a43cc34a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010943984s
STEP: Saw pod success
Aug 27 08:53:25.101: INFO: Pod "downwardapi-volume-60e64ed4-7259-4c45-b410-f759a43cc34a" satisfied condition "Succeeded or Failed"
Aug 27 08:53:25.103: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-60e64ed4-7259-4c45-b410-f759a43cc34a container client-container: <nil>
STEP: delete the pod
Aug 27 08:53:25.174: INFO: Waiting for pod downwardapi-volume-60e64ed4-7259-4c45-b410-f759a43cc34a to disappear
Aug 27 08:53:25.179: INFO: Pod downwardapi-volume-60e64ed4-7259-4c45-b410-f759a43cc34a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:53:25.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5487" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":303,"completed":122,"skipped":1802,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:53:25.205: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name projected-configmap-test-volume-map-89a4c183-5a57-4c5d-b49e-97390d1fd514
STEP: Creating a pod to test consume configMaps
Aug 27 08:53:25.269: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-61e3973a-de41-4b90-abbd-6412d370ac59" in namespace "projected-2319" to be "Succeeded or Failed"
Aug 27 08:53:25.273: INFO: Pod "pod-projected-configmaps-61e3973a-de41-4b90-abbd-6412d370ac59": Phase="Pending", Reason="", readiness=false. Elapsed: 3.349645ms
Aug 27 08:53:27.283: INFO: Pod "pod-projected-configmaps-61e3973a-de41-4b90-abbd-6412d370ac59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012844175s
STEP: Saw pod success
Aug 27 08:53:27.285: INFO: Pod "pod-projected-configmaps-61e3973a-de41-4b90-abbd-6412d370ac59" satisfied condition "Succeeded or Failed"
Aug 27 08:53:27.288: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-configmaps-61e3973a-de41-4b90-abbd-6412d370ac59 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 08:53:27.321: INFO: Waiting for pod pod-projected-configmaps-61e3973a-de41-4b90-abbd-6412d370ac59 to disappear
Aug 27 08:53:27.325: INFO: Pod pod-projected-configmaps-61e3973a-de41-4b90-abbd-6412d370ac59 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:53:27.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2319" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":303,"completed":123,"skipped":1816,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:53:27.337: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[BeforeEach] Update Demo
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:308
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a replication controller
Aug 27 08:53:27.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-7113'
Aug 27 08:53:27.680: INFO: stderr: ""
Aug 27 08:53:27.680: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 08:53:27.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7113'
Aug 27 08:53:27.783: INFO: stderr: ""
Aug 27 08:53:27.783: INFO: stdout: "update-demo-nautilus-vbvcf update-demo-nautilus-wxzkk "
Aug 27 08:53:27.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-vbvcf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7113'
Aug 27 08:53:27.870: INFO: stderr: ""
Aug 27 08:53:27.870: INFO: stdout: ""
Aug 27 08:53:27.870: INFO: update-demo-nautilus-vbvcf is created but not running
Aug 27 08:53:32.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7113'
Aug 27 08:53:32.962: INFO: stderr: ""
Aug 27 08:53:32.962: INFO: stdout: "update-demo-nautilus-vbvcf update-demo-nautilus-wxzkk "
Aug 27 08:53:32.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-vbvcf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7113'
Aug 27 08:53:33.111: INFO: stderr: ""
Aug 27 08:53:33.111: INFO: stdout: "true"
Aug 27 08:53:33.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-vbvcf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7113'
Aug 27 08:53:33.270: INFO: stderr: ""
Aug 27 08:53:33.270: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 08:53:33.270: INFO: validating pod update-demo-nautilus-vbvcf
Aug 27 08:53:33.275: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 08:53:33.275: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 08:53:33.275: INFO: update-demo-nautilus-vbvcf is verified up and running
Aug 27 08:53:33.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-wxzkk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7113'
Aug 27 08:53:33.383: INFO: stderr: ""
Aug 27 08:53:33.383: INFO: stdout: "true"
Aug 27 08:53:33.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-wxzkk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7113'
Aug 27 08:53:33.477: INFO: stderr: ""
Aug 27 08:53:33.477: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 08:53:33.477: INFO: validating pod update-demo-nautilus-wxzkk
Aug 27 08:53:33.481: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 08:53:33.481: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 08:53:33.481: INFO: update-demo-nautilus-wxzkk is verified up and running
STEP: using delete to clean up resources
Aug 27 08:53:33.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-7113'
Aug 27 08:53:33.583: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 08:53:33.583: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 27 08:53:33.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7113'
Aug 27 08:53:33.679: INFO: stderr: "No resources found in kubectl-7113 namespace.\n"
Aug 27 08:53:33.679: INFO: stdout: ""
Aug 27 08:53:33.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -l name=update-demo --namespace=kubectl-7113 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 08:53:33.763: INFO: stderr: ""
Aug 27 08:53:33.763: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:53:33.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7113" for this suite.

• [SLOW TEST:6.434 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:306
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":303,"completed":124,"skipped":1818,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:53:33.772: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 08:53:34.324: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 08:53:36.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734115214, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734115214, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734115214, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734115214, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 08:53:39.350: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:53:49.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2603" for this suite.
STEP: Destroying namespace "webhook-2603-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.412 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":303,"completed":125,"skipped":1852,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:53:50.186: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Starting the proxy
Aug 27 08:53:50.222: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-356341267 proxy --unix-socket=/tmp/kubectl-proxy-unix134618614/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:53:50.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1011" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":303,"completed":126,"skipped":1855,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a volume subpath [sig-storage] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:53:50.339: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a volume subpath [sig-storage] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test substitution in volume subpath
Aug 27 08:53:50.510: INFO: Waiting up to 5m0s for pod "var-expansion-60e6a408-40d6-4aa2-a66a-043d0de80994" in namespace "var-expansion-54" to be "Succeeded or Failed"
Aug 27 08:53:50.513: INFO: Pod "var-expansion-60e6a408-40d6-4aa2-a66a-043d0de80994": Phase="Pending", Reason="", readiness=false. Elapsed: 3.563129ms
Aug 27 08:53:52.518: INFO: Pod "var-expansion-60e6a408-40d6-4aa2-a66a-043d0de80994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0077406s
Aug 27 08:53:54.523: INFO: Pod "var-expansion-60e6a408-40d6-4aa2-a66a-043d0de80994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012741294s
STEP: Saw pod success
Aug 27 08:53:54.523: INFO: Pod "var-expansion-60e6a408-40d6-4aa2-a66a-043d0de80994" satisfied condition "Succeeded or Failed"
Aug 27 08:53:54.526: INFO: Trying to get logs from node ip-10-0-2-216 pod var-expansion-60e6a408-40d6-4aa2-a66a-043d0de80994 container dapi-container: <nil>
STEP: delete the pod
Aug 27 08:53:54.544: INFO: Waiting for pod var-expansion-60e6a408-40d6-4aa2-a66a-043d0de80994 to disappear
Aug 27 08:53:54.548: INFO: Pod var-expansion-60e6a408-40d6-4aa2-a66a-043d0de80994 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:53:54.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-54" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a volume subpath [sig-storage] [Conformance]","total":303,"completed":127,"skipped":1865,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:53:54.564: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating projection with configMap that has name projected-configmap-test-upd-130cf798-9e12-4fd5-b6a3-0868d1acef82
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-130cf798-9e12-4fd5-b6a3-0868d1acef82
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 08:55:03.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8183" for this suite.

• [SLOW TEST:68.624 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":303,"completed":128,"skipped":1896,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 08:55:03.189: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service in namespace services-8097
Aug 27 08:55:05.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug 27 08:55:05.709: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug 27 08:55:05.709: INFO: stdout: "ipvs"
Aug 27 08:55:05.709: INFO: proxyMode: ipvs
Aug 27 08:55:05.726: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:55:05.730: INFO: Pod kube-proxy-mode-detector still exists
Aug 27 08:55:07.730: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:55:07.734: INFO: Pod kube-proxy-mode-detector still exists
Aug 27 08:55:09.730: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:55:09.733: INFO: Pod kube-proxy-mode-detector still exists
Aug 27 08:55:11.730: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:55:11.734: INFO: Pod kube-proxy-mode-detector still exists
Aug 27 08:55:13.730: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:55:13.735: INFO: Pod kube-proxy-mode-detector still exists
Aug 27 08:55:15.730: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 08:55:15.734: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-8097
STEP: creating replication controller affinity-nodeport-timeout in namespace services-8097
I0827 08:55:15.784855      19 runners.go:190] Created replication controller with name: affinity-nodeport-timeout, namespace: services-8097, replica count: 3
I0827 08:55:18.836600      19 runners.go:190] affinity-nodeport-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 08:55:21.836780      19 runners.go:190] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 08:55:21.844: INFO: Creating new exec pod
Aug 27 08:55:24.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c nc -zv -t -w 2 affinity-nodeport-timeout 80'
Aug 27 08:55:25.074: INFO: stderr: "+ nc -zv -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Aug 27 08:55:25.074: INFO: stdout: ""
Aug 27 08:55:25.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c nc -zv -t -w 2 10.3.162.244 80'
Aug 27 08:55:25.523: INFO: stderr: "+ nc -zv -t -w 2 10.3.162.244 80\nConnection to 10.3.162.244 80 port [tcp/http] succeeded!\n"
Aug 27 08:55:25.523: INFO: stdout: ""
Aug 27 08:55:25.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.216 30458'
Aug 27 08:55:25.766: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.216 30458\nConnection to 10.0.2.216 30458 port [tcp/30458] succeeded!\n"
Aug 27 08:55:25.766: INFO: stdout: ""
Aug 27 08:55:25.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c nc -zv -t -w 2 10.0.27.251 30458'
Aug 27 08:55:25.970: INFO: stderr: "+ nc -zv -t -w 2 10.0.27.251 30458\nConnection to 10.0.27.251 30458 port [tcp/30458] succeeded!\n"
Aug 27 08:55:25.970: INFO: stdout: ""
Aug 27 08:55:25.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.2.216:30458/ ; done'
Aug 27 08:55:26.338: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 08:55:26.338: INFO: stdout: "\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb\naffinity-nodeport-timeout-wmrlb"
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Received response from host: affinity-nodeport-timeout-wmrlb
Aug 27 08:55:26.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 08:55:26.554: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 08:55:26.554: INFO: stdout: "affinity-nodeport-timeout-wmrlb"
Aug 27 08:57:31.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 08:57:31.764: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 08:57:31.764: INFO: stdout: "affinity-nodeport-timeout-wmrlb"
Aug 27 08:59:36.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 08:59:36.990: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 08:59:36.991: INFO: stdout: "affinity-nodeport-timeout-wmrlb"
Aug 27 09:01:41.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 09:01:42.274: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 09:01:42.274: INFO: stdout: "affinity-nodeport-timeout-wmrlb"
Aug 27 09:03:47.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 09:03:47.557: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 09:03:47.557: INFO: stdout: "affinity-nodeport-timeout-wmrlb"
Aug 27 09:05:52.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 09:05:52.858: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 09:05:52.858: INFO: stdout: "affinity-nodeport-timeout-wmrlb"
Aug 27 09:07:57.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 09:07:58.214: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 09:07:58.214: INFO: stdout: "affinity-nodeport-timeout-wmrlb"
Aug 27 09:10:03.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 09:10:03.431: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 09:10:03.432: INFO: stdout: "affinity-nodeport-timeout-wmrlb"
Aug 27 09:12:08.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-8097 execpod-affinityp9mk2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.2.216:30458/'
Aug 27 09:12:08.647: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.2.216:30458/\n"
Aug 27 09:12:08.648: INFO: stdout: "affinity-nodeport-timeout-mgpz4"
Aug 27 09:12:08.648: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-8097, will wait for the garbage collector to delete the pods
Aug 27 09:12:08.721: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.057361ms
Aug 27 09:12:09.223: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 501.36971ms
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:24.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8097" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:1041.117 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":303,"completed":129,"skipped":1916,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:24.313: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-volume-6e9b31a0-a933-4d39-9a84-6461b15fff95
STEP: Creating a pod to test consume configMaps
Aug 27 09:12:24.511: INFO: Waiting up to 5m0s for pod "pod-configmaps-e9ec777a-49d5-4a07-9bc7-0060e83fef34" in namespace "configmap-6635" to be "Succeeded or Failed"
Aug 27 09:12:24.637: INFO: Pod "pod-configmaps-e9ec777a-49d5-4a07-9bc7-0060e83fef34": Phase="Pending", Reason="", readiness=false. Elapsed: 126.356237ms
Aug 27 09:12:26.641: INFO: Pod "pod-configmaps-e9ec777a-49d5-4a07-9bc7-0060e83fef34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.129897871s
STEP: Saw pod success
Aug 27 09:12:26.641: INFO: Pod "pod-configmaps-e9ec777a-49d5-4a07-9bc7-0060e83fef34" satisfied condition "Succeeded or Failed"
Aug 27 09:12:26.644: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-e9ec777a-49d5-4a07-9bc7-0060e83fef34 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:12:26.671: INFO: Waiting for pod pod-configmaps-e9ec777a-49d5-4a07-9bc7-0060e83fef34 to disappear
Aug 27 09:12:26.674: INFO: Pod pod-configmaps-e9ec777a-49d5-4a07-9bc7-0060e83fef34 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:26.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6635" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":303,"completed":130,"skipped":1927,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:26.682: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service multi-endpoint-test in namespace services-5066
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5066 to expose endpoints map[]
Aug 27 09:12:26.743: INFO: successfully validated that service multi-endpoint-test in namespace services-5066 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5066
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5066 to expose endpoints map[pod1:[100]]
Aug 27 09:12:28.792: INFO: successfully validated that service multi-endpoint-test in namespace services-5066 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-5066
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5066 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 27 09:12:30.958: INFO: successfully validated that service multi-endpoint-test in namespace services-5066 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Deleting pod pod1 in namespace services-5066
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5066 to expose endpoints map[pod2:[101]]
Aug 27 09:12:31.059: INFO: successfully validated that service multi-endpoint-test in namespace services-5066 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-5066
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5066 to expose endpoints map[]
Aug 27 09:12:32.078: INFO: successfully validated that service multi-endpoint-test in namespace services-5066 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:32.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5066" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:5.424 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":303,"completed":131,"skipped":1948,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:32.110: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward api env vars
Aug 27 09:12:32.157: INFO: Waiting up to 5m0s for pod "downward-api-7d130d58-4976-494a-a90e-2c8d0a239b16" in namespace "downward-api-3076" to be "Succeeded or Failed"
Aug 27 09:12:32.173: INFO: Pod "downward-api-7d130d58-4976-494a-a90e-2c8d0a239b16": Phase="Pending", Reason="", readiness=false. Elapsed: 16.282413ms
Aug 27 09:12:34.222: INFO: Pod "downward-api-7d130d58-4976-494a-a90e-2c8d0a239b16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.064795084s
STEP: Saw pod success
Aug 27 09:12:34.222: INFO: Pod "downward-api-7d130d58-4976-494a-a90e-2c8d0a239b16" satisfied condition "Succeeded or Failed"
Aug 27 09:12:34.225: INFO: Trying to get logs from node ip-10-0-27-251 pod downward-api-7d130d58-4976-494a-a90e-2c8d0a239b16 container dapi-container: <nil>
STEP: delete the pod
Aug 27 09:12:34.265: INFO: Waiting for pod downward-api-7d130d58-4976-494a-a90e-2c8d0a239b16 to disappear
Aug 27 09:12:34.268: INFO: Pod downward-api-7d130d58-4976-494a-a90e-2c8d0a239b16 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:34.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3076" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":303,"completed":132,"skipped":1967,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:34.281: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating the pod
Aug 27 09:12:36.958: INFO: Successfully updated pod "annotationupdate2e6107ec-df84-44c2-868f-8597ddb1230a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:38.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1169" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":303,"completed":133,"skipped":1968,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:38.993: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:12:39.573: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Aug 27 09:12:41.586: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116359, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116359, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116359, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116359, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-85d57b96d6\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:12:44.606: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:12:44.609: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:45.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2714" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:6.810 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":303,"completed":134,"skipped":2042,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:45.811: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:12:45.856: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0e89210-f592-4177-8a64-2fc0db491d9d" in namespace "projected-7639" to be "Succeeded or Failed"
Aug 27 09:12:45.861: INFO: Pod "downwardapi-volume-c0e89210-f592-4177-8a64-2fc0db491d9d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052641ms
Aug 27 09:12:47.865: INFO: Pod "downwardapi-volume-c0e89210-f592-4177-8a64-2fc0db491d9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008610308s
STEP: Saw pod success
Aug 27 09:12:47.866: INFO: Pod "downwardapi-volume-c0e89210-f592-4177-8a64-2fc0db491d9d" satisfied condition "Succeeded or Failed"
Aug 27 09:12:47.869: INFO: Trying to get logs from node ip-10-0-2-216 pod downwardapi-volume-c0e89210-f592-4177-8a64-2fc0db491d9d container client-container: <nil>
STEP: delete the pod
Aug 27 09:12:47.890: INFO: Waiting for pod downwardapi-volume-c0e89210-f592-4177-8a64-2fc0db491d9d to disappear
Aug 27 09:12:47.897: INFO: Pod downwardapi-volume-c0e89210-f592-4177-8a64-2fc0db491d9d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:47.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7639" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":303,"completed":135,"skipped":2066,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:47.911: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:48.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8437" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":303,"completed":136,"skipped":2073,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:48.141: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0827 09:12:49.286726      19 metrics_grabber.go:105] Did not receive an external client interface. Grabbing metrics from ClusterAutoscaler is disabled.
Aug 27 09:12:51.318: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:12:51.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7636" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":303,"completed":137,"skipped":2085,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:12:51.328: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a service nodeport-service with the type=NodePort in namespace services-314
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-314
STEP: creating replication controller externalsvc in namespace services-314
I0827 09:12:51.413985      19 runners.go:190] Created replication controller with name: externalsvc, namespace: services-314, replica count: 2
I0827 09:12:54.483249      19 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Aug 27 09:12:54.501: INFO: Creating new exec pod
Aug 27 09:12:58.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-314 execpod2l6m2 -- /bin/sh -x -c nslookup nodeport-service.services-314.svc.cluster.local'
Aug 27 09:12:58.815: INFO: stderr: "+ nslookup nodeport-service.services-314.svc.cluster.local\n"
Aug 27 09:12:58.815: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nnodeport-service.services-314.svc.cluster.local\tcanonical name = externalsvc.services-314.svc.cluster.local.\nName:\texternalsvc.services-314.svc.cluster.local\nAddress: 10.3.5.43\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-314, will wait for the garbage collector to delete the pods
Aug 27 09:12:58.874: INFO: Deleting ReplicationController externalsvc took: 5.629991ms
Aug 27 09:12:58.988: INFO: Terminating ReplicationController externalsvc pods took: 113.837491ms
Aug 27 09:13:03.833: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:13:03.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-314" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:12.572 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":303,"completed":138,"skipped":2148,"failed":0}
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:13:03.907: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test env composition
Aug 27 09:13:04.091: INFO: Waiting up to 5m0s for pod "var-expansion-96ea15c8-b940-4ae1-a585-eb9a704dba00" in namespace "var-expansion-5232" to be "Succeeded or Failed"
Aug 27 09:13:04.176: INFO: Pod "var-expansion-96ea15c8-b940-4ae1-a585-eb9a704dba00": Phase="Pending", Reason="", readiness=false. Elapsed: 84.961194ms
Aug 27 09:13:06.179: INFO: Pod "var-expansion-96ea15c8-b940-4ae1-a585-eb9a704dba00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.088534506s
STEP: Saw pod success
Aug 27 09:13:06.180: INFO: Pod "var-expansion-96ea15c8-b940-4ae1-a585-eb9a704dba00" satisfied condition "Succeeded or Failed"
Aug 27 09:13:06.183: INFO: Trying to get logs from node ip-10-0-45-43 pod var-expansion-96ea15c8-b940-4ae1-a585-eb9a704dba00 container dapi-container: <nil>
STEP: delete the pod
Aug 27 09:13:06.229: INFO: Waiting for pod var-expansion-96ea15c8-b940-4ae1-a585-eb9a704dba00 to disappear
Aug 27 09:13:06.234: INFO: Pod var-expansion-96ea15c8-b940-4ae1-a585-eb9a704dba00 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:13:06.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5232" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":303,"completed":139,"skipped":2150,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:13:06.249: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test override arguments
Aug 27 09:13:06.332: INFO: Waiting up to 5m0s for pod "client-containers-656a383c-341c-4d71-9360-e33c142e1c73" in namespace "containers-7501" to be "Succeeded or Failed"
Aug 27 09:13:06.352: INFO: Pod "client-containers-656a383c-341c-4d71-9360-e33c142e1c73": Phase="Pending", Reason="", readiness=false. Elapsed: 19.724808ms
Aug 27 09:13:08.356: INFO: Pod "client-containers-656a383c-341c-4d71-9360-e33c142e1c73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023371861s
STEP: Saw pod success
Aug 27 09:13:08.357: INFO: Pod "client-containers-656a383c-341c-4d71-9360-e33c142e1c73" satisfied condition "Succeeded or Failed"
Aug 27 09:13:08.359: INFO: Trying to get logs from node ip-10-0-45-43 pod client-containers-656a383c-341c-4d71-9360-e33c142e1c73 container test-container: <nil>
STEP: delete the pod
Aug 27 09:13:08.380: INFO: Waiting for pod client-containers-656a383c-341c-4d71-9360-e33c142e1c73 to disappear
Aug 27 09:13:08.387: INFO: Pod client-containers-656a383c-341c-4d71-9360-e33c142e1c73 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:13:08.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7501" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":303,"completed":140,"skipped":2164,"failed":0}
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:13:08.408: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:13:12.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8285" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":141,"skipped":2170,"failed":0}

------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:13:12.499: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:13:12.567: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Pending, waiting for it to be Running (with Ready = true)
Aug 27 09:13:14.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:16.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:18.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:20.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:22.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:24.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:26.572: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:28.572: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:30.570: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:32.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:34.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:36.571: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = false)
Aug 27 09:13:38.570: INFO: The status of Pod test-webserver-52bfe664-b02a-41cf-bb1e-69da1dccbe4d is Running (Ready = true)
Aug 27 09:13:38.576: INFO: Container started at 2020-08-27 09:13:13 +0000 UTC, pod became ready at 2020-08-27 09:13:37 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:13:38.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5609" for this suite.

• [SLOW TEST:26.084 seconds]
[k8s.io] Probing container
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":303,"completed":142,"skipped":2170,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:13:38.586: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:162
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
Aug 27 09:13:38.626: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:13:42.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1949" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":303,"completed":143,"skipped":2180,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:13:42.767: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 27 09:13:42.846: INFO: Waiting up to 5m0s for pod "pod-0ab132c0-d729-46fb-887d-4b4d46ef61ae" in namespace "emptydir-500" to be "Succeeded or Failed"
Aug 27 09:13:42.851: INFO: Pod "pod-0ab132c0-d729-46fb-887d-4b4d46ef61ae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.338765ms
Aug 27 09:13:44.854: INFO: Pod "pod-0ab132c0-d729-46fb-887d-4b4d46ef61ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007684162s
Aug 27 09:13:46.857: INFO: Pod "pod-0ab132c0-d729-46fb-887d-4b4d46ef61ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010776446s
STEP: Saw pod success
Aug 27 09:13:46.858: INFO: Pod "pod-0ab132c0-d729-46fb-887d-4b4d46ef61ae" satisfied condition "Succeeded or Failed"
Aug 27 09:13:46.861: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-0ab132c0-d729-46fb-887d-4b4d46ef61ae container test-container: <nil>
STEP: delete the pod
Aug 27 09:13:46.880: INFO: Waiting for pod pod-0ab132c0-d729-46fb-887d-4b4d46ef61ae to disappear
Aug 27 09:13:46.885: INFO: Pod pod-0ab132c0-d729-46fb-887d-4b4d46ef61ae no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:13:46.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-500" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":144,"skipped":2188,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:13:46.905: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:13:47.826: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:13:49.836: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116427, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116427, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116427, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116427, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:13:52.856: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:13:52.859: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:13:53.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4941" for this suite.
STEP: Destroying namespace "webhook-4941-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.180 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":303,"completed":145,"skipped":2190,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:13:54.085: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Aug 27 09:13:54.176: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 09:13:57.140: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:09.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9499" for this suite.

• [SLOW TEST:15.486 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":303,"completed":146,"skipped":2197,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:09.575: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name secret-test-3da33cec-5ee5-4e65-bd59-bdaf9bdcab20
STEP: Creating a pod to test consume secrets
Aug 27 09:14:09.641: INFO: Waiting up to 5m0s for pod "pod-secrets-bdf4a813-bc66-4cea-a310-9eaee5303c49" in namespace "secrets-1059" to be "Succeeded or Failed"
Aug 27 09:14:09.652: INFO: Pod "pod-secrets-bdf4a813-bc66-4cea-a310-9eaee5303c49": Phase="Pending", Reason="", readiness=false. Elapsed: 10.581083ms
Aug 27 09:14:11.657: INFO: Pod "pod-secrets-bdf4a813-bc66-4cea-a310-9eaee5303c49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01495581s
STEP: Saw pod success
Aug 27 09:14:11.658: INFO: Pod "pod-secrets-bdf4a813-bc66-4cea-a310-9eaee5303c49" satisfied condition "Succeeded or Failed"
Aug 27 09:14:11.662: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-secrets-bdf4a813-bc66-4cea-a310-9eaee5303c49 container secret-env-test: <nil>
STEP: delete the pod
Aug 27 09:14:11.699: INFO: Waiting for pod pod-secrets-bdf4a813-bc66-4cea-a310-9eaee5303c49 to disappear
Aug 27 09:14:11.705: INFO: Pod pod-secrets-bdf4a813-bc66-4cea-a310-9eaee5303c49 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:11.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1059" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":303,"completed":147,"skipped":2205,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:11.718: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: starting the proxy server
Aug 27 09:14:11.757: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-356341267 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:11.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9533" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":303,"completed":148,"skipped":2223,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:11.847: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test substitution in container's command
Aug 27 09:14:11.911: INFO: Waiting up to 5m0s for pod "var-expansion-28dce461-895b-4ad5-857f-90a7dd4918af" in namespace "var-expansion-6141" to be "Succeeded or Failed"
Aug 27 09:14:11.915: INFO: Pod "var-expansion-28dce461-895b-4ad5-857f-90a7dd4918af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.261594ms
Aug 27 09:14:13.919: INFO: Pod "var-expansion-28dce461-895b-4ad5-857f-90a7dd4918af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008498552s
STEP: Saw pod success
Aug 27 09:14:13.920: INFO: Pod "var-expansion-28dce461-895b-4ad5-857f-90a7dd4918af" satisfied condition "Succeeded or Failed"
Aug 27 09:14:13.923: INFO: Trying to get logs from node ip-10-0-2-216 pod var-expansion-28dce461-895b-4ad5-857f-90a7dd4918af container dapi-container: <nil>
STEP: delete the pod
Aug 27 09:14:13.939: INFO: Waiting for pod var-expansion-28dce461-895b-4ad5-857f-90a7dd4918af to disappear
Aug 27 09:14:13.948: INFO: Pod var-expansion-28dce461-895b-4ad5-857f-90a7dd4918af no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:13.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6141" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":303,"completed":149,"skipped":2256,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:13.954: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:14:14.009: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ecc515eb-041d-4597-ba9c-db1eae9d23db" in namespace "downward-api-6167" to be "Succeeded or Failed"
Aug 27 09:14:14.049: INFO: Pod "downwardapi-volume-ecc515eb-041d-4597-ba9c-db1eae9d23db": Phase="Pending", Reason="", readiness=false. Elapsed: 39.329964ms
Aug 27 09:14:16.055: INFO: Pod "downwardapi-volume-ecc515eb-041d-4597-ba9c-db1eae9d23db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045600752s
STEP: Saw pod success
Aug 27 09:14:16.055: INFO: Pod "downwardapi-volume-ecc515eb-041d-4597-ba9c-db1eae9d23db" satisfied condition "Succeeded or Failed"
Aug 27 09:14:16.059: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-ecc515eb-041d-4597-ba9c-db1eae9d23db container client-container: <nil>
STEP: delete the pod
Aug 27 09:14:16.088: INFO: Waiting for pod downwardapi-volume-ecc515eb-041d-4597-ba9c-db1eae9d23db to disappear
Aug 27 09:14:16.095: INFO: Pod downwardapi-volume-ecc515eb-041d-4597-ba9c-db1eae9d23db no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:16.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6167" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":303,"completed":150,"skipped":2257,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:16.123: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:14:16.461: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:14:18.469: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116456, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116456, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116456, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116456, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:14:21.501: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:21.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8074" for this suite.
STEP: Destroying namespace "webhook-8074-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.487 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":303,"completed":151,"skipped":2275,"failed":0}
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:21.612: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test substitution in container's args
Aug 27 09:14:21.659: INFO: Waiting up to 5m0s for pod "var-expansion-2ae01c5f-8f14-490c-9758-248e0aab205b" in namespace "var-expansion-2015" to be "Succeeded or Failed"
Aug 27 09:14:21.665: INFO: Pod "var-expansion-2ae01c5f-8f14-490c-9758-248e0aab205b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.655251ms
Aug 27 09:14:23.668: INFO: Pod "var-expansion-2ae01c5f-8f14-490c-9758-248e0aab205b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008924174s
STEP: Saw pod success
Aug 27 09:14:23.669: INFO: Pod "var-expansion-2ae01c5f-8f14-490c-9758-248e0aab205b" satisfied condition "Succeeded or Failed"
Aug 27 09:14:23.671: INFO: Trying to get logs from node ip-10-0-45-43 pod var-expansion-2ae01c5f-8f14-490c-9758-248e0aab205b container dapi-container: <nil>
STEP: delete the pod
Aug 27 09:14:23.688: INFO: Waiting for pod var-expansion-2ae01c5f-8f14-490c-9758-248e0aab205b to disappear
Aug 27 09:14:23.690: INFO: Pod var-expansion-2ae01c5f-8f14-490c-9758-248e0aab205b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:23.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2015" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":303,"completed":152,"skipped":2275,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:23.701: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7961 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7961;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7961 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7961;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7961.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7961.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7961.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7961.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7961.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7961.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7961.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7961.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7961.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7961.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7961.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7961.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7961.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 144.174.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.174.144_udp@PTR;check="$$(dig +tcp +noall +answer +search 144.174.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.174.144_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7961 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7961;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7961 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7961;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7961.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7961.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7961.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7961.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7961.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7961.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7961.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7961.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7961.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7961.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7961.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7961.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7961.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 144.174.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.174.144_udp@PTR;check="$$(dig +tcp +noall +answer +search 144.174.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.174.144_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 09:14:39.796: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.799: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.802: INFO: Unable to read wheezy_udp@dns-test-service.dns-7961 from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.805: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7961 from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.808: INFO: Unable to read wheezy_udp@dns-test-service.dns-7961.svc from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.810: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7961.svc from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.813: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7961.svc from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.815: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7961.svc from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.832: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.835: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.837: INFO: Unable to read jessie_udp@dns-test-service.dns-7961 from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.840: INFO: Unable to read jessie_tcp@dns-test-service.dns-7961 from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.842: INFO: Unable to read jessie_udp@dns-test-service.dns-7961.svc from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.844: INFO: Unable to read jessie_tcp@dns-test-service.dns-7961.svc from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.847: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7961.svc from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.850: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7961.svc from pod dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073: the server could not find the requested resource (get pods dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073)
Aug 27 09:14:39.863: INFO: Lookups using dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7961 wheezy_tcp@dns-test-service.dns-7961 wheezy_udp@dns-test-service.dns-7961.svc wheezy_tcp@dns-test-service.dns-7961.svc wheezy_udp@_http._tcp.dns-test-service.dns-7961.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7961.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7961 jessie_tcp@dns-test-service.dns-7961 jessie_udp@dns-test-service.dns-7961.svc jessie_tcp@dns-test-service.dns-7961.svc jessie_udp@_http._tcp.dns-test-service.dns-7961.svc jessie_tcp@_http._tcp.dns-test-service.dns-7961.svc]

Aug 27 09:14:44.943: INFO: DNS probes using dns-7961/dns-test-2e0524c6-75b2-402d-88b5-4a9e24ddc073 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:45.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7961" for this suite.

• [SLOW TEST:21.612 seconds]
[sig-network] DNS
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":303,"completed":153,"skipped":2288,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:45.339: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:45.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4521" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":303,"completed":154,"skipped":2337,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:45.505: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-volume-map-639d28bc-8dfd-4238-8c1a-eed9552d8057
STEP: Creating a pod to test consume configMaps
Aug 27 09:14:45.697: INFO: Waiting up to 5m0s for pod "pod-configmaps-ee81e706-14a7-4622-8e4a-d6922c1349b7" in namespace "configmap-2487" to be "Succeeded or Failed"
Aug 27 09:14:45.702: INFO: Pod "pod-configmaps-ee81e706-14a7-4622-8e4a-d6922c1349b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.887457ms
Aug 27 09:14:47.705: INFO: Pod "pod-configmaps-ee81e706-14a7-4622-8e4a-d6922c1349b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008242s
STEP: Saw pod success
Aug 27 09:14:47.706: INFO: Pod "pod-configmaps-ee81e706-14a7-4622-8e4a-d6922c1349b7" satisfied condition "Succeeded or Failed"
Aug 27 09:14:47.708: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-ee81e706-14a7-4622-8e4a-d6922c1349b7 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:14:47.731: INFO: Waiting for pod pod-configmaps-ee81e706-14a7-4622-8e4a-d6922c1349b7 to disappear
Aug 27 09:14:47.739: INFO: Pod pod-configmaps-ee81e706-14a7-4622-8e4a-d6922c1349b7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:47.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2487" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":303,"completed":155,"skipped":2339,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:47.763: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:14:47.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec6b784b-d4ba-49a7-bbdc-497e562b6278" in namespace "downward-api-4891" to be "Succeeded or Failed"
Aug 27 09:14:47.898: INFO: Pod "downwardapi-volume-ec6b784b-d4ba-49a7-bbdc-497e562b6278": Phase="Pending", Reason="", readiness=false. Elapsed: 3.517639ms
Aug 27 09:14:49.903: INFO: Pod "downwardapi-volume-ec6b784b-d4ba-49a7-bbdc-497e562b6278": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008115605s
Aug 27 09:14:51.907: INFO: Pod "downwardapi-volume-ec6b784b-d4ba-49a7-bbdc-497e562b6278": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012562458s
STEP: Saw pod success
Aug 27 09:14:51.908: INFO: Pod "downwardapi-volume-ec6b784b-d4ba-49a7-bbdc-497e562b6278" satisfied condition "Succeeded or Failed"
Aug 27 09:14:51.910: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-ec6b784b-d4ba-49a7-bbdc-497e562b6278 container client-container: <nil>
STEP: delete the pod
Aug 27 09:14:51.932: INFO: Waiting for pod downwardapi-volume-ec6b784b-d4ba-49a7-bbdc-497e562b6278 to disappear
Aug 27 09:14:51.936: INFO: Pod downwardapi-volume-ec6b784b-d4ba-49a7-bbdc-497e562b6278 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:51.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4891" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":303,"completed":156,"skipped":2346,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:51.949: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 27 09:14:51.989: INFO: Waiting up to 5m0s for pod "pod-a611f3df-2dfc-4f4e-9f43-b05b68a26f03" in namespace "emptydir-8757" to be "Succeeded or Failed"
Aug 27 09:14:51.993: INFO: Pod "pod-a611f3df-2dfc-4f4e-9f43-b05b68a26f03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.794509ms
Aug 27 09:14:53.996: INFO: Pod "pod-a611f3df-2dfc-4f4e-9f43-b05b68a26f03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006093525s
STEP: Saw pod success
Aug 27 09:14:53.996: INFO: Pod "pod-a611f3df-2dfc-4f4e-9f43-b05b68a26f03" satisfied condition "Succeeded or Failed"
Aug 27 09:14:54.004: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-a611f3df-2dfc-4f4e-9f43-b05b68a26f03 container test-container: <nil>
STEP: delete the pod
Aug 27 09:14:54.046: INFO: Waiting for pod pod-a611f3df-2dfc-4f4e-9f43-b05b68a26f03 to disappear
Aug 27 09:14:54.051: INFO: Pod pod-a611f3df-2dfc-4f4e-9f43-b05b68a26f03 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:14:54.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8757" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":157,"skipped":2350,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:14:54.060: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-14.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-14.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-14.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-14.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-14.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-14.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-14.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-14.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-14.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-14.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-14.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-14.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-14.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 43.141.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.141.43_udp@PTR;check="$$(dig +tcp +noall +answer +search 43.141.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.141.43_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-14.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-14.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-14.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-14.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-14.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-14.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-14.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-14.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-14.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-14.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-14.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-14.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-14.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 43.141.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.141.43_udp@PTR;check="$$(dig +tcp +noall +answer +search 43.141.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.141.43_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 09:14:56.136: INFO: Unable to read wheezy_udp@dns-test-service.dns-14.svc.cluster.local from pod dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a: the server could not find the requested resource (get pods dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a)
Aug 27 09:14:56.139: INFO: Unable to read wheezy_tcp@dns-test-service.dns-14.svc.cluster.local from pod dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a: the server could not find the requested resource (get pods dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a)
Aug 27 09:14:56.142: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-14.svc.cluster.local from pod dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a: the server could not find the requested resource (get pods dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a)
Aug 27 09:14:56.145: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-14.svc.cluster.local from pod dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a: the server could not find the requested resource (get pods dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a)
Aug 27 09:14:56.174: INFO: Unable to read jessie_udp@dns-test-service.dns-14.svc.cluster.local from pod dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a: the server could not find the requested resource (get pods dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a)
Aug 27 09:14:56.180: INFO: Unable to read jessie_tcp@dns-test-service.dns-14.svc.cluster.local from pod dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a: the server could not find the requested resource (get pods dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a)
Aug 27 09:14:56.185: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-14.svc.cluster.local from pod dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a: the server could not find the requested resource (get pods dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a)
Aug 27 09:14:56.191: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-14.svc.cluster.local from pod dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a: the server could not find the requested resource (get pods dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a)
Aug 27 09:14:56.207: INFO: Lookups using dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a failed for: [wheezy_udp@dns-test-service.dns-14.svc.cluster.local wheezy_tcp@dns-test-service.dns-14.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-14.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-14.svc.cluster.local jessie_udp@dns-test-service.dns-14.svc.cluster.local jessie_tcp@dns-test-service.dns-14.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-14.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-14.svc.cluster.local]

Aug 27 09:15:01.606: INFO: DNS probes using dns-14/dns-test-9d511c9d-89f3-443c-a73a-6dc808c3841a succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:15:01.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-14" for this suite.

• [SLOW TEST:7.812 seconds]
[sig-network] DNS
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":303,"completed":158,"skipped":2394,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:15:01.872: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:15:03.180: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:15:05.200: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116503, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116503, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116503, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116503, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:15:08.216: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:15:20.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3875" for this suite.
STEP: Destroying namespace "webhook-3875-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:18.669 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":303,"completed":159,"skipped":2488,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:15:20.543: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 27 09:15:24.744: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 09:15:24.749: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 09:15:26.749: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 09:15:26.752: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 09:15:28.749: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 09:15:28.753: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 09:15:30.751: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 09:15:30.803: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 09:15:32.749: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 09:15:32.752: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 09:15:34.749: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 09:15:34.753: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:15:34.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4422" for this suite.

• [SLOW TEST:14.220 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  when create a pod with lifecycle hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":303,"completed":160,"skipped":2503,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:15:34.766: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:78
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:15:34.815: INFO: Creating deployment "test-recreate-deployment"
Aug 27 09:15:34.819: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 27 09:15:34.831: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 27 09:15:36.838: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 27 09:15:36.841: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116534, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116534, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116534, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116534, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-c96cf48f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:15:38.844: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 27 09:15:38.852: INFO: Updating deployment test-recreate-deployment
Aug 27 09:15:38.852: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
Aug 27 09:15:39.072: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5956 /apis/apps/v1/namespaces/deployment-5956/deployments/test-recreate-deployment 90165914-2cb9-4cc4-904e-26edd217dd6e 21870 2 2020-08-27 09:15:34 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-08-27 09:15:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{}}},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}} {kube-controller-manager Update apps/v1 2020-08-27 09:15:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002e83438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-08-27 09:15:38 +0000 UTC,LastTransitionTime:2020-08-27 09:15:38 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-f79dd4667" is progressing.,LastUpdateTime:2020-08-27 09:15:39 +0000 UTC,LastTransitionTime:2020-08-27 09:15:34 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Aug 27 09:15:39.075: INFO: New ReplicaSet "test-recreate-deployment-f79dd4667" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-f79dd4667  deployment-5956 /apis/apps/v1/namespaces/deployment-5956/replicasets/test-recreate-deployment-f79dd4667 5e64fe67-baaf-4118-8a5b-e2f7a4d68466 21865 1 2020-08-27 09:15:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:f79dd4667] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 90165914-2cb9-4cc4-904e-26edd217dd6e 0xc002e83a00 0xc002e83a01}] []  [{kube-controller-manager Update apps/v1 2020-08-27 09:15:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90165914-2cb9-4cc4-904e-26edd217dd6e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}},"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: f79dd4667,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:f79dd4667] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002e83a78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:15:39.075: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 27 09:15:39.075: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-c96cf48f  deployment-5956 /apis/apps/v1/namespaces/deployment-5956/replicasets/test-recreate-deployment-c96cf48f 670d7469-ef21-4f1d-b89d-9f5f26deba75 21857 2 2020-08-27 09:15:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:c96cf48f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 90165914-2cb9-4cc4-904e-26edd217dd6e 0xc002e838ff 0xc002e83910}] []  [{kube-controller-manager Update apps/v1 2020-08-27 09:15:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90165914-2cb9-4cc4-904e-26edd217dd6e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}},"f:status":{"f:observedGeneration":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c96cf48f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:c96cf48f] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.20 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002e83998 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:15:39.078: INFO: Pod "test-recreate-deployment-f79dd4667-crq6l" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-f79dd4667-crq6l test-recreate-deployment-f79dd4667- deployment-5956 /api/v1/namespaces/deployment-5956/pods/test-recreate-deployment-f79dd4667-crq6l 031b2841-4450-442f-bcf3-7522142b1950 21868 0 2020-08-27 09:15:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:f79dd4667] map[] [{apps/v1 ReplicaSet test-recreate-deployment-f79dd4667 5e64fe67-baaf-4118-8a5b-e2f7a4d68466 0xc002eba060 0xc002eba061}] []  [{kube-controller-manager Update v1 2020-08-27 09:15:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5e64fe67-baaf-4118-8a5b-e2f7a4d68466\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {kubelet Update v1 2020-08-27 09:15:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-68jmr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-68jmr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-68jmr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:15:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:15:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:15:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:15:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.216,PodIP:,StartTime:2020-08-27 09:15:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:15:39.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5956" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":303,"completed":161,"skipped":2523,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:15:39.089: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod busybox-a6b2e530-1285-4c70-afa0-609c42fdeaf2 in namespace container-probe-63
Aug 27 09:15:43.148: INFO: Started pod busybox-a6b2e530-1285-4c70-afa0-609c42fdeaf2 in namespace container-probe-63
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 09:15:43.153: INFO: Initial restart count of pod busybox-a6b2e530-1285-4c70-afa0-609c42fdeaf2 is 0
Aug 27 09:16:33.500: INFO: Restart count of pod container-probe-63/busybox-a6b2e530-1285-4c70-afa0-609c42fdeaf2 is now 1 (50.34678556s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:16:33.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-63" for this suite.

• [SLOW TEST:54.430 seconds]
[k8s.io] Probing container
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":303,"completed":162,"skipped":2537,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:16:33.543: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name secret-test-map-908648f3-098c-4dcc-9915-57f360cd2984
STEP: Creating a pod to test consume secrets
Aug 27 09:16:33.596: INFO: Waiting up to 5m0s for pod "pod-secrets-ff6a8a30-c7b6-4a5d-b0d1-209ed49ed1f3" in namespace "secrets-3038" to be "Succeeded or Failed"
Aug 27 09:16:33.600: INFO: Pod "pod-secrets-ff6a8a30-c7b6-4a5d-b0d1-209ed49ed1f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.196159ms
Aug 27 09:16:35.604: INFO: Pod "pod-secrets-ff6a8a30-c7b6-4a5d-b0d1-209ed49ed1f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007971396s
STEP: Saw pod success
Aug 27 09:16:35.604: INFO: Pod "pod-secrets-ff6a8a30-c7b6-4a5d-b0d1-209ed49ed1f3" satisfied condition "Succeeded or Failed"
Aug 27 09:16:35.607: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-secrets-ff6a8a30-c7b6-4a5d-b0d1-209ed49ed1f3 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 09:16:35.631: INFO: Waiting for pod pod-secrets-ff6a8a30-c7b6-4a5d-b0d1-209ed49ed1f3 to disappear
Aug 27 09:16:35.638: INFO: Pod pod-secrets-ff6a8a30-c7b6-4a5d-b0d1-209ed49ed1f3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:16:35.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3038" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":163,"skipped":2661,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:16:35.649: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name s-test-opt-del-e8b4913b-7cbe-4c99-a0a2-7d5be3061439
STEP: Creating secret with name s-test-opt-upd-22b3baa0-6875-4e66-8941-cfc3aa923a9e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e8b4913b-7cbe-4c99-a0a2-7d5be3061439
STEP: Updating secret s-test-opt-upd-22b3baa0-6875-4e66-8941-cfc3aa923a9e
STEP: Creating secret with name s-test-opt-create-551ffdac-f8f1-4f2a-844e-91af7bb125b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:17:48.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3057" for this suite.

• [SLOW TEST:72.531 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":303,"completed":164,"skipped":2667,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:17:48.187: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating secret with name secret-test-ac64e970-2ac3-4534-a38e-f586ea5baaa0
STEP: Creating a pod to test consume secrets
Aug 27 09:17:48.232: INFO: Waiting up to 5m0s for pod "pod-secrets-dc20fd22-9988-4e57-a929-42803024b072" in namespace "secrets-7552" to be "Succeeded or Failed"
Aug 27 09:17:48.235: INFO: Pod "pod-secrets-dc20fd22-9988-4e57-a929-42803024b072": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075719ms
Aug 27 09:17:50.239: INFO: Pod "pod-secrets-dc20fd22-9988-4e57-a929-42803024b072": Phase="Running", Reason="", readiness=true. Elapsed: 2.006028948s
Aug 27 09:17:52.244: INFO: Pod "pod-secrets-dc20fd22-9988-4e57-a929-42803024b072": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010548286s
STEP: Saw pod success
Aug 27 09:17:52.245: INFO: Pod "pod-secrets-dc20fd22-9988-4e57-a929-42803024b072" satisfied condition "Succeeded or Failed"
Aug 27 09:17:52.248: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-secrets-dc20fd22-9988-4e57-a929-42803024b072 container secret-volume-test: <nil>
STEP: delete the pod
Aug 27 09:17:52.273: INFO: Waiting for pod pod-secrets-dc20fd22-9988-4e57-a929-42803024b072 to disappear
Aug 27 09:17:52.278: INFO: Pod pod-secrets-dc20fd22-9988-4e57-a929-42803024b072 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:17:52.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7552" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":303,"completed":165,"skipped":2695,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:17:52.292: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:18:09.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9441" for this suite.

• [SLOW TEST:17.107 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":303,"completed":166,"skipped":2713,"failed":0}
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:18:09.400: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:18:09.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-3822" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":303,"completed":167,"skipped":2714,"failed":0}
S
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:18:09.456: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 27 09:18:14.534: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:18:15.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5504" for this suite.

• [SLOW TEST:6.117 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":303,"completed":168,"skipped":2715,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:18:15.576: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:18:15.627: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 27 09:18:15.635: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:15.639: INFO: Number of nodes with available pods: 0
Aug 27 09:18:15.640: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:16.683: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:16.687: INFO: Number of nodes with available pods: 0
Aug 27 09:18:16.687: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:17.649: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:17.653: INFO: Number of nodes with available pods: 0
Aug 27 09:18:17.653: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:18.644: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:18.647: INFO: Number of nodes with available pods: 1
Aug 27 09:18:18.647: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:19.643: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:19.647: INFO: Number of nodes with available pods: 3
Aug 27 09:18:19.647: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 27 09:18:19.673: INFO: Wrong image for pod: daemon-set-b8wt7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:19.673: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:19.674: INFO: Wrong image for pod: daemon-set-jr59m. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:19.692: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:20.721: INFO: Wrong image for pod: daemon-set-b8wt7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:20.721: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:20.721: INFO: Wrong image for pod: daemon-set-jr59m. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:20.733: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:21.696: INFO: Wrong image for pod: daemon-set-b8wt7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:21.696: INFO: Pod daemon-set-b8wt7 is not available
Aug 27 09:18:21.697: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:21.697: INFO: Wrong image for pod: daemon-set-jr59m. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:21.700: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:22.826: INFO: Pod daemon-set-2c4m7 is not available
Aug 27 09:18:22.826: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:22.826: INFO: Wrong image for pod: daemon-set-jr59m. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:22.829: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:23.696: INFO: Pod daemon-set-2c4m7 is not available
Aug 27 09:18:23.696: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:23.696: INFO: Wrong image for pod: daemon-set-jr59m. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:23.699: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:24.698: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:24.698: INFO: Wrong image for pod: daemon-set-jr59m. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:24.702: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:25.696: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:25.696: INFO: Wrong image for pod: daemon-set-jr59m. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:25.697: INFO: Pod daemon-set-jr59m is not available
Aug 27 09:18:25.700: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:26.697: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:26.697: INFO: Pod daemon-set-fn9mt is not available
Aug 27 09:18:26.700: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:27.696: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:27.697: INFO: Pod daemon-set-fn9mt is not available
Aug 27 09:18:27.700: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:28.696: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:28.700: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:29.697: INFO: Wrong image for pod: daemon-set-cg8r7. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.20, got: docker.io/library/httpd:2.4.38-alpine.
Aug 27 09:18:29.698: INFO: Pod daemon-set-cg8r7 is not available
Aug 27 09:18:29.704: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:30.696: INFO: Pod daemon-set-p4qm9 is not available
Aug 27 09:18:30.699: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 27 09:18:30.702: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:30.705: INFO: Number of nodes with available pods: 2
Aug 27 09:18:30.705: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:31.720: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:31.725: INFO: Number of nodes with available pods: 2
Aug 27 09:18:31.725: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:32.709: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:32.715: INFO: Number of nodes with available pods: 3
Aug 27 09:18:32.715: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8404, will wait for the garbage collector to delete the pods
Aug 27 09:18:32.793: INFO: Deleting DaemonSet.extensions daemon-set took: 7.197812ms
Aug 27 09:18:33.294: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.12911ms
Aug 27 09:18:44.099: INFO: Number of nodes with available pods: 0
Aug 27 09:18:44.099: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 09:18:44.101: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8404/daemonsets","resourceVersion":"22779"},"items":null}

Aug 27 09:18:44.104: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8404/pods","resourceVersion":"22779"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:18:44.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8404" for this suite.

• [SLOW TEST:28.561 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":303,"completed":169,"skipped":2718,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:18:44.140: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:18:44.202: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6b600d40-abec-45de-a6dd-6d30c041515a" in namespace "downward-api-5853" to be "Succeeded or Failed"
Aug 27 09:18:44.214: INFO: Pod "downwardapi-volume-6b600d40-abec-45de-a6dd-6d30c041515a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.922973ms
Aug 27 09:18:46.218: INFO: Pod "downwardapi-volume-6b600d40-abec-45de-a6dd-6d30c041515a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015919314s
Aug 27 09:18:48.222: INFO: Pod "downwardapi-volume-6b600d40-abec-45de-a6dd-6d30c041515a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020346802s
STEP: Saw pod success
Aug 27 09:18:48.223: INFO: Pod "downwardapi-volume-6b600d40-abec-45de-a6dd-6d30c041515a" satisfied condition "Succeeded or Failed"
Aug 27 09:18:48.226: INFO: Trying to get logs from node ip-10-0-2-216 pod downwardapi-volume-6b600d40-abec-45de-a6dd-6d30c041515a container client-container: <nil>
STEP: delete the pod
Aug 27 09:18:48.243: INFO: Waiting for pod downwardapi-volume-6b600d40-abec-45de-a6dd-6d30c041515a to disappear
Aug 27 09:18:48.246: INFO: Pod downwardapi-volume-6b600d40-abec-45de-a6dd-6d30c041515a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:18:48.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5853" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":170,"skipped":2722,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:18:48.264: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:18:48.352: INFO: Create a RollingUpdate DaemonSet
Aug 27 09:18:48.356: INFO: Check that daemon pods launch on every node of the cluster
Aug 27 09:18:48.361: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:48.364: INFO: Number of nodes with available pods: 0
Aug 27 09:18:48.365: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:49.371: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:49.376: INFO: Number of nodes with available pods: 0
Aug 27 09:18:49.376: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:50.369: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:50.372: INFO: Number of nodes with available pods: 1
Aug 27 09:18:50.372: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:18:51.378: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:18:51.382: INFO: Number of nodes with available pods: 3
Aug 27 09:18:51.382: INFO: Number of running nodes: 3, number of available pods: 3
Aug 27 09:18:51.383: INFO: Update the DaemonSet to trigger a rollout
Aug 27 09:18:51.399: INFO: Updating DaemonSet daemon-set
Aug 27 09:19:05.412: INFO: Roll back the DaemonSet before rollout is complete
Aug 27 09:19:05.419: INFO: Updating DaemonSet daemon-set
Aug 27 09:19:05.419: INFO: Make sure DaemonSet rollback is complete
Aug 27 09:19:05.426: INFO: Wrong image for pod: daemon-set-vd5k8. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Aug 27 09:19:05.426: INFO: Pod daemon-set-vd5k8 is not available
Aug 27 09:19:05.431: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:19:06.435: INFO: Wrong image for pod: daemon-set-vd5k8. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Aug 27 09:19:06.435: INFO: Pod daemon-set-vd5k8 is not available
Aug 27 09:19:06.438: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:19:07.483: INFO: Pod daemon-set-v66mt is not available
Aug 27 09:19:07.523: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8608, will wait for the garbage collector to delete the pods
Aug 27 09:19:07.609: INFO: Deleting DaemonSet.extensions daemon-set took: 5.882297ms
Aug 27 09:19:08.111: INFO: Terminating DaemonSet.extensions daemon-set pods took: 502.102138ms
Aug 27 09:19:13.416: INFO: Number of nodes with available pods: 0
Aug 27 09:19:13.416: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 09:19:13.420: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8608/daemonsets","resourceVersion":"23044"},"items":null}

Aug 27 09:19:13.422: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8608/pods","resourceVersion":"23044"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:19:13.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8608" for this suite.

• [SLOW TEST:25.179 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":303,"completed":171,"skipped":2745,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:19:13.445: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:19:13.485: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:19:14.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6803" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":303,"completed":172,"skipped":2747,"failed":0}

------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:19:14.140: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:162
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
Aug 27 09:19:14.176: INFO: PodSpec: initContainers in spec.initContainers
Aug 27 09:19:57.392: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-8f71bb0d-74c4-437c-b7cb-eee2c91014c6", GenerateName:"", Namespace:"init-container-7486", SelfLink:"/api/v1/namespaces/init-container-7486/pods/pod-init-8f71bb0d-74c4-437c-b7cb-eee2c91014c6", UID:"6715554e-07a3-4112-bb98-af9c0066aae5", ResourceVersion:"23247", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63734116754, loc:(*time.Location)(0x7702840)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"176901893"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.173.126/32", "cni.projectcalico.org/podIPs":"10.2.173.126/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc002970ba0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002970bc0)}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc002970be0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002970c00)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc002970c20), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002970c40)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-q8sxw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0069affc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q8sxw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q8sxw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q8sxw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000a314a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-2-216", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0039c6620), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000a31610)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000a31660)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000a31668), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000a3166c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc004514540), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116754, loc:(*time.Location)(0x7702840)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116754, loc:(*time.Location)(0x7702840)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116754, loc:(*time.Location)(0x7702840)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734116754, loc:(*time.Location)(0x7702840)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.2.216", PodIP:"10.2.173.126", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.2.173.126"}}, StartTime:(*v1.Time)(0xc002970c60), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0039c6700)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0039c6770)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://2c588cda11455995e7cb34d766e1fc629073cf83f996877f1b61f6d06d9c1cd1", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002970ca0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002970c80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc000a31c3f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:19:57.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7486" for this suite.

• [SLOW TEST:43.278 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":303,"completed":173,"skipped":2747,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:19:57.433: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:19:57.493: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1beedd9f-2632-4008-86e4-88d46f7f6177" in namespace "downward-api-7851" to be "Succeeded or Failed"
Aug 27 09:19:57.498: INFO: Pod "downwardapi-volume-1beedd9f-2632-4008-86e4-88d46f7f6177": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067418ms
Aug 27 09:19:59.505: INFO: Pod "downwardapi-volume-1beedd9f-2632-4008-86e4-88d46f7f6177": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011054263s
STEP: Saw pod success
Aug 27 09:19:59.505: INFO: Pod "downwardapi-volume-1beedd9f-2632-4008-86e4-88d46f7f6177" satisfied condition "Succeeded or Failed"
Aug 27 09:19:59.507: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-1beedd9f-2632-4008-86e4-88d46f7f6177 container client-container: <nil>
STEP: delete the pod
Aug 27 09:19:59.547: INFO: Waiting for pod downwardapi-volume-1beedd9f-2632-4008-86e4-88d46f7f6177 to disappear
Aug 27 09:19:59.550: INFO: Pod downwardapi-volume-1beedd9f-2632-4008-86e4-88d46f7f6177 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:19:59.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7851" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":303,"completed":174,"skipped":2754,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:19:59.565: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name projected-configmap-test-volume-map-78db7f38-70b5-4527-b9bb-b61847533d69
STEP: Creating a pod to test consume configMaps
Aug 27 09:19:59.614: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fd0d094d-caaf-44ae-8d3e-b27f714464b0" in namespace "projected-6754" to be "Succeeded or Failed"
Aug 27 09:19:59.618: INFO: Pod "pod-projected-configmaps-fd0d094d-caaf-44ae-8d3e-b27f714464b0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.067961ms
Aug 27 09:20:01.632: INFO: Pod "pod-projected-configmaps-fd0d094d-caaf-44ae-8d3e-b27f714464b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017042266s
STEP: Saw pod success
Aug 27 09:20:01.632: INFO: Pod "pod-projected-configmaps-fd0d094d-caaf-44ae-8d3e-b27f714464b0" satisfied condition "Succeeded or Failed"
Aug 27 09:20:01.645: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-projected-configmaps-fd0d094d-caaf-44ae-8d3e-b27f714464b0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:20:01.834: INFO: Waiting for pod pod-projected-configmaps-fd0d094d-caaf-44ae-8d3e-b27f714464b0 to disappear
Aug 27 09:20:01.909: INFO: Pod pod-projected-configmaps-fd0d094d-caaf-44ae-8d3e-b27f714464b0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:20:01.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6754" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":175,"skipped":2757,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:20:02.094: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating projection with secret that has name projected-secret-test-e4ef982a-eadb-4c8a-a381-d85c2e66f53f
STEP: Creating a pod to test consume secrets
Aug 27 09:20:02.352: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-46490513-a48e-45aa-b5cb-d09bbd5cea47" in namespace "projected-28" to be "Succeeded or Failed"
Aug 27 09:20:02.371: INFO: Pod "pod-projected-secrets-46490513-a48e-45aa-b5cb-d09bbd5cea47": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018302ms
Aug 27 09:20:04.380: INFO: Pod "pod-projected-secrets-46490513-a48e-45aa-b5cb-d09bbd5cea47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026846819s
Aug 27 09:20:06.386: INFO: Pod "pod-projected-secrets-46490513-a48e-45aa-b5cb-d09bbd5cea47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032648093s
STEP: Saw pod success
Aug 27 09:20:06.386: INFO: Pod "pod-projected-secrets-46490513-a48e-45aa-b5cb-d09bbd5cea47" satisfied condition "Succeeded or Failed"
Aug 27 09:20:06.388: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-projected-secrets-46490513-a48e-45aa-b5cb-d09bbd5cea47 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 09:20:06.406: INFO: Waiting for pod pod-projected-secrets-46490513-a48e-45aa-b5cb-d09bbd5cea47 to disappear
Aug 27 09:20:06.408: INFO: Pod pod-projected-secrets-46490513-a48e-45aa-b5cb-d09bbd5cea47 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:20:06.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-28" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":303,"completed":176,"skipped":2768,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:20:06.420: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod liveness-716fd6b8-4281-4f8c-b84a-a799685c419f in namespace container-probe-1584
Aug 27 09:20:10.466: INFO: Started pod liveness-716fd6b8-4281-4f8c-b84a-a799685c419f in namespace container-probe-1584
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 09:20:10.469: INFO: Initial restart count of pod liveness-716fd6b8-4281-4f8c-b84a-a799685c419f is 0
Aug 27 09:20:24.503: INFO: Restart count of pod container-probe-1584/liveness-716fd6b8-4281-4f8c-b84a-a799685c419f is now 1 (14.033575559s elapsed)
Aug 27 09:20:44.548: INFO: Restart count of pod container-probe-1584/liveness-716fd6b8-4281-4f8c-b84a-a799685c419f is now 2 (34.07886077s elapsed)
Aug 27 09:21:04.590: INFO: Restart count of pod container-probe-1584/liveness-716fd6b8-4281-4f8c-b84a-a799685c419f is now 3 (54.120209536s elapsed)
Aug 27 09:21:24.632: INFO: Restart count of pod container-probe-1584/liveness-716fd6b8-4281-4f8c-b84a-a799685c419f is now 4 (1m14.162780441s elapsed)
Aug 27 09:22:24.831: INFO: Restart count of pod container-probe-1584/liveness-716fd6b8-4281-4f8c-b84a-a799685c419f is now 5 (2m14.36163756s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:22:24.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1584" for this suite.

• [SLOW TEST:138.430 seconds]
[k8s.io] Probing container
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":303,"completed":177,"skipped":2777,"failed":0}
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:22:24.854: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 27 09:22:24.898: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 09:22:24.906: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 09:22:24.909: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-2-216 before test
Aug 27 09:22:24.916: INFO: calico-node-87ksr from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 09:22:24.917: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:22:24.917: INFO: coredns-69c75f5c45-9jz8t from kube-system started at 2020-08-27 08:09:33 +0000 UTC (1 container statuses recorded)
Aug 27 09:22:24.917: INFO: 	Container coredns ready: true, restart count 0
Aug 27 09:22:24.917: INFO: kube-proxy-zlwf6 from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 09:22:24.918: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:22:24.918: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-mjhxq from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:22:24.918: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:22:24.918: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 09:22:24.919: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-27-251 before test
Aug 27 09:22:24.924: INFO: calico-node-8g49c from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 09:22:24.924: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:22:24.924: INFO: kube-proxy-zq947 from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 09:22:24.924: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:22:24.924: INFO: sonobuoy-e2e-job-3e3f44f310e74605 from sonobuoy started at 2020-08-27 08:10:16 +0000 UTC (2 container statuses recorded)
Aug 27 09:22:24.924: INFO: 	Container e2e ready: true, restart count 0
Aug 27 09:22:24.924: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 09:22:24.924: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-96j2z from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:22:24.924: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:22:24.924: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 09:22:24.924: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-45-43 before test
Aug 27 09:22:24.929: INFO: calico-node-fj4mf from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 09:22:24.929: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:22:24.929: INFO: kube-proxy-9v45m from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 09:22:24.929: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:22:24.929: INFO: sonobuoy from sonobuoy started at 2020-08-27 08:10:12 +0000 UTC (1 container statuses recorded)
Aug 27 09:22:24.929: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 09:22:24.929: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-6xtvp from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:22:24.929: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:22:24.929: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d32c0fc1-1faf-495a-84ad-5805c3c4c000 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-d32c0fc1-1faf-495a-84ad-5805c3c4c000 off the node ip-10-0-2-216
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d32c0fc1-1faf-495a-84ad-5805c3c4c000
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:22:31.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-850" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:6.172 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":303,"completed":178,"skipped":2777,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:22:31.027: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0827 09:22:41.296358      19 metrics_grabber.go:105] Did not receive an external client interface. Grabbing metrics from ClusterAutoscaler is disabled.
Aug 27 09:22:43.344: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:22:43.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8917" for this suite.

• [SLOW TEST:12.328 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":303,"completed":179,"skipped":2778,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:22:43.355: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:22:43.403: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 27 09:22:46.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-1626 create -f -'
Aug 27 09:22:47.211: INFO: stderr: ""
Aug 27 09:22:47.211: INFO: stdout: "e2e-test-crd-publish-openapi-4188-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 27 09:22:47.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-1626 delete e2e-test-crd-publish-openapi-4188-crds test-cr'
Aug 27 09:22:47.348: INFO: stderr: ""
Aug 27 09:22:47.348: INFO: stdout: "e2e-test-crd-publish-openapi-4188-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Aug 27 09:22:47.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-1626 apply -f -'
Aug 27 09:22:47.556: INFO: stderr: ""
Aug 27 09:22:47.556: INFO: stdout: "e2e-test-crd-publish-openapi-4188-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 27 09:22:47.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-1626 delete e2e-test-crd-publish-openapi-4188-crds test-cr'
Aug 27 09:22:47.644: INFO: stderr: ""
Aug 27 09:22:47.644: INFO: stdout: "e2e-test-crd-publish-openapi-4188-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Aug 27 09:22:47.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 explain e2e-test-crd-publish-openapi-4188-crds'
Aug 27 09:22:47.844: INFO: stderr: ""
Aug 27 09:22:47.844: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4188-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:22:51.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1626" for this suite.

• [SLOW TEST:8.088 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":303,"completed":180,"skipped":2807,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:22:51.444: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:103
STEP: Creating service test in namespace statefulset-9598
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating statefulset ss in namespace statefulset-9598
Aug 27 09:22:51.604: INFO: Found 0 stateful pods, waiting for 1
Aug 27 09:23:01.608: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:114
Aug 27 09:23:01.628: INFO: Deleting all statefulset in ns statefulset-9598
Aug 27 09:23:01.633: INFO: Scaling statefulset ss to 0
Aug 27 09:23:31.740: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 09:23:31.742: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:23:31.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9598" for this suite.

• [SLOW TEST:40.330 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":303,"completed":181,"skipped":2820,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:23:31.774: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:23:31.819: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54627f35-21aa-4209-b8f2-e667d1cd3865" in namespace "projected-3649" to be "Succeeded or Failed"
Aug 27 09:23:31.823: INFO: Pod "downwardapi-volume-54627f35-21aa-4209-b8f2-e667d1cd3865": Phase="Pending", Reason="", readiness=false. Elapsed: 3.215656ms
Aug 27 09:23:33.827: INFO: Pod "downwardapi-volume-54627f35-21aa-4209-b8f2-e667d1cd3865": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007349025s
STEP: Saw pod success
Aug 27 09:23:33.828: INFO: Pod "downwardapi-volume-54627f35-21aa-4209-b8f2-e667d1cd3865" satisfied condition "Succeeded or Failed"
Aug 27 09:23:33.831: INFO: Trying to get logs from node ip-10-0-2-216 pod downwardapi-volume-54627f35-21aa-4209-b8f2-e667d1cd3865 container client-container: <nil>
STEP: delete the pod
Aug 27 09:23:33.855: INFO: Waiting for pod downwardapi-volume-54627f35-21aa-4209-b8f2-e667d1cd3865 to disappear
Aug 27 09:23:33.859: INFO: Pod downwardapi-volume-54627f35-21aa-4209-b8f2-e667d1cd3865 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:23:33.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3649" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":303,"completed":182,"skipped":2822,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:23:33.869: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:103
STEP: Creating service test in namespace statefulset-6402
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a new StatefulSet
Aug 27 09:23:33.921: INFO: Found 0 stateful pods, waiting for 3
Aug 27 09:23:43.925: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 09:23:43.925: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 09:23:43.925: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Aug 27 09:23:43.956: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 27 09:23:54.095: INFO: Updating stateful set ss2
Aug 27 09:23:54.120: INFO: Waiting for Pod statefulset-6402/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 27 09:24:04.163: INFO: Waiting for Pod statefulset-6402/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Aug 27 09:24:14.308: INFO: Found 2 stateful pods, waiting for 3
Aug 27 09:24:24.312: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 09:24:24.313: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 09:24:24.313: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 27 09:24:24.337: INFO: Updating stateful set ss2
Aug 27 09:24:24.355: INFO: Waiting for Pod statefulset-6402/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 27 09:24:34.379: INFO: Updating stateful set ss2
Aug 27 09:24:34.386: INFO: Waiting for StatefulSet statefulset-6402/ss2 to complete update
Aug 27 09:24:34.387: INFO: Waiting for Pod statefulset-6402/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 27 09:24:44.397: INFO: Waiting for StatefulSet statefulset-6402/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:114
Aug 27 09:24:54.392: INFO: Deleting all statefulset in ns statefulset-6402
Aug 27 09:24:54.394: INFO: Scaling statefulset ss2 to 0
Aug 27 09:25:14.410: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 09:25:14.412: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:25:14.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6402" for this suite.

• [SLOW TEST:100.577 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":303,"completed":183,"skipped":2824,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:25:14.449: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Aug 27 09:25:14.492: INFO: Created pod &Pod{ObjectMeta:{dns-4944  dns-4944 /api/v1/namespaces/dns-4944/pods/dns-4944 d473552f-3338-4a79-9435-83e8ec38746c 24788 0 2020-08-27 09:25:14 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2020-08-27 09:25:14 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-js8cj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-js8cj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.20,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-js8cj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:25:14.495: INFO: The status of Pod dns-4944 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 09:25:16.500: INFO: The status of Pod dns-4944 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Aug 27 09:25:16.501: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4944 PodName:dns-4944 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 09:25:16.502: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Verifying customized DNS server is configured on pod...
Aug 27 09:25:16.604: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4944 PodName:dns-4944 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 09:25:16.605: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 09:25:16.719: INFO: Deleting pod dns-4944...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:25:16.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4944" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":303,"completed":184,"skipped":2868,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:25:16.757: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating replication controller my-hostname-basic-050bc40f-0f02-4ca7-8496-17d525992fdc
Aug 27 09:25:16.798: INFO: Pod name my-hostname-basic-050bc40f-0f02-4ca7-8496-17d525992fdc: Found 0 pods out of 1
Aug 27 09:25:21.802: INFO: Pod name my-hostname-basic-050bc40f-0f02-4ca7-8496-17d525992fdc: Found 1 pods out of 1
Aug 27 09:25:21.802: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-050bc40f-0f02-4ca7-8496-17d525992fdc" are running
Aug 27 09:25:21.806: INFO: Pod "my-hostname-basic-050bc40f-0f02-4ca7-8496-17d525992fdc-m7g74" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-27 09:25:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-27 09:25:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-27 09:25:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-27 09:25:16 +0000 UTC Reason: Message:}])
Aug 27 09:25:21.807: INFO: Trying to dial the pod
Aug 27 09:25:26.823: INFO: Controller my-hostname-basic-050bc40f-0f02-4ca7-8496-17d525992fdc: Got expected result from replica 1 [my-hostname-basic-050bc40f-0f02-4ca7-8496-17d525992fdc-m7g74]: "my-hostname-basic-050bc40f-0f02-4ca7-8496-17d525992fdc-m7g74", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:25:26.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-371" for this suite.

• [SLOW TEST:10.076 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":303,"completed":185,"skipped":2895,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:25:26.833: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:89
Aug 27 09:25:26.888: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 09:26:26.939: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Create pods that use 2/3 of node resources.
Aug 27 09:26:26.957: INFO: Created pod: pod0-sched-preemption-low-priority
Aug 27 09:26:26.975: INFO: Created pod: pod1-sched-preemption-medium-priority
Aug 27 09:26:27.028: INFO: Created pod: pod2-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:26:45.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2991" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:77

• [SLOW TEST:78.350 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":303,"completed":186,"skipped":2960,"failed":0}
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:26:45.198: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward api env vars
Aug 27 09:26:45.276: INFO: Waiting up to 5m0s for pod "downward-api-5127b7a9-aad4-4a9e-89b1-8f23b7426bdf" in namespace "downward-api-3344" to be "Succeeded or Failed"
Aug 27 09:26:45.280: INFO: Pod "downward-api-5127b7a9-aad4-4a9e-89b1-8f23b7426bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.588566ms
Aug 27 09:26:47.284: INFO: Pod "downward-api-5127b7a9-aad4-4a9e-89b1-8f23b7426bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007158736s
STEP: Saw pod success
Aug 27 09:26:47.285: INFO: Pod "downward-api-5127b7a9-aad4-4a9e-89b1-8f23b7426bdf" satisfied condition "Succeeded or Failed"
Aug 27 09:26:47.290: INFO: Trying to get logs from node ip-10-0-2-216 pod downward-api-5127b7a9-aad4-4a9e-89b1-8f23b7426bdf container dapi-container: <nil>
STEP: delete the pod
Aug 27 09:26:47.326: INFO: Waiting for pod downward-api-5127b7a9-aad4-4a9e-89b1-8f23b7426bdf to disappear
Aug 27 09:26:47.331: INFO: Pod downward-api-5127b7a9-aad4-4a9e-89b1-8f23b7426bdf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:26:47.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3344" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":303,"completed":187,"skipped":2967,"failed":0}
SSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:26:47.345: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Aug 27 09:26:49.906: INFO: Successfully updated pod "adopt-release-9fvj7"
STEP: Checking that the Job readopts the Pod
Aug 27 09:26:49.906: INFO: Waiting up to 15m0s for pod "adopt-release-9fvj7" in namespace "job-9695" to be "adopted"
Aug 27 09:26:49.912: INFO: Pod "adopt-release-9fvj7": Phase="Running", Reason="", readiness=true. Elapsed: 6.232253ms
Aug 27 09:26:51.915: INFO: Pod "adopt-release-9fvj7": Phase="Running", Reason="", readiness=true. Elapsed: 2.008766636s
Aug 27 09:26:51.915: INFO: Pod "adopt-release-9fvj7" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Aug 27 09:26:52.424: INFO: Successfully updated pod "adopt-release-9fvj7"
STEP: Checking that the Job releases the Pod
Aug 27 09:26:52.425: INFO: Waiting up to 15m0s for pod "adopt-release-9fvj7" in namespace "job-9695" to be "released"
Aug 27 09:26:52.429: INFO: Pod "adopt-release-9fvj7": Phase="Running", Reason="", readiness=true. Elapsed: 3.490004ms
Aug 27 09:26:54.432: INFO: Pod "adopt-release-9fvj7": Phase="Running", Reason="", readiness=true. Elapsed: 2.00633697s
Aug 27 09:26:54.432: INFO: Pod "adopt-release-9fvj7" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:26:54.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9695" for this suite.

• [SLOW TEST:7.095 seconds]
[sig-apps] Job
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":303,"completed":188,"skipped":2970,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:26:54.439: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 27 09:26:54.498: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:26:54.500: INFO: Number of nodes with available pods: 0
Aug 27 09:26:54.500: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:26:55.540: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:26:55.543: INFO: Number of nodes with available pods: 0
Aug 27 09:26:55.543: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:26:56.504: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:26:56.507: INFO: Number of nodes with available pods: 2
Aug 27 09:26:56.507: INFO: Node ip-10-0-27-251 is running more than one daemon pod
Aug 27 09:26:57.506: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:26:57.512: INFO: Number of nodes with available pods: 3
Aug 27 09:26:57.512: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 27 09:26:57.533: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:26:57.537: INFO: Number of nodes with available pods: 2
Aug 27 09:26:57.537: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:26:58.541: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:26:58.544: INFO: Number of nodes with available pods: 2
Aug 27 09:26:58.545: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:26:59.543: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:26:59.548: INFO: Number of nodes with available pods: 2
Aug 27 09:26:59.548: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:27:00.541: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:27:00.544: INFO: Number of nodes with available pods: 2
Aug 27 09:27:00.544: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:27:01.542: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:27:01.556: INFO: Number of nodes with available pods: 2
Aug 27 09:27:01.558: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:27:02.557: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:27:02.564: INFO: Number of nodes with available pods: 2
Aug 27 09:27:02.564: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:27:03.541: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:27:03.545: INFO: Number of nodes with available pods: 2
Aug 27 09:27:03.545: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:27:04.541: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:27:04.544: INFO: Number of nodes with available pods: 2
Aug 27 09:27:04.544: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:27:05.543: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:27:05.546: INFO: Number of nodes with available pods: 2
Aug 27 09:27:05.546: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:27:06.541: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:27:06.545: INFO: Number of nodes with available pods: 3
Aug 27 09:27:06.545: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9464, will wait for the garbage collector to delete the pods
Aug 27 09:27:06.609: INFO: Deleting DaemonSet.extensions daemon-set took: 7.311292ms
Aug 27 09:27:06.709: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.221041ms
Aug 27 09:27:15.213: INFO: Number of nodes with available pods: 0
Aug 27 09:27:15.213: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 09:27:15.219: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9464/daemonsets","resourceVersion":"25535"},"items":null}

Aug 27 09:27:15.226: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9464/pods","resourceVersion":"25535"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:27:15.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9464" for this suite.

• [SLOW TEST:20.864 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":303,"completed":189,"skipped":2992,"failed":0}
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:27:15.308: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:27:15.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d97c493c-b31c-4521-81fb-46c9a728bcee" in namespace "downward-api-684" to be "Succeeded or Failed"
Aug 27 09:27:15.563: INFO: Pod "downwardapi-volume-d97c493c-b31c-4521-81fb-46c9a728bcee": Phase="Pending", Reason="", readiness=false. Elapsed: 56.500644ms
Aug 27 09:27:17.568: INFO: Pod "downwardapi-volume-d97c493c-b31c-4521-81fb-46c9a728bcee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061943807s
Aug 27 09:27:19.572: INFO: Pod "downwardapi-volume-d97c493c-b31c-4521-81fb-46c9a728bcee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065717461s
STEP: Saw pod success
Aug 27 09:27:19.573: INFO: Pod "downwardapi-volume-d97c493c-b31c-4521-81fb-46c9a728bcee" satisfied condition "Succeeded or Failed"
Aug 27 09:27:19.576: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-d97c493c-b31c-4521-81fb-46c9a728bcee container client-container: <nil>
STEP: delete the pod
Aug 27 09:27:19.607: INFO: Waiting for pod downwardapi-volume-d97c493c-b31c-4521-81fb-46c9a728bcee to disappear
Aug 27 09:27:19.611: INFO: Pod downwardapi-volume-d97c493c-b31c-4521-81fb-46c9a728bcee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:27:19.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-684" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":303,"completed":190,"skipped":2992,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:27:19.626: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: getting the auto-created API token
Aug 27 09:27:20.286: INFO: created pod pod-service-account-defaultsa
Aug 27 09:27:20.287: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 27 09:27:20.296: INFO: created pod pod-service-account-mountsa
Aug 27 09:27:20.296: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 27 09:27:20.319: INFO: created pod pod-service-account-nomountsa
Aug 27 09:27:20.319: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 27 09:27:20.387: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 27 09:27:20.387: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 27 09:27:20.488: INFO: created pod pod-service-account-mountsa-mountspec
Aug 27 09:27:20.488: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 27 09:27:20.515: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 27 09:27:20.515: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 27 09:27:20.530: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 27 09:27:20.530: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 27 09:27:20.553: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 27 09:27:20.554: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 27 09:27:20.575: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 27 09:27:20.576: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:27:20.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4521" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":303,"completed":191,"skipped":3029,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:27:20.640: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating service in namespace services-9118
STEP: creating service affinity-nodeport-transition in namespace services-9118
STEP: creating replication controller affinity-nodeport-transition in namespace services-9118
I0827 09:27:20.806914      19 runners.go:190] Created replication controller with name: affinity-nodeport-transition, namespace: services-9118, replica count: 3
I0827 09:27:23.859249      19 runners.go:190] affinity-nodeport-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 09:27:26.860343      19 runners.go:190] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 09:27:26.867: INFO: Creating new exec pod
Aug 27 09:27:31.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-9118 execpod-affinity8qc2w -- /bin/sh -x -c nc -zv -t -w 2 affinity-nodeport-transition 80'
Aug 27 09:27:32.238: INFO: stderr: "+ nc -zv -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Aug 27 09:27:32.238: INFO: stdout: ""
Aug 27 09:27:32.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-9118 execpod-affinity8qc2w -- /bin/sh -x -c nc -zv -t -w 2 10.3.184.177 80'
Aug 27 09:27:32.487: INFO: stderr: "+ nc -zv -t -w 2 10.3.184.177 80\nConnection to 10.3.184.177 80 port [tcp/http] succeeded!\n"
Aug 27 09:27:32.487: INFO: stdout: ""
Aug 27 09:27:32.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-9118 execpod-affinity8qc2w -- /bin/sh -x -c nc -zv -t -w 2 10.0.45.43 31266'
Aug 27 09:27:32.877: INFO: stderr: "+ nc -zv -t -w 2 10.0.45.43 31266\nConnection to 10.0.45.43 31266 port [tcp/31266] succeeded!\n"
Aug 27 09:27:32.877: INFO: stdout: ""
Aug 27 09:27:32.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-9118 execpod-affinity8qc2w -- /bin/sh -x -c nc -zv -t -w 2 10.0.27.251 31266'
Aug 27 09:27:33.080: INFO: stderr: "+ nc -zv -t -w 2 10.0.27.251 31266\nConnection to 10.0.27.251 31266 port [tcp/31266] succeeded!\n"
Aug 27 09:27:33.080: INFO: stdout: ""
Aug 27 09:27:33.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-9118 execpod-affinity8qc2w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.2.216:31266/ ; done'
Aug 27 09:27:33.656: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n"
Aug 27 09:27:33.656: INFO: stdout: "\naffinity-nodeport-transition-fdkdd\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-kkksq\naffinity-nodeport-transition-fdkdd\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-kkksq\naffinity-nodeport-transition-fdkdd\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-kkksq\naffinity-nodeport-transition-fdkdd\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-kkksq\naffinity-nodeport-transition-fdkdd\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-kkksq\naffinity-nodeport-transition-fdkdd"
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-fdkdd
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-kkksq
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-fdkdd
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-kkksq
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-fdkdd
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-kkksq
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-fdkdd
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-kkksq
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-fdkdd
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-kkksq
Aug 27 09:27:33.656: INFO: Received response from host: affinity-nodeport-transition-fdkdd
Aug 27 09:27:33.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-9118 execpod-affinity8qc2w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.2.216:31266/ ; done'
Aug 27 09:27:34.181: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.2.216:31266/\n"
Aug 27 09:27:34.181: INFO: stdout: "\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6\naffinity-nodeport-transition-6zgw6"
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Received response from host: affinity-nodeport-transition-6zgw6
Aug 27 09:27:34.181: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-9118, will wait for the garbage collector to delete the pods
Aug 27 09:27:34.252: INFO: Deleting ReplicationController affinity-nodeport-transition took: 5.300469ms
Aug 27 09:27:34.753: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 500.822056ms
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:27:45.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9118" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:24.607 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":303,"completed":192,"skipped":3046,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:27:45.253: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0827 09:27:46.125535      19 metrics_grabber.go:105] Did not receive an external client interface. Grabbing metrics from ClusterAutoscaler is disabled.
Aug 27 09:27:48.164: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:27:48.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6199" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":303,"completed":193,"skipped":3066,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:27:48.181: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 27 09:27:48.223: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 09:27:48.230: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 09:27:48.233: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-2-216 before test
Aug 27 09:27:48.245: INFO: simpletest.deployment-78c8485b55-s5mc4 from gc-6199 started at 2020-08-27 09:27:45 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.245: INFO: 	Container nginx ready: true, restart count 0
Aug 27 09:27:48.246: INFO: calico-node-87ksr from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.246: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:27:48.246: INFO: coredns-69c75f5c45-9jz8t from kube-system started at 2020-08-27 08:09:33 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.246: INFO: 	Container coredns ready: true, restart count 0
Aug 27 09:27:48.247: INFO: kube-proxy-zlwf6 from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.247: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:27:48.247: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-mjhxq from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:27:48.247: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:27:48.247: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 09:27:48.248: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-27-251 before test
Aug 27 09:27:48.254: INFO: calico-node-8g49c from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.254: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:27:48.255: INFO: kube-proxy-zq947 from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.255: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:27:48.255: INFO: sonobuoy-e2e-job-3e3f44f310e74605 from sonobuoy started at 2020-08-27 08:10:16 +0000 UTC (2 container statuses recorded)
Aug 27 09:27:48.255: INFO: 	Container e2e ready: true, restart count 0
Aug 27 09:27:48.256: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 09:27:48.256: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-96j2z from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:27:48.256: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:27:48.256: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 09:27:48.256: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-45-43 before test
Aug 27 09:27:48.261: INFO: simpletest.deployment-78c8485b55-zh8x6 from gc-6199 started at 2020-08-27 09:27:45 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.261: INFO: 	Container nginx ready: true, restart count 0
Aug 27 09:27:48.261: INFO: calico-node-fj4mf from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.261: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:27:48.261: INFO: kube-proxy-9v45m from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.261: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:27:48.261: INFO: sonobuoy from sonobuoy started at 2020-08-27 08:10:12 +0000 UTC (1 container statuses recorded)
Aug 27 09:27:48.261: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 09:27:48.261: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-6xtvp from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:27:48.261: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:27:48.261: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5648899e-7729-4e07-9e34-a2ca843a2fe9 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-5648899e-7729-4e07-9e34-a2ca843a2fe9 off the node ip-10-0-2-216
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5648899e-7729-4e07-9e34-a2ca843a2fe9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:28:04.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9589" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:16.286 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":303,"completed":194,"skipped":3073,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:28:04.469: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:28:05.154: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:28:08.175: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:28:08.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1966" for this suite.
STEP: Destroying namespace "webhook-1966-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":303,"completed":195,"skipped":3096,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:28:08.288: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod pod-subpath-test-downwardapi-g4mp
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 09:28:08.348: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-g4mp" in namespace "subpath-5608" to be "Succeeded or Failed"
Aug 27 09:28:08.352: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Pending", Reason="", readiness=false. Elapsed: 3.764584ms
Aug 27 09:28:10.362: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014100224s
Aug 27 09:28:12.366: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 4.017752008s
Aug 27 09:28:14.369: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 6.021310081s
Aug 27 09:28:16.373: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 8.025609056s
Aug 27 09:28:18.377: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 10.029384614s
Aug 27 09:28:20.393: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 12.045121804s
Aug 27 09:28:22.398: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 14.05052367s
Aug 27 09:28:24.403: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 16.054666972s
Aug 27 09:28:26.407: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 18.058676745s
Aug 27 09:28:28.412: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Running", Reason="", readiness=true. Elapsed: 20.063739075s
Aug 27 09:28:30.415: INFO: Pod "pod-subpath-test-downwardapi-g4mp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.067359437s
STEP: Saw pod success
Aug 27 09:28:30.416: INFO: Pod "pod-subpath-test-downwardapi-g4mp" satisfied condition "Succeeded or Failed"
Aug 27 09:28:30.419: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-subpath-test-downwardapi-g4mp container test-container-subpath-downwardapi-g4mp: <nil>
STEP: delete the pod
Aug 27 09:28:30.440: INFO: Waiting for pod pod-subpath-test-downwardapi-g4mp to disappear
Aug 27 09:28:30.443: INFO: Pod pod-subpath-test-downwardapi-g4mp no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-g4mp
Aug 27 09:28:30.445: INFO: Deleting pod "pod-subpath-test-downwardapi-g4mp" in namespace "subpath-5608"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:28:30.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5608" for this suite.

• [SLOW TEST:22.169 seconds]
[sig-storage] Subpath
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":303,"completed":196,"skipped":3137,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:28:30.464: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2658
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-2658
I0827 09:28:30.567799      19 runners.go:190] Created replication controller with name: externalname-service, namespace: services-2658, replica count: 2
Aug 27 09:28:33.620: INFO: Creating new exec pod
I0827 09:28:33.620384      19 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 09:28:36.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2658 execpodkpkqz -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Aug 27 09:28:36.874: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 27 09:28:36.874: INFO: stdout: ""
Aug 27 09:28:36.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2658 execpodkpkqz -- /bin/sh -x -c nc -zv -t -w 2 10.3.157.236 80'
Aug 27 09:28:37.137: INFO: stderr: "+ nc -zv -t -w 2 10.3.157.236 80\nConnection to 10.3.157.236 80 port [tcp/http] succeeded!\n"
Aug 27 09:28:37.137: INFO: stdout: ""
Aug 27 09:28:37.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2658 execpodkpkqz -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.216 32722'
Aug 27 09:28:37.385: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.216 32722\nConnection to 10.0.2.216 32722 port [tcp/32722] succeeded!\n"
Aug 27 09:28:37.385: INFO: stdout: ""
Aug 27 09:28:37.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-2658 execpodkpkqz -- /bin/sh -x -c nc -zv -t -w 2 10.0.45.43 32722'
Aug 27 09:28:37.627: INFO: stderr: "+ nc -zv -t -w 2 10.0.45.43 32722\nConnection to 10.0.45.43 32722 port [tcp/32722] succeeded!\n"
Aug 27 09:28:37.627: INFO: stdout: ""
Aug 27 09:28:37.627: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:28:37.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2658" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:7.206 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":303,"completed":197,"skipped":3146,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:28:37.675: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: set up a multi version CRD
Aug 27 09:28:37.736: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:28:55.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8811" for this suite.

• [SLOW TEST:18.266 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":303,"completed":198,"skipped":3192,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:28:55.946: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:29:12.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7267" for this suite.

• [SLOW TEST:16.231 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":303,"completed":199,"skipped":3202,"failed":0}
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:29:12.188: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:29:14.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-731" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":303,"completed":200,"skipped":3203,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:29:14.275: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0827 09:29:54.367690      19 metrics_grabber.go:105] Did not receive an external client interface. Grabbing metrics from ClusterAutoscaler is disabled.
Aug 27 09:29:56.403: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 27 09:29:56.405: INFO: Deleting pod "simpletest.rc-5766t" in namespace "gc-5649"
Aug 27 09:29:56.419: INFO: Deleting pod "simpletest.rc-644w7" in namespace "gc-5649"
Aug 27 09:29:56.450: INFO: Deleting pod "simpletest.rc-8q7zk" in namespace "gc-5649"
Aug 27 09:29:56.475: INFO: Deleting pod "simpletest.rc-99wcs" in namespace "gc-5649"
Aug 27 09:29:56.594: INFO: Deleting pod "simpletest.rc-hp96w" in namespace "gc-5649"
Aug 27 09:29:56.699: INFO: Deleting pod "simpletest.rc-krx6x" in namespace "gc-5649"
Aug 27 09:29:56.714: INFO: Deleting pod "simpletest.rc-nbgln" in namespace "gc-5649"
Aug 27 09:29:56.751: INFO: Deleting pod "simpletest.rc-nm4nw" in namespace "gc-5649"
Aug 27 09:29:56.819: INFO: Deleting pod "simpletest.rc-nssgv" in namespace "gc-5649"
Aug 27 09:29:56.924: INFO: Deleting pod "simpletest.rc-s824s" in namespace "gc-5649"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:29:56.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5649" for this suite.

• [SLOW TEST:42.719 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":303,"completed":201,"skipped":3220,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:29:56.995: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:78
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:29:57.104: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 27 09:30:01.112: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
Aug 27 09:30:01.134: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2401 /apis/apps/v1/namespaces/deployment-2401/deployments/test-cleanup-deployment dae4abfa-e472-48ea-9da5-18c5627696cf 27055 1 2020-08-27 09:30:01 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2020-08-27 09:30:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{}}},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.20 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0059b5388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Aug 27 09:30:01.140: INFO: New ReplicaSet "test-cleanup-deployment-5d446bdd47" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-5d446bdd47  deployment-2401 /apis/apps/v1/namespaces/deployment-2401/replicasets/test-cleanup-deployment-5d446bdd47 e3b48ac6-3a89-4b24-aece-189fbb793090 27057 1 2020-08-27 09:30:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:5d446bdd47] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment dae4abfa-e472-48ea-9da5-18c5627696cf 0xc0059b5d87 0xc0059b5d88}] []  [{kube-controller-manager Update apps/v1 2020-08-27 09:30:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dae4abfa-e472-48ea-9da5-18c5627696cf\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 5d446bdd47,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:5d446bdd47] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.20 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0059b5ef8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:30:01.140: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug 27 09:30:01.141: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2401 /apis/apps/v1/namespaces/deployment-2401/replicasets/test-cleanup-controller 35939827-e8c0-489b-82dd-78ed27b64077 27056 1 2020-08-27 09:29:57 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment dae4abfa-e472-48ea-9da5-18c5627696cf 0xc0059b5af7 0xc0059b5af8}] []  [{e2e.test Update apps/v1 2020-08-27 09:29:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}} {kube-controller-manager Update apps/v1 2020-08-27 09:30:01 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"dae4abfa-e472-48ea-9da5-18c5627696cf\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0059b5ce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:30:01.163: INFO: Pod "test-cleanup-controller-ghh4k" is available:
&Pod{ObjectMeta:{test-cleanup-controller-ghh4k test-cleanup-controller- deployment-2401 /api/v1/namespaces/deployment-2401/pods/test-cleanup-controller-ghh4k 43c87a00-a1bf-46b3-a72b-0af57cb60e93 27053 0 2020-08-27 09:29:57 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:10.2.173.159/32 cni.projectcalico.org/podIPs:10.2.173.159/32] [{apps/v1 ReplicaSet test-cleanup-controller 35939827-e8c0-489b-82dd-78ed27b64077 0xc0078746f7 0xc0078746f8}] []  [{kube-controller-manager Update v1 2020-08-27 09:29:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"35939827-e8c0-489b-82dd-78ed27b64077\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:29:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:30:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.173.159\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hb668,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hb668,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hb668,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:29:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:30:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:30:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:29:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.216,PodIP:10.2.173.159,StartTime:2020-08-27 09:29:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:29:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5ea12d983f5b46341807a49f5cc2d8d6601867d8799239b32c3a6e5757d629e2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.173.159,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:30:01.163: INFO: Pod "test-cleanup-deployment-5d446bdd47-xzkgk" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-5d446bdd47-xzkgk test-cleanup-deployment-5d446bdd47- deployment-2401 /api/v1/namespaces/deployment-2401/pods/test-cleanup-deployment-5d446bdd47-xzkgk fcafba78-3821-4ff2-9b65-d74f2939c147 27059 0 2020-08-27 09:30:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:5d446bdd47] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-5d446bdd47 e3b48ac6-3a89-4b24-aece-189fbb793090 0xc007874907 0xc007874908}] []  [{kube-controller-manager Update v1 2020-08-27 09:30:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e3b48ac6-3a89-4b24-aece-189fbb793090\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hb668,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hb668,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.20,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hb668,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:30:01.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2401" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":303,"completed":202,"skipped":3231,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] PodTemplates
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:30:01.310: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Create set of pod templates
Aug 27 09:30:01.517: INFO: created test-podtemplate-1
Aug 27 09:30:01.523: INFO: created test-podtemplate-2
Aug 27 09:30:01.561: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Aug 27 09:30:01.567: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Aug 27 09:30:01.604: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:30:01.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-4001" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":303,"completed":203,"skipped":3261,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:30:01.681: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward api env vars
Aug 27 09:30:02.210: INFO: Waiting up to 5m0s for pod "downward-api-e2b2018e-9a27-4842-a351-6999824f8f7d" in namespace "downward-api-6034" to be "Succeeded or Failed"
Aug 27 09:30:02.302: INFO: Pod "downward-api-e2b2018e-9a27-4842-a351-6999824f8f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 91.772056ms
Aug 27 09:30:04.306: INFO: Pod "downward-api-e2b2018e-9a27-4842-a351-6999824f8f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095223875s
Aug 27 09:30:06.310: INFO: Pod "downward-api-e2b2018e-9a27-4842-a351-6999824f8f7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.099180308s
STEP: Saw pod success
Aug 27 09:30:06.310: INFO: Pod "downward-api-e2b2018e-9a27-4842-a351-6999824f8f7d" satisfied condition "Succeeded or Failed"
Aug 27 09:30:06.312: INFO: Trying to get logs from node ip-10-0-27-251 pod downward-api-e2b2018e-9a27-4842-a351-6999824f8f7d container dapi-container: <nil>
STEP: delete the pod
Aug 27 09:30:06.369: INFO: Waiting for pod downward-api-e2b2018e-9a27-4842-a351-6999824f8f7d to disappear
Aug 27 09:30:06.377: INFO: Pod downward-api-e2b2018e-9a27-4842-a351-6999824f8f7d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:30:06.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6034" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":303,"completed":204,"skipped":3269,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:30:06.397: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 27 09:30:06.455: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 09:30:06.463: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 09:30:06.468: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-2-216 before test
Aug 27 09:30:06.475: INFO: calico-node-87ksr from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.475: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:30:06.475: INFO: coredns-69c75f5c45-9jz8t from kube-system started at 2020-08-27 08:09:33 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.476: INFO: 	Container coredns ready: true, restart count 0
Aug 27 09:30:06.476: INFO: kube-proxy-zlwf6 from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.476: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:30:06.476: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-mjhxq from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:30:06.476: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:30:06.476: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 09:30:06.477: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-27-251 before test
Aug 27 09:30:06.483: INFO: calico-node-8g49c from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.484: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:30:06.484: INFO: kube-proxy-zq947 from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.484: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:30:06.484: INFO: sonobuoy-e2e-job-3e3f44f310e74605 from sonobuoy started at 2020-08-27 08:10:16 +0000 UTC (2 container statuses recorded)
Aug 27 09:30:06.484: INFO: 	Container e2e ready: true, restart count 0
Aug 27 09:30:06.484: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 09:30:06.485: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-96j2z from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:30:06.485: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:30:06.485: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 09:30:06.485: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-45-43 before test
Aug 27 09:30:06.494: INFO: test-cleanup-deployment-5d446bdd47-xzkgk from deployment-2401 started at 2020-08-27 09:30:01 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.494: INFO: 	Container agnhost ready: true, restart count 0
Aug 27 09:30:06.494: INFO: calico-node-fj4mf from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.494: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:30:06.494: INFO: kube-proxy-9v45m from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.495: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:30:06.495: INFO: sonobuoy from sonobuoy started at 2020-08-27 08:10:12 +0000 UTC (1 container statuses recorded)
Aug 27 09:30:06.495: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 09:30:06.495: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-6xtvp from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:30:06.495: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:30:06.495: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: verifying the node has the label node ip-10-0-2-216
STEP: verifying the node has the label node ip-10-0-27-251
STEP: verifying the node has the label node ip-10-0-45-43
Aug 27 09:30:06.589: INFO: Pod test-cleanup-deployment-5d446bdd47-xzkgk requesting resource cpu=0m on Node ip-10-0-45-43
Aug 27 09:30:06.589: INFO: Pod calico-node-87ksr requesting resource cpu=100m on Node ip-10-0-2-216
Aug 27 09:30:06.589: INFO: Pod calico-node-8g49c requesting resource cpu=100m on Node ip-10-0-27-251
Aug 27 09:30:06.589: INFO: Pod calico-node-fj4mf requesting resource cpu=100m on Node ip-10-0-45-43
Aug 27 09:30:06.589: INFO: Pod coredns-69c75f5c45-9jz8t requesting resource cpu=100m on Node ip-10-0-2-216
Aug 27 09:30:06.589: INFO: Pod kube-proxy-9v45m requesting resource cpu=0m on Node ip-10-0-45-43
Aug 27 09:30:06.589: INFO: Pod kube-proxy-zlwf6 requesting resource cpu=0m on Node ip-10-0-2-216
Aug 27 09:30:06.589: INFO: Pod kube-proxy-zq947 requesting resource cpu=0m on Node ip-10-0-27-251
Aug 27 09:30:06.589: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-45-43
Aug 27 09:30:06.589: INFO: Pod sonobuoy-e2e-job-3e3f44f310e74605 requesting resource cpu=0m on Node ip-10-0-27-251
Aug 27 09:30:06.589: INFO: Pod sonobuoy-systemd-logs-daemon-set-d85445ee63174525-6xtvp requesting resource cpu=0m on Node ip-10-0-45-43
Aug 27 09:30:06.589: INFO: Pod sonobuoy-systemd-logs-daemon-set-d85445ee63174525-96j2z requesting resource cpu=0m on Node ip-10-0-27-251
Aug 27 09:30:06.589: INFO: Pod sonobuoy-systemd-logs-daemon-set-d85445ee63174525-mjhxq requesting resource cpu=0m on Node ip-10-0-2-216
STEP: Starting Pods to consume most of the cluster CPU.
Aug 27 09:30:06.589: INFO: Creating a pod which consumes cpu=560m on Node ip-10-0-2-216
Aug 27 09:30:06.609: INFO: Creating a pod which consumes cpu=630m on Node ip-10-0-27-251
Aug 27 09:30:06.616: INFO: Creating a pod which consumes cpu=630m on Node ip-10-0-45-43
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-50690caf-296c-4d5b-bae2-00febc83a194.162f1606277f3cfe], Reason = [Created], Message = [Created container filler-pod-50690caf-296c-4d5b-bae2-00febc83a194]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4c21021-c7e3-499d-bcb2-225de893afe4.162f160615eabb54], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4c21021-c7e3-499d-bcb2-225de893afe4.162f16061d51285b], Reason = [Created], Message = [Created container filler-pod-d4c21021-c7e3-499d-bcb2-225de893afe4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-50690caf-296c-4d5b-bae2-00febc83a194.162f1605bc53f6da], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1780/filler-pod-50690caf-296c-4d5b-bae2-00febc83a194 to ip-10-0-27-251]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5bd8618c-a26b-4f27-b466-791fec4e3a64.162f16062d3163fa], Reason = [Started], Message = [Started container filler-pod-5bd8618c-a26b-4f27-b466-791fec4e3a64]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5bd8618c-a26b-4f27-b466-791fec4e3a64.162f160624aa8f2a], Reason = [Created], Message = [Created container filler-pod-5bd8618c-a26b-4f27-b466-791fec4e3a64]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5bd8618c-a26b-4f27-b466-791fec4e3a64.162f16061fdb43c6], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4c21021-c7e3-499d-bcb2-225de893afe4.162f160623ec4b8a], Reason = [Started], Message = [Started container filler-pod-d4c21021-c7e3-499d-bcb2-225de893afe4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4c21021-c7e3-499d-bcb2-225de893afe4.162f1605bdf14caa], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1780/filler-pod-d4c21021-c7e3-499d-bcb2-225de893afe4 to ip-10-0-45-43]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-50690caf-296c-4d5b-bae2-00febc83a194.162f160623e8a088], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5bd8618c-a26b-4f27-b466-791fec4e3a64.162f1605bc410723], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1780/filler-pod-5bd8618c-a26b-4f27-b466-791fec4e3a64 to ip-10-0-2-216]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-50690caf-296c-4d5b-bae2-00febc83a194.162f160630494bea], Reason = [Started], Message = [Started container filler-pod-50690caf-296c-4d5b-bae2-00febc83a194]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.162f1606b6c4ca8c], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-2-216
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-27-251
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-45-43
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:30:11.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1780" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:5.514 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":303,"completed":205,"skipped":3281,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:30:11.919: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-volume-76cc46e2-9444-4b72-b628-cae4e659cb0b
STEP: Creating a pod to test consume configMaps
Aug 27 09:30:11.992: INFO: Waiting up to 5m0s for pod "pod-configmaps-4754dbc6-3050-43a0-86e3-fc3dab02d376" in namespace "configmap-3359" to be "Succeeded or Failed"
Aug 27 09:30:12.004: INFO: Pod "pod-configmaps-4754dbc6-3050-43a0-86e3-fc3dab02d376": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010504ms
Aug 27 09:30:14.031: INFO: Pod "pod-configmaps-4754dbc6-3050-43a0-86e3-fc3dab02d376": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038208675s
STEP: Saw pod success
Aug 27 09:30:14.031: INFO: Pod "pod-configmaps-4754dbc6-3050-43a0-86e3-fc3dab02d376" satisfied condition "Succeeded or Failed"
Aug 27 09:30:14.034: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-4754dbc6-3050-43a0-86e3-fc3dab02d376 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:30:14.185: INFO: Waiting for pod pod-configmaps-4754dbc6-3050-43a0-86e3-fc3dab02d376 to disappear
Aug 27 09:30:14.216: INFO: Pod pod-configmaps-4754dbc6-3050-43a0-86e3-fc3dab02d376 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:30:14.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3359" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":303,"completed":206,"skipped":3308,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:30:14.283: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:32:14.502: INFO: Deleting pod "var-expansion-9c385271-6457-43bd-a66b-21733491d90e" in namespace "var-expansion-7831"
Aug 27 09:32:14.507: INFO: Wait up to 5m0s for pod "var-expansion-9c385271-6457-43bd-a66b-21733491d90e" to be fully deleted
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:32:16.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7831" for this suite.

• [SLOW TEST:122.248 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should fail substituting values in a volume subpath with absolute path [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should fail substituting values in a volume subpath with absolute path [sig-storage][Slow] [Conformance]","total":303,"completed":207,"skipped":3327,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:32:16.532: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:32:16.567: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Aug 27 09:32:20.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-3435 create -f -'
Aug 27 09:32:20.483: INFO: stderr: ""
Aug 27 09:32:20.483: INFO: stdout: "e2e-test-crd-publish-openapi-2517-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 27 09:32:20.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-3435 delete e2e-test-crd-publish-openapi-2517-crds test-foo'
Aug 27 09:32:20.573: INFO: stderr: ""
Aug 27 09:32:20.573: INFO: stdout: "e2e-test-crd-publish-openapi-2517-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Aug 27 09:32:20.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-3435 apply -f -'
Aug 27 09:32:20.848: INFO: stderr: ""
Aug 27 09:32:20.848: INFO: stdout: "e2e-test-crd-publish-openapi-2517-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 27 09:32:20.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-3435 delete e2e-test-crd-publish-openapi-2517-crds test-foo'
Aug 27 09:32:20.934: INFO: stderr: ""
Aug 27 09:32:20.934: INFO: stdout: "e2e-test-crd-publish-openapi-2517-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Aug 27 09:32:20.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-3435 create -f -'
Aug 27 09:32:21.133: INFO: rc: 1
Aug 27 09:32:21.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-3435 apply -f -'
Aug 27 09:32:21.399: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Aug 27 09:32:21.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-3435 create -f -'
Aug 27 09:32:21.607: INFO: rc: 1
Aug 27 09:32:21.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-3435 apply -f -'
Aug 27 09:32:21.790: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Aug 27 09:32:21.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 explain e2e-test-crd-publish-openapi-2517-crds'
Aug 27 09:32:21.973: INFO: stderr: ""
Aug 27 09:32:21.973: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Aug 27 09:32:21.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 explain e2e-test-crd-publish-openapi-2517-crds.metadata'
Aug 27 09:32:22.162: INFO: stderr: ""
Aug 27 09:32:22.162: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     NOT return a 409 - instead, it will either return 201 Created or 500 with\n     Reason ServerTimeout indicating a unique name could not be found in the\n     time allotted, and the client should retry (optionally after the time\n     indicated in the Retry-After header).\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only.\n\n     DEPRECATED Kubernetes will stop propagating this field in 1.20 release and\n     the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Aug 27 09:32:22.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 explain e2e-test-crd-publish-openapi-2517-crds.spec'
Aug 27 09:32:22.365: INFO: stderr: ""
Aug 27 09:32:22.365: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Aug 27 09:32:22.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 explain e2e-test-crd-publish-openapi-2517-crds.spec.bars'
Aug 27 09:32:22.582: INFO: stderr: ""
Aug 27 09:32:22.582: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Aug 27 09:32:22.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 explain e2e-test-crd-publish-openapi-2517-crds.spec.bars2'
Aug 27 09:32:22.777: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:32:26.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3435" for this suite.

• [SLOW TEST:9.672 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":303,"completed":208,"skipped":3333,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-instrumentation] Events API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:32:26.210: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:32:26.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5734" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":303,"completed":209,"skipped":3351,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:32:26.324: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:78
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:32:26.372: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 27 09:32:26.383: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 27 09:32:31.403: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 27 09:32:31.404: INFO: Creating deployment "test-rolling-update-deployment"
Aug 27 09:32:31.425: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 27 09:32:31.474: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 27 09:32:33.481: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 27 09:32:33.492: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
Aug 27 09:32:33.501: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9437 /apis/apps/v1/namespaces/deployment-9437/deployments/test-rolling-update-deployment e427591a-76e4-4467-9537-4289108c4f6e 27849 1 2020-08-27 09:32:31 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-08-27 09:32:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{}}},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}} {kube-controller-manager Update apps/v1 2020-08-27 09:32:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.20 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0016d5398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-08-27 09:32:31 +0000 UTC,LastTransitionTime:2020-08-27 09:32:31 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-c4cb8d6d9" has successfully progressed.,LastUpdateTime:2020-08-27 09:32:33 +0000 UTC,LastTransitionTime:2020-08-27 09:32:31 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 09:32:33.508: INFO: New ReplicaSet "test-rolling-update-deployment-c4cb8d6d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-c4cb8d6d9  deployment-9437 /apis/apps/v1/namespaces/deployment-9437/replicasets/test-rolling-update-deployment-c4cb8d6d9 4aef3efc-672f-4070-993c-6a5454eecba5 27838 1 2020-08-27 09:32:31 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:c4cb8d6d9] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment e427591a-76e4-4467-9537-4289108c4f6e 0xc0016d5a60 0xc0016d5a61}] []  [{kube-controller-manager Update apps/v1 2020-08-27 09:32:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e427591a-76e4-4467-9537-4289108c4f6e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}},"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: c4cb8d6d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:c4cb8d6d9] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.20 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0016d5b68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:32:33.508: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 27 09:32:33.509: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9437 /apis/apps/v1/namespaces/deployment-9437/replicasets/test-rolling-update-controller 13757f7c-be1f-41b5-a6c8-1b3faab6ecc4 27847 2 2020-08-27 09:32:26 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment e427591a-76e4-4467-9537-4289108c4f6e 0xc0016d5937 0xc0016d5938}] []  [{e2e.test Update apps/v1 2020-08-27 09:32:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}} {kube-controller-manager Update apps/v1 2020-08-27 09:32:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e427591a-76e4-4467-9537-4289108c4f6e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:replicas":{}},"f:status":{"f:observedGeneration":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0016d59e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:32:33.512: INFO: Pod "test-rolling-update-deployment-c4cb8d6d9-5px8x" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-c4cb8d6d9-5px8x test-rolling-update-deployment-c4cb8d6d9- deployment-9437 /api/v1/namespaces/deployment-9437/pods/test-rolling-update-deployment-c4cb8d6d9-5px8x 619f4bd8-6a81-4cc0-a338-27d4f68e9e19 27837 0 2020-08-27 09:32:31 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:c4cb8d6d9] map[cni.projectcalico.org/podIP:10.2.193.100/32 cni.projectcalico.org/podIPs:10.2.193.100/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-c4cb8d6d9 4aef3efc-672f-4070-993c-6a5454eecba5 0xc00184c170 0xc00184c171}] []  [{kube-controller-manager Update v1 2020-08-27 09:32:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4aef3efc-672f-4070-993c-6a5454eecba5\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:32:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:32:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.193.100\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-d57w6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-d57w6,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.20,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-d57w6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:32:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:32:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:32:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:32:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.45.43,PodIP:10.2.193.100,StartTime:2020-08-27 09:32:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:32:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.20,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0,ContainerID:docker://30fe04403e344dafc47bbe0fb367f1d00315a1f50e64c134b1a586759cb2d423,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.193.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:32:33.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9437" for this suite.

• [SLOW TEST:7.194 seconds]
[sig-apps] Deployment
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":303,"completed":210,"skipped":3366,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:32:33.532: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 27 09:32:33.578: INFO: Waiting up to 5m0s for pod "pod-1cb53090-8755-47a7-a902-4d2cd2d9184e" in namespace "emptydir-6146" to be "Succeeded or Failed"
Aug 27 09:32:33.581: INFO: Pod "pod-1cb53090-8755-47a7-a902-4d2cd2d9184e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.325615ms
Aug 27 09:32:35.597: INFO: Pod "pod-1cb53090-8755-47a7-a902-4d2cd2d9184e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019451494s
Aug 27 09:32:37.604: INFO: Pod "pod-1cb53090-8755-47a7-a902-4d2cd2d9184e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025994962s
STEP: Saw pod success
Aug 27 09:32:37.605: INFO: Pod "pod-1cb53090-8755-47a7-a902-4d2cd2d9184e" satisfied condition "Succeeded or Failed"
Aug 27 09:32:37.607: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-1cb53090-8755-47a7-a902-4d2cd2d9184e container test-container: <nil>
STEP: delete the pod
Aug 27 09:32:37.635: INFO: Waiting for pod pod-1cb53090-8755-47a7-a902-4d2cd2d9184e to disappear
Aug 27 09:32:37.638: INFO: Pod pod-1cb53090-8755-47a7-a902-4d2cd2d9184e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:32:37.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6146" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":211,"skipped":3384,"failed":0}
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:32:37.648: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test override all
Aug 27 09:32:37.690: INFO: Waiting up to 5m0s for pod "client-containers-cd8f5369-190a-442b-855c-62526d9a861d" in namespace "containers-9199" to be "Succeeded or Failed"
Aug 27 09:32:37.692: INFO: Pod "client-containers-cd8f5369-190a-442b-855c-62526d9a861d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.246194ms
Aug 27 09:32:39.695: INFO: Pod "client-containers-cd8f5369-190a-442b-855c-62526d9a861d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005169453s
STEP: Saw pod success
Aug 27 09:32:39.696: INFO: Pod "client-containers-cd8f5369-190a-442b-855c-62526d9a861d" satisfied condition "Succeeded or Failed"
Aug 27 09:32:39.698: INFO: Trying to get logs from node ip-10-0-2-216 pod client-containers-cd8f5369-190a-442b-855c-62526d9a861d container test-container: <nil>
STEP: delete the pod
Aug 27 09:32:39.721: INFO: Waiting for pod client-containers-cd8f5369-190a-442b-855c-62526d9a861d to disappear
Aug 27 09:32:39.724: INFO: Pod client-containers-cd8f5369-190a-442b-855c-62526d9a861d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:32:39.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9199" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":303,"completed":212,"skipped":3389,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:32:39.735: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[BeforeEach] Kubectl label
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1333
STEP: creating the pod
Aug 27 09:32:39.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-8953'
Aug 27 09:32:40.023: INFO: stderr: ""
Aug 27 09:32:40.023: INFO: stdout: "pod/pause created\n"
Aug 27 09:32:40.023: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 27 09:32:40.023: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8953" to be "running and ready"
Aug 27 09:32:40.031: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.724211ms
Aug 27 09:32:42.035: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.012895437s
Aug 27 09:32:42.036: INFO: Pod "pause" satisfied condition "running and ready"
Aug 27 09:32:42.036: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 27 09:32:42.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 label pods pause testing-label=testing-label-value --namespace=kubectl-8953'
Aug 27 09:32:42.209: INFO: stderr: ""
Aug 27 09:32:42.209: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 27 09:32:42.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pod pause -L testing-label --namespace=kubectl-8953'
Aug 27 09:32:42.364: INFO: stderr: ""
Aug 27 09:32:42.364: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 27 09:32:42.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 label pods pause testing-label- --namespace=kubectl-8953'
Aug 27 09:32:42.489: INFO: stderr: ""
Aug 27 09:32:42.489: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 27 09:32:42.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pod pause -L testing-label --namespace=kubectl-8953'
Aug 27 09:32:42.624: INFO: stderr: ""
Aug 27 09:32:42.624: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1340
STEP: using delete to clean up resources
Aug 27 09:32:42.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-8953'
Aug 27 09:32:42.751: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 09:32:42.751: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 27 09:32:42.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get rc,svc -l name=pause --no-headers --namespace=kubectl-8953'
Aug 27 09:32:42.847: INFO: stderr: "No resources found in kubectl-8953 namespace.\n"
Aug 27 09:32:42.847: INFO: stdout: ""
Aug 27 09:32:42.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -l name=pause --namespace=kubectl-8953 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 09:32:42.937: INFO: stderr: ""
Aug 27 09:32:42.937: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:32:42.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8953" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":303,"completed":213,"skipped":3395,"failed":0}
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:32:42.948: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:103
STEP: Creating service test in namespace statefulset-6292
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a new StatefulSet
Aug 27 09:32:43.037: INFO: Found 0 stateful pods, waiting for 3
Aug 27 09:32:53.041: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 09:32:53.041: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 09:32:53.041: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 09:32:53.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-6292 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 09:32:53.360: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 09:32:53.360: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 09:32:53.360: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Aug 27 09:33:03.397: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 27 09:33:13.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-6292 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 09:33:13.677: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 09:33:13.677: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 09:33:13.677: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 09:33:23.720: INFO: Waiting for StatefulSet statefulset-6292/ss2 to complete update
Aug 27 09:33:23.720: INFO: Waiting for Pod statefulset-6292/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 27 09:33:23.720: INFO: Waiting for Pod statefulset-6292/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 27 09:33:23.720: INFO: Waiting for Pod statefulset-6292/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 27 09:33:33.727: INFO: Waiting for StatefulSet statefulset-6292/ss2 to complete update
Aug 27 09:33:33.728: INFO: Waiting for Pod statefulset-6292/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 27 09:33:33.728: INFO: Waiting for Pod statefulset-6292/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Aug 27 09:33:43.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-6292 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 09:33:43.923: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 09:33:43.923: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 09:33:43.923: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 09:33:53.952: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 27 09:34:03.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=statefulset-6292 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 09:34:04.316: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 09:34:04.316: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 09:34:04.316: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:114
Aug 27 09:34:24.333: INFO: Deleting all statefulset in ns statefulset-6292
Aug 27 09:34:24.335: INFO: Scaling statefulset ss2 to 0
Aug 27 09:34:54.356: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 09:34:54.360: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:34:54.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6292" for this suite.

• [SLOW TEST:131.448 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":303,"completed":214,"skipped":3396,"failed":0}
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:34:54.400: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:34:54.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7260" for this suite.
STEP: Destroying namespace "nspatchtest-a8f3e3a7-42dc-4706-8dc8-d3a2ce3cd658-8884" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":303,"completed":215,"skipped":3398,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:34:54.529: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap configmap-1590/configmap-test-711cd76f-8c3d-427f-9248-b926e48d1246
STEP: Creating a pod to test consume configMaps
Aug 27 09:34:54.575: INFO: Waiting up to 5m0s for pod "pod-configmaps-05b61129-fb4a-4d35-ae93-f3c476061f64" in namespace "configmap-1590" to be "Succeeded or Failed"
Aug 27 09:34:54.580: INFO: Pod "pod-configmaps-05b61129-fb4a-4d35-ae93-f3c476061f64": Phase="Pending", Reason="", readiness=false. Elapsed: 3.754662ms
Aug 27 09:34:56.583: INFO: Pod "pod-configmaps-05b61129-fb4a-4d35-ae93-f3c476061f64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00701861s
STEP: Saw pod success
Aug 27 09:34:56.584: INFO: Pod "pod-configmaps-05b61129-fb4a-4d35-ae93-f3c476061f64" satisfied condition "Succeeded or Failed"
Aug 27 09:34:56.587: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-05b61129-fb4a-4d35-ae93-f3c476061f64 container env-test: <nil>
STEP: delete the pod
Aug 27 09:34:56.615: INFO: Waiting for pod pod-configmaps-05b61129-fb4a-4d35-ae93-f3c476061f64 to disappear
Aug 27 09:34:56.618: INFO: Pod pod-configmaps-05b61129-fb4a-4d35-ae93-f3c476061f64 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:34:56.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1590" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":303,"completed":216,"skipped":3457,"failed":0}
SSSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-instrumentation] Events API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:34:56.632: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should delete a collection of events [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Aug 27 09:34:56.829: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:34:56.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1066" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":303,"completed":217,"skipped":3463,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:34:56.899: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 27 09:34:59.021: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:34:59.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5497" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":303,"completed":218,"skipped":3494,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:34:59.077: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:02.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2818" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":303,"completed":219,"skipped":3498,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:02.187: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:35:02.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db817678-c2ed-4c95-897b-df5069143412" in namespace "downward-api-2086" to be "Succeeded or Failed"
Aug 27 09:35:02.288: INFO: Pod "downwardapi-volume-db817678-c2ed-4c95-897b-df5069143412": Phase="Pending", Reason="", readiness=false. Elapsed: 8.999374ms
Aug 27 09:35:04.290: INFO: Pod "downwardapi-volume-db817678-c2ed-4c95-897b-df5069143412": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01150311s
Aug 27 09:35:06.294: INFO: Pod "downwardapi-volume-db817678-c2ed-4c95-897b-df5069143412": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015577453s
STEP: Saw pod success
Aug 27 09:35:06.294: INFO: Pod "downwardapi-volume-db817678-c2ed-4c95-897b-df5069143412" satisfied condition "Succeeded or Failed"
Aug 27 09:35:06.298: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-db817678-c2ed-4c95-897b-df5069143412 container client-container: <nil>
STEP: delete the pod
Aug 27 09:35:06.331: INFO: Waiting for pod downwardapi-volume-db817678-c2ed-4c95-897b-df5069143412 to disappear
Aug 27 09:35:06.334: INFO: Pod downwardapi-volume-db817678-c2ed-4c95-897b-df5069143412 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:06.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2086" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":303,"completed":220,"skipped":3500,"failed":0}
S
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:06.342: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:35:06.392: INFO: Waiting up to 5m0s for pod "busybox-user-65534-1e9158b2-1a2e-45c0-8c16-e77322a5bc10" in namespace "security-context-test-8781" to be "Succeeded or Failed"
Aug 27 09:35:06.396: INFO: Pod "busybox-user-65534-1e9158b2-1a2e-45c0-8c16-e77322a5bc10": Phase="Pending", Reason="", readiness=false. Elapsed: 3.348881ms
Aug 27 09:35:08.399: INFO: Pod "busybox-user-65534-1e9158b2-1a2e-45c0-8c16-e77322a5bc10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006909207s
Aug 27 09:35:08.400: INFO: Pod "busybox-user-65534-1e9158b2-1a2e-45c0-8c16-e77322a5bc10" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:08.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8781" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":221,"skipped":3501,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:08.412: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:35:08.794: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:35:10.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117708, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117708, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117708, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117708, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:35:13.813: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:35:13.816: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6441-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:15.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2628" for this suite.
STEP: Destroying namespace "webhook-2628-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.384 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":303,"completed":222,"skipped":3516,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:15.804: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap configmap-9668/configmap-test-20490d33-1fe3-4de5-973a-d32342b05ffe
STEP: Creating a pod to test consume configMaps
Aug 27 09:35:15.863: INFO: Waiting up to 5m0s for pod "pod-configmaps-64b75065-029c-4977-afea-81001f189ddc" in namespace "configmap-9668" to be "Succeeded or Failed"
Aug 27 09:35:15.880: INFO: Pod "pod-configmaps-64b75065-029c-4977-afea-81001f189ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 16.506932ms
Aug 27 09:35:17.883: INFO: Pod "pod-configmaps-64b75065-029c-4977-afea-81001f189ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020226787s
Aug 27 09:35:19.889: INFO: Pod "pod-configmaps-64b75065-029c-4977-afea-81001f189ddc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025466816s
STEP: Saw pod success
Aug 27 09:35:19.889: INFO: Pod "pod-configmaps-64b75065-029c-4977-afea-81001f189ddc" satisfied condition "Succeeded or Failed"
Aug 27 09:35:19.891: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-64b75065-029c-4977-afea-81001f189ddc container env-test: <nil>
STEP: delete the pod
Aug 27 09:35:19.909: INFO: Waiting for pod pod-configmaps-64b75065-029c-4977-afea-81001f189ddc to disappear
Aug 27 09:35:19.913: INFO: Pod pod-configmaps-64b75065-029c-4977-afea-81001f189ddc no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:19.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9668" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":303,"completed":223,"skipped":3526,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:19.931: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:35:20.860: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:35:22.869: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117720, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117720, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117720, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117720, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:35:25.882: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:35:25.886: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1710-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:27.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2576" for this suite.
STEP: Destroying namespace "webhook-2576-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.866 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":303,"completed":224,"skipped":3527,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:27.804: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating projection with secret that has name projected-secret-test-039e6f10-c040-477b-9326-b5bd27b47d0c
STEP: Creating a pod to test consume secrets
Aug 27 09:35:27.871: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9fd4fb63-99ce-44bc-9fc7-eab75b010c4f" in namespace "projected-2029" to be "Succeeded or Failed"
Aug 27 09:35:27.879: INFO: Pod "pod-projected-secrets-9fd4fb63-99ce-44bc-9fc7-eab75b010c4f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.405516ms
Aug 27 09:35:29.882: INFO: Pod "pod-projected-secrets-9fd4fb63-99ce-44bc-9fc7-eab75b010c4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009610939s
STEP: Saw pod success
Aug 27 09:35:29.882: INFO: Pod "pod-projected-secrets-9fd4fb63-99ce-44bc-9fc7-eab75b010c4f" satisfied condition "Succeeded or Failed"
Aug 27 09:35:29.885: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-secrets-9fd4fb63-99ce-44bc-9fc7-eab75b010c4f container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 09:35:29.906: INFO: Waiting for pod pod-projected-secrets-9fd4fb63-99ce-44bc-9fc7-eab75b010c4f to disappear
Aug 27 09:35:29.909: INFO: Pod pod-projected-secrets-9fd4fb63-99ce-44bc-9fc7-eab75b010c4f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:29.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2029" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":225,"skipped":3531,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:29.921: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating the pod
Aug 27 09:35:32.509: INFO: Successfully updated pod "labelsupdate069a14bf-bad0-47be-81c8-661cdf4e2b20"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:34.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-908" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":303,"completed":226,"skipped":3536,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:34.568: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:35:34.727: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 27 09:35:38.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-1671 create -f -'
Aug 27 09:35:38.556: INFO: stderr: ""
Aug 27 09:35:38.556: INFO: stdout: "e2e-test-crd-publish-openapi-3786-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 27 09:35:38.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-1671 delete e2e-test-crd-publish-openapi-3786-crds test-cr'
Aug 27 09:35:38.643: INFO: stderr: ""
Aug 27 09:35:38.643: INFO: stdout: "e2e-test-crd-publish-openapi-3786-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Aug 27 09:35:38.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-1671 apply -f -'
Aug 27 09:35:38.840: INFO: stderr: ""
Aug 27 09:35:38.840: INFO: stdout: "e2e-test-crd-publish-openapi-3786-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 27 09:35:38.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 --namespace=crd-publish-openapi-1671 delete e2e-test-crd-publish-openapi-3786-crds test-cr'
Aug 27 09:35:38.949: INFO: stderr: ""
Aug 27 09:35:38.949: INFO: stdout: "e2e-test-crd-publish-openapi-3786-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Aug 27 09:35:38.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 explain e2e-test-crd-publish-openapi-3786-crds'
Aug 27 09:35:39.167: INFO: stderr: ""
Aug 27 09:35:39.167: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3786-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:42.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1671" for this suite.

• [SLOW TEST:8.088 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":303,"completed":227,"skipped":3553,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:42.661: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 27 09:35:42.746: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 09:35:42.761: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 09:35:42.768: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-2-216 before test
Aug 27 09:35:42.776: INFO: calico-node-87ksr from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.776: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:35:42.776: INFO: coredns-69c75f5c45-9jz8t from kube-system started at 2020-08-27 08:09:33 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.776: INFO: 	Container coredns ready: true, restart count 0
Aug 27 09:35:42.776: INFO: kube-proxy-zlwf6 from kube-system started at 2020-08-27 08:08:58 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.777: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:35:42.777: INFO: labelsupdate069a14bf-bad0-47be-81c8-661cdf4e2b20 from projected-908 started at 2020-08-27 09:35:29 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.777: INFO: 	Container client-container ready: false, restart count 0
Aug 27 09:35:42.777: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-mjhxq from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:35:42.777: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:35:42.777: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 09:35:42.777: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-27-251 before test
Aug 27 09:35:42.783: INFO: calico-node-8g49c from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.783: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:35:42.783: INFO: kube-proxy-zq947 from kube-system started at 2020-08-27 08:09:23 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.784: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:35:42.784: INFO: sonobuoy-e2e-job-3e3f44f310e74605 from sonobuoy started at 2020-08-27 08:10:16 +0000 UTC (2 container statuses recorded)
Aug 27 09:35:42.784: INFO: 	Container e2e ready: true, restart count 0
Aug 27 09:35:42.784: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 09:35:42.784: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-96j2z from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:35:42.784: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:35:42.785: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 09:35:42.785: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-45-43 before test
Aug 27 09:35:42.791: INFO: calico-node-fj4mf from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.791: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 09:35:42.792: INFO: kube-proxy-9v45m from kube-system started at 2020-08-27 08:08:57 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.792: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 09:35:42.792: INFO: sonobuoy from sonobuoy started at 2020-08-27 08:10:12 +0000 UTC (1 container statuses recorded)
Aug 27 09:35:42.792: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 09:35:42.792: INFO: sonobuoy-systemd-logs-daemon-set-d85445ee63174525-6xtvp from sonobuoy started at 2020-08-27 08:10:17 +0000 UTC (2 container statuses recorded)
Aug 27 09:35:42.792: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 27 09:35:42.793: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.162f165402c9d6bb], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:43.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5703" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":303,"completed":228,"skipped":3584,"failed":0}
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:43.830: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 27 09:35:47.888: INFO: &Pod{ObjectMeta:{send-events-29d98410-771d-4561-92b3-a25dc6b727bf  events-9560 /api/v1/namespaces/events-9560/pods/send-events-29d98410-771d-4561-92b3-a25dc6b727bf a4368f54-44e9-4511-b73f-365b5f0f6ad5 29417 0 2020-08-27 09:35:43 +0000 UTC <nil> <nil> map[name:foo time:871528427] map[cni.projectcalico.org/podIP:10.2.173.177/32 cni.projectcalico.org/podIPs:10.2.173.177/32] [] []  [{e2e.test Update v1 2020-08-27 09:35:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:time":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"p\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":80,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:35:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:35:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.173.177\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-thc28,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-thc28,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:p,Image:k8s.gcr.io/e2e-test-images/agnhost:2.20,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-thc28,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:35:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:35:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.216,PodIP:10.2.173.177,StartTime:2020-08-27 09:35:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:35:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.20,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0,ContainerID:docker://6173a6d52d500aec62b93298c50f2de60d2523d8e06bd99452762f5f541c3c14,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.173.177,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Aug 27 09:35:49.894: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 27 09:35:51.899: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:51.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9560" for this suite.

• [SLOW TEST:8.086 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":303,"completed":229,"skipped":3590,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:51.920: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:35:55.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6131" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":303,"completed":230,"skipped":3620,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:35:55.989: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:35:56.041: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5c2bb8bd-0ff7-4304-81b9-adccc1a129a5" in namespace "projected-2715" to be "Succeeded or Failed"
Aug 27 09:35:56.045: INFO: Pod "downwardapi-volume-5c2bb8bd-0ff7-4304-81b9-adccc1a129a5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.202788ms
Aug 27 09:35:58.053: INFO: Pod "downwardapi-volume-5c2bb8bd-0ff7-4304-81b9-adccc1a129a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011067702s
Aug 27 09:36:00.074: INFO: Pod "downwardapi-volume-5c2bb8bd-0ff7-4304-81b9-adccc1a129a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032612994s
STEP: Saw pod success
Aug 27 09:36:00.075: INFO: Pod "downwardapi-volume-5c2bb8bd-0ff7-4304-81b9-adccc1a129a5" satisfied condition "Succeeded or Failed"
Aug 27 09:36:00.078: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-5c2bb8bd-0ff7-4304-81b9-adccc1a129a5 container client-container: <nil>
STEP: delete the pod
Aug 27 09:36:00.134: INFO: Waiting for pod downwardapi-volume-5c2bb8bd-0ff7-4304-81b9-adccc1a129a5 to disappear
Aug 27 09:36:00.139: INFO: Pod downwardapi-volume-5c2bb8bd-0ff7-4304-81b9-adccc1a129a5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:36:00.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2715" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":303,"completed":231,"skipped":3627,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:36:00.228: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:36:04.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9402" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":232,"skipped":3658,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:36:04.388: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod pod-subpath-test-configmap-spwt
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 09:36:04.449: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-spwt" in namespace "subpath-3972" to be "Succeeded or Failed"
Aug 27 09:36:04.452: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.953407ms
Aug 27 09:36:06.455: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 2.006218162s
Aug 27 09:36:08.459: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 4.010536054s
Aug 27 09:36:10.464: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 6.015245568s
Aug 27 09:36:12.469: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 8.019774882s
Aug 27 09:36:14.473: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 10.023927393s
Aug 27 09:36:16.477: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 12.027805618s
Aug 27 09:36:18.483: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 14.034098747s
Aug 27 09:36:20.488: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 16.039105031s
Aug 27 09:36:22.493: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 18.044310177s
Aug 27 09:36:24.498: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Running", Reason="", readiness=true. Elapsed: 20.048659448s
Aug 27 09:36:26.501: INFO: Pod "pod-subpath-test-configmap-spwt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.051843012s
STEP: Saw pod success
Aug 27 09:36:26.502: INFO: Pod "pod-subpath-test-configmap-spwt" satisfied condition "Succeeded or Failed"
Aug 27 09:36:26.505: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-subpath-test-configmap-spwt container test-container-subpath-configmap-spwt: <nil>
STEP: delete the pod
Aug 27 09:36:26.524: INFO: Waiting for pod pod-subpath-test-configmap-spwt to disappear
Aug 27 09:36:26.530: INFO: Pod pod-subpath-test-configmap-spwt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-spwt
Aug 27 09:36:26.530: INFO: Deleting pod "pod-subpath-test-configmap-spwt" in namespace "subpath-3972"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:36:26.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3972" for this suite.

• [SLOW TEST:22.164 seconds]
[sig-storage] Subpath
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":303,"completed":233,"skipped":3676,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:36:26.556: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:36:27.344: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:36:29.352: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117787, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117787, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117787, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117787, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:36:32.379: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:36:32.382: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-430-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:36:34.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3625" for this suite.
STEP: Destroying namespace "webhook-3625-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.755 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":303,"completed":234,"skipped":3679,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:36:34.315: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:36:34.417: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a771c13-8d26-4c7b-a70d-55435dfa014b" in namespace "projected-1224" to be "Succeeded or Failed"
Aug 27 09:36:34.437: INFO: Pod "downwardapi-volume-6a771c13-8d26-4c7b-a70d-55435dfa014b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.614725ms
Aug 27 09:36:36.441: INFO: Pod "downwardapi-volume-6a771c13-8d26-4c7b-a70d-55435dfa014b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023753389s
Aug 27 09:36:38.444: INFO: Pod "downwardapi-volume-6a771c13-8d26-4c7b-a70d-55435dfa014b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027705386s
STEP: Saw pod success
Aug 27 09:36:38.445: INFO: Pod "downwardapi-volume-6a771c13-8d26-4c7b-a70d-55435dfa014b" satisfied condition "Succeeded or Failed"
Aug 27 09:36:38.448: INFO: Trying to get logs from node ip-10-0-2-216 pod downwardapi-volume-6a771c13-8d26-4c7b-a70d-55435dfa014b container client-container: <nil>
STEP: delete the pod
Aug 27 09:36:38.463: INFO: Waiting for pod downwardapi-volume-6a771c13-8d26-4c7b-a70d-55435dfa014b to disappear
Aug 27 09:36:38.467: INFO: Pod downwardapi-volume-6a771c13-8d26-4c7b-a70d-55435dfa014b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:36:38.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1224" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":303,"completed":235,"skipped":3699,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Events 
  should delete a collection of events [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Events
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:36:38.481: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Create set of events
Aug 27 09:36:38.518: INFO: created test-event-1
Aug 27 09:36:38.523: INFO: created test-event-2
Aug 27 09:36:38.527: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Aug 27 09:36:38.532: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Aug 27 09:36:38.544: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-api-machinery] Events
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:36:38.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-461" for this suite.
•{"msg":"PASSED [sig-api-machinery] Events should delete a collection of events [Conformance]","total":303,"completed":236,"skipped":3711,"failed":0}
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:36:38.579: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Performing setup for networking test in namespace pod-network-test-403
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 27 09:36:38.615: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 27 09:36:38.678: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 09:36:40.687: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 09:36:42.691: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:36:44.681: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:36:46.682: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:36:48.680: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:36:50.682: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:36:52.681: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:36:54.681: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug 27 09:36:54.686: INFO: The status of Pod netserver-1 is Running (Ready = true)
Aug 27 09:36:54.691: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Aug 27 09:36:56.742: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.173.180:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-403 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 09:36:56.743: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 09:36:56.866: INFO: Found all expected endpoints: [netserver-0]
Aug 27 09:36:56.871: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.148.58:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-403 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 09:36:56.872: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 09:36:57.015: INFO: Found all expected endpoints: [netserver-1]
Aug 27 09:36:57.019: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.193.111:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-403 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 09:36:57.020: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 09:36:57.147: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:36:57.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-403" for this suite.

• [SLOW TEST:18.577 seconds]
[sig-network] Networking
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":237,"skipped":3718,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:36:57.160: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 27 09:37:00.246: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:00.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2540" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":303,"completed":238,"skipped":3755,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:00.271: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[BeforeEach] Kubectl logs
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1415
STEP: creating an pod
Aug 27 09:37:00.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.20 --namespace=kubectl-821 --restart=Never -- logs-generator --log-lines-total 100 --run-duration 20s'
Aug 27 09:37:00.551: INFO: stderr: ""
Aug 27 09:37:00.551: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Waiting for log generator to start.
Aug 27 09:37:00.551: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Aug 27 09:37:00.551: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-821" to be "running and ready, or succeeded"
Aug 27 09:37:00.557: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.780904ms
Aug 27 09:37:02.648: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097316431s
Aug 27 09:37:04.651: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.100362544s
Aug 27 09:37:04.651: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Aug 27 09:37:04.651: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Aug 27 09:37:04.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 logs logs-generator logs-generator --namespace=kubectl-821'
Aug 27 09:37:04.757: INFO: stderr: ""
Aug 27 09:37:04.757: INFO: stdout: "I0827 09:37:01.814179       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/pfqq 291\nI0827 09:37:02.016549       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/chjz 362\nI0827 09:37:02.214268       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/px5 292\nI0827 09:37:02.414279       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/j4t 562\nI0827 09:37:02.614276       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/dqdc 219\nI0827 09:37:02.814274       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/vjf 500\nI0827 09:37:03.014265       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/pfv 371\nI0827 09:37:03.214293       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/4hb 203\nI0827 09:37:03.414218       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/vhk 344\nI0827 09:37:03.614256       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/rvl 361\nI0827 09:37:03.814323       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/lwz 402\nI0827 09:37:04.014311       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/5xqw 534\nI0827 09:37:04.214276       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/r5cd 447\nI0827 09:37:04.414302       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/gkzj 394\nI0827 09:37:04.614271       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/fjz 257\n"
STEP: limiting log lines
Aug 27 09:37:04.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 logs logs-generator logs-generator --namespace=kubectl-821 --tail=1'
Aug 27 09:37:04.933: INFO: stderr: ""
Aug 27 09:37:04.933: INFO: stdout: "I0827 09:37:04.814289       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/wd5 299\n"
Aug 27 09:37:04.933: INFO: got output "I0827 09:37:04.814289       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/wd5 299\n"
STEP: limiting log bytes
Aug 27 09:37:04.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 logs logs-generator logs-generator --namespace=kubectl-821 --limit-bytes=1'
Aug 27 09:37:05.059: INFO: stderr: ""
Aug 27 09:37:05.059: INFO: stdout: "I"
Aug 27 09:37:05.059: INFO: got output "I"
STEP: exposing timestamps
Aug 27 09:37:05.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 logs logs-generator logs-generator --namespace=kubectl-821 --tail=1 --timestamps'
Aug 27 09:37:05.158: INFO: stderr: ""
Aug 27 09:37:05.158: INFO: stdout: "2020-08-27T09:37:05.014452000Z I0827 09:37:05.014269       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/qlpv 457\n"
Aug 27 09:37:05.158: INFO: got output "2020-08-27T09:37:05.014452000Z I0827 09:37:05.014269       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/qlpv 457\n"
STEP: restricting to a time range
Aug 27 09:37:07.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 logs logs-generator logs-generator --namespace=kubectl-821 --since=1s'
Aug 27 09:37:07.748: INFO: stderr: ""
Aug 27 09:37:07.748: INFO: stdout: "I0827 09:37:06.014285       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/z8d 497\nI0827 09:37:06.214272       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/wgd 207\nI0827 09:37:06.417521       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/bbqg 224\nI0827 09:37:06.615511       1 logs_generator.go:76] 24 POST /api/v1/namespaces/kube-system/pods/ttv6 533\nI0827 09:37:06.814277       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/ns/pods/q5gk 217\nI0827 09:37:07.014277       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/kube-system/pods/6tjg 421\nI0827 09:37:07.214272       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/tzl2 343\nI0827 09:37:07.414283       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/cccd 397\nI0827 09:37:07.614297       1 logs_generator.go:76] 29 GET /api/v1/namespaces/ns/pods/h2n 265\n"
Aug 27 09:37:07.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 logs logs-generator logs-generator --namespace=kubectl-821 --since=24h'
Aug 27 09:37:07.845: INFO: stderr: ""
Aug 27 09:37:07.845: INFO: stdout: "I0827 09:37:01.814179       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/pfqq 291\nI0827 09:37:02.016549       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/chjz 362\nI0827 09:37:02.214268       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/px5 292\nI0827 09:37:02.414279       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/j4t 562\nI0827 09:37:02.614276       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/dqdc 219\nI0827 09:37:02.814274       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/vjf 500\nI0827 09:37:03.014265       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/pfv 371\nI0827 09:37:03.214293       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/4hb 203\nI0827 09:37:03.414218       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/vhk 344\nI0827 09:37:03.614256       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/rvl 361\nI0827 09:37:03.814323       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/lwz 402\nI0827 09:37:04.014311       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/5xqw 534\nI0827 09:37:04.214276       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/r5cd 447\nI0827 09:37:04.414302       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/gkzj 394\nI0827 09:37:04.614271       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/fjz 257\nI0827 09:37:04.814289       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/wd5 299\nI0827 09:37:05.014269       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/qlpv 457\nI0827 09:37:05.214269       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/w9t 427\nI0827 09:37:05.414268       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/ld7 316\nI0827 09:37:05.614276       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/kzqx 439\nI0827 09:37:05.814276       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/bb7m 594\nI0827 09:37:06.014285       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/z8d 497\nI0827 09:37:06.214272       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/wgd 207\nI0827 09:37:06.417521       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/bbqg 224\nI0827 09:37:06.615511       1 logs_generator.go:76] 24 POST /api/v1/namespaces/kube-system/pods/ttv6 533\nI0827 09:37:06.814277       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/ns/pods/q5gk 217\nI0827 09:37:07.014277       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/kube-system/pods/6tjg 421\nI0827 09:37:07.214272       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/tzl2 343\nI0827 09:37:07.414283       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/cccd 397\nI0827 09:37:07.614297       1 logs_generator.go:76] 29 GET /api/v1/namespaces/ns/pods/h2n 265\nI0827 09:37:07.814279       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/ns/pods/zdw 535\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
Aug 27 09:37:07.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete pod logs-generator --namespace=kubectl-821'
Aug 27 09:37:09.711: INFO: stderr: ""
Aug 27 09:37:09.711: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:09.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-821" for this suite.

• [SLOW TEST:9.447 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1411
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":303,"completed":239,"skipped":3762,"failed":0}
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:09.721: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:37:09.770: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug 27 09:37:10.798: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:11.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3005" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":303,"completed":240,"skipped":3768,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:11.811: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name projected-configmap-test-volume-336fde6f-1eca-488e-b0b8-7c2384349c4c
STEP: Creating a pod to test consume configMaps
Aug 27 09:37:11.876: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6b8a698e-34e3-48a9-bef7-b90d3239e78b" in namespace "projected-7181" to be "Succeeded or Failed"
Aug 27 09:37:11.886: INFO: Pod "pod-projected-configmaps-6b8a698e-34e3-48a9-bef7-b90d3239e78b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.724627ms
Aug 27 09:37:13.889: INFO: Pod "pod-projected-configmaps-6b8a698e-34e3-48a9-bef7-b90d3239e78b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013575177s
Aug 27 09:37:15.899: INFO: Pod "pod-projected-configmaps-6b8a698e-34e3-48a9-bef7-b90d3239e78b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0237897s
STEP: Saw pod success
Aug 27 09:37:15.899: INFO: Pod "pod-projected-configmaps-6b8a698e-34e3-48a9-bef7-b90d3239e78b" satisfied condition "Succeeded or Failed"
Aug 27 09:37:15.903: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-configmaps-6b8a698e-34e3-48a9-bef7-b90d3239e78b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:37:15.919: INFO: Waiting for pod pod-projected-configmaps-6b8a698e-34e3-48a9-bef7-b90d3239e78b to disappear
Aug 27 09:37:15.923: INFO: Pod pod-projected-configmaps-6b8a698e-34e3-48a9-bef7-b90d3239e78b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:15.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7181" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":303,"completed":241,"skipped":3772,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:15.931: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4318.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4318.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 09:37:20.116: INFO: DNS probes using dns-4318/dns-test-f174b348-7046-4d8e-bba6-ccfaead87165 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:20.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4318" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":303,"completed":242,"skipped":3776,"failed":0}
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:20.152: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:161
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:20.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1976" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":303,"completed":243,"skipped":3777,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:20.221: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1152
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-1152
I0827 09:37:20.327323      19 runners.go:190] Created replication controller with name: externalname-service, namespace: services-1152, replica count: 2
I0827 09:37:23.494356      19 runners.go:190] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 09:37:26.494: INFO: Creating new exec pod
I0827 09:37:26.494523      19 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 09:37:29.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-1152 execpod79wvp -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Aug 27 09:37:29.730: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 27 09:37:29.731: INFO: stdout: ""
Aug 27 09:37:29.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-1152 execpod79wvp -- /bin/sh -x -c nc -zv -t -w 2 10.3.166.187 80'
Aug 27 09:37:29.991: INFO: stderr: "+ nc -zv -t -w 2 10.3.166.187 80\nConnection to 10.3.166.187 80 port [tcp/http] succeeded!\n"
Aug 27 09:37:29.991: INFO: stdout: ""
Aug 27 09:37:29.991: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:30.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1152" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:9.827 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":303,"completed":244,"skipped":3787,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:30.124: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:37:31.097: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117851, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117851, loc:(*time.Location)(0x7702840)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-cbccbf6bb\""}}, CollisionCount:(*int32)(nil)}
Aug 27 09:37:33.100: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117851, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117851, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117851, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117851, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:37:36.108: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Aug 27 09:37:36.133: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:36.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4567" for this suite.
STEP: Destroying namespace "webhook-4567-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.093 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":303,"completed":245,"skipped":3850,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:36.222: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:47.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3721" for this suite.

• [SLOW TEST:11.237 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":303,"completed":246,"skipped":3867,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:47.461: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:37:47.517: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-149dd0e9-8e14-4c45-b8b0-e067ac5807ae" in namespace "security-context-test-7748" to be "Succeeded or Failed"
Aug 27 09:37:47.520: INFO: Pod "busybox-privileged-false-149dd0e9-8e14-4c45-b8b0-e067ac5807ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.965035ms
Aug 27 09:37:49.526: INFO: Pod "busybox-privileged-false-149dd0e9-8e14-4c45-b8b0-e067ac5807ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008142005s
Aug 27 09:37:51.529: INFO: Pod "busybox-privileged-false-149dd0e9-8e14-4c45-b8b0-e067ac5807ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012087246s
Aug 27 09:37:51.530: INFO: Pod "busybox-privileged-false-149dd0e9-8e14-4c45-b8b0-e067ac5807ae" satisfied condition "Succeeded or Failed"
Aug 27 09:37:51.538: INFO: Got logs for pod "busybox-privileged-false-149dd0e9-8e14-4c45-b8b0-e067ac5807ae": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:51.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7748" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":247,"skipped":3881,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:51.550: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create deployment with httpd image
Aug 27 09:37:51.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f -'
Aug 27 09:37:51.902: INFO: stderr: ""
Aug 27 09:37:51.902: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Aug 27 09:37:51.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 diff -f -'
Aug 27 09:37:52.302: INFO: rc: 1
Aug 27 09:37:52.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete -f -'
Aug 27 09:37:52.479: INFO: stderr: ""
Aug 27 09:37:52.479: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:52.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4688" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":303,"completed":248,"skipped":3905,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:52.558: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:37:52.924: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:37:54.933: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117872, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117872, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117873, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734117872, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:37:57.943: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:37:57.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9526" for this suite.
STEP: Destroying namespace "webhook-9526-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.480 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":303,"completed":249,"skipped":3966,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:37:58.042: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-projected-all-test-volume-885a0dc6-d3d3-41a7-9d5f-2be469342c95
STEP: Creating secret with name secret-projected-all-test-volume-53d6d1c0-bb7e-443d-ad35-56896d0abeae
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 27 09:37:58.126: INFO: Waiting up to 5m0s for pod "projected-volume-be326ffb-5ea8-488c-8b0e-44e33bb59b44" in namespace "projected-3934" to be "Succeeded or Failed"
Aug 27 09:37:58.143: INFO: Pod "projected-volume-be326ffb-5ea8-488c-8b0e-44e33bb59b44": Phase="Pending", Reason="", readiness=false. Elapsed: 16.602786ms
Aug 27 09:38:00.148: INFO: Pod "projected-volume-be326ffb-5ea8-488c-8b0e-44e33bb59b44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021799678s
STEP: Saw pod success
Aug 27 09:38:00.149: INFO: Pod "projected-volume-be326ffb-5ea8-488c-8b0e-44e33bb59b44" satisfied condition "Succeeded or Failed"
Aug 27 09:38:00.152: INFO: Trying to get logs from node ip-10-0-45-43 pod projected-volume-be326ffb-5ea8-488c-8b0e-44e33bb59b44 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 27 09:38:00.211: INFO: Waiting for pod projected-volume-be326ffb-5ea8-488c-8b0e-44e33bb59b44 to disappear
Aug 27 09:38:00.218: INFO: Pod projected-volume-be326ffb-5ea8-488c-8b0e-44e33bb59b44 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:38:00.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3934" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":303,"completed":250,"skipped":3979,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:38:00.250: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: validating api versions
Aug 27 09:38:00.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 api-versions'
Aug 27 09:38:00.450: INFO: stderr: ""
Aug 27 09:38:00.450: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:38:00.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6103" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":303,"completed":251,"skipped":3980,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:38:00.465: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating projection with secret that has name projected-secret-test-map-cb81f2d8-e7b7-42f3-abb6-286e23cdc409
STEP: Creating a pod to test consume secrets
Aug 27 09:38:00.526: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3fdda5e0-7e95-4915-9d9c-01003e5d6357" in namespace "projected-6928" to be "Succeeded or Failed"
Aug 27 09:38:00.532: INFO: Pod "pod-projected-secrets-3fdda5e0-7e95-4915-9d9c-01003e5d6357": Phase="Pending", Reason="", readiness=false. Elapsed: 4.749888ms
Aug 27 09:38:02.537: INFO: Pod "pod-projected-secrets-3fdda5e0-7e95-4915-9d9c-01003e5d6357": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009567996s
STEP: Saw pod success
Aug 27 09:38:02.538: INFO: Pod "pod-projected-secrets-3fdda5e0-7e95-4915-9d9c-01003e5d6357" satisfied condition "Succeeded or Failed"
Aug 27 09:38:02.546: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-projected-secrets-3fdda5e0-7e95-4915-9d9c-01003e5d6357 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 09:38:02.604: INFO: Waiting for pod pod-projected-secrets-3fdda5e0-7e95-4915-9d9c-01003e5d6357 to disappear
Aug 27 09:38:02.626: INFO: Pod pod-projected-secrets-3fdda5e0-7e95-4915-9d9c-01003e5d6357 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:38:02.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6928" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":303,"completed":252,"skipped":3981,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:38:02.647: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward API volume plugin
Aug 27 09:38:02.784: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6220ee5a-7cb1-4e4d-9565-6b0e5237889a" in namespace "downward-api-7279" to be "Succeeded or Failed"
Aug 27 09:38:02.789: INFO: Pod "downwardapi-volume-6220ee5a-7cb1-4e4d-9565-6b0e5237889a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497936ms
Aug 27 09:38:04.792: INFO: Pod "downwardapi-volume-6220ee5a-7cb1-4e4d-9565-6b0e5237889a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007952415s
STEP: Saw pod success
Aug 27 09:38:04.792: INFO: Pod "downwardapi-volume-6220ee5a-7cb1-4e4d-9565-6b0e5237889a" satisfied condition "Succeeded or Failed"
Aug 27 09:38:04.795: INFO: Trying to get logs from node ip-10-0-45-43 pod downwardapi-volume-6220ee5a-7cb1-4e4d-9565-6b0e5237889a container client-container: <nil>
STEP: delete the pod
Aug 27 09:38:04.814: INFO: Waiting for pod downwardapi-volume-6220ee5a-7cb1-4e4d-9565-6b0e5237889a to disappear
Aug 27 09:38:04.817: INFO: Pod downwardapi-volume-6220ee5a-7cb1-4e4d-9565-6b0e5237889a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:38:04.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7279" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":303,"completed":253,"skipped":3989,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:38:04.828: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name projected-configmap-test-volume-d2f21b17-d240-4311-8670-4e2ecd0c331a
STEP: Creating a pod to test consume configMaps
Aug 27 09:38:04.885: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b8a2759-e696-4259-b800-3380de40f8bd" in namespace "projected-7896" to be "Succeeded or Failed"
Aug 27 09:38:04.892: INFO: Pod "pod-projected-configmaps-5b8a2759-e696-4259-b800-3380de40f8bd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.804243ms
Aug 27 09:38:06.896: INFO: Pod "pod-projected-configmaps-5b8a2759-e696-4259-b800-3380de40f8bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010921755s
Aug 27 09:38:08.900: INFO: Pod "pod-projected-configmaps-5b8a2759-e696-4259-b800-3380de40f8bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01479426s
STEP: Saw pod success
Aug 27 09:38:08.901: INFO: Pod "pod-projected-configmaps-5b8a2759-e696-4259-b800-3380de40f8bd" satisfied condition "Succeeded or Failed"
Aug 27 09:38:08.904: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-configmaps-5b8a2759-e696-4259-b800-3380de40f8bd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:38:08.921: INFO: Waiting for pod pod-projected-configmaps-5b8a2759-e696-4259-b800-3380de40f8bd to disappear
Aug 27 09:38:08.924: INFO: Pod pod-projected-configmaps-5b8a2759-e696-4259-b800-3380de40f8bd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:38:08.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7896" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":254,"skipped":3994,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:38:08.940: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name cm-test-opt-del-6110c648-3507-42b8-b184-b039efdc91b8
STEP: Creating configMap with name cm-test-opt-upd-33d9cd97-0416-47be-8825-3894273fa6cc
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6110c648-3507-42b8-b184-b039efdc91b8
STEP: Updating configmap cm-test-opt-upd-33d9cd97-0416-47be-8825-3894273fa6cc
STEP: Creating configMap with name cm-test-opt-create-461fbfe1-c9ff-444d-84a0-6266f0b807ac
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:39:35.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2197" for this suite.

• [SLOW TEST:86.672 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":303,"completed":255,"skipped":4012,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:39:35.618: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:103
STEP: Creating service test in namespace statefulset-413
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-413
STEP: Creating statefulset with conflicting port in namespace statefulset-413
STEP: Waiting until pod test-pod will start running in namespace statefulset-413
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-413
Aug 27 09:39:39.951: INFO: Observed stateful pod in namespace: statefulset-413, name: ss-0, uid: ea725ab7-4fe3-43da-afe6-6e0aef1e1be4, status phase: Pending. Waiting for statefulset controller to delete.
Aug 27 09:39:40.050: INFO: Observed stateful pod in namespace: statefulset-413, name: ss-0, uid: ea725ab7-4fe3-43da-afe6-6e0aef1e1be4, status phase: Failed. Waiting for statefulset controller to delete.
Aug 27 09:39:40.070: INFO: Observed stateful pod in namespace: statefulset-413, name: ss-0, uid: ea725ab7-4fe3-43da-afe6-6e0aef1e1be4, status phase: Failed. Waiting for statefulset controller to delete.
Aug 27 09:39:40.145: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-413
STEP: Removing pod with conflicting port in namespace statefulset-413
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-413 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:114
Aug 27 09:39:44.250: INFO: Deleting all statefulset in ns statefulset-413
Aug 27 09:39:44.252: INFO: Scaling statefulset ss to 0
Aug 27 09:39:54.265: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 09:39:54.267: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:39:54.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-413" for this suite.

• [SLOW TEST:18.714 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":303,"completed":256,"skipped":4053,"failed":0}
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:39:54.332: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:40:54.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5162" for this suite.

• [SLOW TEST:60.090 seconds]
[k8s.io] Probing container
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":303,"completed":257,"skipped":4055,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:40:54.421: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:41:10.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9677" for this suite.

• [SLOW TEST:16.092 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":303,"completed":258,"skipped":4071,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:41:10.517: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6049.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6049.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6049.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6049.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6049.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6049.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 09:41:14.771: INFO: DNS probes using dns-6049/dns-test-daec3e99-666b-4fb0-9300-44050c97335b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:41:14.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6049" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":303,"completed":259,"skipped":4084,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:41:14.801: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod liveness-a4b1f175-c0d0-4c86-b36a-1754cdd171f6 in namespace container-probe-9256
Aug 27 09:41:18.869: INFO: Started pod liveness-a4b1f175-c0d0-4c86-b36a-1754cdd171f6 in namespace container-probe-9256
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 09:41:18.875: INFO: Initial restart count of pod liveness-a4b1f175-c0d0-4c86-b36a-1754cdd171f6 is 0
Aug 27 09:41:42.970: INFO: Restart count of pod container-probe-9256/liveness-a4b1f175-c0d0-4c86-b36a-1754cdd171f6 is now 1 (24.095085299s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:41:42.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9256" for this suite.

• [SLOW TEST:28.204 seconds]
[k8s.io] Probing container
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":303,"completed":260,"skipped":4098,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:41:43.013: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:78
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:41:43.060: INFO: Creating deployment "webserver-deployment"
Aug 27 09:41:43.075: INFO: Waiting for observed generation 1
Aug 27 09:41:45.126: INFO: Waiting for all required pods to come up
Aug 27 09:41:45.144: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 27 09:41:49.164: INFO: Waiting for deployment "webserver-deployment" to complete
Aug 27 09:41:49.169: INFO: Updating deployment "webserver-deployment" with a non-existent image
Aug 27 09:41:49.175: INFO: Updating deployment webserver-deployment
Aug 27 09:41:49.175: INFO: Waiting for observed generation 2
Aug 27 09:41:51.184: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 27 09:41:51.194: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 27 09:41:51.212: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 27 09:41:51.221: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 27 09:41:51.221: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 27 09:41:51.223: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 27 09:41:51.233: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Aug 27 09:41:51.234: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Aug 27 09:41:51.245: INFO: Updating deployment webserver-deployment
Aug 27 09:41:51.245: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Aug 27 09:41:51.254: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 27 09:41:51.267: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
Aug 27 09:41:51.392: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1344 /apis/apps/v1/namespaces/deployment-1344/deployments/webserver-deployment d7e92a94-a22b-42d1-9e2b-1b959bf0b4e3 32034 3 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{}}},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}} {kube-controller-manager Update apps/v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006977e28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-795d758f88" is progressing.,LastUpdateTime:2020-08-27 09:41:49 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-08-27 09:41:51 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Aug 27 09:41:51.489: INFO: New ReplicaSet "webserver-deployment-795d758f88" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-795d758f88  deployment-1344 /apis/apps/v1/namespaces/deployment-1344/replicasets/webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 32029 3 2020-08-27 09:41:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment d7e92a94-a22b-42d1-9e2b-1b959bf0b4e3 0xc006a622c7 0xc006a622c8}] []  [{kube-controller-manager Update apps/v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d7e92a94-a22b-42d1-9e2b-1b959bf0b4e3\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}},"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 795d758f88,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006a62348 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:41:51.489: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Aug 27 09:41:51.489: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-dd94f59b7  deployment-1344 /apis/apps/v1/namespaces/deployment-1344/replicasets/webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 32028 3 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment d7e92a94-a22b-42d1-9e2b-1b959bf0b4e3 0xc006a623a7 0xc006a623a8}] []  [{kube-controller-manager Update apps/v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d7e92a94-a22b-42d1-9e2b-1b959bf0b4e3\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}},"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: dd94f59b7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006a62418 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:41:51.579: INFO: Pod "webserver-deployment-795d758f88-27lfh" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-27lfh webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-27lfh 8718a78a-74ad-4be1-af29-b06841ba9d60 32056 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a62967 0xc006a62968}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.579: INFO: Pod "webserver-deployment-795d758f88-4qn4m" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-4qn4m webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-4qn4m 9a193ad1-8712-464c-b00d-068176f12021 32055 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a62aa0 0xc006a62aa1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.580: INFO: Pod "webserver-deployment-795d758f88-5cdsw" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-5cdsw webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-5cdsw db1b753f-661d-43f2-b826-072ce7027dd8 31991 0 2020-08-27 09:41:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a62c00 0xc006a62c01}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {kubelet Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.216,PodIP:,StartTime:2020-08-27 09:41:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.581: INFO: Pod "webserver-deployment-795d758f88-6xsg6" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-6xsg6 webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-6xsg6 ea2a609c-c2e1-40d2-a1bd-608ac247dbba 32019 0 2020-08-27 09:41:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.2.193.122/32 cni.projectcalico.org/podIPs:10.2.193.122/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a62dc0 0xc006a62dc1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.193.122\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.45.43,PodIP:10.2.193.122,StartTime:2020-08-27 09:41:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.193.122,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.581: INFO: Pod "webserver-deployment-795d758f88-8rlnq" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-8rlnq webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-8rlnq 08da8d6d-f890-4c4b-88cb-2ea6578d8fca 32069 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a62fb0 0xc006a62fb1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.585: INFO: Pod "webserver-deployment-795d758f88-b9pzx" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-b9pzx webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-b9pzx 8dca8b3e-f398-4c16-b3bf-ab5c35575b68 32071 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a630c7 0xc006a630c8}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.586: INFO: Pod "webserver-deployment-795d758f88-bhwgh" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-bhwgh webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-bhwgh 6b338a57-5eb9-4ff7-9dc6-44bd75f93962 32059 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a63200 0xc006a63201}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.586: INFO: Pod "webserver-deployment-795d758f88-chghj" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-chghj webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-chghj 1e431a1d-57bc-46a1-97a8-0bca336692ed 32000 0 2020-08-27 09:41:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.2.148.65/32 cni.projectcalico.org/podIPs:10.2.148.65/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a63360 0xc006a63361}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {kubelet Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}}} {calico Update v1 2020-08-27 09:41:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.251,PodIP:,StartTime:2020-08-27 09:41:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.586: INFO: Pod "webserver-deployment-795d758f88-fxb6x" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-fxb6x webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-fxb6x 1c2a2e6e-ffd7-41f3-8221-5be69df43515 32064 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a63520 0xc006a63521}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.586: INFO: Pod "webserver-deployment-795d758f88-hnxz5" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-hnxz5 webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-hnxz5 35035450-beb7-472a-8f35-52206ef825f1 32009 0 2020-08-27 09:41:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.2.148.66/32 cni.projectcalico.org/podIPs:10.2.148.66/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a63680 0xc006a63681}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {kubelet Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}}} {calico Update v1 2020-08-27 09:41:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.251,PodIP:,StartTime:2020-08-27 09:41:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.586: INFO: Pod "webserver-deployment-795d758f88-lthvq" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-lthvq webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-lthvq 2f2041b5-1f60-47ae-8ed1-938c09d4c46c 32057 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a63840 0xc006a63841}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.586: INFO: Pod "webserver-deployment-795d758f88-pnmvg" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-pnmvg webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-pnmvg 29863c70-e506-4f82-be6a-8176ea001071 32058 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a63980 0xc006a63981}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {kubelet Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.45.43,PodIP:,StartTime:2020-08-27 09:41:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.587: INFO: Pod "webserver-deployment-795d758f88-zx6p5" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-zx6p5 webserver-deployment-795d758f88- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-795d758f88-zx6p5 03dd180a-85b5-449a-acc3-85ae748df2b7 31963 0 2020-08-27 09:41:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 d18fd2f5-528d-4beb-919c-8dc382c5ff4c 0xc006a63b30 0xc006a63b31}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d18fd2f5-528d-4beb-919c-8dc382c5ff4c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {kubelet Update v1 2020-08-27 09:41:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.216,PodIP:,StartTime:2020-08-27 09:41:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.589: INFO: Pod "webserver-deployment-dd94f59b7-6d64x" is available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-6d64x webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-6d64x 9914a0ad-36f3-4dbb-88dd-f95da65142d4 31882 0 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[cni.projectcalico.org/podIP:10.2.148.63/32 cni.projectcalico.org/podIPs:10.2.148.63/32] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a63cf0 0xc006a63cf1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.148.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.251,PodIP:10.2.148.63,StartTime:2020-08-27 09:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:41:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://94a600e6cee85c9db5cbc83b9d28073222cf3d42294922ab6e98756566725587,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.148.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.589: INFO: Pod "webserver-deployment-dd94f59b7-7mxpv" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-7mxpv webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-7mxpv 6462529c-54fb-4d63-83bf-966f8df11c61 32060 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a63eb0 0xc006a63eb1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {kubelet Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.216,PodIP:,StartTime:2020-08-27 09:41:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.589: INFO: Pod "webserver-deployment-dd94f59b7-9g5rv" is available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-9g5rv webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-9g5rv 38eabf88-e7e4-4afe-9409-19f3344576e2 31885 0 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[cni.projectcalico.org/podIP:10.2.148.62/32 cni.projectcalico.org/podIPs:10.2.148.62/32] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80050 0xc006a80051}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.148.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.251,PodIP:10.2.148.62,StartTime:2020-08-27 09:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:41:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://263b0f0d367ea1784d5fdf0f3857e166ca3763740e04a6a1bc18ef51c2c8abbe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.148.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.590: INFO: Pod "webserver-deployment-dd94f59b7-9mbr5" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-9mbr5 webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-9mbr5 ce9bc48b-7da9-4aa8-922c-7bfaae453e77 32070 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80210 0xc006a80211}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.590: INFO: Pod "webserver-deployment-dd94f59b7-9wzct" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-9wzct webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-9wzct 82b05134-b9ee-4129-b359-bb82354fa9e0 32043 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80340 0xc006a80341}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.590: INFO: Pod "webserver-deployment-dd94f59b7-bld7x" is available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-bld7x webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-bld7x 55eb5b03-0ba4-41f4-99d6-4085f5959abb 31900 0 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[cni.projectcalico.org/podIP:10.2.193.120/32 cni.projectcalico.org/podIPs:10.2.193.120/32] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80490 0xc006a80491}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.193.120\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.45.43,PodIP:10.2.193.120,StartTime:2020-08-27 09:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:41:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7b61b04e782ec0e412931cca83eb082d062220bac6f1f09b064f30064e64e841,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.193.120,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.593: INFO: Pod "webserver-deployment-dd94f59b7-dtqfr" is available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-dtqfr webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-dtqfr 80efaec7-806e-4d72-bcf9-5bb494411c50 31918 0 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[cni.projectcalico.org/podIP:10.2.173.196/32 cni.projectcalico.org/podIPs:10.2.173.196/32] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80670 0xc006a80671}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.173.196\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.216,PodIP:10.2.173.196,StartTime:2020-08-27 09:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:41:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://8e6ab4af01e684cdd7ef94c9d30a2e41b87c1bbc5e4f1b2ad64d21826d3f2b41,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.173.196,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.593: INFO: Pod "webserver-deployment-dd94f59b7-fw4g9" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-fw4g9 webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-fw4g9 a474bee0-f00a-421a-97f9-d22bf90e8d30 32074 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80830 0xc006a80831}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.593: INFO: Pod "webserver-deployment-dd94f59b7-hs5ng" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-hs5ng webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-hs5ng 626a02e6-2541-4f15-8dd7-24a0b43bafa5 32077 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80960 0xc006a80961}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.593: INFO: Pod "webserver-deployment-dd94f59b7-kp2v5" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-kp2v5 webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-kp2v5 cc9524f6-15ec-44fc-b837-c1f9b8c8cd63 32080 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80a90 0xc006a80a91}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.594: INFO: Pod "webserver-deployment-dd94f59b7-lm6vr" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-lm6vr webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-lm6vr 91b24ecd-45fe-4599-8641-43f70222c46f 32078 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80bc0 0xc006a80bc1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.594: INFO: Pod "webserver-deployment-dd94f59b7-lv48g" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-lv48g webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-lv48g 95a4c56b-377b-40a2-afd0-e3244ae158df 32073 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80cf0 0xc006a80cf1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.594: INFO: Pod "webserver-deployment-dd94f59b7-q7sfm" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-q7sfm webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-q7sfm 894c8f01-c4e0-4db0-a83e-ab5ead44f15f 32048 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80e20 0xc006a80e21}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.594: INFO: Pod "webserver-deployment-dd94f59b7-qc7gx" is available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-qc7gx webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-qc7gx 799dac03-3119-47f4-be42-bd7706625e6b 31921 0 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[cni.projectcalico.org/podIP:10.2.173.198/32 cni.projectcalico.org/podIPs:10.2.173.198/32] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a80f90 0xc006a80f91}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.173.198\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.216,PodIP:10.2.173.198,StartTime:2020-08-27 09:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:41:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a7738722e27e7233ea5ca68830e7abf96502745f4eeff7260917d06a698cec99,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.173.198,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.594: INFO: Pod "webserver-deployment-dd94f59b7-rkd84" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-rkd84 webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-rkd84 7aa43f44-ac04-4d98-9df5-9d7477855bc2 32072 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a81160 0xc006a81161}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.594: INFO: Pod "webserver-deployment-dd94f59b7-tk6lp" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-tk6lp webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-tk6lp 551c4d5b-e073-4282-a6ae-6f62ae275f16 32079 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a81290 0xc006a81291}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.597: INFO: Pod "webserver-deployment-dd94f59b7-tzqww" is not available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-tzqww webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-tzqww 25e2023b-48d9-4fbf-96bb-0803466ca8f8 32076 0 2020-08-27 09:41:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a813c0 0xc006a813c1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.597: INFO: Pod "webserver-deployment-dd94f59b7-x2p56" is available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-x2p56 webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-x2p56 4c343655-fd09-4e4e-9919-0d796e393195 31865 0 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[cni.projectcalico.org/podIP:10.2.193.121/32 cni.projectcalico.org/podIPs:10.2.193.121/32] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a81510 0xc006a81511}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.193.121\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.45.43,PodIP:10.2.193.121,StartTime:2020-08-27 09:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:41:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://db6b5ddf63f20531aad640a14d5b5b8aaa1f314207030f1cf4d578ae6767bd49,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.193.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.599: INFO: Pod "webserver-deployment-dd94f59b7-z9hjv" is available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-z9hjv webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-z9hjv c05d8b2f-5f88-40cb-9bbc-b9fe58f4d805 31889 0 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[cni.projectcalico.org/podIP:10.2.148.64/32 cni.projectcalico.org/podIPs:10.2.148.64/32] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a816f0 0xc006a816f1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.148.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-251,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.251,PodIP:10.2.148.64,StartTime:2020-08-27 09:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:41:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://28c6da9de1bad19d6ca13261fede8bb96507be1c361ced078ff818053f911fd9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.148.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 09:41:51.600: INFO: Pod "webserver-deployment-dd94f59b7-zwkgz" is available:
&Pod{ObjectMeta:{webserver-deployment-dd94f59b7-zwkgz webserver-deployment-dd94f59b7- deployment-1344 /api/v1/namespaces/deployment-1344/pods/webserver-deployment-dd94f59b7-zwkgz 8706ebf2-95f0-4a92-a411-33f816eaaaef 31869 0 2020-08-27 09:41:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:dd94f59b7] map[cni.projectcalico.org/podIP:10.2.193.119/32 cni.projectcalico.org/podIPs:10.2.193.119/32] [{apps/v1 ReplicaSet webserver-deployment-dd94f59b7 5f9d341f-3907-46ae-b67a-a7b615361e6c 0xc006a818d0 0xc006a818d1}] []  [{kube-controller-manager Update v1 2020-08-27 09:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f9d341f-3907-46ae-b67a-a7b615361e6c\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:41:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:41:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.193.119\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-96lg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-96lg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-96lg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.45.43,PodIP:10.2.193.119,StartTime:2020-08-27 09:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:41:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://084f2c9c5581fb7ce94c29dc28d433ed48269080ea40d10b52f9880aa28cf9d4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.193.119,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:41:51.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1344" for this suite.

• [SLOW TEST:8.651 seconds]
[sig-apps] Deployment
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":303,"completed":261,"skipped":4121,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:41:51.664: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:41:52.569: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:41:54.590: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:41:56.595: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:41:58.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:42:00.598: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118112, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:42:03.602: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:03.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5756" for this suite.
STEP: Destroying namespace "webhook-5756-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:12.091 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":303,"completed":262,"skipped":4145,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:03.832: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 27 09:42:03.908: INFO: Waiting up to 5m0s for pod "pod-53d060a1-9594-4d5d-9534-536915b7f643" in namespace "emptydir-5923" to be "Succeeded or Failed"
Aug 27 09:42:03.919: INFO: Pod "pod-53d060a1-9594-4d5d-9534-536915b7f643": Phase="Pending", Reason="", readiness=false. Elapsed: 11.146476ms
Aug 27 09:42:05.922: INFO: Pod "pod-53d060a1-9594-4d5d-9534-536915b7f643": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01425768s
STEP: Saw pod success
Aug 27 09:42:05.922: INFO: Pod "pod-53d060a1-9594-4d5d-9534-536915b7f643" satisfied condition "Succeeded or Failed"
Aug 27 09:42:05.925: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-53d060a1-9594-4d5d-9534-536915b7f643 container test-container: <nil>
STEP: delete the pod
Aug 27 09:42:05.956: INFO: Waiting for pod pod-53d060a1-9594-4d5d-9534-536915b7f643 to disappear
Aug 27 09:42:05.959: INFO: Pod pod-53d060a1-9594-4d5d-9534-536915b7f643 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:05.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5923" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":263,"skipped":4185,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:05.971: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:42:06.023: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:07.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2578" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":303,"completed":264,"skipped":4192,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:07.810: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:42:07.848: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:17.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3728" for this suite.

• [SLOW TEST:10.154 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":303,"completed":265,"skipped":4217,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:17.970: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 27 09:42:18.039: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5949 /api/v1/namespaces/watch-5949/configmaps/e2e-watch-test-resource-version 080773a5-9352-4eb2-ba01-af3232b141a5 32741 0 2020-08-27 09:42:18 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-08-27 09:42:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 09:42:18.039: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5949 /api/v1/namespaces/watch-5949/configmaps/e2e-watch-test-resource-version 080773a5-9352-4eb2-ba01-af3232b141a5 32742 0 2020-08-27 09:42:18 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-08-27 09:42:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:18.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5949" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":303,"completed":266,"skipped":4222,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:18.048: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-volume-3367e569-1c05-46f4-bbf1-3499828e7a27
STEP: Creating a pod to test consume configMaps
Aug 27 09:42:18.093: INFO: Waiting up to 5m0s for pod "pod-configmaps-753b86a1-c3cf-4a77-a282-d450b721f89e" in namespace "configmap-3038" to be "Succeeded or Failed"
Aug 27 09:42:18.100: INFO: Pod "pod-configmaps-753b86a1-c3cf-4a77-a282-d450b721f89e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.119325ms
Aug 27 09:42:20.103: INFO: Pod "pod-configmaps-753b86a1-c3cf-4a77-a282-d450b721f89e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007521955s
Aug 27 09:42:22.108: INFO: Pod "pod-configmaps-753b86a1-c3cf-4a77-a282-d450b721f89e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01304637s
STEP: Saw pod success
Aug 27 09:42:22.109: INFO: Pod "pod-configmaps-753b86a1-c3cf-4a77-a282-d450b721f89e" satisfied condition "Succeeded or Failed"
Aug 27 09:42:22.111: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-753b86a1-c3cf-4a77-a282-d450b721f89e container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:42:22.129: INFO: Waiting for pod pod-configmaps-753b86a1-c3cf-4a77-a282-d450b721f89e to disappear
Aug 27 09:42:22.133: INFO: Pod pod-configmaps-753b86a1-c3cf-4a77-a282-d450b721f89e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:22.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3038" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":303,"completed":267,"skipped":4242,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:22.144: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test override command
Aug 27 09:42:22.187: INFO: Waiting up to 5m0s for pod "client-containers-32a8e8bd-56e1-4f58-a178-9185dd61b17b" in namespace "containers-5301" to be "Succeeded or Failed"
Aug 27 09:42:22.191: INFO: Pod "client-containers-32a8e8bd-56e1-4f58-a178-9185dd61b17b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.001696ms
Aug 27 09:42:24.194: INFO: Pod "client-containers-32a8e8bd-56e1-4f58-a178-9185dd61b17b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006248433s
STEP: Saw pod success
Aug 27 09:42:24.194: INFO: Pod "client-containers-32a8e8bd-56e1-4f58-a178-9185dd61b17b" satisfied condition "Succeeded or Failed"
Aug 27 09:42:24.196: INFO: Trying to get logs from node ip-10-0-2-216 pod client-containers-32a8e8bd-56e1-4f58-a178-9185dd61b17b container test-container: <nil>
STEP: delete the pod
Aug 27 09:42:24.210: INFO: Waiting for pod client-containers-32a8e8bd-56e1-4f58-a178-9185dd61b17b to disappear
Aug 27 09:42:24.213: INFO: Pod client-containers-32a8e8bd-56e1-4f58-a178-9185dd61b17b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:24.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5301" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":303,"completed":268,"skipped":4278,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Events
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:24.222: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-api-machinery] Events
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:24.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2319" for this suite.
•{"msg":"PASSED [sig-api-machinery] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":303,"completed":269,"skipped":4290,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:24.288: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating the pod
Aug 27 09:42:28.853: INFO: Successfully updated pod "labelsupdatee5ac9f59-95a6-45d3-a858-f1ebd1a755d7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:30.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2474" for this suite.

• [SLOW TEST:6.596 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":303,"completed":270,"skipped":4313,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:30.885: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9475.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9475.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9475.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9475.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 09:42:32.955: INFO: DNS probes using dns-test-0510f3b5-2cb2-4b6b-af0b-b3248758a52d succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9475.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9475.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9475.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9475.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 09:42:37.013: INFO: File wheezy_udp@dns-test-service-3.dns-9475.svc.cluster.local from pod  dns-9475/dns-test-42436771-b90d-4a46-bc55-bdaa9fc2f552 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 09:42:37.017: INFO: File jessie_udp@dns-test-service-3.dns-9475.svc.cluster.local from pod  dns-9475/dns-test-42436771-b90d-4a46-bc55-bdaa9fc2f552 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 09:42:37.017: INFO: Lookups using dns-9475/dns-test-42436771-b90d-4a46-bc55-bdaa9fc2f552 failed for: [wheezy_udp@dns-test-service-3.dns-9475.svc.cluster.local jessie_udp@dns-test-service-3.dns-9475.svc.cluster.local]

Aug 27 09:42:42.024: INFO: DNS probes using dns-test-42436771-b90d-4a46-bc55-bdaa9fc2f552 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9475.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9475.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9475.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9475.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 09:42:46.096: INFO: DNS probes using dns-test-b7b34089-9943-4801-b05f-35c8e42f8acf succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:42:46.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9475" for this suite.

• [SLOW TEST:15.256 seconds]
[sig-network] DNS
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":303,"completed":271,"skipped":4342,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:42:46.152: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod pod-subpath-test-secret-rgwh
STEP: Creating a pod to test atomic-volume-subpath
Aug 27 09:42:46.391: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rgwh" in namespace "subpath-8178" to be "Succeeded or Failed"
Aug 27 09:42:46.406: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Pending", Reason="", readiness=false. Elapsed: 14.773689ms
Aug 27 09:42:48.410: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 2.018443407s
Aug 27 09:42:50.413: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 4.021980099s
Aug 27 09:42:52.417: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 6.025256532s
Aug 27 09:42:54.420: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 8.028928553s
Aug 27 09:42:56.424: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 10.032861973s
Aug 27 09:42:58.428: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 12.036347713s
Aug 27 09:43:00.432: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 14.040251473s
Aug 27 09:43:02.436: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 16.044598168s
Aug 27 09:43:04.441: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 18.04921435s
Aug 27 09:43:06.447: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Running", Reason="", readiness=true. Elapsed: 20.055745875s
Aug 27 09:43:08.454: INFO: Pod "pod-subpath-test-secret-rgwh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.062399568s
STEP: Saw pod success
Aug 27 09:43:08.455: INFO: Pod "pod-subpath-test-secret-rgwh" satisfied condition "Succeeded or Failed"
Aug 27 09:43:08.458: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-subpath-test-secret-rgwh container test-container-subpath-secret-rgwh: <nil>
STEP: delete the pod
Aug 27 09:43:08.516: INFO: Waiting for pod pod-subpath-test-secret-rgwh to disappear
Aug 27 09:43:08.520: INFO: Pod pod-subpath-test-secret-rgwh no longer exists
STEP: Deleting pod pod-subpath-test-secret-rgwh
Aug 27 09:43:08.521: INFO: Deleting pod "pod-subpath-test-secret-rgwh" in namespace "subpath-8178"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:43:08.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8178" for this suite.

• [SLOW TEST:22.386 seconds]
[sig-storage] Subpath
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":303,"completed":272,"skipped":4400,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:43:08.544: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:43:08.605: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:43:10.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9602" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":303,"completed":273,"skipped":4421,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:43:10.590: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:78
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:43:10.630: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 27 09:43:15.632: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 27 09:43:15.632: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 27 09:43:17.636: INFO: Creating deployment "test-rollover-deployment"
Aug 27 09:43:17.645: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 27 09:43:19.650: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 27 09:43:19.654: INFO: Ensure that both replica sets have 1 created replica
Aug 27 09:43:19.659: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 27 09:43:19.664: INFO: Updating deployment test-rollover-deployment
Aug 27 09:43:19.664: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 27 09:43:21.671: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 27 09:43:21.676: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 27 09:43:21.680: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 09:43:21.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118201, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5797c7764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:43:23.686: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 09:43:23.686: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118201, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5797c7764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:43:25.689: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 09:43:25.690: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118201, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5797c7764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:43:27.692: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 09:43:27.692: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118201, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5797c7764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:43:29.688: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 09:43:29.688: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118201, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118197, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5797c7764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 09:43:31.693: INFO: 
Aug 27 09:43:31.693: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
Aug 27 09:43:31.706: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4704 /apis/apps/v1/namespaces/deployment-4704/deployments/test-rollover-deployment 59e11090-0e5b-4250-a2a9-dd13203f3ddf 33327 2 2020-08-27 09:43:17 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-08-27 09:43:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{}}},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}} {kube-controller-manager Update apps/v1 2020-08-27 09:43:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.20 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001928b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-08-27 09:43:17 +0000 UTC,LastTransitionTime:2020-08-27 09:43:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-5797c7764" has successfully progressed.,LastUpdateTime:2020-08-27 09:43:31 +0000 UTC,LastTransitionTime:2020-08-27 09:43:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 09:43:31.710: INFO: New ReplicaSet "test-rollover-deployment-5797c7764" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-5797c7764  deployment-4704 /apis/apps/v1/namespaces/deployment-4704/replicasets/test-rollover-deployment-5797c7764 a357b247-2834-422b-a63b-9f0e3dab3cac 33316 2 2020-08-27 09:43:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5797c7764] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 59e11090-0e5b-4250-a2a9-dd13203f3ddf 0xc001929080 0xc001929081}] []  [{kube-controller-manager Update apps/v1 2020-08-27 09:43:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"59e11090-0e5b-4250-a2a9-dd13203f3ddf\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}},"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5797c7764,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5797c7764] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.20 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0019290f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:43:31.710: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 27 09:43:31.710: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4704 /apis/apps/v1/namespaces/deployment-4704/replicasets/test-rollover-controller 947c905b-1986-4f9d-9373-420fd4e74ca8 33325 2 2020-08-27 09:43:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 59e11090-0e5b-4250-a2a9-dd13203f3ddf 0xc001928f67 0xc001928f68}] []  [{e2e.test Update apps/v1 2020-08-27 09:43:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}}} {kube-controller-manager Update apps/v1 2020-08-27 09:43:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"59e11090-0e5b-4250-a2a9-dd13203f3ddf\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:replicas":{}},"f:status":{"f:observedGeneration":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001929008 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:43:31.710: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-78bc8b888c  deployment-4704 /apis/apps/v1/namespaces/deployment-4704/replicasets/test-rollover-deployment-78bc8b888c dc650b91-7391-4613-ad14-00fb1f3ab113 33269 2 2020-08-27 09:43:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:78bc8b888c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 59e11090-0e5b-4250-a2a9-dd13203f3ddf 0xc001929167 0xc001929168}] []  [{kube-controller-manager Update apps/v1 2020-08-27 09:43:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"59e11090-0e5b-4250-a2a9-dd13203f3ddf\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{"f:matchLabels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}},"f:status":{"f:observedGeneration":{},"f:replicas":{}}}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 78bc8b888c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:78bc8b888c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0019291f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 09:43:31.713: INFO: Pod "test-rollover-deployment-5797c7764-fqqrk" is available:
&Pod{ObjectMeta:{test-rollover-deployment-5797c7764-fqqrk test-rollover-deployment-5797c7764- deployment-4704 /api/v1/namespaces/deployment-4704/pods/test-rollover-deployment-5797c7764-fqqrk d8f7b7d3-5a63-416f-971b-a11990013282 33288 0 2020-08-27 09:43:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5797c7764] map[cni.projectcalico.org/podIP:10.2.193.131/32 cni.projectcalico.org/podIPs:10.2.193.131/32] [{apps/v1 ReplicaSet test-rollover-deployment-5797c7764 a357b247-2834-422b-a63b-9f0e3dab3cac 0xc0019297b0 0xc0019297b1}] []  [{kube-controller-manager Update v1 2020-08-27 09:43:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a357b247-2834-422b-a63b-9f0e3dab3cac\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}} {calico Update v1 2020-08-27 09:43:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}}} {kubelet Update v1 2020-08-27 09:43:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.193.131\"}":{".":{},"f:ip":{}}},"f:startTime":{}}}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-75q9w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-75q9w,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.20,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-75q9w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-45-43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:43:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:43:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:43:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-27 09:43:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.45.43,PodIP:10.2.193.131,StartTime:2020-08-27 09:43:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-27 09:43:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.20,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0,ContainerID:docker://6887118481e3bd082a4dc45b0ec0ac0b100c17db2a40f41fb23d88be1c986680,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.193.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:43:31.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4704" for this suite.

• [SLOW TEST:21.134 seconds]
[sig-apps] Deployment
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":303,"completed":274,"skipped":4426,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:43:31.725: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-volume-map-cc5b1891-8bf8-4af3-aa1e-2a3d3180c70b
STEP: Creating a pod to test consume configMaps
Aug 27 09:43:31.783: INFO: Waiting up to 5m0s for pod "pod-configmaps-07a61cea-10b1-4ddc-b64b-c8d34758665a" in namespace "configmap-3331" to be "Succeeded or Failed"
Aug 27 09:43:31.788: INFO: Pod "pod-configmaps-07a61cea-10b1-4ddc-b64b-c8d34758665a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030082ms
Aug 27 09:43:33.791: INFO: Pod "pod-configmaps-07a61cea-10b1-4ddc-b64b-c8d34758665a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007267329s
STEP: Saw pod success
Aug 27 09:43:33.792: INFO: Pod "pod-configmaps-07a61cea-10b1-4ddc-b64b-c8d34758665a" satisfied condition "Succeeded or Failed"
Aug 27 09:43:33.794: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-configmaps-07a61cea-10b1-4ddc-b64b-c8d34758665a container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:43:33.813: INFO: Waiting for pod pod-configmaps-07a61cea-10b1-4ddc-b64b-c8d34758665a to disappear
Aug 27 09:43:33.816: INFO: Pod pod-configmaps-07a61cea-10b1-4ddc-b64b-c8d34758665a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:43:33.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3331" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":275,"skipped":4431,"failed":0}

------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:43:33.821: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 27 09:43:33.924: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:43:33.926: INFO: Number of nodes with available pods: 0
Aug 27 09:43:33.926: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:43:34.937: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:43:34.940: INFO: Number of nodes with available pods: 0
Aug 27 09:43:34.940: INFO: Node ip-10-0-2-216 is running more than one daemon pod
Aug 27 09:43:35.930: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:43:35.933: INFO: Number of nodes with available pods: 2
Aug 27 09:43:35.933: INFO: Node ip-10-0-45-43 is running more than one daemon pod
Aug 27 09:43:36.931: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:43:36.937: INFO: Number of nodes with available pods: 2
Aug 27 09:43:36.938: INFO: Node ip-10-0-45-43 is running more than one daemon pod
Aug 27 09:43:37.930: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:43:37.933: INFO: Number of nodes with available pods: 3
Aug 27 09:43:37.933: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 27 09:43:38.167: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:43:38.183: INFO: Number of nodes with available pods: 2
Aug 27 09:43:38.189: INFO: Node ip-10-0-27-251 is running more than one daemon pod
Aug 27 09:43:39.197: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:43:39.201: INFO: Number of nodes with available pods: 2
Aug 27 09:43:39.201: INFO: Node ip-10-0-27-251 is running more than one daemon pod
Aug 27 09:43:40.192: INFO: DaemonSet pods can't tolerate node ip-10-0-8-142 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 09:43:40.196: INFO: Number of nodes with available pods: 3
Aug 27 09:43:40.197: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4214, will wait for the garbage collector to delete the pods
Aug 27 09:43:40.281: INFO: Deleting DaemonSet.extensions daemon-set took: 5.850939ms
Aug 27 09:43:40.382: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.548093ms
Aug 27 09:43:55.208: INFO: Number of nodes with available pods: 0
Aug 27 09:43:55.208: INFO: Number of running nodes: 0, number of available pods: 0
Aug 27 09:43:55.215: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4214/daemonsets","resourceVersion":"33559"},"items":null}

Aug 27 09:43:55.219: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4214/pods","resourceVersion":"33559"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:43:55.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4214" for this suite.

• [SLOW TEST:21.427 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":303,"completed":276,"skipped":4431,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:43:55.250: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:181
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:43:57.331: INFO: Waiting up to 5m0s for pod "client-envvars-6e7b63d3-93bd-4374-973e-af03c8377428" in namespace "pods-4768" to be "Succeeded or Failed"
Aug 27 09:43:57.337: INFO: Pod "client-envvars-6e7b63d3-93bd-4374-973e-af03c8377428": Phase="Pending", Reason="", readiness=false. Elapsed: 5.139356ms
Aug 27 09:43:59.341: INFO: Pod "client-envvars-6e7b63d3-93bd-4374-973e-af03c8377428": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009525913s
STEP: Saw pod success
Aug 27 09:43:59.341: INFO: Pod "client-envvars-6e7b63d3-93bd-4374-973e-af03c8377428" satisfied condition "Succeeded or Failed"
Aug 27 09:43:59.345: INFO: Trying to get logs from node ip-10-0-45-43 pod client-envvars-6e7b63d3-93bd-4374-973e-af03c8377428 container env3cont: <nil>
STEP: delete the pod
Aug 27 09:43:59.387: INFO: Waiting for pod client-envvars-6e7b63d3-93bd-4374-973e-af03c8377428 to disappear
Aug 27 09:43:59.393: INFO: Pod client-envvars-6e7b63d3-93bd-4374-973e-af03c8377428 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:43:59.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4768" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":303,"completed":277,"skipped":4439,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:43:59.415: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5964
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5964
STEP: creating replication controller externalsvc in namespace services-5964
I0827 09:43:59.496649      19 runners.go:190] Created replication controller with name: externalsvc, namespace: services-5964, replica count: 2
I0827 09:44:02.548536      19 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Aug 27 09:44:02.591: INFO: Creating new exec pod
Aug 27 09:44:04.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 exec --namespace=services-5964 execpodjk4n6 -- /bin/sh -x -c nslookup clusterip-service.services-5964.svc.cluster.local'
Aug 27 09:44:05.069: INFO: stderr: "+ nslookup clusterip-service.services-5964.svc.cluster.local\n"
Aug 27 09:44:05.069: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nclusterip-service.services-5964.svc.cluster.local\tcanonical name = externalsvc.services-5964.svc.cluster.local.\nName:\texternalsvc.services-5964.svc.cluster.local\nAddress: 10.3.255.245\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5964, will wait for the garbage collector to delete the pods
Aug 27 09:44:05.135: INFO: Deleting ReplicationController externalsvc took: 11.091699ms
Aug 27 09:44:05.236: INFO: Terminating ReplicationController externalsvc pods took: 100.972137ms
Aug 27 09:44:14.151: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:44:14.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5964" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786

• [SLOW TEST:14.778 seconds]
[sig-network] Services
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":303,"completed":278,"skipped":4482,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:44:14.198: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:44:14.928: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 27 09:44:16.937: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118254, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118254, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118254, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118254, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-cbccbf6bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:44:19.949: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:44:20.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7894" for this suite.
STEP: Destroying namespace "webhook-7894-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.967 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":303,"completed":279,"skipped":4482,"failed":0}
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:44:20.164: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 27 09:44:26.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 09:44:26.279: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 09:44:28.279: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 09:44:28.283: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 09:44:30.279: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 09:44:30.282: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:44:30.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2330" for this suite.

• [SLOW TEST:10.131 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  when create a pod with lifecycle hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":303,"completed":280,"skipped":4484,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:44:30.297: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name projected-configmap-test-volume-map-3a32ad2b-51e7-41d0-a62b-4c37d519a415
STEP: Creating a pod to test consume configMaps
Aug 27 09:44:30.344: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e0f2a902-4120-479e-a646-7a25573741db" in namespace "projected-3705" to be "Succeeded or Failed"
Aug 27 09:44:30.348: INFO: Pod "pod-projected-configmaps-e0f2a902-4120-479e-a646-7a25573741db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.085692ms
Aug 27 09:44:32.351: INFO: Pod "pod-projected-configmaps-e0f2a902-4120-479e-a646-7a25573741db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006371306s
STEP: Saw pod success
Aug 27 09:44:32.352: INFO: Pod "pod-projected-configmaps-e0f2a902-4120-479e-a646-7a25573741db" satisfied condition "Succeeded or Failed"
Aug 27 09:44:32.355: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-configmaps-e0f2a902-4120-479e-a646-7a25573741db container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:44:32.378: INFO: Waiting for pod pod-projected-configmaps-e0f2a902-4120-479e-a646-7a25573741db to disappear
Aug 27 09:44:32.383: INFO: Pod pod-projected-configmaps-e0f2a902-4120-479e-a646-7a25573741db no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:44:32.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3705" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":303,"completed":281,"skipped":4487,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:44:32.390: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating projection with secret that has name projected-secret-test-768e0239-17b6-4766-80ea-db944b653d8b
STEP: Creating a pod to test consume secrets
Aug 27 09:44:32.455: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7052174a-7c42-49d8-b957-badd34f6b97e" in namespace "projected-9217" to be "Succeeded or Failed"
Aug 27 09:44:32.466: INFO: Pod "pod-projected-secrets-7052174a-7c42-49d8-b957-badd34f6b97e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.50426ms
Aug 27 09:44:34.470: INFO: Pod "pod-projected-secrets-7052174a-7c42-49d8-b957-badd34f6b97e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014213403s
STEP: Saw pod success
Aug 27 09:44:34.470: INFO: Pod "pod-projected-secrets-7052174a-7c42-49d8-b957-badd34f6b97e" satisfied condition "Succeeded or Failed"
Aug 27 09:44:34.473: INFO: Trying to get logs from node ip-10-0-2-216 pod pod-projected-secrets-7052174a-7c42-49d8-b957-badd34f6b97e container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 27 09:44:34.489: INFO: Waiting for pod pod-projected-secrets-7052174a-7c42-49d8-b957-badd34f6b97e to disappear
Aug 27 09:44:34.502: INFO: Pod pod-projected-secrets-7052174a-7c42-49d8-b957-badd34f6b97e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:44:34.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9217" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":282,"skipped":4488,"failed":0}
SSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:44:34.516: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9753, will wait for the garbage collector to delete the pods
Aug 27 09:44:38.627: INFO: Deleting Job.batch foo took: 4.87083ms
Aug 27 09:44:38.728: INFO: Terminating Job.batch foo pods took: 100.559311ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:45:23.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9753" for this suite.

• [SLOW TEST:48.829 seconds]
[sig-apps] Job
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":303,"completed":283,"skipped":4491,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Ingress API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:45:23.352: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug 27 09:45:23.419: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Aug 27 09:45:23.422: INFO: starting watch
STEP: patching
STEP: updating
Aug 27 09:45:23.433: INFO: waiting for watch events with expected annotations
Aug 27 09:45:23.433: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:45:23.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-9013" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":303,"completed":284,"skipped":4521,"failed":0}

------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:45:23.474: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:45:23.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-6088" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":303,"completed":285,"skipped":4521,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:45:23.548: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating the pod
Aug 27 09:45:26.130: INFO: Successfully updated pod "annotationupdatec11de5cc-6f2b-4dce-9ce2-502cdf2f8b91"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:45:28.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9119" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":303,"completed":286,"skipped":4528,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:45:28.163: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:47:28.224: INFO: Deleting pod "var-expansion-738da685-8c05-4720-976d-30b1832468c5" in namespace "var-expansion-5440"
Aug 27 09:47:28.229: INFO: Wait up to 5m0s for pod "var-expansion-738da685-8c05-4720-976d-30b1832468c5" to be fully deleted
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:47:32.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5440" for this suite.

• [SLOW TEST:124.079 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should fail substituting values in a volume subpath with backticks [sig-storage][Slow] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should fail substituting values in a volume subpath with backticks [sig-storage][Slow] [Conformance]","total":303,"completed":287,"skipped":4535,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:47:32.244: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[BeforeEach] Kubectl replace
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 27 09:47:32.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-8347'
Aug 27 09:47:32.731: INFO: stderr: ""
Aug 27 09:47:32.731: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Aug 27 09:47:37.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pod e2e-test-httpd-pod --namespace=kubectl-8347 -o json'
Aug 27 09:47:37.879: INFO: stderr: ""
Aug 27 09:47:37.879: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.173.228/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.2.173.228/32\"\n        },\n        \"creationTimestamp\": \"2020-08-27T09:47:32Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl-run\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-08-27T09:47:32Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \".\": {},\n                            \"f:cni.projectcalico.org/podIP\": {},\n                            \"f:cni.projectcalico.org/podIPs\": {}\n                        }\n                    }\n                },\n                \"manager\": \"calico\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-08-27T09:47:33Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"10.2.173.228\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-08-27T09:47:34Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8347\",\n        \"resourceVersion\": \"34719\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8347/pods/e2e-test-httpd-pod\",\n        \"uid\": \"3aeb1697-00d6-4c21-be03-237d44f9a1f0\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-47q66\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-2-216\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-47q66\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-47q66\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-27T09:47:32Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-27T09:47:34Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-27T09:47:34Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-27T09:47:32Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://2036aaadb1ec1a009b461b75ad5d12f825d144d3fa2ad8a52040f7bb513087b0\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-08-27T09:47:33Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.2.216\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.173.228\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.2.173.228\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-08-27T09:47:32Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 27 09:47:37.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 replace -f - --namespace=kubectl-8347'
Aug 27 09:47:38.160: INFO: stderr: ""
Aug 27 09:47:38.160: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1586
Aug 27 09:47:38.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete pods e2e-test-httpd-pod --namespace=kubectl-8347'
Aug 27 09:47:39.553: INFO: stderr: ""
Aug 27 09:47:39.553: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:47:39.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8347" for this suite.

• [SLOW TEST:7.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1577
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":303,"completed":288,"skipped":4567,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:47:39.571: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating pod test-webserver-9b5b60ba-5110-4b29-898e-9131f25ae7a0 in namespace container-probe-8693
Aug 27 09:47:41.618: INFO: Started pod test-webserver-9b5b60ba-5110-4b29-898e-9131f25ae7a0 in namespace container-probe-8693
STEP: checking the pod's current state and verifying that restartCount is present
Aug 27 09:47:41.621: INFO: Initial restart count of pod test-webserver-9b5b60ba-5110-4b29-898e-9131f25ae7a0 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:51:42.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8693" for this suite.

• [SLOW TEST:242.849 seconds]
[k8s.io] Probing container
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":303,"completed":289,"skipped":4644,"failed":0}
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:51:42.423: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Performing setup for networking test in namespace pod-network-test-6772
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 27 09:51:42.484: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 27 09:51:42.593: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 09:51:44.596: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 09:51:46.598: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:51:48.597: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:51:50.597: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:51:52.597: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:51:54.598: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:51:56.598: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:51:58.597: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:52:00.598: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:52:02.597: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 27 09:52:04.598: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug 27 09:52:04.603: INFO: The status of Pod netserver-1 is Running (Ready = true)
Aug 27 09:52:04.607: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Aug 27 09:52:06.649: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.173.230 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6772 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 09:52:06.651: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 09:52:07.764: INFO: Found all expected endpoints: [netserver-0]
Aug 27 09:52:07.767: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.148.78 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6772 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 09:52:07.767: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 09:52:08.949: INFO: Found all expected endpoints: [netserver-1]
Aug 27 09:52:08.957: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.193.137 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6772 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 27 09:52:08.957: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
Aug 27 09:52:10.264: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:52:10.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6772" for this suite.

• [SLOW TEST:27.849 seconds]
[sig-network] Networking
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":290,"skipped":4645,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:52:10.275: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Aug 27 09:52:11.137: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Aug 27 09:52:13.164: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118731, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118731, loc:(*time.Location)(0x7702840)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118731, loc:(*time.Location)(0x7702840)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63734118731, loc:(*time.Location)(0x7702840)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-85d57b96d6\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 27 09:52:16.182: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:52:16.188: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:52:18.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2002" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.954 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":303,"completed":291,"skipped":4647,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:52:18.234: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test downward api env vars
Aug 27 09:52:18.282: INFO: Waiting up to 5m0s for pod "downward-api-5dfc5d21-b719-4478-9359-586b15b810ce" in namespace "downward-api-8236" to be "Succeeded or Failed"
Aug 27 09:52:18.286: INFO: Pod "downward-api-5dfc5d21-b719-4478-9359-586b15b810ce": Phase="Pending", Reason="", readiness=false. Elapsed: 3.2692ms
Aug 27 09:52:20.289: INFO: Pod "downward-api-5dfc5d21-b719-4478-9359-586b15b810ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006440509s
STEP: Saw pod success
Aug 27 09:52:20.289: INFO: Pod "downward-api-5dfc5d21-b719-4478-9359-586b15b810ce" satisfied condition "Succeeded or Failed"
Aug 27 09:52:20.292: INFO: Trying to get logs from node ip-10-0-45-43 pod downward-api-5dfc5d21-b719-4478-9359-586b15b810ce container dapi-container: <nil>
STEP: delete the pod
Aug 27 09:52:20.320: INFO: Waiting for pod downward-api-5dfc5d21-b719-4478-9359-586b15b810ce to disappear
Aug 27 09:52:20.323: INFO: Pod downward-api-5dfc5d21-b719-4478-9359-586b15b810ce no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:52:20.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8236" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":303,"completed":292,"skipped":4741,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:52:20.330: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:52:26.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8838" for this suite.
STEP: Destroying namespace "nsdeletetest-6215" for this suite.
Aug 27 09:52:26.478: INFO: Namespace nsdeletetest-6215 was already deleted
STEP: Destroying namespace "nsdeletetest-9819" for this suite.

• [SLOW TEST:6.153 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":303,"completed":293,"skipped":4748,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:52:26.491: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
Aug 27 09:52:26.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-8971'
Aug 27 09:52:26.872: INFO: stderr: ""
Aug 27 09:52:26.872: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Aug 27 09:52:26.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-8971'
Aug 27 09:52:27.111: INFO: stderr: ""
Aug 27 09:52:27.111: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug 27 09:52:28.115: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 09:52:28.115: INFO: Found 0 / 1
Aug 27 09:52:29.115: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 09:52:29.115: INFO: Found 1 / 1
Aug 27 09:52:29.115: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 27 09:52:29.118: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 09:52:29.118: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 09:52:29.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 describe pod agnhost-primary-kmccg --namespace=kubectl-8971'
Aug 27 09:52:29.245: INFO: stderr: ""
Aug 27 09:52:29.245: INFO: stdout: "Name:         agnhost-primary-kmccg\nNamespace:    kubectl-8971\nPriority:     0\nNode:         ip-10-0-2-216/10.0.2.216\nStart Time:   Thu, 27 Aug 2020 09:52:26 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  cni.projectcalico.org/podIP: 10.2.173.233/32\n              cni.projectcalico.org/podIPs: 10.2.173.233/32\nStatus:       Running\nIP:           10.2.173.233\nIPs:\n  IP:           10.2.173.233\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://a3844a5b100d4ab436a3cd4cb5268ce80686abf4fab0d933095b7b5257c301f7\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.20\n    Image ID:       docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 27 Aug 2020 09:52:28 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rtl89 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-rtl89:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-rtl89\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  3s    default-scheduler       Successfully assigned kubectl-8971/agnhost-primary-kmccg to ip-10-0-2-216\n  Normal  Pulled     2s    kubelet, ip-10-0-2-216  Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-0-2-216  Created container agnhost-primary\n  Normal  Started    1s    kubelet, ip-10-0-2-216  Started container agnhost-primary\n"
Aug 27 09:52:29.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 describe rc agnhost-primary --namespace=kubectl-8971'
Aug 27 09:52:29.472: INFO: stderr: ""
Aug 27 09:52:29.472: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8971\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.20\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-kmccg\n"
Aug 27 09:52:29.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 describe service agnhost-primary --namespace=kubectl-8971'
Aug 27 09:52:29.649: INFO: stderr: ""
Aug 27 09:52:29.649: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8971\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP:                10.3.115.42\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.2.173.233:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 27 09:52:29.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 describe node ip-10-0-2-216'
Aug 27 09:52:29.758: INFO: stderr: ""
Aug 27 09:52:29.758: INFO: stdout: "Name:               ip-10-0-2-216\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-2-216\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/node=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.2.216/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.2.173.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 27 Aug 2020 08:08:57 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-10-0-2-216\n  AcquireTime:     <unset>\n  RenewTime:       Thu, 27 Aug 2020 09:52:21 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 27 Aug 2020 08:09:22 +0000   Thu, 27 Aug 2020 08:09:22 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Thu, 27 Aug 2020 09:51:57 +0000   Thu, 27 Aug 2020 08:08:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 27 Aug 2020 09:51:57 +0000   Thu, 27 Aug 2020 08:08:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 27 Aug 2020 09:51:57 +0000   Thu, 27 Aug 2020 08:08:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 27 Aug 2020 09:51:57 +0000   Thu, 27 Aug 2020 08:09:28 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.2.216\n  Hostname:    ip-10-0-2-216\nCapacity:\n  cpu:                  1\n  ephemeral-storage:    30921708Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               1988880Ki\n  pods:                 110\nAllocatable:\n  cpu:                  1\n  ephemeral-storage:    28497446046\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               1886480Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                 a8eb6cac33e701ae867269db5ce80e7f\n  System UUID:                ec25892c-6a5b-be92-b2a5-9e0a99b50c83\n  Boot ID:                    096a1c87-e1cd-4908-9164-078af42d3c24\n  Kernel Version:             5.7.12-200.fc32.x86_64\n  OS Image:                   Fedora CoreOS 32.20200809.3.0\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://19.3.11\n  Kubelet Version:            v1.19.0\n  Kube-Proxy Version:         v1.19.0\nPodCIDR:                      10.2.2.0/24\nPodCIDRs:                     10.2.2.0/24\nNon-terminated Pods:          (5 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-87ksr                                          100m (10%)    0 (0%)      0 (0%)           0 (0%)         103m\n  kube-system                 coredns-69c75f5c45-9jz8t                                   100m (10%)    0 (0%)      70Mi (3%)        170Mi (9%)     104m\n  kube-system                 kube-proxy-zlwf6                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         103m\n  kubectl-8971                agnhost-primary-kmccg                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-d85445ee63174525-mjhxq    0 (0%)        0 (0%)      0 (0%)           0 (0%)         102m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests    Limits\n  --------             --------    ------\n  cpu                  200m (20%)  0 (0%)\n  memory               70Mi (3%)   170Mi (9%)\n  ephemeral-storage    0 (0%)      0 (0%)\n  hugepages-1Gi        0 (0%)      0 (0%)\n  hugepages-2Mi        0 (0%)      0 (0%)\n  example.com/fakecpu  0           0\nEvents:                <none>\n"
Aug 27 09:52:29.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 describe namespace kubectl-8971'
Aug 27 09:52:29.849: INFO: stderr: ""
Aug 27 09:52:29.849: INFO: stdout: "Name:         kubectl-8971\nLabels:       e2e-framework=kubectl\n              e2e-run=bdc88c35-17bb-41ca-958b-48ca3c0772e5\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:52:29.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8971" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":303,"completed":294,"skipped":4790,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:52:29.855: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 27 09:52:29.896: INFO: Waiting up to 5m0s for pod "pod-0a562b29-00d3-46dc-a3cd-0ee0c53a00f9" in namespace "emptydir-2672" to be "Succeeded or Failed"
Aug 27 09:52:29.898: INFO: Pod "pod-0a562b29-00d3-46dc-a3cd-0ee0c53a00f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.602266ms
Aug 27 09:52:31.901: INFO: Pod "pod-0a562b29-00d3-46dc-a3cd-0ee0c53a00f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005467297s
Aug 27 09:52:33.905: INFO: Pod "pod-0a562b29-00d3-46dc-a3cd-0ee0c53a00f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009058225s
STEP: Saw pod success
Aug 27 09:52:33.905: INFO: Pod "pod-0a562b29-00d3-46dc-a3cd-0ee0c53a00f9" satisfied condition "Succeeded or Failed"
Aug 27 09:52:33.908: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-0a562b29-00d3-46dc-a3cd-0ee0c53a00f9 container test-container: <nil>
STEP: delete the pod
Aug 27 09:52:33.950: INFO: Waiting for pod pod-0a562b29-00d3-46dc-a3cd-0ee0c53a00f9 to disappear
Aug 27 09:52:33.956: INFO: Pod pod-0a562b29-00d3-46dc-a3cd-0ee0c53a00f9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:52:33.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2672" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":295,"skipped":4809,"failed":0}
SS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:52:33.971: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating projection with secret that has name secret-emptykey-test-21cc9d08-d4ce-41b1-9afd-906356aaea9b
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:52:34.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4069" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":303,"completed":296,"skipped":4811,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:52:34.067: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:181
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 27 09:52:38.679: INFO: Successfully updated pod "pod-update-activedeadlineseconds-7d3e0cef-7290-4611-9038-6741756e2f09"
Aug 27 09:52:38.679: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-7d3e0cef-7290-4611-9038-6741756e2f09" in namespace "pods-9998" to be "terminated due to deadline exceeded"
Aug 27 09:52:38.683: INFO: Pod "pod-update-activedeadlineseconds-7d3e0cef-7290-4611-9038-6741756e2f09": Phase="Running", Reason="", readiness=true. Elapsed: 3.984963ms
Aug 27 09:52:40.702: INFO: Pod "pod-update-activedeadlineseconds-7d3e0cef-7290-4611-9038-6741756e2f09": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.023031023s
Aug 27 09:52:40.702: INFO: Pod "pod-update-activedeadlineseconds-7d3e0cef-7290-4611-9038-6741756e2f09" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:52:40.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9998" for this suite.

• [SLOW TEST:6.642 seconds]
[k8s.io] Pods
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":303,"completed":297,"skipped":4817,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:52:40.711: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:256
[BeforeEach] Update Demo
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:308
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: creating a replication controller
Aug 27 09:52:40.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 create -f - --namespace=kubectl-2009'
Aug 27 09:52:41.022: INFO: stderr: ""
Aug 27 09:52:41.022: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 09:52:41.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2009'
Aug 27 09:52:41.212: INFO: stderr: ""
Aug 27 09:52:41.212: INFO: stdout: "update-demo-nautilus-2ftz4 update-demo-nautilus-4rdbn "
Aug 27 09:52:41.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:41.359: INFO: stderr: ""
Aug 27 09:52:41.359: INFO: stdout: ""
Aug 27 09:52:41.359: INFO: update-demo-nautilus-2ftz4 is created but not running
Aug 27 09:52:46.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2009'
Aug 27 09:52:46.464: INFO: stderr: ""
Aug 27 09:52:46.465: INFO: stdout: "update-demo-nautilus-2ftz4 update-demo-nautilus-4rdbn "
Aug 27 09:52:46.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:46.556: INFO: stderr: ""
Aug 27 09:52:46.556: INFO: stdout: "true"
Aug 27 09:52:46.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:46.647: INFO: stderr: ""
Aug 27 09:52:46.647: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 09:52:46.647: INFO: validating pod update-demo-nautilus-2ftz4
Aug 27 09:52:46.653: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 09:52:46.653: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 09:52:46.653: INFO: update-demo-nautilus-2ftz4 is verified up and running
Aug 27 09:52:46.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-4rdbn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:46.751: INFO: stderr: ""
Aug 27 09:52:46.751: INFO: stdout: "true"
Aug 27 09:52:46.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-4rdbn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:46.840: INFO: stderr: ""
Aug 27 09:52:46.840: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 09:52:46.840: INFO: validating pod update-demo-nautilus-4rdbn
Aug 27 09:52:46.850: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 09:52:46.850: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 09:52:46.850: INFO: update-demo-nautilus-4rdbn is verified up and running
STEP: scaling down the replication controller
Aug 27 09:52:46.852: INFO: scanned /root for discovery docs: <nil>
Aug 27 09:52:46.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2009'
Aug 27 09:52:47.969: INFO: stderr: ""
Aug 27 09:52:47.969: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 09:52:47.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2009'
Aug 27 09:52:48.058: INFO: stderr: ""
Aug 27 09:52:48.058: INFO: stdout: "update-demo-nautilus-2ftz4 update-demo-nautilus-4rdbn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 27 09:52:53.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2009'
Aug 27 09:52:53.155: INFO: stderr: ""
Aug 27 09:52:53.155: INFO: stdout: "update-demo-nautilus-2ftz4 "
Aug 27 09:52:53.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:53.252: INFO: stderr: ""
Aug 27 09:52:53.253: INFO: stdout: "true"
Aug 27 09:52:53.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:53.372: INFO: stderr: ""
Aug 27 09:52:53.372: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 09:52:53.372: INFO: validating pod update-demo-nautilus-2ftz4
Aug 27 09:52:53.376: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 09:52:53.376: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 09:52:53.376: INFO: update-demo-nautilus-2ftz4 is verified up and running
STEP: scaling up the replication controller
Aug 27 09:52:53.379: INFO: scanned /root for discovery docs: <nil>
Aug 27 09:52:53.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2009'
Aug 27 09:52:54.504: INFO: stderr: ""
Aug 27 09:52:54.504: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 27 09:52:54.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2009'
Aug 27 09:52:54.590: INFO: stderr: ""
Aug 27 09:52:54.590: INFO: stdout: "update-demo-nautilus-2ftz4 update-demo-nautilus-c7xq8 "
Aug 27 09:52:54.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:54.670: INFO: stderr: ""
Aug 27 09:52:54.670: INFO: stdout: "true"
Aug 27 09:52:54.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:54.757: INFO: stderr: ""
Aug 27 09:52:54.757: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 09:52:54.757: INFO: validating pod update-demo-nautilus-2ftz4
Aug 27 09:52:54.762: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 09:52:54.762: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 09:52:54.762: INFO: update-demo-nautilus-2ftz4 is verified up and running
Aug 27 09:52:54.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-c7xq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:52:54.843: INFO: stderr: ""
Aug 27 09:52:54.843: INFO: stdout: ""
Aug 27 09:52:54.843: INFO: update-demo-nautilus-c7xq8 is created but not running
Aug 27 09:52:59.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2009'
Aug 27 09:52:59.940: INFO: stderr: ""
Aug 27 09:52:59.940: INFO: stdout: "update-demo-nautilus-2ftz4 update-demo-nautilus-c7xq8 "
Aug 27 09:52:59.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:53:00.091: INFO: stderr: ""
Aug 27 09:53:00.091: INFO: stdout: "true"
Aug 27 09:53:00.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-2ftz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:53:00.220: INFO: stderr: ""
Aug 27 09:53:00.220: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 09:53:00.220: INFO: validating pod update-demo-nautilus-2ftz4
Aug 27 09:53:00.248: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 09:53:00.249: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 09:53:00.249: INFO: update-demo-nautilus-2ftz4 is verified up and running
Aug 27 09:53:00.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-c7xq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:53:00.443: INFO: stderr: ""
Aug 27 09:53:00.443: INFO: stdout: "true"
Aug 27 09:53:00.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods update-demo-nautilus-c7xq8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2009'
Aug 27 09:53:00.559: INFO: stderr: ""
Aug 27 09:53:00.559: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 27 09:53:00.559: INFO: validating pod update-demo-nautilus-c7xq8
Aug 27 09:53:00.578: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 09:53:00.578: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 09:53:00.578: INFO: update-demo-nautilus-c7xq8 is verified up and running
STEP: using delete to clean up resources
Aug 27 09:53:00.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 delete --grace-period=0 --force -f - --namespace=kubectl-2009'
Aug 27 09:53:00.810: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 09:53:00.810: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 27 09:53:00.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2009'
Aug 27 09:53:00.898: INFO: stderr: "No resources found in kubectl-2009 namespace.\n"
Aug 27 09:53:00.898: INFO: stdout: ""
Aug 27 09:53:00.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -l name=update-demo --namespace=kubectl-2009 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 09:53:00.985: INFO: stderr: ""
Aug 27 09:53:00.985: INFO: stdout: "update-demo-nautilus-2ftz4\nupdate-demo-nautilus-c7xq8\n"
Aug 27 09:53:01.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2009'
Aug 27 09:53:01.576: INFO: stderr: "No resources found in kubectl-2009 namespace.\n"
Aug 27 09:53:01.576: INFO: stdout: ""
Aug 27 09:53:01.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356341267 get pods -l name=update-demo --namespace=kubectl-2009 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 09:53:01.663: INFO: stderr: ""
Aug 27 09:53:01.663: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:53:01.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2009" for this suite.

• [SLOW TEST:20.961 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:306
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":303,"completed":298,"skipped":4826,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:53:01.672: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 27 09:53:05.782: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 09:53:05.789: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 09:53:07.789: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 09:53:07.793: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 09:53:09.789: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 09:53:09.794: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 09:53:11.789: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 09:53:11.793: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 09:53:13.789: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 09:53:13.793: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 09:53:15.790: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 09:53:15.795: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:53:15.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6715" for this suite.

• [SLOW TEST:14.131 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:592
  when create a pod with lifecycle hook
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":303,"completed":299,"skipped":4834,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-node] PodTemplates
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:53:15.826: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[AfterEach] [sig-node] PodTemplates
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:53:15.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2593" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":303,"completed":300,"skipped":4846,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:53:15.923: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3941.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3941.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3941.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3941.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 27 09:53:20.041: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local from pod dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea: the server could not find the requested resource (get pods dns-test-7da72d33-33b3-4b63-946f-c136e2532dea)
Aug 27 09:53:20.055: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local from pod dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea: the server could not find the requested resource (get pods dns-test-7da72d33-33b3-4b63-946f-c136e2532dea)
Aug 27 09:53:20.071: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3941.svc.cluster.local from pod dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea: the server could not find the requested resource (get pods dns-test-7da72d33-33b3-4b63-946f-c136e2532dea)
Aug 27 09:53:20.091: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3941.svc.cluster.local from pod dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea: the server could not find the requested resource (get pods dns-test-7da72d33-33b3-4b63-946f-c136e2532dea)
Aug 27 09:53:20.112: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local from pod dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea: the server could not find the requested resource (get pods dns-test-7da72d33-33b3-4b63-946f-c136e2532dea)
Aug 27 09:53:20.120: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local from pod dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea: the server could not find the requested resource (get pods dns-test-7da72d33-33b3-4b63-946f-c136e2532dea)
Aug 27 09:53:20.128: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3941.svc.cluster.local from pod dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea: the server could not find the requested resource (get pods dns-test-7da72d33-33b3-4b63-946f-c136e2532dea)
Aug 27 09:53:20.132: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3941.svc.cluster.local from pod dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea: the server could not find the requested resource (get pods dns-test-7da72d33-33b3-4b63-946f-c136e2532dea)
Aug 27 09:53:20.142: INFO: Lookups using dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3941.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3941.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3941.svc.cluster.local jessie_udp@dns-test-service-2.dns-3941.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3941.svc.cluster.local]

Aug 27 09:53:25.195: INFO: DNS probes using dns-3941/dns-test-7da72d33-33b3-4b63-946f-c136e2532dea succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:53:25.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3941" for this suite.

• [SLOW TEST:9.626 seconds]
[sig-network] DNS
/workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":303,"completed":301,"skipped":4851,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:53:25.548: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 27 09:53:25.725: INFO: Waiting up to 5m0s for pod "pod-a035f3fe-859f-465e-886a-a2eb5f90d88c" in namespace "emptydir-2315" to be "Succeeded or Failed"
Aug 27 09:53:25.734: INFO: Pod "pod-a035f3fe-859f-465e-886a-a2eb5f90d88c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.466124ms
Aug 27 09:53:27.738: INFO: Pod "pod-a035f3fe-859f-465e-886a-a2eb5f90d88c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011729507s
STEP: Saw pod success
Aug 27 09:53:27.738: INFO: Pod "pod-a035f3fe-859f-465e-886a-a2eb5f90d88c" satisfied condition "Succeeded or Failed"
Aug 27 09:53:27.740: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-a035f3fe-859f-465e-886a-a2eb5f90d88c container test-container: <nil>
STEP: delete the pod
Aug 27 09:53:27.758: INFO: Waiting for pod pod-a035f3fe-859f-465e-886a-a2eb5f90d88c to disappear
Aug 27 09:53:27.764: INFO: Pod pod-a035f3fe-859f-465e-886a-a2eb5f90d88c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:53:27.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2315" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":302,"skipped":4858,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174
STEP: Creating a kubernetes client
Aug 27 09:53:27.773: INFO: >>> kubeConfig: /tmp/kubeconfig-356341267
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
STEP: Creating configMap with name configmap-test-volume-be337e42-97d3-4735-8db5-cddebc3f7b62
STEP: Creating a pod to test consume configMaps
Aug 27 09:53:27.830: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ea8ae24-d4bb-48dd-95ea-5db2bba21e19" in namespace "configmap-5741" to be "Succeeded or Failed"
Aug 27 09:53:27.834: INFO: Pod "pod-configmaps-2ea8ae24-d4bb-48dd-95ea-5db2bba21e19": Phase="Pending", Reason="", readiness=false. Elapsed: 3.449368ms
Aug 27 09:53:29.837: INFO: Pod "pod-configmaps-2ea8ae24-d4bb-48dd-95ea-5db2bba21e19": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006797453s
STEP: Saw pod success
Aug 27 09:53:29.838: INFO: Pod "pod-configmaps-2ea8ae24-d4bb-48dd-95ea-5db2bba21e19" satisfied condition "Succeeded or Failed"
Aug 27 09:53:29.840: INFO: Trying to get logs from node ip-10-0-45-43 pod pod-configmaps-2ea8ae24-d4bb-48dd-95ea-5db2bba21e19 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 27 09:53:29.856: INFO: Waiting for pod pod-configmaps-2ea8ae24-d4bb-48dd-95ea-5db2bba21e19 to disappear
Aug 27 09:53:29.860: INFO: Pod pod-configmaps-2ea8ae24-d4bb-48dd-95ea-5db2bba21e19 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.19.0-rc.4.197+594f888e19d8da/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175
Aug 27 09:53:29.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5741" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":303,"completed":303,"skipped":4929,"failed":0}
Aug 27 09:53:29.876: INFO: Running AfterSuite actions on all nodes
Aug 27 09:53:29.877: INFO: Running AfterSuite actions on node 1
Aug 27 09:53:29.877: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":303,"completed":303,"skipped":4929,"failed":0}

Ran 303 of 5232 Specs in 6171.249 seconds
SUCCESS! -- 303 Passed | 0 Failed | 0 Pending | 4929 Skipped
PASS

Ginkgo ran 1 suite in 1h42m54.35223773s
Test Suite Passed
